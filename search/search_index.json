{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Saltbox \u00b6 Created with the help of \u00b6 Ansible Docker Bash Python What is it? \u00b6 You can read more about what Saltbox is here . How do I install it? \u00b6 Installation instructions are located here . Can I migrate from Cloudbox or PlexGuide? \u00b6 There are notes on migration from Cloudbox and Plexguide . How does Saltbox differ from Cloudbox? \u00b6 See here . Is there a Discord server for support? \u00b6 Why, yes there is . What if I see a mistake in or have a suggestion about the docs? \u00b6 Please report any mistakes or suggestions for improving the documentation on our discord or on the docs repository , would be much appreciated. Docs: Issues Saltbox: Issues Sandbox: Issues","title":"Home"},{"location":"#welcome-to-saltbox","text":"","title":"Welcome to Saltbox"},{"location":"#created-with-the-help-of","text":"Ansible Docker Bash Python","title":"Created with the help of"},{"location":"#what-is-it","text":"You can read more about what Saltbox is here .","title":"What is it?"},{"location":"#how-do-i-install-it","text":"Installation instructions are located here .","title":"How do I install it?"},{"location":"#can-i-migrate-from-cloudbox-or-plexguide","text":"There are notes on migration from Cloudbox and Plexguide .","title":"Can I migrate from Cloudbox or PlexGuide?"},{"location":"#how-does-saltbox-differ-from-cloudbox","text":"See here .","title":"How does Saltbox differ from Cloudbox?"},{"location":"#is-there-a-discord-server-for-support","text":"Why, yes there is .","title":"Is there a Discord server for support?"},{"location":"#what-if-i-see-a-mistake-in-or-have-a-suggestion-about-the-docs","text":"Please report any mistakes or suggestions for improving the documentation on our discord or on the docs repository , would be much appreciated. Docs: Issues Saltbox: Issues Sandbox: Issues","title":"What if I see a mistake in or have a suggestion about the docs?"},{"location":"advanced/","text":"In this section you will find various guides for advanced use cases \u00b6","title":"Index"},{"location":"advanced/#in-this-section-you-will-find-various-guides-for-advanced-use-cases","text":"","title":"In this section you will find various guides for advanced use cases"},{"location":"advanced/feeder/","text":"Intro \u00b6 For setups with separate Feeder and Media boxes, you will have newly downloaded media that will not be instantly available on cloud storage (e.g. Google Drive) and, therefore, inaccessible to Mediabox (e.g. Plex) when Sonarr/Radarr sends a media scan request. To remedy this issue, you can use Saltbox's Feeder Mounter to mount your Feederbox's /mnt/local path, onto your Mediabox's /mnt/feeder location, so that you are able to play those newly downloaded media files even if they haven't been uploaded to the cloud. Note: Running the below commands will replace your unionfs.service or mergerfs.service file. If you have any custom paths in there (e.g. /mnt/rclone ), make sure you back that up and add them back in once you mount/dismount the Feederbox. Mount \u00b6 The following steps will be done on the Mediabox. In rclone config, create an sftp remote to your Feederbox called feeder ( asciicast ). Note: If you don't already have one, add the feederbox [[subdomain|Adding a Subdomain]] and point it to your Feederbox's IP address. If you are using Cloudflare, make sure CDN/Proxy is not enabled for this subdomain. Edit the mounts section of adv_settings.yml and set feeder to \"yes\": mounts: remote: rclone_vfs feeder: yes Run the following command: sb install mounts Your docker containers will restart and media on Feederbox will be available to them. Note: You do not need to do anything to your apps (eg no need to edit Plex library paths etc).","title":"Feeder Mount"},{"location":"advanced/feeder/#intro","text":"For setups with separate Feeder and Media boxes, you will have newly downloaded media that will not be instantly available on cloud storage (e.g. Google Drive) and, therefore, inaccessible to Mediabox (e.g. Plex) when Sonarr/Radarr sends a media scan request. To remedy this issue, you can use Saltbox's Feeder Mounter to mount your Feederbox's /mnt/local path, onto your Mediabox's /mnt/feeder location, so that you are able to play those newly downloaded media files even if they haven't been uploaded to the cloud. Note: Running the below commands will replace your unionfs.service or mergerfs.service file. If you have any custom paths in there (e.g. /mnt/rclone ), make sure you back that up and add them back in once you mount/dismount the Feederbox.","title":"Intro"},{"location":"advanced/feeder/#mount","text":"The following steps will be done on the Mediabox. In rclone config, create an sftp remote to your Feederbox called feeder ( asciicast ). Note: If you don't already have one, add the feederbox [[subdomain|Adding a Subdomain]] and point it to your Feederbox's IP address. If you are using Cloudflare, make sure CDN/Proxy is not enabled for this subdomain. Edit the mounts section of adv_settings.yml and set feeder to \"yes\": mounts: remote: rclone_vfs feeder: yes Run the following command: sb install mounts Your docker containers will restart and media on Feederbox will be available to them. Note: You do not need to do anything to your apps (eg no need to edit Plex library paths etc).","title":"Mount"},{"location":"advanced/healthchecks/","text":"Container Healthchecks \u00b6 Saltbox can set a custom healthcheck on a Docker container via the inventory system. The syntax for this <rolename>_docker_healthcheck : test : [ \"healthcheck\" , \"in\" , \"command\" , \"notation\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s Below are some samples for various available roles: postgres_docker_healthcheck : test : [ \"CMD-SHELL\" , \"pg_isready\" , \"-d\" , \"{{ postgres_docker_env_db }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s aria2_ng_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:8080\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s docspell_docker_healthcheck : test : [ \"CMD\" , \"wget\" , \"--spider\" , \"http://localhost:{{ docspell_web_port }}/api/info/version\" ] interval : 1m timeout : 10s retries : 2 start_period : 30s duplicati_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ duplicati_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s elasticsearch_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:9200\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s gaps_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:8484\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s heimdall_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:80\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s homeassistant_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ homeassistant_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s koel_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s lunasea_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s omegabrr_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ omegabrr_web_port }}/api/webhook/trigger\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s phpmyadmin_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ phpmyadmin_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s plexshare_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ plexshare_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s reposilite_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ reposilite_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s rflood_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:3000\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s solr_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://localhost:{{ solr_docker_env_port }}/solr/{{ solr_docker_env_core_name }}/admin/ping\" ] interval : 1m timeout : 10s retries : 5 start_period : 30s tubearchivist_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ tubearchivist_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s tvheadend_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ tvheadend_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s wikijs_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:3000\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s","title":"Container Healthchecks"},{"location":"advanced/healthchecks/#container-healthchecks","text":"Saltbox can set a custom healthcheck on a Docker container via the inventory system. The syntax for this <rolename>_docker_healthcheck : test : [ \"healthcheck\" , \"in\" , \"command\" , \"notation\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s Below are some samples for various available roles: postgres_docker_healthcheck : test : [ \"CMD-SHELL\" , \"pg_isready\" , \"-d\" , \"{{ postgres_docker_env_db }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s aria2_ng_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:8080\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s docspell_docker_healthcheck : test : [ \"CMD\" , \"wget\" , \"--spider\" , \"http://localhost:{{ docspell_web_port }}/api/info/version\" ] interval : 1m timeout : 10s retries : 2 start_period : 30s duplicati_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ duplicati_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s elasticsearch_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:9200\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s gaps_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:8484\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s heimdall_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:80\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s homeassistant_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ homeassistant_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s koel_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s lunasea_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s omegabrr_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ omegabrr_web_port }}/api/webhook/trigger\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s phpmyadmin_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ phpmyadmin_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s plexshare_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ plexshare_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s reposilite_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ reposilite_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s rflood_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:3000\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s solr_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"-f\" , \"http://localhost:{{ solr_docker_env_port }}/solr/{{ solr_docker_env_core_name }}/admin/ping\" ] interval : 1m timeout : 10s retries : 5 start_period : 30s tubearchivist_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ tubearchivist_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s tvheadend_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:{{ tvheadend_web_port }}\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s wikijs_docker_healthcheck : test : [ \"CMD\" , \"curl\" , \"--fail\" , \"http://localhost:3000\" ] interval : 10s timeout : 5s retries : 10 start_period : 10s","title":"Container Healthchecks"},{"location":"advanced/styled-error-pages/","text":"Styled Error Pages \u00b6 What is this? \u00b6 If this flag is set in the adv_settings.yml : error_pages : yes Common error pages can be displayed with some consistent styling, based on this system . What themes are available? \u00b6 There are initially seven \"themes\" available, which are stored in /opt/error_pages : cats ghost hacker-terminal l7-dark l7-light noise shuffle Samples of the themed pages can be viewed here How do I change the theme? \u00b6 The default theme is l7-dark . Changing the theme can be done via the inventory : error_pages_template : \"hacker-terminal\" How do I enable the error pages? \u00b6 Enable error pages per role by adding the following to the inventory as desired: rolename_traefik_error_pages_enabled : true rolename is, of course, the name of the role, as: sonarr_traefik_error_pages_enabled : true These error pages do not work with every app; do your own a/b testing to verify that nothing unexpected results. You can find the roles [across saltbox and sandbox] that are known to NOT work with: grep -Ril \"_traefik_error_pages_enabled: false\" /srv/git/saltbox/roles /opt/sandbox | cut -d/ -f6 | sort -u Can I create a theme? \u00b6 Duplicate one of the directories in /opt/error_pages and make your changes.","title":"Styled Error Pages"},{"location":"advanced/styled-error-pages/#styled-error-pages","text":"","title":"Styled Error Pages"},{"location":"advanced/styled-error-pages/#what-is-this","text":"If this flag is set in the adv_settings.yml : error_pages : yes Common error pages can be displayed with some consistent styling, based on this system .","title":"What is this?"},{"location":"advanced/styled-error-pages/#what-themes-are-available","text":"There are initially seven \"themes\" available, which are stored in /opt/error_pages : cats ghost hacker-terminal l7-dark l7-light noise shuffle Samples of the themed pages can be viewed here","title":"What themes are available?"},{"location":"advanced/styled-error-pages/#how-do-i-change-the-theme","text":"The default theme is l7-dark . Changing the theme can be done via the inventory : error_pages_template : \"hacker-terminal\"","title":"How do I change the theme?"},{"location":"advanced/styled-error-pages/#how-do-i-enable-the-error-pages","text":"Enable error pages per role by adding the following to the inventory as desired: rolename_traefik_error_pages_enabled : true rolename is, of course, the name of the role, as: sonarr_traefik_error_pages_enabled : true These error pages do not work with every app; do your own a/b testing to verify that nothing unexpected results. You can find the roles [across saltbox and sandbox] that are known to NOT work with: grep -Ril \"_traefik_error_pages_enabled: false\" /srv/git/saltbox/roles /opt/sandbox | cut -d/ -f6 | sort -u","title":"How do I enable the error pages?"},{"location":"advanced/styled-error-pages/#can-i-create-a-theme","text":"Duplicate one of the directories in /opt/error_pages and make your changes.","title":"Can I create a theme?"},{"location":"advanced/themepark/","text":"Themepark Styles \u00b6 Saltbox can apply themes from ThemePark to supported applications through the inventory. Applications that can support cont-init.d scripts will utilize scripts that modify the CSS within the source files. Support is also available for additional apps via the Traefik Plugin which performs CSS replacement at the reverse proxy (rather than application) level. Plugin note: You must run sb install traefik once after setting global_themepark_plugin_enabled: \"true\" in order to provision the theme middlewares. For example: NZBGet default appearance: NZBGet with the \"nord\" theme: Sonarr with the \"hotline\" theme: Choose the theme and apply it to containers in in inventory: # global theme global_themepark_theme : \"nord\" # enable Traefik plugin global_themepark_plugin_enabled : true # apps using global theme: container_name_themepark_enabled : true # different theme for an app: container_name_themepark_theme : hotline container_name_themepark_enabled : true for example, in /srv/git/saltbox/inventories/host_vars/localhost.yml : # Instructions on how to utilize this file can be found here https://docs.saltbox.dev/saltbox/inventory/ # global theme global_themepark_theme : \"nord\" # apps using global theme: nzbget_themepark_enabled : true # different theme for an app: sonarr_themepark_theme : \"hotline\" sonarr_themepark_enabled : true # enable Traefik plugin global_themepark_plugin_enabled : true # apps using Traefik plugin plex_themepark_enabled : true nzbhydra2_themepark_enabled : true Available themes can be found here . Refer to them in the inventory file by name: organizr dark dracula aquamarine space gray plex hotline hotpink overseerr nord maroon Note: If you are utilizing Theme.Park on any roles, you must run sb install traefik after changing any themes via inventory variables.","title":"Themepark Styles for apps"},{"location":"advanced/themepark/#themepark-styles","text":"Saltbox can apply themes from ThemePark to supported applications through the inventory. Applications that can support cont-init.d scripts will utilize scripts that modify the CSS within the source files. Support is also available for additional apps via the Traefik Plugin which performs CSS replacement at the reverse proxy (rather than application) level. Plugin note: You must run sb install traefik once after setting global_themepark_plugin_enabled: \"true\" in order to provision the theme middlewares. For example: NZBGet default appearance: NZBGet with the \"nord\" theme: Sonarr with the \"hotline\" theme: Choose the theme and apply it to containers in in inventory: # global theme global_themepark_theme : \"nord\" # enable Traefik plugin global_themepark_plugin_enabled : true # apps using global theme: container_name_themepark_enabled : true # different theme for an app: container_name_themepark_theme : hotline container_name_themepark_enabled : true for example, in /srv/git/saltbox/inventories/host_vars/localhost.yml : # Instructions on how to utilize this file can be found here https://docs.saltbox.dev/saltbox/inventory/ # global theme global_themepark_theme : \"nord\" # apps using global theme: nzbget_themepark_enabled : true # different theme for an app: sonarr_themepark_theme : \"hotline\" sonarr_themepark_enabled : true # enable Traefik plugin global_themepark_plugin_enabled : true # apps using Traefik plugin plex_themepark_enabled : true nzbhydra2_themepark_enabled : true Available themes can be found here . Refer to them in the inventory file by name: organizr dark dracula aquamarine space gray plex hotline hotpink overseerr nord maroon Note: If you are utilizing Theme.Park on any roles, you must run sb install traefik after changing any themes via inventory variables.","title":"Themepark Styles"},{"location":"advanced/user-crontab-examples/","text":"Note that this is just some examples, not a list of things that any particular user should have in their crontab \u00b6 Nothing in here is a specific recommendation. DO NOT copy and paste this with the idea that saltbox team is sugeesting that you should do all these things. They may not work as shown here, depending on your setup. It's just a catalog of examples to demonstrate how one might set this sort of thing up. To edit your crontab, enter crontab -e PATH = /usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin @daily cd /opt/plex-meta-manager && python plex-meta-manager.py -r 0 7 * * 7 sudo PATH = '/usr/bin:/bin:/usr/local/bin' env ANSIBLE_CONFIG = '/srv/git/saltbox/ansible.cfg' 'sb install backup' -v >> '/home/seed/logs/saltbox_backup.log' 2 > & 1 * * * * * /opt/scripts/nzbget/cleanup.sh 0 10 * * * /opt/scripts/plex/optimize.sh 0 * * * * PATH = '/usr/bin:/bin:/usr/local/bin' cd /opt/SonarrSync/ ; /usr/bin/python SonarrSync.py Line 1 PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin sets the PATH environment variable. - Allows using sb commands in cronjobs. e.g sb update Line 2: plex-meta-manager script to make Plex collections. - [Runs midnight daily server time ] Line 3: Saltbox backup. - [Runs every Sunday @ 7AM server time ] Line 4: Update Saltbox and do auto-updates - [Runs daily] NOTE: Doing this in an unattended context carries risk. If an error occurs during the process, it could leave all the containers shut down. Line 5: cleanup script to remove left over junk in /downloads/nzbs/nzbget/completed/sonarr/* etc. - [Runs every minute] Note: Scroll down for a couple ideas for this script. Line 6: Script to optimize the Plex database. - [Runs daily @ 10AM server time ] Note: Scroll down for script. Line 7: Enormoz's SonarrSync (based on Sperryfreak's RadarrSync) - [Runs hourly] pho's cleanup.sh \u00b6 This script deletes * everything under a size of 100M * every unwanted file immediately * everything but the wanted files after 10 hours * every empty folder #!/bin/bash ##################################################### # script by pho ##################################################### # basic settings TARGET_FOLDER = \"/mnt/local/downloads/nzbs/{sabnzbd,nzbget}/completed/{radarr,sonarr,lidarr}/\" # find files in this folders FIND_SAMPLE_SIZE = '100M' # files smaller then this are seen as samples and get deleted # advanced settings FIND = $( which find ) FIND_BASE_CONDITION_WANTED = '-type f -amin +600' FIND_BASE_CONDITION_UNWANTED = '-type f' FIND_ADD_NAME = '-o -iname' FIND_DEL_NAME = '! -iname' FIND_ACTION = '-not -path \"*_UNPACK_*\" -delete > /dev/null 2>&1' command = \" ${ FIND } ${ TARGET_FOLDER } -mindepth 1 ${ FIND_BASE_CONDITION_WANTED } -size - ${ FIND_SAMPLE_SIZE } ${ FIND_ACTION } \" #echo \"Executing ${command}\" eval \" ${ command } \" WANTED_FILES =( '*.mkv' '*.mpg' '*.mpeg' '*.avi' '*.mp4' '*.mp3' '*.flac' '*.srt' '*.idx' '*.sub' ) UNWANTED_FILES =( '*.nfo' '*.jpeg' '*.jpg' '*.gif' '*.rar' '*sample.*' '*.sh' '*.pdf' '*.doc' '*.docx' '*.xls' '*.xlsx' '*.xml' '*.html' '*.htm' '*.exe' '*.nzb' ) #Folder Setting condition = \"-iname ' ${ UNWANTED_FILES [0] } '\" for (( i = 1 ; i < ${# UNWANTED_FILES [@] } ; i++ )) do condition = \" ${ condition } ${ FIND_ADD_NAME } ' ${ UNWANTED_FILES [i] } '\" done command = \" ${ FIND } ${ TARGET_FOLDER } -mindepth 1 ${ FIND_BASE_CONDITION_UNWANTED } \\( ${ condition } \\) ${ FIND_ACTION } \" #echo \"Executing ${command}\" eval \" ${ command } \" for (( i = 0 ; i < ${# WANTED_FILES [@] } -1 ; i++ )) do condition2 = \" ${ condition2 } ${ FIND_DEL_NAME } ' ${ WANTED_FILES [i] } '\" done command = \" ${ FIND } ${ TARGET_FOLDER } -mindepth 1 ${ FIND_BASE_CONDITION_WANTED } \\( ${ condition2 } \\) ${ FIND_ACTION } \" #echo \"Executing ${command}\" eval \" ${ command } \" command = \" ${ FIND } ${ TARGET_FOLDER } -mindepth 1 -type d -empty ${ FIND_ACTION } \" #echo \"Executing ${command}\" eval \" ${ command } \" RXWatcher's cleanup.sh \u00b6 Note that this script is specific to its author's setup when it was written. It probably won't work for you as-is. You'll need to edit the paths to match your situation. #!/bin/bash find /mnt/local/downloads/nzbget/completed/sonarr/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/radarr/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/books/* -type d -mmin +240 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/sonarr/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/radarr4k/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/anime/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null RXWatcher's optimize.sh \u00b6 #!/bin/sh # Get the contents of the Preferences file, keep only what we need, push to a temp, then use it in the curl command cat \"/opt/plex/Library/Application Support/Plex Media Server/Preferences.xml\" | \\ sed -e 's;^.* PlexOnlineToken=\";;' | sed -e 's;\".*$;;' | tail -1 > /tmp/plex.tmp curl --request PUT http://plex:32400/library/optimize \\? async = 1 \\& X-Plex-Token = ` cat /tmp/plex.tmp ` rm -f /tmp/plex.tmp","title":"User crontab examples"},{"location":"advanced/user-crontab-examples/#note-that-this-is-just-some-examples-not-a-list-of-things-that-any-particular-user-should-have-in-their-crontab","text":"Nothing in here is a specific recommendation. DO NOT copy and paste this with the idea that saltbox team is sugeesting that you should do all these things. They may not work as shown here, depending on your setup. It's just a catalog of examples to demonstrate how one might set this sort of thing up. To edit your crontab, enter crontab -e PATH = /usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin @daily cd /opt/plex-meta-manager && python plex-meta-manager.py -r 0 7 * * 7 sudo PATH = '/usr/bin:/bin:/usr/local/bin' env ANSIBLE_CONFIG = '/srv/git/saltbox/ansible.cfg' 'sb install backup' -v >> '/home/seed/logs/saltbox_backup.log' 2 > & 1 * * * * * /opt/scripts/nzbget/cleanup.sh 0 10 * * * /opt/scripts/plex/optimize.sh 0 * * * * PATH = '/usr/bin:/bin:/usr/local/bin' cd /opt/SonarrSync/ ; /usr/bin/python SonarrSync.py Line 1 PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin sets the PATH environment variable. - Allows using sb commands in cronjobs. e.g sb update Line 2: plex-meta-manager script to make Plex collections. - [Runs midnight daily server time ] Line 3: Saltbox backup. - [Runs every Sunday @ 7AM server time ] Line 4: Update Saltbox and do auto-updates - [Runs daily] NOTE: Doing this in an unattended context carries risk. If an error occurs during the process, it could leave all the containers shut down. Line 5: cleanup script to remove left over junk in /downloads/nzbs/nzbget/completed/sonarr/* etc. - [Runs every minute] Note: Scroll down for a couple ideas for this script. Line 6: Script to optimize the Plex database. - [Runs daily @ 10AM server time ] Note: Scroll down for script. Line 7: Enormoz's SonarrSync (based on Sperryfreak's RadarrSync) - [Runs hourly]","title":"Note that this is just some examples, not a list of things that any particular user should have in their crontab"},{"location":"advanced/user-crontab-examples/#phos-cleanupsh","text":"This script deletes * everything under a size of 100M * every unwanted file immediately * everything but the wanted files after 10 hours * every empty folder #!/bin/bash ##################################################### # script by pho ##################################################### # basic settings TARGET_FOLDER = \"/mnt/local/downloads/nzbs/{sabnzbd,nzbget}/completed/{radarr,sonarr,lidarr}/\" # find files in this folders FIND_SAMPLE_SIZE = '100M' # files smaller then this are seen as samples and get deleted # advanced settings FIND = $( which find ) FIND_BASE_CONDITION_WANTED = '-type f -amin +600' FIND_BASE_CONDITION_UNWANTED = '-type f' FIND_ADD_NAME = '-o -iname' FIND_DEL_NAME = '! -iname' FIND_ACTION = '-not -path \"*_UNPACK_*\" -delete > /dev/null 2>&1' command = \" ${ FIND } ${ TARGET_FOLDER } -mindepth 1 ${ FIND_BASE_CONDITION_WANTED } -size - ${ FIND_SAMPLE_SIZE } ${ FIND_ACTION } \" #echo \"Executing ${command}\" eval \" ${ command } \" WANTED_FILES =( '*.mkv' '*.mpg' '*.mpeg' '*.avi' '*.mp4' '*.mp3' '*.flac' '*.srt' '*.idx' '*.sub' ) UNWANTED_FILES =( '*.nfo' '*.jpeg' '*.jpg' '*.gif' '*.rar' '*sample.*' '*.sh' '*.pdf' '*.doc' '*.docx' '*.xls' '*.xlsx' '*.xml' '*.html' '*.htm' '*.exe' '*.nzb' ) #Folder Setting condition = \"-iname ' ${ UNWANTED_FILES [0] } '\" for (( i = 1 ; i < ${# UNWANTED_FILES [@] } ; i++ )) do condition = \" ${ condition } ${ FIND_ADD_NAME } ' ${ UNWANTED_FILES [i] } '\" done command = \" ${ FIND } ${ TARGET_FOLDER } -mindepth 1 ${ FIND_BASE_CONDITION_UNWANTED } \\( ${ condition } \\) ${ FIND_ACTION } \" #echo \"Executing ${command}\" eval \" ${ command } \" for (( i = 0 ; i < ${# WANTED_FILES [@] } -1 ; i++ )) do condition2 = \" ${ condition2 } ${ FIND_DEL_NAME } ' ${ WANTED_FILES [i] } '\" done command = \" ${ FIND } ${ TARGET_FOLDER } -mindepth 1 ${ FIND_BASE_CONDITION_WANTED } \\( ${ condition2 } \\) ${ FIND_ACTION } \" #echo \"Executing ${command}\" eval \" ${ command } \" command = \" ${ FIND } ${ TARGET_FOLDER } -mindepth 1 -type d -empty ${ FIND_ACTION } \" #echo \"Executing ${command}\" eval \" ${ command } \"","title":"pho's cleanup.sh"},{"location":"advanced/user-crontab-examples/#rxwatchers-cleanupsh","text":"Note that this script is specific to its author's setup when it was written. It probably won't work for you as-is. You'll need to edit the paths to match your situation. #!/bin/bash find /mnt/local/downloads/nzbget/completed/sonarr/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/radarr/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/books/* -type d -mmin +240 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/sonarr/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/radarr4k/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null find /mnt/local/downloads/nzbget/completed/anime/* -type d -mmin +60 -ls -exec rm -rf {} + 2 >/dev/null","title":"RXWatcher's cleanup.sh"},{"location":"advanced/user-crontab-examples/#rxwatchers-optimizesh","text":"#!/bin/sh # Get the contents of the Preferences file, keep only what we need, push to a temp, then use it in the curl command cat \"/opt/plex/Library/Application Support/Plex Media Server/Preferences.xml\" | \\ sed -e 's;^.* PlexOnlineToken=\";;' | sed -e 's;\".*$;;' | tail -1 > /tmp/plex.tmp curl --request PUT http://plex:32400/library/optimize \\? async = 1 \\& X-Plex-Token = ` cat /tmp/plex.tmp ` rm -f /tmp/plex.tmp","title":"RXWatcher's optimize.sh"},{"location":"advanced/your-own-containers/","text":"Prerequisites \u00b6 When you install existing roles in saltbox, some things get handled behind the scenes for you. Notably, this includes creating the subdomain[s] at cloudflare and creating the /opt/APPNAME directory tree. When you add a container manually as outlined on this page, neither of those things will be done for you, so prior to running the docker commands described below you will have to create the APPNAME.domain.tld subdomain at cloudflare [or wherever your DNS is] and create the required /opt/APPNAME directory tree. The examples below are docker run commands that you would execute in an SSH session on your server. If you want to create a role file that you can install like the built-in applications, see here . Format \u00b6 docker run -d \\ --name= APPNAME \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ -v /opt/ APPNAME : /CONFIG \\ -v /etc/localtime:/etc/localtime:ro \\ --network=saltbox \\ --network-alias= APPNAME \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=true \\ --label traefik.http.routers. APPNAME -http.entrypoints=web \\ --label traefik.http.routers. APPNAME -http.middlewares=globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers. APPNAME -http.rule=Host\\(\\` APPNAME .yourdomain.com\\`\\) \\ --label traefik.http.routers. APPNAME -http.service= APPNAME \\ --label traefik.http.routers. APPNAME .entrypoints=websecure \\ --label traefik.http.routers. APPNAME .middlewares=globalHeaders@file,secureHeaders@file \\ --label traefik.http.routers. APPNAME .rule=Host\\(\\` APPNAME .yourdomain.com\\`\\) \\ --label traefik.http.routers. APPNAME .service= APPNAME \\ --label traefik.http.routers. APPNAME .tls.certresolver=cfdns \\ --label traefik.http.routers. APPNAME .tls.options=securetls@file \\ --label traefik.http.services. APPNAME .loadbalancer.server.port= APPLICATION_PORT \\ docker/image Format (detailed) \u00b6 Note: containers will not always use /config , nor will they necessarily use everything shown here. The required volume maps and environment variables will vary by the docker image being used. docker run -d \\ --name APPNAME \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ --network=saltbox \\ --network-alias= APPNAME \\ -p host_port1 : container_misc_port1 \\ -p host_port2 : container_misc_port2 \\ -v /opt/ APPNAME /:/config \\ -v /mnt/:/mnt/ \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=true \\ --label traefik.http.routers. APPNAME -http.entrypoints=web \\ --label traefik.http.routers. APPNAME -http.middlewares=globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers. APPNAME -http.rule=Host\\(\\` APPNAME .yourdomain.com\\`\\) \\ --label traefik.http.routers. APPNAME -http.service= APPNAME \\ --label traefik.http.routers. APPNAME .entrypoints=websecure \\ --label traefik.http.routers. APPNAME .middlewares=globalHeaders@file,secureHeaders@file \\ --label traefik.http.routers. APPNAME .rule=Host\\(\\` APPNAME .yourdomain.com\\`\\) \\ --label traefik.http.routers. APPNAME .service= APPNAME \\ --label traefik.http.routers. APPNAME .tls.certresolver=cfdns \\ --label traefik.http.routers. APPNAME .tls.options=securetls@file \\ --label traefik.http.services. APPNAME .loadbalancer.server.port= APPLICATION_PORT \\ docker-hub-user/repo-name Examples \u00b6 Tautulli listens on port 8181 docker run -d \\ --name tautulli \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ --network=saltbox \\ --network-alias= tautulli \\ -v /opt/ tautulli /:/config \\ -v /opt/ tautulli/transcode :/transcode \\ -v /mnt/:/mnt/ \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/plex/Library/Application Support/Plex Media Server/Logs:/logs \\ -v /opt:/opt \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=true \\ --label traefik.http.routers. tautulli -http.entrypoints=web \\ --label traefik.http.routers. tautulli -http.middlewares=globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers. tautulli -http.rule=Host\\(\\` tautulli.yourdomain.com \\`\\) \\ --label traefik.http.routers. tautulli -http.service= tautulli \\ --label traefik.http.routers. tautulli .entrypoints=websecure \\ --label traefik.http.routers. tautulli .middlewares=globalHeaders@file,secureHeaders@file \\ --label traefik.http.routers. tautulli .rule=Host\\(\\` tautulli.yourdomain.com \\`\\) \\ --label traefik.http.routers. tautulli .service= tautulli \\ --label traefik.http.routers. tautulli .tls.certresolver=cfdns \\ --label traefik.http.routers. tautulli .tls.options=securetls@file \\ --label traefik.http.services. tautulli .loadbalancer.server.port= 8181 \\ linuxserver/tautulli Speedtest listens on port 80, doesn't have a config dir docker run -d \\ --name= speedtest \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ -v /opt/speedtest:/var/www/html \\ --network=saltbox \\ --network-alias= speedtest \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=true \\ --label traefik.http.routers. speedtest -http.entrypoints=web \\ --label traefik.http.routers. speedtest -http.middlewares=globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers. speedtest -http.rule=Host\\(\\` speedtest.yourdomain.com \\`\\) \\ --label traefik.http.routers. speedtest -http.service= speedtest \\ --label traefik.http.routers. speedtest .entrypoints=websecure \\ --label traefik.http.routers. speedtest .middlewares=globalHeaders@file,secureHeaders@file \\ --label traefik.http.routers. speedtest .rule=Host\\(\\` speedtest.yourdomain.com \\`\\) \\ --label traefik.http.routers. speedtest .service= speedtest \\ --label traefik.http.routers. speedtest .tls.certresolver=cfdns \\ --label traefik.http.routers. speedtest .tls.options=securetls@file \\ --label traefik.http.services. speedtest .loadbalancer.server.port= 80 \\ satzisa/html5-speedtest Plex-Patrol doesn't need to be behind the proxy, but you want it on the saltbox network and you want saltbox to take it down for backups. docker run -d \\ --name= plex_patrol \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ -v /opt/ plex_patrol : /config \\ --network=saltbox \\ --network-alias= plex_patrol \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=false \\ cloudb0x/plex_patrol:latest Autoscan exposing an alternate port for perhaps a second instance, but only visible on the host [not outside] docker run -d \\ --name= autoscan \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ -p 127.0.0.1:3033 : 3030 \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/autoscan:/config \\ -v /mnt:/mnt \\ --network=saltbox \\ --network-alias= autoscan \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=false \\ cloudb0x/autoscan:master Details \u00b6 Notes \u00b6 Replace all <tags> with your info. All <container_*> items are specified by the Docker container. Ideally, you want all <name> items to have the same name. Pick docker images that allow you to specify the PUID/PGID. You can break a command into multiple lines with a backslash ( \\ ) at the end of all the lines except the last one. Basics \u00b6 --name=<name> --restart=unless-stopped To have it startup automatically, unless the container was previously stopped. -v /etc/localtime:/etc/localtime:ro To set the docker container's timezone to your host timezone. -e PUID=<your_user_ID> -e PGID=<your_group_ID> Replace <user> and <group> to match yours (see here ). --label com.github.saltbox.saltbox_managed=true Is used to determine whether the container is shut down or not during Saltbox backup and other tasks. If you want this container to not be shut down, leave the label out or set it to false . If you do decide leave this out or set this to false , it will probably be a good idea to store the config files at another location other than /opt as a running container could cause issues during Saltbox Backup. Mount Paths \u00b6 Mount paths are in the format of path/on/host:path/within/container . You may change the path on host (left side), but not the path set for the container, internally (right side). -v /opt/<name>:<container_config_path> This is where your config files will go You will need to: Create the folder: mkdir /opt/<name> Set ownership: sudo chown -R <user>:<group> /opt/<name> Replace <user> and <group> to match yours' (see here ) Set permissions: sudo chmod -R ugo+X /opt<name> -v /mnt/local/downloads/<name>:/downloads/<name> Only required if your Docker app needs a path for downloads. You will need to set /downloads/<name> as the downloads path in your app. This path will be accessible to Sonarr and Radarr. You will need to: Create the folder: mkdir /mnt/local/downloads/<name> Set ownership: sudo chown -R <user>:<group> /mnt/local/downloads/<name> Replace <user> and <group> to match yours' (see here ) Set permissions: sudo chmod -R ugo+X /mnt/local/downloads/<name> Network \u00b6 Note: These are important, but leave them out if your docker run command requires --net=host . --network=saltbox --network-alias=<name> (aliases are shortcuts to communicate across dockers) Ports \u00b6 Ports are in the format of host_port:container_port . For the main, web admin/page port (e.g. 32400 in Plex): You do not need to specify this port with -p . Since this port will not be accessible over the net or from the host. Instead, Traefik will redirect the subdomain to it. If you do want the port accessible from the host (but not from the net), simply add 127.0.0.1: to it and specify it via: -p 127.0.0.1:<host_port>:<container_webadmin_port> If you expose ports to the host like this, make sure they don't conflict with another one on that host. For all other ports: -p <host_port>:<container_other_ports> These are accessible from the net. If this is a home install, you will probably need to forward the port to the Saltbox machine. Traefik Proxy \u00b6 --label traefik.enable = true --label traefik.http.routers.<name>-http.entrypoints = web \\ --label traefik.http.routers.<name>-http.middlewares = globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers.<name>-http.rule = Host \\(\\` <name>.yourdomain.com \\`\\) \\ --label traefik.http.routers.<name>-http.service = <name> \\ --label traefik.http.routers.<name>.entrypoints = websecure \\ --label traefik.http.routers.<name>.middlewares = globalHeaders@file,secureHeaders@file,authelia@docker \\ # (1) --label traefik.http.routers.<name>.rule = Host \\(\\` <name>.yourdomain.com \\`\\) \\ --label traefik.http.routers.<name>.service = <name> \\ --label traefik.http.routers.<name>.tls.certresolver = cfdns \\ --label traefik.http.routers.<name>.tls.options = securetls@file \\ --label traefik.http.services.<name>.loadbalancer.server.port = <container_webpage_port> # (2) Omit authelia@docker to disable SSO. If your Authelia master instance is on another server (i.e. split feederbox/mediabox setup) modify this to be authelia only. The port for the web admin page for the container. You'll need to add the subdomain manually at your DNS provider if you're not using wild-card DNS. Docker Compose \u00b6 Here is the example in compose format and connecting to the saltbox Docker network to be served by Traefik. As noted above, you will have to create the APPNAME.domain.tld subdomain at cloudflare [or wherever your DNS is] and create any required /opt/APPNAME directory tree manually. Creating the container using docker-compose will not do those things automatically the way an sb install APPNAME Ansible run would. version : \"3\" services : APPNAME : restart : unless-stopped container_name : APPNAME image : docker/image:tag hostname : APPNAME environment : - PUID=1000 - PGID=1000 - TZ=Etc/UTC networks : - saltbox labels : traefik.enable : true traefik.http.routers.APPNAME-http.entrypoints : web traefik.http.routers.APPNAME-http.middlewares : globalHeaders@file,redirect-to-https,gzip traefik.http.routers.APPNAME-http.rule : Host(`APPNAME.yourdomain.com`) traefik.http.routers.APPNAME-http.service : APPNAME traefik.http.routers.APPNAME.entrypoints : websecure traefik.http.routers.APPNAME.middlewares : globalHeaders@file,secureHeaders@file traefik.http.routers.APPNAME.rule : Host(`APPNAME.yourdomain.com`) traefik.http.routers.APPNAME.service : APPNAME traefik.http.routers.APPNAME.tls.certresolver : cfdns traefik.http.routers.APPNAME.tls.options : securetls@file traefik.http.services.APPNAME.loadbalancer.server.port : APPLICATION_PORT volumes : - /opt/APPNAME:/CONFIG - /etc/localtime:/etc/localtime:ro networks : saltbox : external : true","title":"Adding Your Own Containers"},{"location":"advanced/your-own-containers/#prerequisites","text":"When you install existing roles in saltbox, some things get handled behind the scenes for you. Notably, this includes creating the subdomain[s] at cloudflare and creating the /opt/APPNAME directory tree. When you add a container manually as outlined on this page, neither of those things will be done for you, so prior to running the docker commands described below you will have to create the APPNAME.domain.tld subdomain at cloudflare [or wherever your DNS is] and create the required /opt/APPNAME directory tree. The examples below are docker run commands that you would execute in an SSH session on your server. If you want to create a role file that you can install like the built-in applications, see here .","title":"Prerequisites"},{"location":"advanced/your-own-containers/#format","text":"docker run -d \\ --name= APPNAME \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ -v /opt/ APPNAME : /CONFIG \\ -v /etc/localtime:/etc/localtime:ro \\ --network=saltbox \\ --network-alias= APPNAME \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=true \\ --label traefik.http.routers. APPNAME -http.entrypoints=web \\ --label traefik.http.routers. APPNAME -http.middlewares=globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers. APPNAME -http.rule=Host\\(\\` APPNAME .yourdomain.com\\`\\) \\ --label traefik.http.routers. APPNAME -http.service= APPNAME \\ --label traefik.http.routers. APPNAME .entrypoints=websecure \\ --label traefik.http.routers. APPNAME .middlewares=globalHeaders@file,secureHeaders@file \\ --label traefik.http.routers. APPNAME .rule=Host\\(\\` APPNAME .yourdomain.com\\`\\) \\ --label traefik.http.routers. APPNAME .service= APPNAME \\ --label traefik.http.routers. APPNAME .tls.certresolver=cfdns \\ --label traefik.http.routers. APPNAME .tls.options=securetls@file \\ --label traefik.http.services. APPNAME .loadbalancer.server.port= APPLICATION_PORT \\ docker/image","title":"Format"},{"location":"advanced/your-own-containers/#format-detailed","text":"Note: containers will not always use /config , nor will they necessarily use everything shown here. The required volume maps and environment variables will vary by the docker image being used. docker run -d \\ --name APPNAME \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ --network=saltbox \\ --network-alias= APPNAME \\ -p host_port1 : container_misc_port1 \\ -p host_port2 : container_misc_port2 \\ -v /opt/ APPNAME /:/config \\ -v /mnt/:/mnt/ \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=true \\ --label traefik.http.routers. APPNAME -http.entrypoints=web \\ --label traefik.http.routers. APPNAME -http.middlewares=globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers. APPNAME -http.rule=Host\\(\\` APPNAME .yourdomain.com\\`\\) \\ --label traefik.http.routers. APPNAME -http.service= APPNAME \\ --label traefik.http.routers. APPNAME .entrypoints=websecure \\ --label traefik.http.routers. APPNAME .middlewares=globalHeaders@file,secureHeaders@file \\ --label traefik.http.routers. APPNAME .rule=Host\\(\\` APPNAME .yourdomain.com\\`\\) \\ --label traefik.http.routers. APPNAME .service= APPNAME \\ --label traefik.http.routers. APPNAME .tls.certresolver=cfdns \\ --label traefik.http.routers. APPNAME .tls.options=securetls@file \\ --label traefik.http.services. APPNAME .loadbalancer.server.port= APPLICATION_PORT \\ docker-hub-user/repo-name","title":"Format (detailed)"},{"location":"advanced/your-own-containers/#examples","text":"Tautulli listens on port 8181 docker run -d \\ --name tautulli \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ --network=saltbox \\ --network-alias= tautulli \\ -v /opt/ tautulli /:/config \\ -v /opt/ tautulli/transcode :/transcode \\ -v /mnt/:/mnt/ \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/plex/Library/Application Support/Plex Media Server/Logs:/logs \\ -v /opt:/opt \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=true \\ --label traefik.http.routers. tautulli -http.entrypoints=web \\ --label traefik.http.routers. tautulli -http.middlewares=globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers. tautulli -http.rule=Host\\(\\` tautulli.yourdomain.com \\`\\) \\ --label traefik.http.routers. tautulli -http.service= tautulli \\ --label traefik.http.routers. tautulli .entrypoints=websecure \\ --label traefik.http.routers. tautulli .middlewares=globalHeaders@file,secureHeaders@file \\ --label traefik.http.routers. tautulli .rule=Host\\(\\` tautulli.yourdomain.com \\`\\) \\ --label traefik.http.routers. tautulli .service= tautulli \\ --label traefik.http.routers. tautulli .tls.certresolver=cfdns \\ --label traefik.http.routers. tautulli .tls.options=securetls@file \\ --label traefik.http.services. tautulli .loadbalancer.server.port= 8181 \\ linuxserver/tautulli Speedtest listens on port 80, doesn't have a config dir docker run -d \\ --name= speedtest \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ -v /opt/speedtest:/var/www/html \\ --network=saltbox \\ --network-alias= speedtest \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=true \\ --label traefik.http.routers. speedtest -http.entrypoints=web \\ --label traefik.http.routers. speedtest -http.middlewares=globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers. speedtest -http.rule=Host\\(\\` speedtest.yourdomain.com \\`\\) \\ --label traefik.http.routers. speedtest -http.service= speedtest \\ --label traefik.http.routers. speedtest .entrypoints=websecure \\ --label traefik.http.routers. speedtest .middlewares=globalHeaders@file,secureHeaders@file \\ --label traefik.http.routers. speedtest .rule=Host\\(\\` speedtest.yourdomain.com \\`\\) \\ --label traefik.http.routers. speedtest .service= speedtest \\ --label traefik.http.routers. speedtest .tls.certresolver=cfdns \\ --label traefik.http.routers. speedtest .tls.options=securetls@file \\ --label traefik.http.services. speedtest .loadbalancer.server.port= 80 \\ satzisa/html5-speedtest Plex-Patrol doesn't need to be behind the proxy, but you want it on the saltbox network and you want saltbox to take it down for backups. docker run -d \\ --name= plex_patrol \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ -v /opt/ plex_patrol : /config \\ --network=saltbox \\ --network-alias= plex_patrol \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=false \\ cloudb0x/plex_patrol:latest Autoscan exposing an alternate port for perhaps a second instance, but only visible on the host [not outside] docker run -d \\ --name= autoscan \\ --restart=unless-stopped \\ -e PGID= 1000 -e PUID= 1000 \\ -p 127.0.0.1:3033 : 3030 \\ -v /etc/localtime:/etc/localtime:ro \\ -v /opt/autoscan:/config \\ -v /mnt:/mnt \\ --network=saltbox \\ --network-alias= autoscan \\ --label com.github.saltbox.saltbox_managed=true \\ --label traefik.enable=false \\ cloudb0x/autoscan:master","title":"Examples"},{"location":"advanced/your-own-containers/#details","text":"","title":"Details"},{"location":"advanced/your-own-containers/#notes","text":"Replace all <tags> with your info. All <container_*> items are specified by the Docker container. Ideally, you want all <name> items to have the same name. Pick docker images that allow you to specify the PUID/PGID. You can break a command into multiple lines with a backslash ( \\ ) at the end of all the lines except the last one.","title":"Notes"},{"location":"advanced/your-own-containers/#basics","text":"--name=<name> --restart=unless-stopped To have it startup automatically, unless the container was previously stopped. -v /etc/localtime:/etc/localtime:ro To set the docker container's timezone to your host timezone. -e PUID=<your_user_ID> -e PGID=<your_group_ID> Replace <user> and <group> to match yours (see here ). --label com.github.saltbox.saltbox_managed=true Is used to determine whether the container is shut down or not during Saltbox backup and other tasks. If you want this container to not be shut down, leave the label out or set it to false . If you do decide leave this out or set this to false , it will probably be a good idea to store the config files at another location other than /opt as a running container could cause issues during Saltbox Backup.","title":"Basics"},{"location":"advanced/your-own-containers/#mount-paths","text":"Mount paths are in the format of path/on/host:path/within/container . You may change the path on host (left side), but not the path set for the container, internally (right side). -v /opt/<name>:<container_config_path> This is where your config files will go You will need to: Create the folder: mkdir /opt/<name> Set ownership: sudo chown -R <user>:<group> /opt/<name> Replace <user> and <group> to match yours' (see here ) Set permissions: sudo chmod -R ugo+X /opt<name> -v /mnt/local/downloads/<name>:/downloads/<name> Only required if your Docker app needs a path for downloads. You will need to set /downloads/<name> as the downloads path in your app. This path will be accessible to Sonarr and Radarr. You will need to: Create the folder: mkdir /mnt/local/downloads/<name> Set ownership: sudo chown -R <user>:<group> /mnt/local/downloads/<name> Replace <user> and <group> to match yours' (see here ) Set permissions: sudo chmod -R ugo+X /mnt/local/downloads/<name>","title":"Mount Paths"},{"location":"advanced/your-own-containers/#network","text":"Note: These are important, but leave them out if your docker run command requires --net=host . --network=saltbox --network-alias=<name> (aliases are shortcuts to communicate across dockers)","title":"Network"},{"location":"advanced/your-own-containers/#ports","text":"Ports are in the format of host_port:container_port . For the main, web admin/page port (e.g. 32400 in Plex): You do not need to specify this port with -p . Since this port will not be accessible over the net or from the host. Instead, Traefik will redirect the subdomain to it. If you do want the port accessible from the host (but not from the net), simply add 127.0.0.1: to it and specify it via: -p 127.0.0.1:<host_port>:<container_webadmin_port> If you expose ports to the host like this, make sure they don't conflict with another one on that host. For all other ports: -p <host_port>:<container_other_ports> These are accessible from the net. If this is a home install, you will probably need to forward the port to the Saltbox machine.","title":"Ports"},{"location":"advanced/your-own-containers/#traefik-proxy","text":"--label traefik.enable = true --label traefik.http.routers.<name>-http.entrypoints = web \\ --label traefik.http.routers.<name>-http.middlewares = globalHeaders@file,redirect-to-https,gzip \\ --label traefik.http.routers.<name>-http.rule = Host \\(\\` <name>.yourdomain.com \\`\\) \\ --label traefik.http.routers.<name>-http.service = <name> \\ --label traefik.http.routers.<name>.entrypoints = websecure \\ --label traefik.http.routers.<name>.middlewares = globalHeaders@file,secureHeaders@file,authelia@docker \\ # (1) --label traefik.http.routers.<name>.rule = Host \\(\\` <name>.yourdomain.com \\`\\) \\ --label traefik.http.routers.<name>.service = <name> \\ --label traefik.http.routers.<name>.tls.certresolver = cfdns \\ --label traefik.http.routers.<name>.tls.options = securetls@file \\ --label traefik.http.services.<name>.loadbalancer.server.port = <container_webpage_port> # (2) Omit authelia@docker to disable SSO. If your Authelia master instance is on another server (i.e. split feederbox/mediabox setup) modify this to be authelia only. The port for the web admin page for the container. You'll need to add the subdomain manually at your DNS provider if you're not using wild-card DNS.","title":"Traefik Proxy"},{"location":"advanced/your-own-containers/#docker-compose","text":"Here is the example in compose format and connecting to the saltbox Docker network to be served by Traefik. As noted above, you will have to create the APPNAME.domain.tld subdomain at cloudflare [or wherever your DNS is] and create any required /opt/APPNAME directory tree manually. Creating the container using docker-compose will not do those things automatically the way an sb install APPNAME Ansible run would. version : \"3\" services : APPNAME : restart : unless-stopped container_name : APPNAME image : docker/image:tag hostname : APPNAME environment : - PUID=1000 - PGID=1000 - TZ=Etc/UTC networks : - saltbox labels : traefik.enable : true traefik.http.routers.APPNAME-http.entrypoints : web traefik.http.routers.APPNAME-http.middlewares : globalHeaders@file,redirect-to-https,gzip traefik.http.routers.APPNAME-http.rule : Host(`APPNAME.yourdomain.com`) traefik.http.routers.APPNAME-http.service : APPNAME traefik.http.routers.APPNAME.entrypoints : websecure traefik.http.routers.APPNAME.middlewares : globalHeaders@file,secureHeaders@file traefik.http.routers.APPNAME.rule : Host(`APPNAME.yourdomain.com`) traefik.http.routers.APPNAME.service : APPNAME traefik.http.routers.APPNAME.tls.certresolver : cfdns traefik.http.routers.APPNAME.tls.options : securetls@file traefik.http.services.APPNAME.loadbalancer.server.port : APPLICATION_PORT volumes : - /opt/APPNAME:/CONFIG - /etc/localtime:/etc/localtime:ro networks : saltbox : external : true","title":"Docker Compose"},{"location":"apps/asshama/","text":"Absolute Series Scanner and HAMA role for anime \u00b6 What is it? \u00b6 asshama will install the Absolute Series Scanner (ASS) and the HTTP Anidb Metadata Agent (HAMA) . HAMA is a plex agent specifically for anime and its various challenges. It is recommended to use the HAMA agent with the Absolute Series Scanner (ASS). Hama agent features include: - Both Movies and Series Agent AniDB ID to TVDB/TMDB ID matching (with studio and episode mapping list) with ScudLee's xml mapping file Posters from TVDB (assign a poster to each anidb id in anidb to tvdb mapping file to avoid poster duplicates) TVDB episode screenshots Episode summary (in English only) courtesy of TVDB through ScudLee's XML episode mappings Uses studio from mapping file then AniDB (as often missing from AniDB) Search part entirely local through AniDB HTML API database file anime-titles.xml Separate language order selection for the series name and episode titles in Agent Settings (Supports Kanji characters in folders, filenames, titles) Warnings in html report files (no poster available, episode summary empty, TVDB id not in mapping file) to allow the community to update more easily the mapping XML or TVDB, list of missing episodes Collection mapping from ScudLee's movie collection ammended with AniDB RelatedAnime field Unique posters by using the anidbid rank in the mapping to rotate the posters when a serie is not found in AniDB, search TVDB and TMDB automatically Trakt scrobbling supports Hama guids Project Information \u00b6 Absolute Series Scanner (A.S.S.) HTTP Anidb Metadata Agent (HAMA) 1. Installation \u00b6 sb install asshama 3. Setup \u00b6 Documentation","title":"asshama"},{"location":"apps/asshama/#absolute-series-scanner-and-hama-role-for-anime","text":"","title":"Absolute Series Scanner and HAMA role for anime"},{"location":"apps/asshama/#what-is-it","text":"asshama will install the Absolute Series Scanner (ASS) and the HTTP Anidb Metadata Agent (HAMA) . HAMA is a plex agent specifically for anime and its various challenges. It is recommended to use the HAMA agent with the Absolute Series Scanner (ASS). Hama agent features include: - Both Movies and Series Agent AniDB ID to TVDB/TMDB ID matching (with studio and episode mapping list) with ScudLee's xml mapping file Posters from TVDB (assign a poster to each anidb id in anidb to tvdb mapping file to avoid poster duplicates) TVDB episode screenshots Episode summary (in English only) courtesy of TVDB through ScudLee's XML episode mappings Uses studio from mapping file then AniDB (as often missing from AniDB) Search part entirely local through AniDB HTML API database file anime-titles.xml Separate language order selection for the series name and episode titles in Agent Settings (Supports Kanji characters in folders, filenames, titles) Warnings in html report files (no poster available, episode summary empty, TVDB id not in mapping file) to allow the community to update more easily the mapping XML or TVDB, list of missing episodes Collection mapping from ScudLee's movie collection ammended with AniDB RelatedAnime field Unique posters by using the anidbid rank in the mapping to rotate the posters when a serie is not found in AniDB, search TVDB and TMDB automatically Trakt scrobbling supports Hama guids","title":"What is it?"},{"location":"apps/asshama/#project-information","text":"Absolute Series Scanner (A.S.S.) HTTP Anidb Metadata Agent (HAMA)","title":"Project Information"},{"location":"apps/asshama/#1-installation","text":"sb install asshama","title":"1. Installation"},{"location":"apps/asshama/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"apps/autoscan/","text":"Autoscan \u00b6 What is it? \u00b6 Autoscan replaces the default Plex, Emby, and Jellyfin behaviour for picking up file changes on the file system. Autoscan integrates with Sonarr, Radarr, Lidarr and Google Shared Drives to fetch changes in near real-time without relying on the file system. Autoscan is a rewrite of the original Plex Autoscan written in the Go language. In addition, this rewrite introduces a more modular approach and should be easy to extend in the future. Details Project home Docs Github Docker Setup \u00b6 The Saltbox Autoscan role will attempt to partially configure your autoscan config file located at /opt/autoscan/config.yml . You should refer to the documentation and adjust this file as suits your own needs. The config generated is very minimal. a-train is now replacing the bernard trigger. The generated config file will look something like this: # <- processor -> # Override the minimum age before a scan request is sent to the target (Default 10m): minimum-age : 10m # Override the delay between processed scans (Default 5s): scan-delay : 5s # Set anchor files for remote storage. If these are missing no scans will be sent to the target to avoid files being trashed when a mount fails anchors : - /mnt/unionfs/mounted.bin # <- triggers -> # Optionally, protect your webhooks with authentication authentication : username : USERNAME_FROM_SETTINGS password : PASSWORD_FROM_SETTINGS # Port for Autoscan webhooks to listen on port : 3030 triggers : a-train : priority : 5 rewrite : # Global rewrites - from : ^/Media/ to : /mnt/unionfs/Media/ inotify : - priority : 0 # Filter with regular expressions include : - ^/mnt/unionfs/Media/ exclude : - '\\.(srt|pdf)$' # rewrite inotify path to unified filesystem rewrite : - from : ^/mnt/local/Media/ to : /mnt/unionfs/Media/ # Local filesystem paths to monitor paths : - path : /mnt/local/Media sonarr : - name : sonarr # /triggers/sonarr priority : 2 radarr : - name : radarr # /triggers/radarr priority : 2 lidarr : - name : lidarr # /triggers/lidarr priority : 1 # <- targets -> targets : plex : - url : https://plex.DOMAIN.TLD # plex token : YOUR_PLEX_TOKEN Then edit the anchors section: anchors : - /mnt/unionfs/mounted.bin To reflect your own configuration. For example, if you went through the saltbox rclone setup process, you'll need to enter something like this: anchors : - /mnt/unionfs/bvoiwepopz-movies_mounted.bin - /mnt/unionfs/bvoiwepopz-tv_mounted.bin - /mnt/unionfs/bvoiwepopz-music_mounted.bin - /mnt/unionfs/bvoiwepopz-anime_mounted.bin ... Everything else should be ready to go for standard usage. What are those mount files? Autoscan uses these to determine if your cloud storage is mounted and visible; if autoscan can't see these files, no scans will be sent to Plex since doing so would empty your library as Plex removed all the files it can no longer see [assuming that \"empty trash on scan\" is enabled]. There's nothing special about the contents of these files; autoscan just needs to see that they exist. Typically they are empty. If you went through the saltbox rclone setup, these files got created for you. `ls /mnt/unionfs/*.bin` will give you the list of files you should enter here. A-Train \u00b6 Autoscan can monitor Google Drive changes via a trigger called \"Bernard\". The code behind Bernard can sometimes get out of sync with the state of Google Drive and miss things, so now we are using A-Train. \"A-Train\" is a rewrite of the Bernard concepts, and is currently available as a second docker image as part of Sandbox. It will likely be integrated into autoscan. Enter the names of the remotes you want to monitor in the sandbox settings.yml . The Remotes can be either drive remotes or union remotes. You may use rclone listremotes to get your drive remotes. Example: a_train : remotes : [ \"bvoiwepopz-Movies\" , \"bvoiwepopz-TV\" ] or a_train : remotes : [ \"google\" ] Run the a-train tag to create the container: sb install sandbox-a_train Copy one of your service account files from its current location to /opt/a-train/account.json . Remember to rename your service account file to \" account.json \". Example: cp /opt/sa/all/160.json /opt/a-train/account.json Run the autoscan tag to rebuild the container: sb install autoscan Run the a-train tag to rebuild the container: sb install sandbox-a_train Bernard \u00b6 If for some reason you still wanted to use Bernard, it would look like this: triggers : bernard : - account : /config/sa.json # Path inside the container where your SA is located cron : \"*/5 * * * *\" # every five minutes (the \"\" are important) priority : 0 drives : - id : drive_id #Friendly title # Rewrite gdrive to the local filesystem rewrite : - from : ^/Media/ to : /mnt/unionfs/Media/ # Filter with regular expressions include : - ^/mnt/unionfs/Media/ exclude : - '\\.srt$' Further documentation: A-Train Docker page A-Train initial documentation Documentation Next \u00b6 Are you setting Saltbox up for the first time? Continue to Sonarr .","title":"Autoscan"},{"location":"apps/autoscan/#autoscan","text":"","title":"Autoscan"},{"location":"apps/autoscan/#what-is-it","text":"Autoscan replaces the default Plex, Emby, and Jellyfin behaviour for picking up file changes on the file system. Autoscan integrates with Sonarr, Radarr, Lidarr and Google Shared Drives to fetch changes in near real-time without relying on the file system. Autoscan is a rewrite of the original Plex Autoscan written in the Go language. In addition, this rewrite introduces a more modular approach and should be easy to extend in the future. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/autoscan/#setup","text":"The Saltbox Autoscan role will attempt to partially configure your autoscan config file located at /opt/autoscan/config.yml . You should refer to the documentation and adjust this file as suits your own needs. The config generated is very minimal. a-train is now replacing the bernard trigger. The generated config file will look something like this: # <- processor -> # Override the minimum age before a scan request is sent to the target (Default 10m): minimum-age : 10m # Override the delay between processed scans (Default 5s): scan-delay : 5s # Set anchor files for remote storage. If these are missing no scans will be sent to the target to avoid files being trashed when a mount fails anchors : - /mnt/unionfs/mounted.bin # <- triggers -> # Optionally, protect your webhooks with authentication authentication : username : USERNAME_FROM_SETTINGS password : PASSWORD_FROM_SETTINGS # Port for Autoscan webhooks to listen on port : 3030 triggers : a-train : priority : 5 rewrite : # Global rewrites - from : ^/Media/ to : /mnt/unionfs/Media/ inotify : - priority : 0 # Filter with regular expressions include : - ^/mnt/unionfs/Media/ exclude : - '\\.(srt|pdf)$' # rewrite inotify path to unified filesystem rewrite : - from : ^/mnt/local/Media/ to : /mnt/unionfs/Media/ # Local filesystem paths to monitor paths : - path : /mnt/local/Media sonarr : - name : sonarr # /triggers/sonarr priority : 2 radarr : - name : radarr # /triggers/radarr priority : 2 lidarr : - name : lidarr # /triggers/lidarr priority : 1 # <- targets -> targets : plex : - url : https://plex.DOMAIN.TLD # plex token : YOUR_PLEX_TOKEN Then edit the anchors section: anchors : - /mnt/unionfs/mounted.bin To reflect your own configuration. For example, if you went through the saltbox rclone setup process, you'll need to enter something like this: anchors : - /mnt/unionfs/bvoiwepopz-movies_mounted.bin - /mnt/unionfs/bvoiwepopz-tv_mounted.bin - /mnt/unionfs/bvoiwepopz-music_mounted.bin - /mnt/unionfs/bvoiwepopz-anime_mounted.bin ... Everything else should be ready to go for standard usage. What are those mount files? Autoscan uses these to determine if your cloud storage is mounted and visible; if autoscan can't see these files, no scans will be sent to Plex since doing so would empty your library as Plex removed all the files it can no longer see [assuming that \"empty trash on scan\" is enabled]. There's nothing special about the contents of these files; autoscan just needs to see that they exist. Typically they are empty. If you went through the saltbox rclone setup, these files got created for you. `ls /mnt/unionfs/*.bin` will give you the list of files you should enter here.","title":"Setup"},{"location":"apps/autoscan/#a-train","text":"Autoscan can monitor Google Drive changes via a trigger called \"Bernard\". The code behind Bernard can sometimes get out of sync with the state of Google Drive and miss things, so now we are using A-Train. \"A-Train\" is a rewrite of the Bernard concepts, and is currently available as a second docker image as part of Sandbox. It will likely be integrated into autoscan. Enter the names of the remotes you want to monitor in the sandbox settings.yml . The Remotes can be either drive remotes or union remotes. You may use rclone listremotes to get your drive remotes. Example: a_train : remotes : [ \"bvoiwepopz-Movies\" , \"bvoiwepopz-TV\" ] or a_train : remotes : [ \"google\" ] Run the a-train tag to create the container: sb install sandbox-a_train Copy one of your service account files from its current location to /opt/a-train/account.json . Remember to rename your service account file to \" account.json \". Example: cp /opt/sa/all/160.json /opt/a-train/account.json Run the autoscan tag to rebuild the container: sb install autoscan Run the a-train tag to rebuild the container: sb install sandbox-a_train","title":"A-Train"},{"location":"apps/autoscan/#bernard","text":"If for some reason you still wanted to use Bernard, it would look like this: triggers : bernard : - account : /config/sa.json # Path inside the container where your SA is located cron : \"*/5 * * * *\" # every five minutes (the \"\" are important) priority : 0 drives : - id : drive_id #Friendly title # Rewrite gdrive to the local filesystem rewrite : - from : ^/Media/ to : /mnt/unionfs/Media/ # Filter with regular expressions include : - ^/mnt/unionfs/Media/ exclude : - '\\.srt$' Further documentation: A-Train Docker page A-Train initial documentation Documentation","title":"Bernard"},{"location":"apps/autoscan/#next","text":"Are you setting Saltbox up for the first time? Continue to Sonarr .","title":"Next"},{"location":"apps/bazarr/","text":"Bazarr \u00b6 What is it? \u00b6 Bazarr is a companion application to Sonarr and Radarr that manages and downloads subtitles based on your requirements. Details Project home Docs Github Docker 1. Installation \u00b6 sb install bazarr 2. URL \u00b6 To access Bazarr, visit https://bazarr._yourdomain.com_ 3. Setup \u00b6 Documentation TraSH Guides","title":"Bazarr"},{"location":"apps/bazarr/#bazarr","text":"","title":"Bazarr"},{"location":"apps/bazarr/#what-is-it","text":"Bazarr is a companion application to Sonarr and Radarr that manages and downloads subtitles based on your requirements. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/bazarr/#1-installation","text":"sb install bazarr","title":"1. Installation"},{"location":"apps/bazarr/#2-url","text":"To access Bazarr, visit https://bazarr._yourdomain.com_","title":"2. URL"},{"location":"apps/bazarr/#3-setup","text":"Documentation TraSH Guides","title":"3. Setup"},{"location":"apps/btrfsmaintenance/","text":"BTRFS Maintenance \u00b6 What is it? \u00b6 BTRFS Maintenance is a set of scripts supplementing the btrfs filesystem and aims to automate a few maintenance tasks. This means the scrub, balance, trim or defragmentation. Each of the tasks can be turned on/off and configured independently. The default config values were selected to fit the default installation profile with btrfs on the root filesystem. Details Project home Docs Github Docker 1. Installation \u00b6 sb install btrfsmaintenance 2. Setup \u00b6 Documentation","title":"BTRFS Maintenance"},{"location":"apps/btrfsmaintenance/#btrfs-maintenance","text":"","title":"BTRFS Maintenance"},{"location":"apps/btrfsmaintenance/#what-is-it","text":"BTRFS Maintenance is a set of scripts supplementing the btrfs filesystem and aims to automate a few maintenance tasks. This means the scrub, balance, trim or defragmentation. Each of the tasks can be turned on/off and configured independently. The default config values were selected to fit the default installation profile with btrfs on the root filesystem. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/btrfsmaintenance/#1-installation","text":"sb install btrfsmaintenance","title":"1. Installation"},{"location":"apps/btrfsmaintenance/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"apps/cloudplow/","text":"What is it? \u00b6 Cloudplow (CP) is a script created by l3uddz that has one main component as relates to Saltbox: it's an uploader to Rclone remote. Files are moved off local storage. With support for multiple uploaders (i.e. remote/folder pairings). Details Project home Docs Github Docker Remote Uploader Function \u00b6 As setup for Saltbox, Cloudplow uploads all the content in /mnt/local/Media/ (see Paths ) to your cloud storage provider (e.g. Google Drive), after the folder reaches a 200 GB size threshold, when checked every 30 minutes. Note: The size threshold and the check interval can be changed via steps mentioned on this page. Google Drive Daily Upload Limit (click to expand) Google Drive has a max upload limit of about 750GB per day. When this limit is reached, Google Drive will put you in a 24 hour soft ban. When Cloudplow detects this (with the phrase `Failed to copy: googleapi: Error 403: User rate limit exceeded`), uploading will be suspended for 25 hours (i.e. a 25 hour ban sleep), and upon waking up, it will resume its checking and uploading tasks. This feature is enabled by default. This method is better than running Rclone task with a `bwlimit`, because you can just upload in bursts when the uploading resumes. _Note: The keywords or phrases that are used to monitor the ban, and the duration of the sleep time, can be changed at any time by editing the `config.json` file._ Cloudplow can also use service accounts to upload and work around this limitation. Config \u00b6 Note that this is an extract from the cloudplow docs and does not cover everythign that cloudplow can do. Please refer to the Cloudplow github for complete details on available options. Default config.json file \u00b6 See Example Cloudplow configs . Location \u00b6 /opt/cloudplow/config.json Note: Config changes require a restart: sudo systemctl restart cloudplow . Editing \u00b6 Edit in your favorite code editor (with json highlighting) or even a unix editor like nano. nano /opt/cloudplow/config.json Note: The cloudplow config file is a JSON file. JSON files have a particular format and syntax. If you are unfamiliar with JSON formatting and syntax, don't edit this file until you have gained that familiarity. Here's a random YouTube video that will give you a ten-minute overview. Modify Upload Threshold and Interval \u00b6 \"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : false , \"max_size_gb\" : 200 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] } \"check_interval\": How often (in minutes) Cloudplow checks the size of /mnt/local/Media . \"max_size_gb\": Max size (in GB) Cloudplow allows /mnt/local/Media to get before starting an upload task. Note: max_size_gb is rounded up, so it is advised to have it minimum 2GB or else it would attempt upload at each interval. Explanation below. 1GB is basically anything in there. 2GB is at least 1GB of data. Plex Integration \u00b6 Cloudplow can throttle Rclone uploads during active, playing Plex streams (paused streams are ignored). \"plex\" : { \"enabled\" : false , \"url\" : \"https://plex.domain.com\" , \"token\" : \"YOUR_TOKEN_HERE\" , \"poll_interval\" : 60 , \"max_streams_before_throttle\" : 1 , \"rclone\" : { \"throttle_speeds\" : { \"0\" : \"1000M\" , \"1\" : \"50M\" , \"2\" : \"40M\" , \"3\" : \"30M\" , \"4\" : \"20M\" , \"5\" : \"10M\" }, \"url\" : \"http://localhost:7949\" } } enabled - Change false to true to enable. url - Your Plex URL. token - Your Plex Access Token . poll_interval - How often (in seconds) Plex is checked for active streams. max_streams_before_throttle - How many playing streams are allowed before enabling throttling. rclone url - Leave as default. throttle_speeds - Categorized option to configure upload speeds for various stream counts (where 5 represents 5 or more streams). M is MB/s. Format: \"STREAM COUNT\" : \"THROTTLED UPLOAD SPEED\" , NZBget Integration \u00b6 Cloudplow can pause the NZBGet download queue when an upload starts; and then resume it upon the upload finishing. \"nzbget\" : { \"enabled\" : false , \"url\" : \"https://user:pass@nzbget.domain.com\" }, enabled - true to enable. Sabnzbd Integration \u00b6 Cloudplow can pause the Sabnzbd download queue when an upload starts; and then resume it upon the upload finishing. \"sabnzbd\" : { \"enabled\" : false , \"url\" : \"https://sabnzbd.domain.com\" \"apikey\" : \"1314234234\" }, enabled - true to enable. Service account uploading \u00b6 You can tell cloudplow to use a set of service accounts when uploading to Google Drive to go past hte daily 750G upload limit. Details are available here , but in a nutshell you will add the service_account_path to the uploader: \"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 500 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ], \"service_account_path\" : \"/home/user/config/cloudplow/service_accounts/\" } } If you used the saltbox scripted rclone setup, there is a script that will make these changes for you described here . Restart \u00b6 Restart Cloudplow to apply the changes to the config. sudo systemctl restart cloudplow Logs and status \u00b6 Details here CLI \u00b6 You can run a manual Cloudplow task from anywhere by just using the cloudplow command. Manual Upload \u00b6 To start uploading right away, regardless of what the folder size is: cloudplow upload","title":"Cloudplow"},{"location":"apps/cloudplow/#what-is-it","text":"Cloudplow (CP) is a script created by l3uddz that has one main component as relates to Saltbox: it's an uploader to Rclone remote. Files are moved off local storage. With support for multiple uploaders (i.e. remote/folder pairings). Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/cloudplow/#remote-uploader-function","text":"As setup for Saltbox, Cloudplow uploads all the content in /mnt/local/Media/ (see Paths ) to your cloud storage provider (e.g. Google Drive), after the folder reaches a 200 GB size threshold, when checked every 30 minutes. Note: The size threshold and the check interval can be changed via steps mentioned on this page. Google Drive Daily Upload Limit (click to expand) Google Drive has a max upload limit of about 750GB per day. When this limit is reached, Google Drive will put you in a 24 hour soft ban. When Cloudplow detects this (with the phrase `Failed to copy: googleapi: Error 403: User rate limit exceeded`), uploading will be suspended for 25 hours (i.e. a 25 hour ban sleep), and upon waking up, it will resume its checking and uploading tasks. This feature is enabled by default. This method is better than running Rclone task with a `bwlimit`, because you can just upload in bursts when the uploading resumes. _Note: The keywords or phrases that are used to monitor the ban, and the duration of the sleep time, can be changed at any time by editing the `config.json` file._ Cloudplow can also use service accounts to upload and work around this limitation.","title":"Remote Uploader Function"},{"location":"apps/cloudplow/#config","text":"Note that this is an extract from the cloudplow docs and does not cover everythign that cloudplow can do. Please refer to the Cloudplow github for complete details on available options.","title":"Config"},{"location":"apps/cloudplow/#default-configjson-file","text":"See Example Cloudplow configs .","title":"Default config.json file"},{"location":"apps/cloudplow/#location","text":"/opt/cloudplow/config.json Note: Config changes require a restart: sudo systemctl restart cloudplow .","title":"Location"},{"location":"apps/cloudplow/#editing","text":"Edit in your favorite code editor (with json highlighting) or even a unix editor like nano. nano /opt/cloudplow/config.json Note: The cloudplow config file is a JSON file. JSON files have a particular format and syntax. If you are unfamiliar with JSON formatting and syntax, don't edit this file until you have gained that familiarity. Here's a random YouTube video that will give you a ten-minute overview.","title":"Editing"},{"location":"apps/cloudplow/#modify-upload-threshold-and-interval","text":"\"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : false , \"max_size_gb\" : 200 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] } \"check_interval\": How often (in minutes) Cloudplow checks the size of /mnt/local/Media . \"max_size_gb\": Max size (in GB) Cloudplow allows /mnt/local/Media to get before starting an upload task. Note: max_size_gb is rounded up, so it is advised to have it minimum 2GB or else it would attempt upload at each interval. Explanation below. 1GB is basically anything in there. 2GB is at least 1GB of data.","title":"Modify Upload Threshold and Interval"},{"location":"apps/cloudplow/#plex-integration","text":"Cloudplow can throttle Rclone uploads during active, playing Plex streams (paused streams are ignored). \"plex\" : { \"enabled\" : false , \"url\" : \"https://plex.domain.com\" , \"token\" : \"YOUR_TOKEN_HERE\" , \"poll_interval\" : 60 , \"max_streams_before_throttle\" : 1 , \"rclone\" : { \"throttle_speeds\" : { \"0\" : \"1000M\" , \"1\" : \"50M\" , \"2\" : \"40M\" , \"3\" : \"30M\" , \"4\" : \"20M\" , \"5\" : \"10M\" }, \"url\" : \"http://localhost:7949\" } } enabled - Change false to true to enable. url - Your Plex URL. token - Your Plex Access Token . poll_interval - How often (in seconds) Plex is checked for active streams. max_streams_before_throttle - How many playing streams are allowed before enabling throttling. rclone url - Leave as default. throttle_speeds - Categorized option to configure upload speeds for various stream counts (where 5 represents 5 or more streams). M is MB/s. Format: \"STREAM COUNT\" : \"THROTTLED UPLOAD SPEED\" ,","title":"Plex Integration"},{"location":"apps/cloudplow/#nzbget-integration","text":"Cloudplow can pause the NZBGet download queue when an upload starts; and then resume it upon the upload finishing. \"nzbget\" : { \"enabled\" : false , \"url\" : \"https://user:pass@nzbget.domain.com\" }, enabled - true to enable.","title":"NZBget Integration"},{"location":"apps/cloudplow/#sabnzbd-integration","text":"Cloudplow can pause the Sabnzbd download queue when an upload starts; and then resume it upon the upload finishing. \"sabnzbd\" : { \"enabled\" : false , \"url\" : \"https://sabnzbd.domain.com\" \"apikey\" : \"1314234234\" }, enabled - true to enable.","title":"Sabnzbd Integration"},{"location":"apps/cloudplow/#service-account-uploading","text":"You can tell cloudplow to use a set of service accounts when uploading to Google Drive to go past hte daily 750G upload limit. Details are available here , but in a nutshell you will add the service_account_path to the uploader: \"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 500 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ], \"service_account_path\" : \"/home/user/config/cloudplow/service_accounts/\" } } If you used the saltbox scripted rclone setup, there is a script that will make these changes for you described here .","title":"Service account uploading"},{"location":"apps/cloudplow/#restart","text":"Restart Cloudplow to apply the changes to the config. sudo systemctl restart cloudplow","title":"Restart"},{"location":"apps/cloudplow/#logs-and-status","text":"Details here","title":"Logs and status"},{"location":"apps/cloudplow/#cli","text":"You can run a manual Cloudplow task from anywhere by just using the cloudplow command.","title":"CLI"},{"location":"apps/cloudplow/#manual-upload","text":"To start uploading right away, regardless of what the folder size is: cloudplow upload","title":"Manual Upload"},{"location":"apps/deluge/","text":"Deluge \u00b6 What is it? \u00b6 Deluge is a torrent client that can be used as an alternative to rutorrent. Details Project home Docs Github Docker 1. Installation \u00b6 sb install deluge 2. URL \u00b6 To access Deluge, visit https://deluge._yourdomain.com_ Info default login user : admin password : deluge 3. Setup \u00b6 Change login password. Click Preferences in the top bar and on the Downloads section enter the following paths: Download to: /mnt/unionfs/downloads/torrents/deluge/incoming Move completed to: /mnt/unionfs/downloads/torrents/deluge/completed Autoadd .torrent files from: /mnt/unionfs/downloads/torrents/deluge/watched Select Network section, uncheck Use Random Ports under Incoming Ports and set both input fields to 58112 . Click the Plugins section enable the labels plugin. enable and the Extractor plugin. In order for Sonarr or Radarr to import media packaged within .rar files, they will have to be extracted. After clicking \"Apply\" , select the Extractor plugin on the left. Make sure the directory points to the completed folder within your Deluge data directory. /mnt/unionfs/downloads/torrents/deluge/completed Also, make sure that the Create torrent name sub-folder setting is checked. 4. Adding to Sonarr/Radarr \u00b6 To add Deluge as a download client in Sonarr/Radarr use the following settings. Both are able to remove completed torrents after they have finished seeding. Documentation","title":"Deluge"},{"location":"apps/deluge/#deluge","text":"","title":"Deluge"},{"location":"apps/deluge/#what-is-it","text":"Deluge is a torrent client that can be used as an alternative to rutorrent. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/deluge/#1-installation","text":"sb install deluge","title":"1. Installation"},{"location":"apps/deluge/#2-url","text":"To access Deluge, visit https://deluge._yourdomain.com_ Info default login user : admin password : deluge","title":"2. URL"},{"location":"apps/deluge/#3-setup","text":"Change login password. Click Preferences in the top bar and on the Downloads section enter the following paths: Download to: /mnt/unionfs/downloads/torrents/deluge/incoming Move completed to: /mnt/unionfs/downloads/torrents/deluge/completed Autoadd .torrent files from: /mnt/unionfs/downloads/torrents/deluge/watched Select Network section, uncheck Use Random Ports under Incoming Ports and set both input fields to 58112 . Click the Plugins section enable the labels plugin. enable and the Extractor plugin. In order for Sonarr or Radarr to import media packaged within .rar files, they will have to be extracted. After clicking \"Apply\" , select the Extractor plugin on the left. Make sure the directory points to the completed folder within your Deluge data directory. /mnt/unionfs/downloads/torrents/deluge/completed Also, make sure that the Create torrent name sub-folder setting is checked.","title":"3. Setup"},{"location":"apps/deluge/#4-adding-to-sonarrradarr","text":"To add Deluge as a download client in Sonarr/Radarr use the following settings. Both are able to remove completed torrents after they have finished seeding. Documentation","title":"4. Adding to Sonarr/Radarr"},{"location":"apps/diun/","text":"diun \u00b6 What is it? \u00b6 diun Docker Image Update Notifier is a CLI application written in Go and delivered as a single executable (and a Docker image) to receive notifications when a Docker image is updated on a Docker registry. Details Project home Docs Github Docker 1. Installation \u00b6 sb install diun 2. Setup \u00b6 The config file for diun is located at /opt/diun/diun.yml Documentation: diun Docs","title":"diun"},{"location":"apps/diun/#diun","text":"","title":"diun"},{"location":"apps/diun/#what-is-it","text":"diun Docker Image Update Notifier is a CLI application written in Go and delivered as a single executable (and a Docker image) to receive notifications when a Docker image is updated on a Docker registry. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/diun/#1-installation","text":"sb install diun","title":"1. Installation"},{"location":"apps/diun/#2-setup","text":"The config file for diun is located at /opt/diun/diun.yml Documentation: diun Docs","title":"2. Setup"},{"location":"apps/emby/","text":"What is it? \u00b6 Emby is a media server designed to organize, play, and stream audio and video to a variety of devices Details Project home Docs Github Docker 1. Introduction \u00b6 2. URL \u00b6 To access Emby, visit https://emby._yourdomain.com_ 3. Initial Setup \u00b6 i. Domain \u00b6 See Adding a Subdomain on how to add the subdomain emby to your DNS provider. Note: You can skip this step if you are using Cloudflare with Saltbox. ii. Install \u00b6 Run the following command: sb install emby 4. Setup Wizard \u00b6 Visit https://emby._yourdomain.com_ . Select your preferred display language . Click Next . ) Type the following and click Next : Username: The username you wwant to use to log into Emby New Password: A strong password you'll use to log into Emby New Password Confirm: That same password again Emby connect username or email address : your Emby Connect username (important) Confirm the message by clicking Got It . Confirm the link in your email. Skip the adding of the libraries. Click Next . Select your Preferred Metadata Language and Country ( English and United States are recommended ) and click Next . Uncheck Enable automatic port mapping . Click Next . Check to accept the terms. Click Next . Click Finish . You will now be taken to the Dashboard view. 5. Settings \u00b6 i. Transcoding \u00b6 Go to Settings . Go to Transcoding . Under Enable hardware acceleration when available , select Advanced . Under Transcoding temporary path , type in or choose /transcode . Click Save . iii. Libraries \u00b6 In this section, we will add two libraries: one for Movies and one for TV Shows. Add Movie Library \u00b6 Go to Settings . Go to Library . Click + New Library . Under Content type , select Movies . Click + next to Folders . Type in or choose /mnt/unionfs/Media/Movies . Click OK . Note: These paths are for the standard library setup. If you have customized it, use those paths instead. Click OK once more. Add TV Shows Library \u00b6 Go to Settings . Go to Library . Click + New Library . Under Content type , select TV shows . Click + next to Folders . Type in or choose /mnt/unionfs/Media/TV . Click OK . Note: These paths are for the standard library setup. If you have customized it, use those paths instead. Click OK once more. 6. API Key \u00b6 Instructions below will guide you through creating an API Key for a specific app. Click the Settings icon. Under Advanced , click API Keys . Click + New API Key . Fill in an App name (e.g. Ombi) and click OK . You have now have created an Api Key for your app.","title":"Emby"},{"location":"apps/emby/#what-is-it","text":"Emby is a media server designed to organize, play, and stream audio and video to a variety of devices Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/emby/#1-introduction","text":"","title":"1. Introduction"},{"location":"apps/emby/#2-url","text":"To access Emby, visit https://emby._yourdomain.com_","title":"2. URL"},{"location":"apps/emby/#3-initial-setup","text":"","title":"3. Initial Setup"},{"location":"apps/emby/#i-domain","text":"See Adding a Subdomain on how to add the subdomain emby to your DNS provider. Note: You can skip this step if you are using Cloudflare with Saltbox.","title":"i. Domain"},{"location":"apps/emby/#ii-install","text":"Run the following command: sb install emby","title":"ii. Install"},{"location":"apps/emby/#4-setup-wizard","text":"Visit https://emby._yourdomain.com_ . Select your preferred display language . Click Next . ) Type the following and click Next : Username: The username you wwant to use to log into Emby New Password: A strong password you'll use to log into Emby New Password Confirm: That same password again Emby connect username or email address : your Emby Connect username (important) Confirm the message by clicking Got It . Confirm the link in your email. Skip the adding of the libraries. Click Next . Select your Preferred Metadata Language and Country ( English and United States are recommended ) and click Next . Uncheck Enable automatic port mapping . Click Next . Check to accept the terms. Click Next . Click Finish . You will now be taken to the Dashboard view.","title":"4. Setup Wizard"},{"location":"apps/emby/#5-settings","text":"","title":"5. Settings"},{"location":"apps/emby/#i-transcoding","text":"Go to Settings . Go to Transcoding . Under Enable hardware acceleration when available , select Advanced . Under Transcoding temporary path , type in or choose /transcode . Click Save .","title":"i. Transcoding"},{"location":"apps/emby/#iii-libraries","text":"In this section, we will add two libraries: one for Movies and one for TV Shows.","title":"iii. Libraries"},{"location":"apps/emby/#add-movie-library","text":"Go to Settings . Go to Library . Click + New Library . Under Content type , select Movies . Click + next to Folders . Type in or choose /mnt/unionfs/Media/Movies . Click OK . Note: These paths are for the standard library setup. If you have customized it, use those paths instead. Click OK once more.","title":"Add Movie Library"},{"location":"apps/emby/#add-tv-shows-library","text":"Go to Settings . Go to Library . Click + New Library . Under Content type , select TV shows . Click + next to Folders . Type in or choose /mnt/unionfs/Media/TV . Click OK . Note: These paths are for the standard library setup. If you have customized it, use those paths instead. Click OK once more.","title":"Add TV Shows Library"},{"location":"apps/emby/#6-api-key","text":"Instructions below will guide you through creating an API Key for a specific app. Click the Settings icon. Under Advanced , click API Keys . Click + New API Key . Fill in an App name (e.g. Ombi) and click OK . You have now have created an Api Key for your app.","title":"6. API Key"},{"location":"apps/hetzner_nfs/","text":"Hetzner NFS VLAN \u00b6 What is it? \u00b6 Connect 2+ servers hosted on Hetzner using NFS and VLAN. Note 1: This comes with no support other than the instructions provided here. Note 2: This setup has been tested to work with standard Unionfs/Rclone VFS setup. Using either MergerFS or any non-standard setup will require you to tweak the appropriate mounts. You can look at the roles to see what changes need to be done. 1. Installation \u00b6 In this example, we'll set our Feederbox as the NFS server and our Mediabox as the NFS client - this is so that the feeder data can be available to the media server. There are 3 phases to the setup. They are broken down below. Hetzner Robot \u00b6 Log into Hetzner Robot . Create a VLAN ( vSwitch ) and add servers to it. Note the VLAN ID. Setup Firewall. Mediabox: Feederbox: NFS Server (Feederbox) \u00b6 Setup the Ansible role config. Add vlan_id . mount_client setting is ignored for the NFS server (i.e. it will just use 2 ). nano /opt/community/hetzner_nfs.yml hetzner_nfs : vlan_id : 4001 mount_client : 3 Run Ansible role to configure the NFS server. sb install hetzner_nfs_server NFS Client (Mediabox) \u00b6 Setup the Ansible role config. Add vlan_id . Add mount_client . Note: mount_client will need to be either 3 or a number > 250 . nano /opt/community/hetzner_nfs.yml hetzner_nfs : vlan_id : 4001 mount_client : 3 Run Ansible role to configure the NFS client. sb install hetzner_nfs_server Uninstall \u00b6 Simply run the following commands on their respective servers: NFS Server (Feederbox) \u00b6 sb install hetzner_nfs_server_uninstall NFS Client (Mediabox) \u00b6 sb install hetzner_nfs_client_unmount","title":"Hetzner NFS"},{"location":"apps/hetzner_nfs/#hetzner-nfs-vlan","text":"","title":"Hetzner NFS VLAN"},{"location":"apps/hetzner_nfs/#what-is-it","text":"Connect 2+ servers hosted on Hetzner using NFS and VLAN. Note 1: This comes with no support other than the instructions provided here. Note 2: This setup has been tested to work with standard Unionfs/Rclone VFS setup. Using either MergerFS or any non-standard setup will require you to tweak the appropriate mounts. You can look at the roles to see what changes need to be done.","title":"What is it?"},{"location":"apps/hetzner_nfs/#1-installation","text":"In this example, we'll set our Feederbox as the NFS server and our Mediabox as the NFS client - this is so that the feeder data can be available to the media server. There are 3 phases to the setup. They are broken down below.","title":"1. Installation"},{"location":"apps/hetzner_nfs/#hetzner-robot","text":"Log into Hetzner Robot . Create a VLAN ( vSwitch ) and add servers to it. Note the VLAN ID. Setup Firewall. Mediabox: Feederbox:","title":"Hetzner Robot"},{"location":"apps/hetzner_nfs/#nfs-server-feederbox","text":"Setup the Ansible role config. Add vlan_id . mount_client setting is ignored for the NFS server (i.e. it will just use 2 ). nano /opt/community/hetzner_nfs.yml hetzner_nfs : vlan_id : 4001 mount_client : 3 Run Ansible role to configure the NFS server. sb install hetzner_nfs_server","title":"NFS Server (Feederbox)"},{"location":"apps/hetzner_nfs/#nfs-client-mediabox","text":"Setup the Ansible role config. Add vlan_id . Add mount_client . Note: mount_client will need to be either 3 or a number > 250 . nano /opt/community/hetzner_nfs.yml hetzner_nfs : vlan_id : 4001 mount_client : 3 Run Ansible role to configure the NFS client. sb install hetzner_nfs_server","title":"NFS Client (Mediabox)"},{"location":"apps/hetzner_nfs/#uninstall","text":"Simply run the following commands on their respective servers:","title":"Uninstall"},{"location":"apps/hetzner_nfs/#nfs-server-feederbox_1","text":"sb install hetzner_nfs_server_uninstall","title":"NFS Server (Feederbox)"},{"location":"apps/hetzner_nfs/#nfs-client-mediabox_1","text":"sb install hetzner_nfs_client_unmount","title":"NFS Client (Mediabox)"},{"location":"apps/jackett/","text":"What is it? \u00b6 Jackett (based on the original work of Matthew Little aka zone117x ) is a web-based app that acts like a proxy server, directing search queries from download clients (e.g. Sonarr) to torrent tracker sites and sending the results back. Download clients can also use Jackett to fetch RSS feeds from tracker sites. Finally, it can be used as a meta search tool to find torrents, right from within the app. Details Project home Docs Github Docker Note: If you don't use torrents, you may just skip this page. 1. URL \u00b6 To access Jackett, visit http://jackett._yourdomain.com_ 2. Settings \u00b6 Disabling Auto Update \u00b6 Under \"Jackett Configuration\": Check \"Disable auto update\". Check \"External access\". Click \"Apply server settings\". The page will now reload. 3. Adding Indexers to Sonarr/Radarr \u00b6 Under \"Configured Indexers\": Click \"Add Indexer\" to add your favorite indexers (i.e. torrent trackers ). When adding indexers into Sonarr / Radarr , you will need: Indexer's Torznab Feed Copy this by clicking on \"Copy Torznab Feed\" button next to the Indexer. You will need to replace... https with http jackett.yourdomain.com with jackett:9117 Jacket API Key 4. Next \u00b6 Are you setting Saltbox up for the first time? Continue to Plex Media Server .","title":"Jackett"},{"location":"apps/jackett/#what-is-it","text":"Jackett (based on the original work of Matthew Little aka zone117x ) is a web-based app that acts like a proxy server, directing search queries from download clients (e.g. Sonarr) to torrent tracker sites and sending the results back. Download clients can also use Jackett to fetch RSS feeds from tracker sites. Finally, it can be used as a meta search tool to find torrents, right from within the app. Details Project home Docs Github Docker Note: If you don't use torrents, you may just skip this page.","title":"What is it?"},{"location":"apps/jackett/#1-url","text":"To access Jackett, visit http://jackett._yourdomain.com_","title":"1. URL"},{"location":"apps/jackett/#2-settings","text":"","title":"2. Settings"},{"location":"apps/jackett/#disabling-auto-update","text":"Under \"Jackett Configuration\": Check \"Disable auto update\". Check \"External access\". Click \"Apply server settings\". The page will now reload.","title":"Disabling Auto Update"},{"location":"apps/jackett/#3-adding-indexers-to-sonarrradarr","text":"Under \"Configured Indexers\": Click \"Add Indexer\" to add your favorite indexers (i.e. torrent trackers ). When adding indexers into Sonarr / Radarr , you will need: Indexer's Torznab Feed Copy this by clicking on \"Copy Torznab Feed\" button next to the Indexer. You will need to replace... https with http jackett.yourdomain.com with jackett:9117 Jacket API Key","title":"3. Adding Indexers to Sonarr/Radarr"},{"location":"apps/jackett/#4-next","text":"Are you setting Saltbox up for the first time? Continue to Plex Media Server .","title":"4. Next"},{"location":"apps/jellyfin/","text":"Jellyfin \u00b6 What is it? \u00b6 Jellyfin is the volunteer-built media solution that puts you in control of your media. Stream to any device from your own server, with no strings attached. Your media, your server, your way. Details Project home Docs Github Docker 1. Installation \u00b6 sb install jellyfin 2. URL \u00b6 To access Jellyfin, visit https://jellyfin._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Jellyfin"},{"location":"apps/jellyfin/#jellyfin","text":"","title":"Jellyfin"},{"location":"apps/jellyfin/#what-is-it","text":"Jellyfin is the volunteer-built media solution that puts you in control of your media. Stream to any device from your own server, with no strings attached. Your media, your server, your way. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/jellyfin/#1-installation","text":"sb install jellyfin","title":"1. Installation"},{"location":"apps/jellyfin/#2-url","text":"To access Jellyfin, visit https://jellyfin._yourdomain.com_","title":"2. URL"},{"location":"apps/jellyfin/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"apps/lidarr/","text":"What is it? \u00b6 Lidarr is basically Sonarr for music. It functions as a music collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds from Bittorrent trackers and Usenet Indexers, looking for new tracks from your favorite artists and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available. Details Project home Docs Github Docker URL \u00b6 To access Lidarr, visit https://lidarr._yourdomain.com_ Settings \u00b6 Click on \"Settings\" in the sidebar. Click \"Show Advanced\" at the top of the Settings pane. Make changes in the following sections: Settings Media Management Indexers Download Clients Connect General These settings control management of media files. Movie Naming Folders Importing File Management Permissions Save \"Rename Tracks\": Yes \"Replace Illegal Characters\": Yes Set your preferred naming format; here are some examples. Plex's Naming Preference Example: 01 - Shine On You Crazy Diamond (Parts I-V).m4a Standard Track Format: {track:00} - {Track Title} Artist Folder Format: {Artist Name} Album Folder Format: {Artist Name} - {Album Title} Reference: https://support.plex.tv/articles/categories/media-preparation/naming-and-organizing-music-media/ \"Create empty artist folders\": No \"Delete empty folders\": No \"Skip Free Space Check\": No \"Minimum Free Space\": 100 ( can be your preference so long as you use a reasonable value ) \"Use Hardlinks instead of Copy\": Yes \"Import Extra Files\": Yes ( can be your preference ) \"Extra File Extensions\": srt ( can be your preference ) \"Ignore Deleted Tracks\": No ( can be your preference ) \"Propers and Repacks\": Prefer and Upgrade ( can be your preference ) \"Watch Root Folders for file changes\": 'Yes' \"Rescan Artist Folder after Refresh\": Never \"Allow Fingerprinting\": For new imports only \"Change File Date\": Album Release Date ( can be your preference ) \"Recycle Bin\": blank (Rclone deletes are sent to Gdrive trash folder, anyway) \"Recycling Bin Cleanup\": '0' Set Permissions: No Click \"Save\". These settings control indexers and related behavior. NZBHydra2 Jackett Click Add Indexer ( + ). Select \"Newznab\". Add the following: Name: NZBHydra2 Enable RSS Sync: Your Preference Enable Automatic Search: Your Preference Enable Interactive Search: Your Preference URL: http://nzbhydra2:5076 API Key: Your NZBHydra2 API Key Early Download Limit: Your Preference Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add NZBHydra2. Note: The \"Test\" will keep failing until you add an indexer in NZBHydra2 . Note: Each Indexer you have defined in Jackett will need to be added separately. Click Add Indexer ( + ) Select \"Torznab\". Add the following: Name: Indexer Name Enable RSS Sync: Your Preference Enable Automatic Search: Your Preference Enable Interactive Search: Your Preference URL: Indexer's Torznab Feed API Key: Your Jackett API Key Early Download Limit: Your Preference Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add the indexer. These settings control downloading behavior and clients. Completed Download Handling Failed Download Handling NZBGet ruTorrent qBittorrent \"Enable\": Yes \"Remove\": Yes ( can be your preference ) \"Redownload\": Yes \"Remove\": Yes Click Add ( + ) Add a new \"NZBGet\" download client. Add the following: Name: NZBGet Enable: Yes Host: nzbget Port: 6789 Username: Your NZBGet Username Password: Your NZBGet Password Category: lidarr Use SSL: No Add Paused: No Your settings will look like this: Click \"Save\" to add NZBGet. Click Add ( + ) Add a new \"rTorrent\" download client. Add the following: Name: ruTorrent Enable: Yes Host: rutorrent Port: 80 URL Path: RPC2 Use SSL: No Username: Your ruTorrent Username Password: Your ruTorrent Password Category: lidarr Directory: Leave Blank Your settings will now look like this: Click \"Save\" to add ruTorrent. Click Add ('+') Add a new \"qBittorrent\" download client. Add the following: Name: qBittorrent Enable: 'Yes' Host: 'qBittorrent' Port: '8080' Username: Your qBittorrent Username Password: Your qBittorrent Password Category: 'lidarr' Your settings will now look like this: Click \"Save\" to add qBittorrent qb These settings control connections to other applications or systems. Torrent Cleanup Autoscan Torrent Cleanup Script is a custom script that will clean up torrents from ruTorrent that were auto-extracted, but still being seeded. So if the script detects that .rar files are in the folder that Radarr just imported from, it will delete the imported audio file(s), leaving just the .rar files for seeding. Click \"Settings\" -> \"Connect\". Add a new \"Custom Script\". Add the following: Name: Torrent Cleanup On Grab: No On Release Import: Yes On Upgrade: Yes On Rename: No Path: /scripts/torrents/TorrentCleanup.py The settings will look like this: Click \"Save\" to add the Torrent Cleanup script. Click \"Settings\" -> \"Connect\". Add a new \"Webhook\". Add the following: Name: Autoscan On Grab: No On Release Import: Yes On Upgrade: Yes On Rename: Yes On Track Retag: No On Health Issue: No Tags: Leave Blank URL: http://autoscan:3030/triggers/lidarr Method: POST Username: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] Password: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] The settings will look like this: Click \"Save\" to add Autoscan. These settings control general aspects of Radarr. Start-Up Proxy Settings Logging Analytics Updates Save \"Bind Address: * \"Port Number\": 8686 \"URL Base\": blank \"Enable SSL\": No ( SSL is handled by Traefik ) \"Open browser on start\": No \"Use Proxy\": No \"Log Level\": Debug \"Send Anonymous Usage Data\": No ( your preference ) \"Branch\": develop \"Automatic\": Off Click \"Save\". Music Path \u00b6 When you are ready to add your first artist to Lidarr, click the \"Path\" drop-down and select \"Add a different path\". Click the blue \"Browse\" button, navigate to /mnt/unionfs/Media/Music , scroll to the bottom, and select \"OK\". Click the green \"check\" button to add the path. All artists added now will have that path set. API Key \u00b6 This is used during the setup of Organizr . Go to \"Settings\" -> \"General\" -> \"Security\" -> \"API Key\". Next \u00b6 Are you setting Saltbox up for the first time? Continue to Tautulli .","title":"Lidarr"},{"location":"apps/lidarr/#what-is-it","text":"Lidarr is basically Sonarr for music. It functions as a music collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds from Bittorrent trackers and Usenet Indexers, looking for new tracks from your favorite artists and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/lidarr/#url","text":"To access Lidarr, visit https://lidarr._yourdomain.com_","title":"URL"},{"location":"apps/lidarr/#settings","text":"Click on \"Settings\" in the sidebar. Click \"Show Advanced\" at the top of the Settings pane. Make changes in the following sections: Settings Media Management Indexers Download Clients Connect General These settings control management of media files. Movie Naming Folders Importing File Management Permissions Save \"Rename Tracks\": Yes \"Replace Illegal Characters\": Yes Set your preferred naming format; here are some examples. Plex's Naming Preference Example: 01 - Shine On You Crazy Diamond (Parts I-V).m4a Standard Track Format: {track:00} - {Track Title} Artist Folder Format: {Artist Name} Album Folder Format: {Artist Name} - {Album Title} Reference: https://support.plex.tv/articles/categories/media-preparation/naming-and-organizing-music-media/ \"Create empty artist folders\": No \"Delete empty folders\": No \"Skip Free Space Check\": No \"Minimum Free Space\": 100 ( can be your preference so long as you use a reasonable value ) \"Use Hardlinks instead of Copy\": Yes \"Import Extra Files\": Yes ( can be your preference ) \"Extra File Extensions\": srt ( can be your preference ) \"Ignore Deleted Tracks\": No ( can be your preference ) \"Propers and Repacks\": Prefer and Upgrade ( can be your preference ) \"Watch Root Folders for file changes\": 'Yes' \"Rescan Artist Folder after Refresh\": Never \"Allow Fingerprinting\": For new imports only \"Change File Date\": Album Release Date ( can be your preference ) \"Recycle Bin\": blank (Rclone deletes are sent to Gdrive trash folder, anyway) \"Recycling Bin Cleanup\": '0' Set Permissions: No Click \"Save\". These settings control indexers and related behavior. NZBHydra2 Jackett Click Add Indexer ( + ). Select \"Newznab\". Add the following: Name: NZBHydra2 Enable RSS Sync: Your Preference Enable Automatic Search: Your Preference Enable Interactive Search: Your Preference URL: http://nzbhydra2:5076 API Key: Your NZBHydra2 API Key Early Download Limit: Your Preference Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add NZBHydra2. Note: The \"Test\" will keep failing until you add an indexer in NZBHydra2 . Note: Each Indexer you have defined in Jackett will need to be added separately. Click Add Indexer ( + ) Select \"Torznab\". Add the following: Name: Indexer Name Enable RSS Sync: Your Preference Enable Automatic Search: Your Preference Enable Interactive Search: Your Preference URL: Indexer's Torznab Feed API Key: Your Jackett API Key Early Download Limit: Your Preference Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add the indexer. These settings control downloading behavior and clients. Completed Download Handling Failed Download Handling NZBGet ruTorrent qBittorrent \"Enable\": Yes \"Remove\": Yes ( can be your preference ) \"Redownload\": Yes \"Remove\": Yes Click Add ( + ) Add a new \"NZBGet\" download client. Add the following: Name: NZBGet Enable: Yes Host: nzbget Port: 6789 Username: Your NZBGet Username Password: Your NZBGet Password Category: lidarr Use SSL: No Add Paused: No Your settings will look like this: Click \"Save\" to add NZBGet. Click Add ( + ) Add a new \"rTorrent\" download client. Add the following: Name: ruTorrent Enable: Yes Host: rutorrent Port: 80 URL Path: RPC2 Use SSL: No Username: Your ruTorrent Username Password: Your ruTorrent Password Category: lidarr Directory: Leave Blank Your settings will now look like this: Click \"Save\" to add ruTorrent. Click Add ('+') Add a new \"qBittorrent\" download client. Add the following: Name: qBittorrent Enable: 'Yes' Host: 'qBittorrent' Port: '8080' Username: Your qBittorrent Username Password: Your qBittorrent Password Category: 'lidarr' Your settings will now look like this: Click \"Save\" to add qBittorrent qb These settings control connections to other applications or systems. Torrent Cleanup Autoscan Torrent Cleanup Script is a custom script that will clean up torrents from ruTorrent that were auto-extracted, but still being seeded. So if the script detects that .rar files are in the folder that Radarr just imported from, it will delete the imported audio file(s), leaving just the .rar files for seeding. Click \"Settings\" -> \"Connect\". Add a new \"Custom Script\". Add the following: Name: Torrent Cleanup On Grab: No On Release Import: Yes On Upgrade: Yes On Rename: No Path: /scripts/torrents/TorrentCleanup.py The settings will look like this: Click \"Save\" to add the Torrent Cleanup script. Click \"Settings\" -> \"Connect\". Add a new \"Webhook\". Add the following: Name: Autoscan On Grab: No On Release Import: Yes On Upgrade: Yes On Rename: Yes On Track Retag: No On Health Issue: No Tags: Leave Blank URL: http://autoscan:3030/triggers/lidarr Method: POST Username: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] Password: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] The settings will look like this: Click \"Save\" to add Autoscan. These settings control general aspects of Radarr. Start-Up Proxy Settings Logging Analytics Updates Save \"Bind Address: * \"Port Number\": 8686 \"URL Base\": blank \"Enable SSL\": No ( SSL is handled by Traefik ) \"Open browser on start\": No \"Use Proxy\": No \"Log Level\": Debug \"Send Anonymous Usage Data\": No ( your preference ) \"Branch\": develop \"Automatic\": Off Click \"Save\".","title":"Settings"},{"location":"apps/lidarr/#music-path","text":"When you are ready to add your first artist to Lidarr, click the \"Path\" drop-down and select \"Add a different path\". Click the blue \"Browse\" button, navigate to /mnt/unionfs/Media/Music , scroll to the bottom, and select \"OK\". Click the green \"check\" button to add the path. All artists added now will have that path set.","title":"Music Path"},{"location":"apps/lidarr/#api-key","text":"This is used during the setup of Organizr . Go to \"Settings\" -> \"General\" -> \"Security\" -> \"API Key\".","title":"API Key"},{"location":"apps/lidarr/#next","text":"Are you setting Saltbox up for the first time? Continue to Tautulli .","title":"Next"},{"location":"apps/mariadb/","text":"MariaDB \u00b6 What is it? \u00b6 MariaDB MariaDB Server is one of the most popular open source relational databases. It\u2019s made by the original developers of MySQL and guaranteed to stay open source. Details Project home Docs Github Docker 1. Installation \u00b6 sb install mariadb 2. Setup \u00b6 Info The default password for this container is password321 To easily manage the db, consider adminer Documentation: MariaDB Docs","title":"MariaDB"},{"location":"apps/mariadb/#mariadb","text":"","title":"MariaDB"},{"location":"apps/mariadb/#what-is-it","text":"MariaDB MariaDB Server is one of the most popular open source relational databases. It\u2019s made by the original developers of MySQL and guaranteed to stay open source. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/mariadb/#1-installation","text":"sb install mariadb","title":"1. Installation"},{"location":"apps/mariadb/#2-setup","text":"Info The default password for this container is password321 To easily manage the db, consider adminer Documentation: MariaDB Docs","title":"2. Setup"},{"location":"apps/netdata/","text":"Netdata \u00b6 What is it? \u00b6 Netdata is distributed, real-time, performance and health monitoring for systems and applications. Netdata provides insights, in real-time, of everything happening on the systems it runs (including web servers, databases, applications), using highly interactive web dashboards. It can run autonomously, without any third party components, or it can be integrated to existing monitoring toolchains (Prometheus, Graphite, OpenTSDB, Kafka, Grafana, etc). Netdata is designed to permanently run on all systems (physical & virtual servers, containers, IoT devices), without disrupting their core function. Netdata is free, open-source software. Details Project home Docs Github Docker 1. Installation \u00b6 sb install netdata 2. URL \u00b6 To access Netdata, visit https://netdata._yourdomain.com_ Documentation: Netdata Docs","title":"Netdata"},{"location":"apps/netdata/#netdata","text":"","title":"Netdata"},{"location":"apps/netdata/#what-is-it","text":"Netdata is distributed, real-time, performance and health monitoring for systems and applications. Netdata provides insights, in real-time, of everything happening on the systems it runs (including web servers, databases, applications), using highly interactive web dashboards. It can run autonomously, without any third party components, or it can be integrated to existing monitoring toolchains (Prometheus, Graphite, OpenTSDB, Kafka, Grafana, etc). Netdata is designed to permanently run on all systems (physical & virtual servers, containers, IoT devices), without disrupting their core function. Netdata is free, open-source software. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/netdata/#1-installation","text":"sb install netdata","title":"1. Installation"},{"location":"apps/netdata/#2-url","text":"To access Netdata, visit https://netdata._yourdomain.com_ Documentation: Netdata Docs","title":"2. URL"},{"location":"apps/nzbget/","text":"What is it? \u00b6 NZBGet (by Andrey Prygunkov aka hugbug) is a very efficient, cross-platform usenet downloader. Details Project home Docs Github Docker 1. Accessing NZBGet \u00b6 To access NZBGet, visit https://nzbget._yourdomain.com_ 2. Settings \u00b6 Paths \u00b6 Download paths have already been specified, no need to change those. News-Servers \u00b6 Add your news servers . Security \u00b6 Login settings are preset out of the box ( user / passwd as set in accounts.yml ). Download Queue \u00b6 Disk Space By default, minimum disk space is set at 100000 (i.e. 100GB). When space goes lower than this, NZBGet will pause the queue. If you have a smaller hard drive, you will need to lower this setting. Connection \u00b6 DailyQuota If you set up the 300 service accounts in Rclone you can ignore this. Otherwise it's recommended you set this to 750000 (i.e. 750GB), to coincide with the Google Drive daily upload limit. 3. Extensions \u00b6 Location on server: /opt/scripts/nzbget . Location within NZBGet: /scripts/nzbget . 4. Next \u00b6 Are you setting Saltbox up for the first time? Continue to ruTorrent .","title":"Nzbget"},{"location":"apps/nzbget/#what-is-it","text":"NZBGet (by Andrey Prygunkov aka hugbug) is a very efficient, cross-platform usenet downloader. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/nzbget/#1-accessing-nzbget","text":"To access NZBGet, visit https://nzbget._yourdomain.com_","title":"1. Accessing NZBGet"},{"location":"apps/nzbget/#2-settings","text":"","title":"2. Settings"},{"location":"apps/nzbget/#paths","text":"Download paths have already been specified, no need to change those.","title":"Paths"},{"location":"apps/nzbget/#news-servers","text":"Add your news servers .","title":"News-Servers"},{"location":"apps/nzbget/#security","text":"Login settings are preset out of the box ( user / passwd as set in accounts.yml ).","title":"Security"},{"location":"apps/nzbget/#download-queue","text":"Disk Space By default, minimum disk space is set at 100000 (i.e. 100GB). When space goes lower than this, NZBGet will pause the queue. If you have a smaller hard drive, you will need to lower this setting.","title":"Download Queue"},{"location":"apps/nzbget/#connection","text":"DailyQuota If you set up the 300 service accounts in Rclone you can ignore this. Otherwise it's recommended you set this to 750000 (i.e. 750GB), to coincide with the Google Drive daily upload limit.","title":"Connection"},{"location":"apps/nzbget/#3-extensions","text":"Location on server: /opt/scripts/nzbget . Location within NZBGet: /scripts/nzbget .","title":"3. Extensions"},{"location":"apps/nzbget/#4-next","text":"Are you setting Saltbox up for the first time? Continue to ruTorrent .","title":"4. Next"},{"location":"apps/nzbhydra2/","text":"THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX What is it? \u00b6 NZBHydra2 , by TheOtherP , is a meta search tool for NZB indexers. It provides easy access to a number of NZB indexers. You can search all your indexers from one place and use it as indexer source for tools like Sonarr or CouchPotato. Details Project home Docs Github Docker Three Ways to setup NZB indexers with Sonarr/Radarr/Lidarr: Skip this page and add all your NZB Indexers directly into Sonarr/Radarr/Lidarr. Benefit from the seeing indexer sources during manual lookups in Sonarr/Radarr/Lidarr. This method is also useful when diagnosing issues with indexers during failed searches; Add all your NZB Indexers directly into Sonarr/Radarr/Lidarr, but also add them in NZBHydra2, so it could be used a tool for manual downloads; or Add all your NZB indexers in NZBHydra2 and then just add the one NZBHydra2 \"indexer\" into Sonarr/Radarr/Lidarr. This is the most popular choice among users. To Setup NZBHydra2, follow the steps below. 2. URL \u00b6 URL to access NZBHydra2, visit https://nzbhydra2._yourdomain.com_ 3. Setup \u00b6 Enter setup by clicking on \"Config\" at the top. Main \u00b6 Under 'Security', click the icon next to the 'API key *' field to generate an API key. Click 'Save'. Authorization \u00b6 Login settings are preset out of the box ( user / passwd as set in accounts.yml ). Indexers \u00b6 Add your indexers. Click \"Save\". Downloaders \u00b6 NZBGet settings are preset out of the box. 4. API Key \u00b6 To find the NZBHydra2 API Key, go to \"Config\" --> \"Main\". This will be used later in Sonarr and Radarr . 5. Next \u00b6 Are you setting Saltbox up for the first time? Continue to Jackett .","title":"Nzbhydra2"},{"location":"apps/nzbhydra2/#what-is-it","text":"NZBHydra2 , by TheOtherP , is a meta search tool for NZB indexers. It provides easy access to a number of NZB indexers. You can search all your indexers from one place and use it as indexer source for tools like Sonarr or CouchPotato. Details Project home Docs Github Docker Three Ways to setup NZB indexers with Sonarr/Radarr/Lidarr: Skip this page and add all your NZB Indexers directly into Sonarr/Radarr/Lidarr. Benefit from the seeing indexer sources during manual lookups in Sonarr/Radarr/Lidarr. This method is also useful when diagnosing issues with indexers during failed searches; Add all your NZB Indexers directly into Sonarr/Radarr/Lidarr, but also add them in NZBHydra2, so it could be used a tool for manual downloads; or Add all your NZB indexers in NZBHydra2 and then just add the one NZBHydra2 \"indexer\" into Sonarr/Radarr/Lidarr. This is the most popular choice among users. To Setup NZBHydra2, follow the steps below.","title":"What is it?"},{"location":"apps/nzbhydra2/#2-url","text":"URL to access NZBHydra2, visit https://nzbhydra2._yourdomain.com_","title":"2. URL"},{"location":"apps/nzbhydra2/#3-setup","text":"Enter setup by clicking on \"Config\" at the top.","title":"3. Setup"},{"location":"apps/nzbhydra2/#main","text":"Under 'Security', click the icon next to the 'API key *' field to generate an API key. Click 'Save'.","title":"Main"},{"location":"apps/nzbhydra2/#authorization","text":"Login settings are preset out of the box ( user / passwd as set in accounts.yml ).","title":"Authorization"},{"location":"apps/nzbhydra2/#indexers","text":"Add your indexers. Click \"Save\".","title":"Indexers"},{"location":"apps/nzbhydra2/#downloaders","text":"NZBGet settings are preset out of the box.","title":"Downloaders"},{"location":"apps/nzbhydra2/#4-api-key","text":"To find the NZBHydra2 API Key, go to \"Config\" --> \"Main\". This will be used later in Sonarr and Radarr .","title":"4. API Key"},{"location":"apps/nzbhydra2/#5-next","text":"Are you setting Saltbox up for the first time? Continue to Jackett .","title":"5. Next"},{"location":"apps/organizr/","text":"What is it? \u00b6 Organizr (by CauseFX) is a web-based, HTPC server organizer, that allows you to manage various tools and programs within tabs. Also supports user management, allowing for non admin users or guests to access certain web-pages via Organizr, even if it is behind HTTP authentication. This guide is to help you get Organizr setup and running by no means is this a complete guide to Organizr as you'll see the depth of it is pretty vast and there are plenty of customizations available to you at every turn. Details Project home Docs Github Docker 2. URL \u00b6 To access Organizr, visit https://organizr._yourdomain_.com 3. Initial Setup \u00b6 The first time you go to the Organizr page, you will be presented with Install Type , Admin Info , Security , Database and Verify sections. In the Install Type section select Personal In the Admin Info section enter your details such as the preferred password to log in and personal email. Note: it is suggested to enter your plex username and password In the Security section enter your fill in the Hash Key and Registration Password any type of password will do but if you want a secure one then follow these steps; First for the Hash Key you can head over to Base64 Encode and convert a string to Base64. Keep in mind the Hash Key can be anywhere between 3 to 30 which mean you can enter string up to 21 characters in Base64 For the password just use any strong password you prefer, if you want a strong one then Password Generator , there is no limit on the password section go crazy ;) The API key should be auto-generated so no need to worry about this if the API key is throwing an error such as shorter than it suppose to be or longer it's most likely due to the web browser auto-fill, make sure it's disabled or just use another browser that doesn't have auto-fill or you don't use much e.g Internet Explorer \ud83d\udc40. You should have something like this: In the Database section enter your preferred database name (there is 30 character limit), then after that for the \"Database Location\" set it as /config/www then click test path it should be a success. You should have something like this: In the Verify section you will just need to confirm everything but feel free to take note of your API key and save it somewhere safe. After clicking finish you will be taken to a log in the page just enter the username and password you have inserted in the Admin info section. You should have something like this: 4. Settings \u00b6 You will now be taken to the main Organizr Page and asked to login with the credentials you created in the previous steps. Tabs \u00b6 Click \"Settings\" on the left menu, to be taken to the \"Organizr Settings\" page. Things to note on this page, the Homepage is disabled by default and note the \"Type\" is set to \"Internal\". Your normal Apps with Saltbox will all need to have a Type: \"iFrame\" unless you have a particular app you wish to open in another window which is also a Type option. Go ahead and click \"+ on the right\". You will be prompted for information regarding the tab. Before hitting the Edit Tab button in the bottom right, please hit the \"Test Tab\" button, sometimes the Tab will check for you if iFrame is possible. This will test if the information you inputted can be open in an iFrame. Which is the secret sauce in Organizr's tabbed browsing. You will need to create multiple tabs with the information below. These are merely a suggestion and examples to get you up and going. Any changes made, won't be reflected until Organizr is reloaded. You can also drag and drop to change the order of the apps (don't forget to reload) Tab Name Tab URL Icon URL Category Group Type Active Portainer https://portainer.yourdomain.tld images/organizr.png (default) Unsorted Admin iFrame Y Sonarr https://sonarr.yourdomain.tld images/sonarr.png Unsorted Admin iFrame Y Radarr https://radarr.yourdomain.tld images/radarr.png Unsorted Admin iFrame Y NZBGet https://nzbget.yourdomain.tld images/nzbget.png Unsorted Admin iFrame Y Rutorrent https://rutorrent.yourdomain.tld images/rutorrent.png Unsorted Admin iFrame Y NZBHydra2 https://nzbhydra2.yourdomain.tld images/hydra.png Unsorted Admin iFrame Y Jackett https://jackett.yourdomain.tld images/jackett.png Unsorted Admin iFrame Y Plex https://plex.yourdomain.tld images/plex.png Unsorted User iFrame Y Tautulli https://tautulli.yourdomain.tld images/tautulli.png Unsorted User iFrame Y Ombi https://ombi.yourdomain.tld images/ombi.png Unsorted User iFrame Y Overseerr https://overseerr.yourdomain.tld images/overseerr.png Unsorted User iFrame Y Note: If Sonarr or Radarr are lagging a lot, you may set it to a specific page in each. (e.g. Sonarr: https://sonarr.yourdomain.com/calendar ; Radarr: https://radarr.yourdomain.com/activity/history ) Homepage (Make you have Homepage ACTIVE in Tabs section) \u00b6 Click \"Homepage Items\" under the Tab Editor section, to be taken to the \"Homepage Items\" page. Click the Plex icon at the top. You'll have to Enable it and verify the Minimum Authentication Click on the Connection Tab and set \"Plex URL\": http://plex:32400 Click \"Retrieve\" under Get Plex Token Click \"Save\" icon at the top right Set your preferred options on the remaining tabs Click \"SAVE\". Click the Sonarr icon at the top. Enable it. On the Connections Tab, Set \"Sonarr URL\": http://sonarr:8989 Set \"Sonarr API Key\": [[Your Sonarr API Key|Install: Sonarr#9-retrieving-the-api-key]] Go over any other Miscellaneous Options on the next Tab and set your preferences. Click \"SAVE\". Click the Radarr icon at the top. Enable it. Set \"Radarr URL\": http://radarr:7878 Set \"Radarr API Key\": [[Your Radarr API Key|Install: Radarr#9-retrieving-the-api-key]] Go over any other Miscellaneous Options on the next Tab and set your preferences. Click \"SAVE\". Click the NZBGet icon at the top. Enable it. Set \"NZBGet URL\": http://nzbget:6789 For \"Username\" / \"Password\": fill in your NZBGet login (see [[NZBGet|Install: NZBGet#2-setup]]) Click \"SAVE\". Homepage Order \u00b6 This is where you organize the apps and other items and how they will appear on your Homepage. There's no right or wrong order so simply move things around and find out what works for you. Any additional question please reach out to the Organizr team, either via their Discord Server or their subreddit Next \u00b6 Are you setting Saltbox up for the first time? You're ready to explore Saltbox! You can start checking out community apps in Sandbox if you wish.","title":"Organizr"},{"location":"apps/organizr/#what-is-it","text":"Organizr (by CauseFX) is a web-based, HTPC server organizer, that allows you to manage various tools and programs within tabs. Also supports user management, allowing for non admin users or guests to access certain web-pages via Organizr, even if it is behind HTTP authentication. This guide is to help you get Organizr setup and running by no means is this a complete guide to Organizr as you'll see the depth of it is pretty vast and there are plenty of customizations available to you at every turn. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/organizr/#2-url","text":"To access Organizr, visit https://organizr._yourdomain_.com","title":"2. URL"},{"location":"apps/organizr/#3-initial-setup","text":"The first time you go to the Organizr page, you will be presented with Install Type , Admin Info , Security , Database and Verify sections. In the Install Type section select Personal In the Admin Info section enter your details such as the preferred password to log in and personal email. Note: it is suggested to enter your plex username and password In the Security section enter your fill in the Hash Key and Registration Password any type of password will do but if you want a secure one then follow these steps; First for the Hash Key you can head over to Base64 Encode and convert a string to Base64. Keep in mind the Hash Key can be anywhere between 3 to 30 which mean you can enter string up to 21 characters in Base64 For the password just use any strong password you prefer, if you want a strong one then Password Generator , there is no limit on the password section go crazy ;) The API key should be auto-generated so no need to worry about this if the API key is throwing an error such as shorter than it suppose to be or longer it's most likely due to the web browser auto-fill, make sure it's disabled or just use another browser that doesn't have auto-fill or you don't use much e.g Internet Explorer \ud83d\udc40. You should have something like this: In the Database section enter your preferred database name (there is 30 character limit), then after that for the \"Database Location\" set it as /config/www then click test path it should be a success. You should have something like this: In the Verify section you will just need to confirm everything but feel free to take note of your API key and save it somewhere safe. After clicking finish you will be taken to a log in the page just enter the username and password you have inserted in the Admin info section. You should have something like this:","title":"3. Initial Setup"},{"location":"apps/organizr/#4-settings","text":"You will now be taken to the main Organizr Page and asked to login with the credentials you created in the previous steps.","title":"4. Settings"},{"location":"apps/organizr/#tabs","text":"Click \"Settings\" on the left menu, to be taken to the \"Organizr Settings\" page. Things to note on this page, the Homepage is disabled by default and note the \"Type\" is set to \"Internal\". Your normal Apps with Saltbox will all need to have a Type: \"iFrame\" unless you have a particular app you wish to open in another window which is also a Type option. Go ahead and click \"+ on the right\". You will be prompted for information regarding the tab. Before hitting the Edit Tab button in the bottom right, please hit the \"Test Tab\" button, sometimes the Tab will check for you if iFrame is possible. This will test if the information you inputted can be open in an iFrame. Which is the secret sauce in Organizr's tabbed browsing. You will need to create multiple tabs with the information below. These are merely a suggestion and examples to get you up and going. Any changes made, won't be reflected until Organizr is reloaded. You can also drag and drop to change the order of the apps (don't forget to reload) Tab Name Tab URL Icon URL Category Group Type Active Portainer https://portainer.yourdomain.tld images/organizr.png (default) Unsorted Admin iFrame Y Sonarr https://sonarr.yourdomain.tld images/sonarr.png Unsorted Admin iFrame Y Radarr https://radarr.yourdomain.tld images/radarr.png Unsorted Admin iFrame Y NZBGet https://nzbget.yourdomain.tld images/nzbget.png Unsorted Admin iFrame Y Rutorrent https://rutorrent.yourdomain.tld images/rutorrent.png Unsorted Admin iFrame Y NZBHydra2 https://nzbhydra2.yourdomain.tld images/hydra.png Unsorted Admin iFrame Y Jackett https://jackett.yourdomain.tld images/jackett.png Unsorted Admin iFrame Y Plex https://plex.yourdomain.tld images/plex.png Unsorted User iFrame Y Tautulli https://tautulli.yourdomain.tld images/tautulli.png Unsorted User iFrame Y Ombi https://ombi.yourdomain.tld images/ombi.png Unsorted User iFrame Y Overseerr https://overseerr.yourdomain.tld images/overseerr.png Unsorted User iFrame Y Note: If Sonarr or Radarr are lagging a lot, you may set it to a specific page in each. (e.g. Sonarr: https://sonarr.yourdomain.com/calendar ; Radarr: https://radarr.yourdomain.com/activity/history )","title":"Tabs"},{"location":"apps/organizr/#homepage-make-you-have-homepage-active-in-tabs-section","text":"Click \"Homepage Items\" under the Tab Editor section, to be taken to the \"Homepage Items\" page. Click the Plex icon at the top. You'll have to Enable it and verify the Minimum Authentication Click on the Connection Tab and set \"Plex URL\": http://plex:32400 Click \"Retrieve\" under Get Plex Token Click \"Save\" icon at the top right Set your preferred options on the remaining tabs Click \"SAVE\". Click the Sonarr icon at the top. Enable it. On the Connections Tab, Set \"Sonarr URL\": http://sonarr:8989 Set \"Sonarr API Key\": [[Your Sonarr API Key|Install: Sonarr#9-retrieving-the-api-key]] Go over any other Miscellaneous Options on the next Tab and set your preferences. Click \"SAVE\". Click the Radarr icon at the top. Enable it. Set \"Radarr URL\": http://radarr:7878 Set \"Radarr API Key\": [[Your Radarr API Key|Install: Radarr#9-retrieving-the-api-key]] Go over any other Miscellaneous Options on the next Tab and set your preferences. Click \"SAVE\". Click the NZBGet icon at the top. Enable it. Set \"NZBGet URL\": http://nzbget:6789 For \"Username\" / \"Password\": fill in your NZBGet login (see [[NZBGet|Install: NZBGet#2-setup]]) Click \"SAVE\".","title":"Homepage (Make you have Homepage ACTIVE in Tabs section)"},{"location":"apps/organizr/#homepage-order","text":"This is where you organize the apps and other items and how they will appear on your Homepage. There's no right or wrong order so simply move things around and find out what works for you. Any additional question please reach out to the Organizr team, either via their Discord Server or their subreddit","title":"Homepage Order"},{"location":"apps/organizr/#next","text":"Are you setting Saltbox up for the first time? You're ready to explore Saltbox! You can start checking out community apps in Sandbox if you wish.","title":"Next"},{"location":"apps/overseerr/","text":"What is it? \u00b6 Overseerr is a request management and media discovery tool built to work with your existing Plex ecosystem. Details Project home Docs Github Docker 1. URL \u00b6 To access Overseerr, visit https://overseerr._yourdomain.com_ 2. Settings \u00b6 This setup needs to take place AFTER you've set up Plex, Radarr, and Sonarr, since it involves connections to all three of those. You will need your API Keys from both Radarr and Sonarr. Click \"Sign In\" and sign into your Plex account. Click the \"refresh\" icon, then select your Plex server from the dropdown. Click \"Save Changes\" to retrieve the libraries from Plex. Scroll down and flip the switch on the libraries you want to expose for requests and discovery. Click \"Continue\". Click \"Add Radarr Server\". On this screen: Check \"Default server\" Enter a name Enter radarr as the hostname Enter your Radarr API Key Click \"Test\" to connect to Radarr and retrieve Quality Profiles, etc. Select a Quality, Root Folder, and Minimum Availability, then click \"Add Server\". This will return you to the screen from the previous step. Click \"Add Sonarr Server\" On this screen: Check \"Default server\" Enter a name Enter sonarr as the hostname Enter your Sonarr API Key Scroll down and click \"Test\" to connect to Sonarr and retrieve Quality Profiles, etc. Select a Quality, Root Folder, and Minimum Availability for standard and Anime series. Click \"Add Server\". Click \"Finish Setup\" Click \"Settings\" over on the left. Click \"Users\" on the left, then \"Import Users From Plex\" Setup is complete. 3. Next \u00b6 Are you setting Saltbox up for the first time? Continue to Portainer .","title":"Overseerr"},{"location":"apps/overseerr/#what-is-it","text":"Overseerr is a request management and media discovery tool built to work with your existing Plex ecosystem. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/overseerr/#1-url","text":"To access Overseerr, visit https://overseerr._yourdomain.com_","title":"1. URL"},{"location":"apps/overseerr/#2-settings","text":"This setup needs to take place AFTER you've set up Plex, Radarr, and Sonarr, since it involves connections to all three of those. You will need your API Keys from both Radarr and Sonarr. Click \"Sign In\" and sign into your Plex account. Click the \"refresh\" icon, then select your Plex server from the dropdown. Click \"Save Changes\" to retrieve the libraries from Plex. Scroll down and flip the switch on the libraries you want to expose for requests and discovery. Click \"Continue\". Click \"Add Radarr Server\". On this screen: Check \"Default server\" Enter a name Enter radarr as the hostname Enter your Radarr API Key Click \"Test\" to connect to Radarr and retrieve Quality Profiles, etc. Select a Quality, Root Folder, and Minimum Availability, then click \"Add Server\". This will return you to the screen from the previous step. Click \"Add Sonarr Server\" On this screen: Check \"Default server\" Enter a name Enter sonarr as the hostname Enter your Sonarr API Key Scroll down and click \"Test\" to connect to Sonarr and retrieve Quality Profiles, etc. Select a Quality, Root Folder, and Minimum Availability for standard and Anime series. Click \"Add Server\". Click \"Finish Setup\" Click \"Settings\" over on the left. Click \"Users\" on the left, then \"Import Users From Plex\" Setup is complete.","title":"2. Settings"},{"location":"apps/overseerr/#3-next","text":"Are you setting Saltbox up for the first time? Continue to Portainer .","title":"3. Next"},{"location":"apps/petio/","text":"Petio \u00b6 What is it? \u00b6 Petio is a third party companion app available to Plex server owners to allow their users to request, review and discover content. The app is built to appear instantly familiar and intuitive to even the most tech-agnostic users. Petio will help you manage requests from your users, connect to other third party apps such as Sonarr and Radarr, notify users when content is available and track request progress. Petio also allows users to discover media both on and off your server, quickly and easily find related content and review to leave their opinion for other users. Petio is an ongoing, forever free, always evolving project currently in alpha prototype stage and now available! Details Project home Docs Github Docker 1. Installation \u00b6 sb install petio 2. URL \u00b6 To access Petio, visit https://petio._yourdomain.com_ 3. Setup \u00b6 Click Login With Plex and follow the steps to log in. After you log in with Plex you will need to specify your Petio specific admin credentials, by default it uses your Plex username and email but you still need to specify your own password. After setting up your credentials, you need to pick your Plex server. Leave MongoDB settings as default. Once the last step is finished, you will be presented with a login screen. Use your Plex username and the password you set up on Step 2. You can now get started with configuring Radarr, Sonarr and start requesting! See the Petio documentation for more information. Documentation","title":"Petio"},{"location":"apps/petio/#petio","text":"","title":"Petio"},{"location":"apps/petio/#what-is-it","text":"Petio is a third party companion app available to Plex server owners to allow their users to request, review and discover content. The app is built to appear instantly familiar and intuitive to even the most tech-agnostic users. Petio will help you manage requests from your users, connect to other third party apps such as Sonarr and Radarr, notify users when content is available and track request progress. Petio also allows users to discover media both on and off your server, quickly and easily find related content and review to leave their opinion for other users. Petio is an ongoing, forever free, always evolving project currently in alpha prototype stage and now available! Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/petio/#1-installation","text":"sb install petio","title":"1. Installation"},{"location":"apps/petio/#2-url","text":"To access Petio, visit https://petio._yourdomain.com_","title":"2. URL"},{"location":"apps/petio/#3-setup","text":"Click Login With Plex and follow the steps to log in. After you log in with Plex you will need to specify your Petio specific admin credentials, by default it uses your Plex username and email but you still need to specify your own password. After setting up your credentials, you need to pick your Plex server. Leave MongoDB settings as default. Once the last step is finished, you will be presented with a login screen. Use your Plex username and the password you set up on Step 2. You can now get started with configuring Radarr, Sonarr and start requesting! See the Petio documentation for more information. Documentation","title":"3. Setup"},{"location":"apps/plex-autoscan/","text":"Plex Autoscan \u00b6 What is it? \u00b6 Plex Autoscan (by l3uddz ) is a script that assists Plex with the adding media files, that were imported by Sonarr / Radarr, by only scanning the folder that has been imported (vs the entire section library folder), thereby preventing Google API bans. Plex Autoscan comes configured out of the box (as related to Saltbox). However, there a few things that need to be set by you. Details Project home Docs Github Docker 1. Installation \u00b6 sb install plex_autoscan 2. Setup \u00b6 The role will configure Plex Autoscan, which should leave it ready to go. However, there are some details you may need to tweak yourself. Do a One-Time, Manual Scan in Plex \u00b6 For Plex Autoscan to work, at least one item needs to exist in each library before new items can show up. If you already have media, simply add it to the library and do a manual scan within Plex, for each library you have, to build the DB. If you currently don\u2019t have any media, continue on with the setup, and when you have acquired some media, you will then perform a do a manual scan within Plex, for each library, to build the DB. For more info, see this . Add Your Plex Access Token into Plex Autoscan Config \u00b6 You can skip this step if you entered in your Plex credentials in accounts.yml during setup. Note: For Mediabox / Feederbox setups, the following will be done on the Mediabox. Get your Plex Autoscan Token here . On the server's shell, run the following command: nano /opt/plex_autoscan/config/config.json 3. Add the Plex Access Token to \"PLEX_TOKEN\": so that it now appears as: \"PLEX_TOKEN\": \"xxxxxxxxxxxxxx\", Note: Make sure it is within the quotes ( \" ) and there is a comma ( , ) after it. Ctrl + X Y Enter to save. Obtaining the Plex Autoscan URL \u00b6 Note: For Mediabox / Feederbox setup, the following will be done on the Mediabox. The Plex Autoscan URL is needed during the setup of Sonarr , Radarr , and Lidarr . To get your Plex Autoscan URL, run the following command: /opt/scripts/plex_autoscan/plex_autoscan_url.sh This will be in the format of: http://subdomain.domain.com:plex_autoscan_port/plex_autoscan_pass or http://server_ip_address:plex_autoscan_port/plex_autoscan_pass Example: http://plex.domain.com:3468/aiG7Uwie9iodTTlaisahcieNaeVonu6I Note 1: The url will not use plex.domain.com if the IP address it points to does not match the server's IP address (e.g. Cloudflare CDN enabled). Note 2: If the url is plex.domain.com , but you decide to enable Cloudflare proxy for the plex subdomain later, you will need to generate another Plex Autoscan URL and add that into Sonarr/Radarr/Lidarr instead, as the scan request will need to go to you server's actual IP and not a Cloudflare one. Note 3: For Mediabox setups, make sure that the port is open in the firewall and/or router. Note 4: The PAS URL is not meant to be accessed via a browser by default (i.e. going there will give you a 401 Unauthorized error). However, you can enable a web UI for manual scan requests, see here . Upload Control File to Google Drive \u00b6 The following step is important so that Plex Autoscan can remove missing/replaced media files out of Plex (i.e. empty trash). Without it, Plex will be left with \"unavailable\" media that can't play (i.e. media posters with trash icons on them). For more details on what the control file is, see here . If you used the scripted rclone setup ; these control files were created for you, and you can skip this step. To upload the mounted.bin control file, run the following command: rclone touch google:/mounted.bin Note 1: If your Rclone remote config has a different name for Google Drive, replace google: with yours. Note 2: Above command requires Rclone version 1.39+ Edit the control files in the Plex Autoscan config file. \u00b6 If you did step 4; you can skip this step. On the server's shell, run the following command: ls /mnt/remote/*.bin To get the file names that you will need to enter into the Plex-autoscan config. They'll look like: aarsqytesx-movies_mounted.bin , and in the default case there will be three of them. On the server's shell, run the following command: nano /opt/plex_autoscan/config/config.json Find the following: \"PLEX_EMPTY_TRASH_CONTROL_FILES\" : [ \"/mnt/unionfs/mounted.bin\" ], Change it to [of course, these should match the file names you found in step 2]: \"PLEX_EMPTY_TRASH_CONTROL_FILES\" : [ \"/mnt/unionfs/aarsqytesx-movies_mounted.bin\" , \"/mnt/unionfs/aarsqytesx-music_mounted.bin\" , \"/mnt/unionfs/aarsqytesx-tv_mounted.bin\" ], Note: Make sure there is a comma ( , ) after each line except the last. Ctrl + X Y Enter to save. Enabling Google Drive Monitoring in Plex Autoscan \u00b6 See the Plex-autoscan Extras page Invoking a manual scan in Plex Autoscan \u00b6 See the Plex-autoscan Extras page Plex Autoscan and its Virtual Environment \u00b6 To make this transparent to the user, saltbox installs a wrapper script that accounts for this. This means that you can run Plex Autoscan manually like this: plex_autoscan COMMAND For example, if some documentation says you should run: python scan.py sections In saltbox you'd run: plex_autoscan sections If this doesn't work for you, update saltbox and rerun the plex-autoscan role: sb update sb install plex-autoscan","title":"Plex Autoscan"},{"location":"apps/plex-autoscan/#plex-autoscan","text":"","title":"Plex Autoscan"},{"location":"apps/plex-autoscan/#what-is-it","text":"Plex Autoscan (by l3uddz ) is a script that assists Plex with the adding media files, that were imported by Sonarr / Radarr, by only scanning the folder that has been imported (vs the entire section library folder), thereby preventing Google API bans. Plex Autoscan comes configured out of the box (as related to Saltbox). However, there a few things that need to be set by you. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/plex-autoscan/#1-installation","text":"sb install plex_autoscan","title":"1. Installation"},{"location":"apps/plex-autoscan/#2-setup","text":"The role will configure Plex Autoscan, which should leave it ready to go. However, there are some details you may need to tweak yourself.","title":"2. Setup"},{"location":"apps/plex-autoscan/#do-a-one-time-manual-scan-in-plex","text":"For Plex Autoscan to work, at least one item needs to exist in each library before new items can show up. If you already have media, simply add it to the library and do a manual scan within Plex, for each library you have, to build the DB. If you currently don\u2019t have any media, continue on with the setup, and when you have acquired some media, you will then perform a do a manual scan within Plex, for each library, to build the DB. For more info, see this .","title":"Do a One-Time, Manual Scan in Plex"},{"location":"apps/plex-autoscan/#add-your-plex-access-token-into-plex-autoscan-config","text":"You can skip this step if you entered in your Plex credentials in accounts.yml during setup. Note: For Mediabox / Feederbox setups, the following will be done on the Mediabox. Get your Plex Autoscan Token here . On the server's shell, run the following command: nano /opt/plex_autoscan/config/config.json 3. Add the Plex Access Token to \"PLEX_TOKEN\": so that it now appears as: \"PLEX_TOKEN\": \"xxxxxxxxxxxxxx\", Note: Make sure it is within the quotes ( \" ) and there is a comma ( , ) after it. Ctrl + X Y Enter to save.","title":"Add Your Plex Access Token into Plex Autoscan Config"},{"location":"apps/plex-autoscan/#obtaining-the-plex-autoscan-url","text":"Note: For Mediabox / Feederbox setup, the following will be done on the Mediabox. The Plex Autoscan URL is needed during the setup of Sonarr , Radarr , and Lidarr . To get your Plex Autoscan URL, run the following command: /opt/scripts/plex_autoscan/plex_autoscan_url.sh This will be in the format of: http://subdomain.domain.com:plex_autoscan_port/plex_autoscan_pass or http://server_ip_address:plex_autoscan_port/plex_autoscan_pass Example: http://plex.domain.com:3468/aiG7Uwie9iodTTlaisahcieNaeVonu6I Note 1: The url will not use plex.domain.com if the IP address it points to does not match the server's IP address (e.g. Cloudflare CDN enabled). Note 2: If the url is plex.domain.com , but you decide to enable Cloudflare proxy for the plex subdomain later, you will need to generate another Plex Autoscan URL and add that into Sonarr/Radarr/Lidarr instead, as the scan request will need to go to you server's actual IP and not a Cloudflare one. Note 3: For Mediabox setups, make sure that the port is open in the firewall and/or router. Note 4: The PAS URL is not meant to be accessed via a browser by default (i.e. going there will give you a 401 Unauthorized error). However, you can enable a web UI for manual scan requests, see here .","title":"Obtaining the Plex Autoscan URL"},{"location":"apps/plex-autoscan/#upload-control-file-to-google-drive","text":"The following step is important so that Plex Autoscan can remove missing/replaced media files out of Plex (i.e. empty trash). Without it, Plex will be left with \"unavailable\" media that can't play (i.e. media posters with trash icons on them). For more details on what the control file is, see here . If you used the scripted rclone setup ; these control files were created for you, and you can skip this step. To upload the mounted.bin control file, run the following command: rclone touch google:/mounted.bin Note 1: If your Rclone remote config has a different name for Google Drive, replace google: with yours. Note 2: Above command requires Rclone version 1.39+","title":"Upload Control File to Google Drive"},{"location":"apps/plex-autoscan/#edit-the-control-files-in-the-plex-autoscan-config-file","text":"If you did step 4; you can skip this step. On the server's shell, run the following command: ls /mnt/remote/*.bin To get the file names that you will need to enter into the Plex-autoscan config. They'll look like: aarsqytesx-movies_mounted.bin , and in the default case there will be three of them. On the server's shell, run the following command: nano /opt/plex_autoscan/config/config.json Find the following: \"PLEX_EMPTY_TRASH_CONTROL_FILES\" : [ \"/mnt/unionfs/mounted.bin\" ], Change it to [of course, these should match the file names you found in step 2]: \"PLEX_EMPTY_TRASH_CONTROL_FILES\" : [ \"/mnt/unionfs/aarsqytesx-movies_mounted.bin\" , \"/mnt/unionfs/aarsqytesx-music_mounted.bin\" , \"/mnt/unionfs/aarsqytesx-tv_mounted.bin\" ], Note: Make sure there is a comma ( , ) after each line except the last. Ctrl + X Y Enter to save.","title":"Edit the control files in the Plex Autoscan config file."},{"location":"apps/plex-autoscan/#enabling-google-drive-monitoring-in-plex-autoscan","text":"See the Plex-autoscan Extras page","title":"Enabling Google Drive Monitoring in Plex Autoscan"},{"location":"apps/plex-autoscan/#invoking-a-manual-scan-in-plex-autoscan","text":"See the Plex-autoscan Extras page","title":"Invoking a manual scan in Plex Autoscan"},{"location":"apps/plex-autoscan/#plex-autoscan-and-its-virtual-environment","text":"To make this transparent to the user, saltbox installs a wrapper script that accounts for this. This means that you can run Plex Autoscan manually like this: plex_autoscan COMMAND For example, if some documentation says you should run: python scan.py sections In saltbox you'd run: plex_autoscan sections If this doesn't work for you, update saltbox and rerun the plex-autoscan role: sb update sb install plex-autoscan","title":"Plex Autoscan and its Virtual Environment"},{"location":"apps/plex/","text":"What is it? \u00b6 Plex is a media server. Details Project home Docs Github Docker URL \u00b6 To access Plex, visit https://plex._yourdomain.com_ Login with your Plex account Setup Wizard \u00b6 First time you log in, you will be presented with a welcome screen. Click \"GOT IT!\" to continue. Next screen will show you your server, with a randomly generated name. Give it a friendly name and click \"NEXT\". On the next screen, click \"NEXT\" (we will add Libraries later). Click \"DONE\". Settings Library Network Transcoder DLNA Scheduled Tasks Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Library\" (left). Click \"SHOW ADVANCED\" in the upper right. Set the following: \"Empty trash automatically after every scan\": enabled THIS IS A CHANGE FROM WHEN Plex Autoscan WAS THE DEFAULT Autoscan is now the default scan app, and it does not empty trash \"Allow media deletion\": enabled \"Generate video preview thumbnails\": never \"Generate intro video markers\": never \"Generate chapter thumbnails\": never \"Analyze audio tracks for loudness\": never \"Analyze audio tracks for sonic features\": never The reasoning behind disabling these things is mostly related to Google Drive API usage, data transfer, and disk space. Accessing large portions of a given video file to generate thumbnails may generate large numbers of Google Drive API calls, and large amounts of data transfer. Either of these things may result in your account suffering one of the various types of 24-hour bans Google hands out, which may prevent your server from playing media at all. Also, storing these images will greatly inflate the size of /opt/plex , which can affect the speed of backups, your ability to download, and anything else related to disk space usage. These are generally considered Bad Things, so the recommendation is to avoid the possibility by turning these options off. Click \"SAVE CHANGES\". Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Network\" (left). Set the following: \"Secure Connections\": Preferred . \"Enable local network discovery (GDM)\": disabled . \"Remote streams allowed per user\": your preference . \"Custom server access URLs\" will be prefilled; do not edit this field as it will be overwritten. Click \"SAVE CHANGES\". Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Transcoder\" (left). Set the following: \"Transcoder temporary directory\": /transcode \"Transcoder default throttle buffer\": 150 \"Use hardware acceleration when available\": enabled \"Maximum simultaneous video transcode\": unlimited Click \"SAVE CHANGES\". Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"DLNA\" (left). Set the following: \"Enable the DLNA server\": disabled \"DLNA server timeline reporting\": disabled Click \"SAVE CHANGES\". Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Scheduled Tasks\" (left). Set the following: \"Update all libraries during maintenance\": disabled \"Upgrade media analysis during maintenance\": disabled \"Perform extensive media analysis during maintenance\": disabled Click \"SAVE CHANGES\". Add Media Libraries \u00b6 In this section, we will add two libraries: one for Movies and one for TV. Note: If you would like to have custom Plex libraries (more than just a Movies and TV one), see Customizing Plex Libraries . Libraries Add the Movie Library Add the TV Library In the main Plex screen (Home icon on the top left), click \"+\" next to \"LIBRARIES\". In the \"Add Library\" window, select \"Movies\" and click \"NEXT\". Click \"BROWSE FOR MEDIA FOLDER\". Navigate to /mnt/unionfs/Media/Movies , and then click the \"ADD\" button. You will now see /mnt/unionfs/Media/Movies in the text box (don't click \"ADD LIBRARY\" yet). Click \"Advanced\" on the left. Set the following: \"Enable Cinema Trailers\": disabled (optional) \"Enable video preview thumbnails\": disabled \"Find trailers and extras automatically (Plex Pass required)\": disabled (optional) Click \"ADD LIBRARY\". In the main Plex screen (Home icon on the top left), click \"+\" next to \"LIBRARIES\". In the \"Add Library\" window, select \"TV Shows\" and click \"NEXT\". Click \"BROWSE FOR MEDIA FOLDER\". Navigate to /mnt/unionfs/Media/TV , and then click the \"ADD\" button. You will now see /mnt/unionfs/Media/TV in the text box (don't click \"ADD LIBRARY\" yet). Click \"Advanced\" on the left. Set the following: \"Enable video preview thumbnails\": disabled \"Find trailers and extras automatically (Plex Pass required)\": disabled (optional) Click \"ADD LIBRARY\". Scan Media libraries \u00b6 As mentioned in the Introduction page, Autoscan will automatically scan the media files into Plex as they are downloaded, but this will require the Plex database to not be completely empty. So for every new library that is added, a one-time, manual scan is required. To do so: Click the 3 dots next to a Plex library. Select \"Scan Library Files\". Repeat steps 1-2 for each library. Webtools \u00b6 Webtools for Plex comes preinstalled. If you wish to setup Webtools and install 3rd party add-ons, you can go to https://plex-webtools._yourdomain.com_ and log in with your Plex account. Next \u00b6 Are you setting Saltbox up for the first time? Continue to Autoscan . 4. Sonarr 5. Radarr 6. Lidarr 7. Tautulli 8. Overseerr 9. Portainer 10. Organizr","title":"Plex"},{"location":"apps/plex/#what-is-it","text":"Plex is a media server. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/plex/#url","text":"To access Plex, visit https://plex._yourdomain.com_ Login with your Plex account","title":"URL"},{"location":"apps/plex/#setup-wizard","text":"First time you log in, you will be presented with a welcome screen. Click \"GOT IT!\" to continue. Next screen will show you your server, with a randomly generated name. Give it a friendly name and click \"NEXT\". On the next screen, click \"NEXT\" (we will add Libraries later). Click \"DONE\". Settings Library Network Transcoder DLNA Scheduled Tasks Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Library\" (left). Click \"SHOW ADVANCED\" in the upper right. Set the following: \"Empty trash automatically after every scan\": enabled THIS IS A CHANGE FROM WHEN Plex Autoscan WAS THE DEFAULT Autoscan is now the default scan app, and it does not empty trash \"Allow media deletion\": enabled \"Generate video preview thumbnails\": never \"Generate intro video markers\": never \"Generate chapter thumbnails\": never \"Analyze audio tracks for loudness\": never \"Analyze audio tracks for sonic features\": never The reasoning behind disabling these things is mostly related to Google Drive API usage, data transfer, and disk space. Accessing large portions of a given video file to generate thumbnails may generate large numbers of Google Drive API calls, and large amounts of data transfer. Either of these things may result in your account suffering one of the various types of 24-hour bans Google hands out, which may prevent your server from playing media at all. Also, storing these images will greatly inflate the size of /opt/plex , which can affect the speed of backups, your ability to download, and anything else related to disk space usage. These are generally considered Bad Things, so the recommendation is to avoid the possibility by turning these options off. Click \"SAVE CHANGES\". Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Network\" (left). Set the following: \"Secure Connections\": Preferred . \"Enable local network discovery (GDM)\": disabled . \"Remote streams allowed per user\": your preference . \"Custom server access URLs\" will be prefilled; do not edit this field as it will be overwritten. Click \"SAVE CHANGES\". Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Transcoder\" (left). Set the following: \"Transcoder temporary directory\": /transcode \"Transcoder default throttle buffer\": 150 \"Use hardware acceleration when available\": enabled \"Maximum simultaneous video transcode\": unlimited Click \"SAVE CHANGES\". Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"DLNA\" (left). Set the following: \"Enable the DLNA server\": disabled \"DLNA server timeline reporting\": disabled Click \"SAVE CHANGES\". Click the Settings icon (top right) \u2192 \"Server\" (top) \u2192 \"Scheduled Tasks\" (left). Set the following: \"Update all libraries during maintenance\": disabled \"Upgrade media analysis during maintenance\": disabled \"Perform extensive media analysis during maintenance\": disabled Click \"SAVE CHANGES\".","title":"Setup Wizard"},{"location":"apps/plex/#add-media-libraries","text":"In this section, we will add two libraries: one for Movies and one for TV. Note: If you would like to have custom Plex libraries (more than just a Movies and TV one), see Customizing Plex Libraries . Libraries Add the Movie Library Add the TV Library In the main Plex screen (Home icon on the top left), click \"+\" next to \"LIBRARIES\". In the \"Add Library\" window, select \"Movies\" and click \"NEXT\". Click \"BROWSE FOR MEDIA FOLDER\". Navigate to /mnt/unionfs/Media/Movies , and then click the \"ADD\" button. You will now see /mnt/unionfs/Media/Movies in the text box (don't click \"ADD LIBRARY\" yet). Click \"Advanced\" on the left. Set the following: \"Enable Cinema Trailers\": disabled (optional) \"Enable video preview thumbnails\": disabled \"Find trailers and extras automatically (Plex Pass required)\": disabled (optional) Click \"ADD LIBRARY\". In the main Plex screen (Home icon on the top left), click \"+\" next to \"LIBRARIES\". In the \"Add Library\" window, select \"TV Shows\" and click \"NEXT\". Click \"BROWSE FOR MEDIA FOLDER\". Navigate to /mnt/unionfs/Media/TV , and then click the \"ADD\" button. You will now see /mnt/unionfs/Media/TV in the text box (don't click \"ADD LIBRARY\" yet). Click \"Advanced\" on the left. Set the following: \"Enable video preview thumbnails\": disabled \"Find trailers and extras automatically (Plex Pass required)\": disabled (optional) Click \"ADD LIBRARY\".","title":"Add Media Libraries"},{"location":"apps/plex/#scan-media-libraries","text":"As mentioned in the Introduction page, Autoscan will automatically scan the media files into Plex as they are downloaded, but this will require the Plex database to not be completely empty. So for every new library that is added, a one-time, manual scan is required. To do so: Click the 3 dots next to a Plex library. Select \"Scan Library Files\". Repeat steps 1-2 for each library.","title":"Scan Media libraries"},{"location":"apps/plex/#webtools","text":"Webtools for Plex comes preinstalled. If you wish to setup Webtools and install 3rd party add-ons, you can go to https://plex-webtools._yourdomain.com_ and log in with your Plex account.","title":"Webtools"},{"location":"apps/plex/#next","text":"Are you setting Saltbox up for the first time? Continue to Autoscan . 4. Sonarr 5. Radarr 6. Lidarr 7. Tautulli 8. Overseerr 9. Portainer 10. Organizr","title":"Next"},{"location":"apps/portainer/","text":"THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX What is it? \u00b6 Portainer is an open-source lightweight management UI which allows you to easily manage your Docker containers, images, networks and volumes. Details Project home Docs Github Docker 2. URL \u00b6 To access Portainer, visit https://portainer._yourdomain.com_ 3. Initial Setup \u00b6 The first time you go to the Portainer page, you will be presented with the message \"Please create the initial administrator user.\". Fill in your preferred admin username and password. Click Create User . On this first visit when you set up the admin user, you will be logged in automagically. On future visits, you will be asked to log in with your username and password. On the \"Connect Portainer to the Docker environment you want to manage.\" screen, select Local: Manage the local Docker environment and click Connect . Note: Don't be confused by \"local\" in this context. It is referring to the relationship between the Docker instance you're managing on your Saltbox server and this instance of Portainer. These things are local to each other on your Saltbox server, wherever that is. They may be remote from you, but they are local to each other. Pay no mind to what looks like a warning at the bottom. Saltbox has already taken care of that. Portainer is now set up. 4. Next \u00b6 Are you setting Saltbox up for the first time? Continue to Organizr .","title":"Portainer"},{"location":"apps/portainer/#what-is-it","text":"Portainer is an open-source lightweight management UI which allows you to easily manage your Docker containers, images, networks and volumes. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/portainer/#2-url","text":"To access Portainer, visit https://portainer._yourdomain.com_","title":"2. URL"},{"location":"apps/portainer/#3-initial-setup","text":"The first time you go to the Portainer page, you will be presented with the message \"Please create the initial administrator user.\". Fill in your preferred admin username and password. Click Create User . On this first visit when you set up the admin user, you will be logged in automagically. On future visits, you will be asked to log in with your username and password. On the \"Connect Portainer to the Docker environment you want to manage.\" screen, select Local: Manage the local Docker environment and click Connect . Note: Don't be confused by \"local\" in this context. It is referring to the relationship between the Docker instance you're managing on your Saltbox server and this instance of Portainer. These things are local to each other on your Saltbox server, wherever that is. They may be remote from you, but they are local to each other. Pay no mind to what looks like a warning at the bottom. Saltbox has already taken care of that. Portainer is now set up.","title":"3. Initial Setup"},{"location":"apps/portainer/#4-next","text":"Are you setting Saltbox up for the first time? Continue to Organizr .","title":"4. Next"},{"location":"apps/postgres/","text":"Postgres \u00b6 What is it? \u00b6 Postgres PostgreSQL, often simply \"Postgres\", is an object-relational database management system (ORDBMS) with an emphasis on extensibility and standards-compliance. Details Project home Docs Github Docker 1. Installation \u00b6 sb install postgres 2. Setup \u00b6 Info The default password for this container is password4321 To easily manage the db, consider adminer Documentation: Postgres Docs","title":"PostgreSQL"},{"location":"apps/postgres/#postgres","text":"","title":"Postgres"},{"location":"apps/postgres/#what-is-it","text":"Postgres PostgreSQL, often simply \"Postgres\", is an object-relational database management system (ORDBMS) with an emphasis on extensibility and standards-compliance. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/postgres/#1-installation","text":"sb install postgres","title":"1. Installation"},{"location":"apps/postgres/#2-setup","text":"Info The default password for this container is password4321 To easily manage the db, consider adminer Documentation: Postgres Docs","title":"2. Setup"},{"location":"apps/prowlarr/","text":"Prowlarr \u00b6 What is it? \u00b6 Prowlarr is an indexer manager/proxy built on the popular arr .net/reactjs base stack to integrate with your various PVR apps. Prowlarr supports management of both Torrent Trackers and Usenet Indexers. It integrates seamlessly with Lidarr, Mylar3, Radarr, Readarr, and Sonarr offering complete management of your indexers with no per app Indexer setup required (we do it all). Details Project home Docs Github Docker 1. Installation \u00b6 sb install prowlarr 2. URL \u00b6 To access Prowlarr, visit https://prowlarr._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Prowlarr"},{"location":"apps/prowlarr/#prowlarr","text":"","title":"Prowlarr"},{"location":"apps/prowlarr/#what-is-it","text":"Prowlarr is an indexer manager/proxy built on the popular arr .net/reactjs base stack to integrate with your various PVR apps. Prowlarr supports management of both Torrent Trackers and Usenet Indexers. It integrates seamlessly with Lidarr, Mylar3, Radarr, Readarr, and Sonarr offering complete management of your indexers with no per app Indexer setup required (we do it all). Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/prowlarr/#1-installation","text":"sb install prowlarr","title":"1. Installation"},{"location":"apps/prowlarr/#2-url","text":"To access Prowlarr, visit https://prowlarr._yourdomain.com_","title":"2. URL"},{"location":"apps/prowlarr/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"apps/qbittorrent/","text":"qBittorrent \u00b6 What is it? \u00b6 qBittorrent is a bittorrent client programmed in C++ / Qt that uses libtorrent (sometimes called libtorrent-rasterbar) by Arvid Norberg. It aims to be a good alternative to all other bittorrent clients out there. qBittorrent is fast, stable and provides unicode support as well as many features. Details Project home Docs Github Docker 1. Installation \u00b6 sb install qbittorrent 2. URL \u00b6 To access qBittorrent, visit https://qbittorrent._yourdomain.com_ 3. Setup \u00b6 Access qbittorrent at https://qbittorrent._yourdomain.com_ username : ` admin` password : ` adminadmin`. First go to Options -> Web UI and set a new username and a strong password. Under Options -> Connection , set the port to 56881. Under Options -> Downloads , set the following; Save files to location: /mnt/unionfs/downloads/torrents/qbittorrent/completed/ Keep incomplete torrents in: /mnt/unionfs/downloads/torrents/qbittorrent/incoming/ Copy .torrent files to: /mnt/unionfs/downloads/torrents/qbittorrent/torrents/ Copy .torrent files for finished downloads to: /mnt/unionfs/downloads/torrents/qbittorrent/torrents/ Additionally you can set monitored folder to: /mnt/unionfs/downloads/torrents/qbittorrent/watched/ tick Run external program on torrent completion and paste this into the box: /usr/bin/unrar x -r \"%F/.\" \"%F/\" Warning Make sure to choose a strong username/password combination because by default qBittorrent's Web API is completely exposed to the internet! If someone guesses your qBit's credentials, they can, among other things, steal your tracker passkeys and delete torrents (data included). If you don't need the Web API exposed, you can do so using the inventory system with qbittorrent_traefik_api_enabled : false and by rerunning the `qbittorrent` tag. Note if you're using private trackers be sure to go to Options -> BittTorrent and uncheck everything in Privacy section. Documentation","title":"Qbittorrent"},{"location":"apps/qbittorrent/#qbittorrent","text":"","title":"qBittorrent"},{"location":"apps/qbittorrent/#what-is-it","text":"qBittorrent is a bittorrent client programmed in C++ / Qt that uses libtorrent (sometimes called libtorrent-rasterbar) by Arvid Norberg. It aims to be a good alternative to all other bittorrent clients out there. qBittorrent is fast, stable and provides unicode support as well as many features. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/qbittorrent/#1-installation","text":"sb install qbittorrent","title":"1. Installation"},{"location":"apps/qbittorrent/#2-url","text":"To access qBittorrent, visit https://qbittorrent._yourdomain.com_","title":"2. URL"},{"location":"apps/qbittorrent/#3-setup","text":"Access qbittorrent at https://qbittorrent._yourdomain.com_ username : ` admin` password : ` adminadmin`. First go to Options -> Web UI and set a new username and a strong password. Under Options -> Connection , set the port to 56881. Under Options -> Downloads , set the following; Save files to location: /mnt/unionfs/downloads/torrents/qbittorrent/completed/ Keep incomplete torrents in: /mnt/unionfs/downloads/torrents/qbittorrent/incoming/ Copy .torrent files to: /mnt/unionfs/downloads/torrents/qbittorrent/torrents/ Copy .torrent files for finished downloads to: /mnt/unionfs/downloads/torrents/qbittorrent/torrents/ Additionally you can set monitored folder to: /mnt/unionfs/downloads/torrents/qbittorrent/watched/ tick Run external program on torrent completion and paste this into the box: /usr/bin/unrar x -r \"%F/.\" \"%F/\" Warning Make sure to choose a strong username/password combination because by default qBittorrent's Web API is completely exposed to the internet! If someone guesses your qBit's credentials, they can, among other things, steal your tracker passkeys and delete torrents (data included). If you don't need the Web API exposed, you can do so using the inventory system with qbittorrent_traefik_api_enabled : false and by rerunning the `qbittorrent` tag. Note if you're using private trackers be sure to go to Options -> BittTorrent and uncheck everything in Privacy section. Documentation","title":"3. Setup"},{"location":"apps/radarr/","text":"What is it? \u00b6 Radarr is a movie collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new movies and will interface with clients and indexers to grab, sort, and rename them. It can also be configured to automatically upgrade the quality of existing files in the library when a better quality format becomes available. Details Project home Docs Github Docker URL \u00b6 To access Radarr, visit https://radarr._yourdomain.com_ Settings \u00b6 Click on \"Settings\" in the sidebar. Click \"Show Advanced\" at the top of the Settings pane. Make changes in the following sections: Settings Media Management Indexers Download Clients qBittorrent Connect General These settings control management of media files. Movie Naming Folders Importing File Management Permissions Save \"Rename Movies\": Yes \"Replace Illegal Characters\": Yes Colon Replacement Format: Delete Note: You could use Replace with Space Dash but only if your file naming format is not using spaces (e.g. using dots) to separate words. Set your preferred naming format; here are some examples. TRaSH' naming guide [Recommended] Go here for the latest updates. These examples may be out of date. Example: The Movie Title (2010) Ultimate Extended Edition [imdb-tt0066921][Surround Sound x264][Bluray-1080p Proper][3D][HDR][10bit][x264][DTS 5.1]-EVOLVE.mkv Standard Movie Format: {Movie CleanTitle} {(Release Year)} {Edition Tags} [imdb-{ImdbId}]{[Custom Formats]}{[Quality Full]}{[MediaInfo 3D]}{[MediaInfo VideoDynamicRange]}[{Mediainfo VideoBitDepth}bit][{Mediainfo VideoCodec}]{[Mediainfo AudioCodec}{ Mediainfo AudioChannels}]{-Release Group} Reference: https://trash-guides.info/Radarr/Radarr-recommended-naming-scheme/ The TRaSH naming guide is recommended since some other tools, notably Plex Meta Manager, expect it in their default setup. Plex's Naming Preference Example: /Guardians of the Galaxy (2014)/Guardians of the Galaxy (2014).mkv Standard Movie Format: {Movie Title} ({Release Year}) Movie Folder Format: {Movie Title} ({Release Year}) Reference: https://support.plex.tv/articles/200381023-naming-movie-files/ Radarr's Wiki Example Example: The Movie Title (2010) - [ULTIMATE EXTENDED EDITION][BLURAY-1080P PROPER][DTS 5.1][X264]-EVOLVE.mkv Standard Movie Format: {Movie Title} ({Release Year}) - {[EDITION TAGS]}{[QUALITY FULL]}{[MEDIAINFO AUDIOCODEC}{ MEDIAINFO AUDIOCHANNELS]}{[MEDIAINFO VIDEOCODEC]}{-RELEASE GROUP} Reference: https://github.com/Radarr/Radarr/wiki/Sorting-and-Renaming \"Create empty movie folders\": No \"Automatically Rename Folders\": No \"Movie Paths Default to Static\": No \"Skip Free Space Check\": No \"Use Hardlinks instead of Copy\": Yes \"Import Extra Files\": Yes ( can be your preference ) \"Extra File Extensions\": srt, sub, idx \"Ignore Deleted Movies\": No ( can be your preference ) \"Download Propers\": No ( can be your preference ) \"Analyse video files\": No \"Change File Date\": None \"Recycle Bin\": blank (Rclone deletes are sent to Gdrive trash folder, anyway) Set Permissions: No Click \"Save\". These settings control indexers and related behavior. NZBHydra2 Jackett Click Add Indexer ( + ). Select \"Newznab\". Add the following: Name: NZBHydra2 Enable RSS Sync: Your Preference Enable Search: Your Preference URL: http://nzbhydra2:5076 API Key: Your NZBHydra2 API Key Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add NZBHydra2. Note: The \"Test\" will keep failing until you add an indexer in NZBHydra2 . Note: Each Indexer you have defined in Jackett will need to be added separately. Click Add Indexer ( + ) Select \"Torznab\". Add the following: Name: Indexer Name Enable RSS Sync: Your Preference Enable Search: Your Preference URL: Indexer's Torznab Feed API Key: Your Jackett API Key Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add the indexer. These settings control downloading behavior and clients. Completed Download Handling Failed Download Handling NZBGet ruTorrent \"Enable\": Yes \"Remove\": Yes ( can be your preference ) \"Redownload\": Yes \"Remove\": Yes Click Add ( + ) Add a new \"NZBGet\" download client. Add the following: Name: NZBGet Enable: Yes Host: nzbget Port: 6789 Username: Your NZBGet Username Password: Your NZBGet Password Category: radarr Use SSL: No Add Paused: No Your settings will look like this: Click \"Save\" to add NZBGet. Click Add ( + ) Add a new \"rTorrent\" download client. Add the following: Name: ruTorrent Enable: Yes Host: rutorrent Port: 80 URL Path: RPC2 Use SSL: No Username: Your ruTorrent Username Password: Your ruTorrent Password Category: radarr Directory: Leave Blank Your settings will now look like this: Click \"Save\" to add ruTorrent. Click Add ('+') Add a new \"qBittorrent\" download client. Add the following: Name: qBittorrent Enable: 'Yes' Host: 'qBittorrent' Port: '8080' Username: [Your qBittorrent Username](../community/apps/qbittorrent.md) Password: [Your qBittorrent Password](../community/apps/qbittorrent.md) Category: 'radarr' Your settings will now look like this: Click \"Save\" to add qBittorrent qb These settings control connections to other applications or systems. Torrent Cleanup Autoscan Torrent Cleanup Script is a custom script that will cleanup torrents from ruTorrent that were auto-extracted, but still being seeded. So if the script detects that .rar files are in the folder that Radarr just imported from, it will delete the imported video file(s), leaving just the .rar files for seeding. Click \"Settings\" -> \"Connect\". Add a new \"Custom Script\". Add the following: Name: Torrent Cleanup On Grab: No On Download: Yes On Upgrade: Yes On Rename: No Path: /scripts/torrents/TorrentCleanup.py The settings will look like this: Click \"Save\" to add the Torrent Cleanup script. Click \"Settings\" -> \"Connect\". Add a new \"Webhook\". Add the following: Name: Autoscan On Grab: No On Import: Yes On Upgrade: Yes On Rename: Yes On Movie Delete: Yes On Movie File Delete: Yes On Movie File Delete For Upgrade: Yes Tags: Leave Blank URL: http://autoscan:3030/triggers/radarr Method: POST Username: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] Password: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] The settings will look like this: Click \"Save\" to add Autoscan. These settings control general aspects of Radarr. Start-Up Proxy Settings Logging Analytics Updates Save \"Bind Address: * \"Port Number\": 7878 \"URL Base\": blank \"Enable SSL\": No ( SSL is handled by Traefik ) \"Use Proxy\": No \"Log Level\": Debug \"Enable\": No ( your preference ) These settings may be grayed out or unavailable; skip this if that's the case. \"Branch\": nightly or develop \"Automatic\": Off Click \"Save\". Movies Path \u00b6 When you are ready to add your first movie to Radarr, click the \"Path\" drop-down and select \"Add a new path\". Click the blue \"Browse\" button, navigate to /mnt/unionfs/Media/Movies , scroll to the bottom, and select \"OK\". Click the green \"check\" button to add the path. All movies added now will have that path set. API Key \u00b6 This is used during the setup of Overseerr and Organizr . Go to \"Settings\" -> \"General\" -> \"Security\" -> \"API Key\". Guide \u00b6 TraSH Guides Next \u00b6 Are you setting Saltbox up for the first time? Continue to Lidarr .","title":"Radarr"},{"location":"apps/radarr/#what-is-it","text":"Radarr is a movie collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new movies and will interface with clients and indexers to grab, sort, and rename them. It can also be configured to automatically upgrade the quality of existing files in the library when a better quality format becomes available. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/radarr/#url","text":"To access Radarr, visit https://radarr._yourdomain.com_","title":"URL"},{"location":"apps/radarr/#settings","text":"Click on \"Settings\" in the sidebar. Click \"Show Advanced\" at the top of the Settings pane. Make changes in the following sections: Settings Media Management Indexers Download Clients qBittorrent Connect General These settings control management of media files. Movie Naming Folders Importing File Management Permissions Save \"Rename Movies\": Yes \"Replace Illegal Characters\": Yes Colon Replacement Format: Delete Note: You could use Replace with Space Dash but only if your file naming format is not using spaces (e.g. using dots) to separate words. Set your preferred naming format; here are some examples. TRaSH' naming guide [Recommended] Go here for the latest updates. These examples may be out of date. Example: The Movie Title (2010) Ultimate Extended Edition [imdb-tt0066921][Surround Sound x264][Bluray-1080p Proper][3D][HDR][10bit][x264][DTS 5.1]-EVOLVE.mkv Standard Movie Format: {Movie CleanTitle} {(Release Year)} {Edition Tags} [imdb-{ImdbId}]{[Custom Formats]}{[Quality Full]}{[MediaInfo 3D]}{[MediaInfo VideoDynamicRange]}[{Mediainfo VideoBitDepth}bit][{Mediainfo VideoCodec}]{[Mediainfo AudioCodec}{ Mediainfo AudioChannels}]{-Release Group} Reference: https://trash-guides.info/Radarr/Radarr-recommended-naming-scheme/ The TRaSH naming guide is recommended since some other tools, notably Plex Meta Manager, expect it in their default setup. Plex's Naming Preference Example: /Guardians of the Galaxy (2014)/Guardians of the Galaxy (2014).mkv Standard Movie Format: {Movie Title} ({Release Year}) Movie Folder Format: {Movie Title} ({Release Year}) Reference: https://support.plex.tv/articles/200381023-naming-movie-files/ Radarr's Wiki Example Example: The Movie Title (2010) - [ULTIMATE EXTENDED EDITION][BLURAY-1080P PROPER][DTS 5.1][X264]-EVOLVE.mkv Standard Movie Format: {Movie Title} ({Release Year}) - {[EDITION TAGS]}{[QUALITY FULL]}{[MEDIAINFO AUDIOCODEC}{ MEDIAINFO AUDIOCHANNELS]}{[MEDIAINFO VIDEOCODEC]}{-RELEASE GROUP} Reference: https://github.com/Radarr/Radarr/wiki/Sorting-and-Renaming \"Create empty movie folders\": No \"Automatically Rename Folders\": No \"Movie Paths Default to Static\": No \"Skip Free Space Check\": No \"Use Hardlinks instead of Copy\": Yes \"Import Extra Files\": Yes ( can be your preference ) \"Extra File Extensions\": srt, sub, idx \"Ignore Deleted Movies\": No ( can be your preference ) \"Download Propers\": No ( can be your preference ) \"Analyse video files\": No \"Change File Date\": None \"Recycle Bin\": blank (Rclone deletes are sent to Gdrive trash folder, anyway) Set Permissions: No Click \"Save\". These settings control indexers and related behavior. NZBHydra2 Jackett Click Add Indexer ( + ). Select \"Newznab\". Add the following: Name: NZBHydra2 Enable RSS Sync: Your Preference Enable Search: Your Preference URL: http://nzbhydra2:5076 API Key: Your NZBHydra2 API Key Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add NZBHydra2. Note: The \"Test\" will keep failing until you add an indexer in NZBHydra2 . Note: Each Indexer you have defined in Jackett will need to be added separately. Click Add Indexer ( + ) Select \"Torznab\". Add the following: Name: Indexer Name Enable RSS Sync: Your Preference Enable Search: Your Preference URL: Indexer's Torznab Feed API Key: Your Jackett API Key Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add the indexer. These settings control downloading behavior and clients. Completed Download Handling Failed Download Handling NZBGet ruTorrent \"Enable\": Yes \"Remove\": Yes ( can be your preference ) \"Redownload\": Yes \"Remove\": Yes Click Add ( + ) Add a new \"NZBGet\" download client. Add the following: Name: NZBGet Enable: Yes Host: nzbget Port: 6789 Username: Your NZBGet Username Password: Your NZBGet Password Category: radarr Use SSL: No Add Paused: No Your settings will look like this: Click \"Save\" to add NZBGet. Click Add ( + ) Add a new \"rTorrent\" download client. Add the following: Name: ruTorrent Enable: Yes Host: rutorrent Port: 80 URL Path: RPC2 Use SSL: No Username: Your ruTorrent Username Password: Your ruTorrent Password Category: radarr Directory: Leave Blank Your settings will now look like this: Click \"Save\" to add ruTorrent. Click Add ('+') Add a new \"qBittorrent\" download client. Add the following: Name: qBittorrent Enable: 'Yes' Host: 'qBittorrent' Port: '8080' Username: [Your qBittorrent Username](../community/apps/qbittorrent.md) Password: [Your qBittorrent Password](../community/apps/qbittorrent.md) Category: 'radarr' Your settings will now look like this: Click \"Save\" to add qBittorrent qb These settings control connections to other applications or systems. Torrent Cleanup Autoscan Torrent Cleanup Script is a custom script that will cleanup torrents from ruTorrent that were auto-extracted, but still being seeded. So if the script detects that .rar files are in the folder that Radarr just imported from, it will delete the imported video file(s), leaving just the .rar files for seeding. Click \"Settings\" -> \"Connect\". Add a new \"Custom Script\". Add the following: Name: Torrent Cleanup On Grab: No On Download: Yes On Upgrade: Yes On Rename: No Path: /scripts/torrents/TorrentCleanup.py The settings will look like this: Click \"Save\" to add the Torrent Cleanup script. Click \"Settings\" -> \"Connect\". Add a new \"Webhook\". Add the following: Name: Autoscan On Grab: No On Import: Yes On Upgrade: Yes On Rename: Yes On Movie Delete: Yes On Movie File Delete: Yes On Movie File Delete For Upgrade: Yes Tags: Leave Blank URL: http://autoscan:3030/triggers/radarr Method: POST Username: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] Password: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] The settings will look like this: Click \"Save\" to add Autoscan. These settings control general aspects of Radarr. Start-Up Proxy Settings Logging Analytics Updates Save \"Bind Address: * \"Port Number\": 7878 \"URL Base\": blank \"Enable SSL\": No ( SSL is handled by Traefik ) \"Use Proxy\": No \"Log Level\": Debug \"Enable\": No ( your preference ) These settings may be grayed out or unavailable; skip this if that's the case. \"Branch\": nightly or develop \"Automatic\": Off Click \"Save\".","title":"Settings"},{"location":"apps/radarr/#movies-path","text":"When you are ready to add your first movie to Radarr, click the \"Path\" drop-down and select \"Add a new path\". Click the blue \"Browse\" button, navigate to /mnt/unionfs/Media/Movies , scroll to the bottom, and select \"OK\". Click the green \"check\" button to add the path. All movies added now will have that path set.","title":"Movies Path"},{"location":"apps/radarr/#api-key","text":"This is used during the setup of Overseerr and Organizr . Go to \"Settings\" -> \"General\" -> \"Security\" -> \"API Key\".","title":"API Key"},{"location":"apps/radarr/#guide","text":"TraSH Guides","title":"Guide"},{"location":"apps/radarr/#next","text":"Are you setting Saltbox up for the first time? Continue to Lidarr .","title":"Next"},{"location":"apps/readarr/","text":"Readarr \u00b6 What is it? \u00b6 Readarr is an ebook and audiobook collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new books from your favourite authors and will grab, sort and rename them. Note that only one type of a given book is supported. If you want both an audiobook and ebook of a given book you will need multiple instances. Note Readarr is currently in beta testing and is generally still in a work in progress. Features may be broken, incomplete, or cause spontaneous combustion. Details Project home Docs Github Docker 1. Installation \u00b6 sb install readarr 2. URL \u00b6 To access Readarr, visit https://readarr._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Readarr"},{"location":"apps/readarr/#readarr","text":"","title":"Readarr"},{"location":"apps/readarr/#what-is-it","text":"Readarr is an ebook and audiobook collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new books from your favourite authors and will grab, sort and rename them. Note that only one type of a given book is supported. If you want both an audiobook and ebook of a given book you will need multiple instances. Note Readarr is currently in beta testing and is generally still in a work in progress. Features may be broken, incomplete, or cause spontaneous combustion. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/readarr/#1-installation","text":"sb install readarr","title":"1. Installation"},{"location":"apps/readarr/#2-url","text":"To access Readarr, visit https://readarr._yourdomain.com_","title":"2. URL"},{"location":"apps/readarr/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"apps/rutorrent/","text":"THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX What is it? \u00b6 ruTorrent (by Novik) is a front-end for the popular, lightweight, and extensible BitTorrent client rtorrent (by Jari Sundell aka rakshasa). Note: public trackers are disabled by default in the standard install. Refer to the FAQ for instructions on re-enabling them . Details Project home Docs Github ruTorrent Github rTorrent Docker 1. URL \u00b6 To access ruTorrent, visit https://rutorrent._yourdomain.com_ 2. Basics \u00b6 Setup \u00b6 The setup for Sonarr , Radarr , and Lidarr are done on their respective wiki pages. 3. Enable AutoUnpack \u00b6 AutoUnpack is a plugin that will automatically unrar/unzip torrent data. This will allow Sonarr/Radarr/Lidarr to import the media files that would otherwise be ignored. After Sonarr and Radarr import the media files, Torrent Cleanup Script will then delete the extracted media files and ruTorrent will continue to seed the torrents (until they are either removed manually or automatically via ruTorrent's Ratio Group rules). To enable AutoUnpack: Open \"Settings\" by clicking the gear icon at the top Go to \"Unpack\" on the left. Check \"Enable autounpacking if torrents label matches filter\" and add the following: /.*(radarr|sonarr|lidarr).*/i Leave the other fields blank. Your settings will now look like this: Click \"OK\". 3. Custom Plugins and Themes \u00b6 You can have custom plugins and themes imported during Docker container rebuild. Just place them in the following paths: /opt/rutorrent/plugins/ /opt/rutorrent/themes/ And then restart the Docker container: docker restart rutorrent 4. Next \u00b6 Are you setting Saltbox up for the first time? Continue to NZBHydra2 .","title":"Rutorrent"},{"location":"apps/rutorrent/#what-is-it","text":"ruTorrent (by Novik) is a front-end for the popular, lightweight, and extensible BitTorrent client rtorrent (by Jari Sundell aka rakshasa). Note: public trackers are disabled by default in the standard install. Refer to the FAQ for instructions on re-enabling them . Details Project home Docs Github ruTorrent Github rTorrent Docker","title":"What is it?"},{"location":"apps/rutorrent/#1-url","text":"To access ruTorrent, visit https://rutorrent._yourdomain.com_","title":"1. URL"},{"location":"apps/rutorrent/#2-basics","text":"","title":"2. Basics"},{"location":"apps/rutorrent/#setup","text":"The setup for Sonarr , Radarr , and Lidarr are done on their respective wiki pages.","title":"Setup"},{"location":"apps/rutorrent/#3-enable-autounpack","text":"AutoUnpack is a plugin that will automatically unrar/unzip torrent data. This will allow Sonarr/Radarr/Lidarr to import the media files that would otherwise be ignored. After Sonarr and Radarr import the media files, Torrent Cleanup Script will then delete the extracted media files and ruTorrent will continue to seed the torrents (until they are either removed manually or automatically via ruTorrent's Ratio Group rules). To enable AutoUnpack: Open \"Settings\" by clicking the gear icon at the top Go to \"Unpack\" on the left. Check \"Enable autounpacking if torrents label matches filter\" and add the following: /.*(radarr|sonarr|lidarr).*/i Leave the other fields blank. Your settings will now look like this: Click \"OK\".","title":"3. Enable AutoUnpack"},{"location":"apps/rutorrent/#3-custom-plugins-and-themes","text":"You can have custom plugins and themes imported during Docker container rebuild. Just place them in the following paths: /opt/rutorrent/plugins/ /opt/rutorrent/themes/ And then restart the Docker container: docker restart rutorrent","title":"3. Custom Plugins and Themes"},{"location":"apps/rutorrent/#4-next","text":"Are you setting Saltbox up for the first time? Continue to NZBHydra2 .","title":"4. Next"},{"location":"apps/sabnzbd/","text":"THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX What is it? \u00b6 SABnzbd is an Open Source Binary Newsreader written in Python. It's totally free, easy to use, and works practically everywhere. SABnzbd makes Usenet as simple and streamlined as possible by automating everything we can. All you have to do is add an .nzb. SABnzbd takes over from there, where it will be automatically downloaded, verified, repaired, extracted and filed away with zero human interaction. SABnzbd offers an easy setup wizard and has self-analysis tools to verify your setup. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sabnzbd 1. URL \u00b6 To access sabnzbd, visit https://sabnzbd._yourdomain.com_ 2. Basics \u00b6 Go through the setup wizard. YOu will need to enter server details: When you get to the end of the wizard, click \"Go To SABnzbd\" Go to SABnzbd Config You will need to add in categories for sonarr , radarr , and lidarr . Set a relative directory name for each category. You will need a category for each instance of sonarr / radarr / lidarr [for example, if you have a radarr and radarr4k you will need a category for each] SABnzbd requires the server to be filled in to set categories up. This needs to be done BEFORE adding sabnzbd as a downloader to any of those apps. Direct unpack is disabled by default. Configure this as you prefer. Make note of the API Key in the \"General\" section When creating the connection in the arrs, use API Key rather than user/pass. Note that the category matches between Radarr and Sab. The specific category doesn't matter; just that they match.","title":"Sabnzbd"},{"location":"apps/sabnzbd/#what-is-it","text":"SABnzbd is an Open Source Binary Newsreader written in Python. It's totally free, easy to use, and works practically everywhere. SABnzbd makes Usenet as simple and streamlined as possible by automating everything we can. All you have to do is add an .nzb. SABnzbd takes over from there, where it will be automatically downloaded, verified, repaired, extracted and filed away with zero human interaction. SABnzbd offers an easy setup wizard and has self-analysis tools to verify your setup. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/sabnzbd/#1-installation","text":"sb install sabnzbd","title":"1. Installation"},{"location":"apps/sabnzbd/#1-url","text":"To access sabnzbd, visit https://sabnzbd._yourdomain.com_","title":"1. URL"},{"location":"apps/sabnzbd/#2-basics","text":"Go through the setup wizard. YOu will need to enter server details: When you get to the end of the wizard, click \"Go To SABnzbd\" Go to SABnzbd Config You will need to add in categories for sonarr , radarr , and lidarr . Set a relative directory name for each category. You will need a category for each instance of sonarr / radarr / lidarr [for example, if you have a radarr and radarr4k you will need a category for each] SABnzbd requires the server to be filled in to set categories up. This needs to be done BEFORE adding sabnzbd as a downloader to any of those apps. Direct unpack is disabled by default. Configure this as you prefer. Make note of the API Key in the \"General\" section When creating the connection in the arrs, use API Key rather than user/pass. Note that the category matches between Radarr and Sab. The specific category doesn't matter; just that they match.","title":"2. Basics"},{"location":"apps/sonarr/","text":"What is it? \u00b6 Sonarr is a PVR for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new episodes of your favorite shows and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available. Details Project home Docs Github Docker URL \u00b6 To access Sonarr, visit https://sonarr._yourdomain.com_ Settings \u00b6 Click on \"Settings\" in the sidebar. Click \"Show Advanced\" at the top of the Settings pane. Make changes in the following sections: Settings Media Management Indexers Download Clients Connect General These settings control management of media files. Episode Naming Folders Importing File Management Permissions Save \"Rename Episodes\": Yes \"Replace Illegal Characters\": Yes Set your preferred naming format; here are some examples: TRaSH' naming guide [Recommended[ Go here for the latest updates. These examples may be out of date. Example: Single Episode: The Series Title! (2010) - S01E01 - Episode Title 1 [AMZN WEBDL-1080p Proper][HDR][10bit][x264][DTS 5.1]-RlsGrp Multi Episode: The Series Title! (2010) - S01E01-E02-E03 - Episode Title [AMZN WEBDL-1080p Proper][HDR][10bit][x264][DTS 5.1]-RlsGrp Standard Episode Format: {Series TitleYear} - S{season:00}E{episode:00} - {Episode CleanTitle} [{Preferred Words }{Quality Full}]{[MediaInfo VideoDynamicRange]}[{MediaInfo VideoBitDepth}bit]{[MediaInfo VideoCodec]}{[Mediainfo AudioCodec}{ Mediainfo AudioChannels]}{MediaInfo AudioLanguages}{-Release Group} for more examples and discussion see the reference: https://trash-guides.info/Sonarr/Sonarr-recommended-naming-scheme/ The TRaSH naming guide is recommended since some other tools, notably Plex Meta Manager, expect it in their default setup. Plex's Naming Preference Example: /Gotham/Season 01/Gotham - s01e01 - Pilot.mkv Standard Episode Format: {Series Title} - s{season:00}e{episode:00} - {Episode Title} Anime Episode Format: {Series Title} - s{season:00}e{episode:00} - {Episode Title} Daily Episode Format: {Series Title} - {Air-Date} - {Episode Title} Season Folder Format: Season {season:00} Multi-Episode Style: Prefixed Range Reference: https://support.plex.tv/articles/200220687-naming-series-season-based-tv-shows/ \"Create empty series folders\": No \"Delete empty folders\": No \"Skip Free Space Check\": No \"Use Hardlinks instead of Copy\": Yes \"Import Extra Files\": Yes ( can be your preference ) \"Extra File Extensions\": srt, sub, idx \"Ignore Deleted Episodes\": No ( can be your preference ) \"Download Propers\": No ( can be your preference ) \"Analyse video files\": No \"Change File Date\": None \"Recycle Bin\": blank (Rclone deletes are sent to Gdrive trash folder, anyway) Set Permissions: No Click \"Save\". These settings control indexers and related behavior. NZBHydra2 Jackett Click Add Indexer ( + ). Select \"Newznab\". Add the following: Name: NZBHydra2 Enable RSS Sync: Your Preference Enable Search: Your Preference URL: http://nzbhydra2:5076 API Key: Your NZBHydra2 API Key Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add NZBHydra2. Note: The \"Test\" will keep failing until you add an indexer in NZBHydra2 . Note: Each Indexer you have defined in Jackett will need to be added separately. Click Add Indexer ( + ) Select \"Torznab\". Add the following: Name: Indexer Name Enable RSS Sync: Your Preference Enable Search: Your Preference URL: Indexer's Torznab Feed API Key: Your Jackett API Key Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add the indexer. These settings control downloading behavior and clients. Completed Download Handling Failed Download Handling NZBGet ruTorrent \"Enable\": Yes \"Remove\": Yes ( can be your preference ) \"Redownload\": Yes \"Remove\": Yes Click Add ( + ) Add a new \"NZBGet\" download client. Add the following: Name: NZBGet Enable: Yes Host: nzbget Port: 6789 Username: Your NZBGet Username Password: Your NZBGet Password Category: sonarr Use SSL: No Add Paused: No Your settings will look like this: Click \"Save\" to add NZBGet. Click Add ( + ) Add a new \"rTorrent\" download client. Add the following: Name: ruTorrent Enable: Yes Host: rutorrent Port: 80 URL Path: RPC2 Use SSL: No Username: Your ruTorrent Username Password: Your ruTorrent Password Category: sonarr Directory: Leave Blank Your settings will now look like this: Click \"Save\" to add ruTorrent. These settings control connections to other applications or systems. Torrent Cleanup Autoscan Torrent Cleanup Script is a custom script that will cleanup torrents from ruTorrent that were auto-extracted, but still being seeded. So if the script detects that .rar files are in the folder that Sonarr just imported from, it will delete the imported video file(s), leaving just the .rar files for seeding. Click \"Settings\" -> \"Connect\". Add a new \"Custom Script\". Add the following: Name: Torrent Cleanup On Grab: No On Download: Yes On Upgrade: Yes On Rename: No Path: /scripts/torrents/TorrentCleanup.py The settings will look like this: Click \"Save\" to add the Torrent Cleanup script. Click \"Settings\" -> \"Connect\". Add a new \"Webhook\". Add the following: Name: Autoscan On Grab: No On Import: Yes On Upgrade: Yes On Rename: Yes On Series Delete: Yes On Episode File Delete: Yes On Episode File Delete For Upgrade: Yes Tags: Leave Blank URL: http://autoscan:3030/triggers/sonarr Method: POST Username: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] Password: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] The settings will look like this: Click \"Save\" to add Autoscan. These settings control general aspects of Sonarr. Start-Up Proxy Settings Logging Analytics Updates Save \"Bind Address: * \"Port Number\": 8989 \"URL Base\": blank \"Enable SSL\": No ( SSL is handled by Traefik ) \"Use Proxy\": No \"Log Level\": Debug \"Enable\": No ( your preference ) These settings may be grayed out or unavailable; skip this if that's the case. \"Branch\": main \"Automatic\": Off Click \"Save\". TV Path \u00b6 When you are ready to add your first show to Sonarr, click the \"Root Path\" drop-down and select \"Add a different path\". Click the blue \"Browse\" button, navigate to /mnt/unionfs/Media/TV , scroll to the bottom, and select \"OK\". Click the green \"check\" button to add the path. All TV shows added now will have that path set. API Key \u00b6 This is used during the setup of Overseer and Organizr . Go to \"Settings\" -> \"General\" -> \"Security\" -> \"API Key\". Guides \u00b6 TraSH Guides Next \u00b6 Are you setting Saltbox up for the first time? Continue to Radarr .","title":"Sonarr"},{"location":"apps/sonarr/#what-is-it","text":"Sonarr is a PVR for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new episodes of your favorite shows and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/sonarr/#url","text":"To access Sonarr, visit https://sonarr._yourdomain.com_","title":"URL"},{"location":"apps/sonarr/#settings","text":"Click on \"Settings\" in the sidebar. Click \"Show Advanced\" at the top of the Settings pane. Make changes in the following sections: Settings Media Management Indexers Download Clients Connect General These settings control management of media files. Episode Naming Folders Importing File Management Permissions Save \"Rename Episodes\": Yes \"Replace Illegal Characters\": Yes Set your preferred naming format; here are some examples: TRaSH' naming guide [Recommended[ Go here for the latest updates. These examples may be out of date. Example: Single Episode: The Series Title! (2010) - S01E01 - Episode Title 1 [AMZN WEBDL-1080p Proper][HDR][10bit][x264][DTS 5.1]-RlsGrp Multi Episode: The Series Title! (2010) - S01E01-E02-E03 - Episode Title [AMZN WEBDL-1080p Proper][HDR][10bit][x264][DTS 5.1]-RlsGrp Standard Episode Format: {Series TitleYear} - S{season:00}E{episode:00} - {Episode CleanTitle} [{Preferred Words }{Quality Full}]{[MediaInfo VideoDynamicRange]}[{MediaInfo VideoBitDepth}bit]{[MediaInfo VideoCodec]}{[Mediainfo AudioCodec}{ Mediainfo AudioChannels]}{MediaInfo AudioLanguages}{-Release Group} for more examples and discussion see the reference: https://trash-guides.info/Sonarr/Sonarr-recommended-naming-scheme/ The TRaSH naming guide is recommended since some other tools, notably Plex Meta Manager, expect it in their default setup. Plex's Naming Preference Example: /Gotham/Season 01/Gotham - s01e01 - Pilot.mkv Standard Episode Format: {Series Title} - s{season:00}e{episode:00} - {Episode Title} Anime Episode Format: {Series Title} - s{season:00}e{episode:00} - {Episode Title} Daily Episode Format: {Series Title} - {Air-Date} - {Episode Title} Season Folder Format: Season {season:00} Multi-Episode Style: Prefixed Range Reference: https://support.plex.tv/articles/200220687-naming-series-season-based-tv-shows/ \"Create empty series folders\": No \"Delete empty folders\": No \"Skip Free Space Check\": No \"Use Hardlinks instead of Copy\": Yes \"Import Extra Files\": Yes ( can be your preference ) \"Extra File Extensions\": srt, sub, idx \"Ignore Deleted Episodes\": No ( can be your preference ) \"Download Propers\": No ( can be your preference ) \"Analyse video files\": No \"Change File Date\": None \"Recycle Bin\": blank (Rclone deletes are sent to Gdrive trash folder, anyway) Set Permissions: No Click \"Save\". These settings control indexers and related behavior. NZBHydra2 Jackett Click Add Indexer ( + ). Select \"Newznab\". Add the following: Name: NZBHydra2 Enable RSS Sync: Your Preference Enable Search: Your Preference URL: http://nzbhydra2:5076 API Key: Your NZBHydra2 API Key Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add NZBHydra2. Note: The \"Test\" will keep failing until you add an indexer in NZBHydra2 . Note: Each Indexer you have defined in Jackett will need to be added separately. Click Add Indexer ( + ) Select \"Torznab\". Add the following: Name: Indexer Name Enable RSS Sync: Your Preference Enable Search: Your Preference URL: Indexer's Torznab Feed API Key: Your Jackett API Key Additional Parameters: Leave Blank Your settings will look like this: Click \"Save\" to add the indexer. These settings control downloading behavior and clients. Completed Download Handling Failed Download Handling NZBGet ruTorrent \"Enable\": Yes \"Remove\": Yes ( can be your preference ) \"Redownload\": Yes \"Remove\": Yes Click Add ( + ) Add a new \"NZBGet\" download client. Add the following: Name: NZBGet Enable: Yes Host: nzbget Port: 6789 Username: Your NZBGet Username Password: Your NZBGet Password Category: sonarr Use SSL: No Add Paused: No Your settings will look like this: Click \"Save\" to add NZBGet. Click Add ( + ) Add a new \"rTorrent\" download client. Add the following: Name: ruTorrent Enable: Yes Host: rutorrent Port: 80 URL Path: RPC2 Use SSL: No Username: Your ruTorrent Username Password: Your ruTorrent Password Category: sonarr Directory: Leave Blank Your settings will now look like this: Click \"Save\" to add ruTorrent. These settings control connections to other applications or systems. Torrent Cleanup Autoscan Torrent Cleanup Script is a custom script that will cleanup torrents from ruTorrent that were auto-extracted, but still being seeded. So if the script detects that .rar files are in the folder that Sonarr just imported from, it will delete the imported video file(s), leaving just the .rar files for seeding. Click \"Settings\" -> \"Connect\". Add a new \"Custom Script\". Add the following: Name: Torrent Cleanup On Grab: No On Download: Yes On Upgrade: Yes On Rename: No Path: /scripts/torrents/TorrentCleanup.py The settings will look like this: Click \"Save\" to add the Torrent Cleanup script. Click \"Settings\" -> \"Connect\". Add a new \"Webhook\". Add the following: Name: Autoscan On Grab: No On Import: Yes On Upgrade: Yes On Rename: Yes On Series Delete: Yes On Episode File Delete: Yes On Episode File Delete For Upgrade: Yes Tags: Leave Blank URL: http://autoscan:3030/triggers/sonarr Method: POST Username: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] Password: AS SET IN AUTOSCAN CONFIG [defaults to Saltbox Username] The settings will look like this: Click \"Save\" to add Autoscan. These settings control general aspects of Sonarr. Start-Up Proxy Settings Logging Analytics Updates Save \"Bind Address: * \"Port Number\": 8989 \"URL Base\": blank \"Enable SSL\": No ( SSL is handled by Traefik ) \"Use Proxy\": No \"Log Level\": Debug \"Enable\": No ( your preference ) These settings may be grayed out or unavailable; skip this if that's the case. \"Branch\": main \"Automatic\": Off Click \"Save\".","title":"Settings"},{"location":"apps/sonarr/#tv-path","text":"When you are ready to add your first show to Sonarr, click the \"Root Path\" drop-down and select \"Add a different path\". Click the blue \"Browse\" button, navigate to /mnt/unionfs/Media/TV , scroll to the bottom, and select \"OK\". Click the green \"check\" button to add the path. All TV shows added now will have that path set.","title":"TV Path"},{"location":"apps/sonarr/#api-key","text":"This is used during the setup of Overseer and Organizr . Go to \"Settings\" -> \"General\" -> \"Security\" -> \"API Key\".","title":"API Key"},{"location":"apps/sonarr/#guides","text":"TraSH Guides","title":"Guides"},{"location":"apps/sonarr/#next","text":"Are you setting Saltbox up for the first time? Continue to Radarr .","title":"Next"},{"location":"apps/sstv/","text":"THIS PAGE HAS NOT BEEN FULLY UPDATED FOR SALTBOX","title":"SSTV"},{"location":"apps/tautulli/","text":"What is it? \u00b6 Tautulli (Tautulli), by JonnyWong16, is a web-based application runs alongside the Plex Media Server to monitor activity and track various statistics (eg most watched media). Details Project home Docs Github Docker 2. URL \u00b6 To access Tautulli, visit https://tautulli._yourdomain_.com 3. Setup Wizard \u00b6 First time you go to the Tautulli site, you will be presented with the \"Tautulli Setup Wizard\". Click Next . On the \"Plex Authentication\" page, sign in with your Plex username and password, and click Authenticate . When you see the \"Authentication successful.\" message, click Next . On the \"Plex Media Server\" page, set the following: \"Plex IP or Hostname\": plex \"Port Number\": 32400 \"Use SSL\": disabled \"Remote Server\": disabled Click Verify . When you see the \"Server found!\" message, click Next . On the \"Activity Logging\" page, select your preferences (default is OK) and click Next . On the \"Notifications\" page, simply click Next . On the \"Database Import\" page, click Finish to complete the setup. 4. Settings \u00b6 Once the Tautulli page comes up, go to \"Settings\". Click \"Web Interface\" on the left. Fill in \"HTTP Username\" and \"HTTP Password (this will be the login for your Tautulli site), but don't click Save yet. Click \"Plex Media Server\" on the left. Click \"Show Advanced\" at the top. Under \"Logs Folder\", type in /logs . Now you can click Save . Also verify 'Use SSL' and 'Remote Server` are unchecked. On the \"Restart\" popup window, click Restart . 5. Next \u00b6 Are you setting Saltbox up for the first time? Continue to Overseerr .","title":"Tautulli"},{"location":"apps/tautulli/#what-is-it","text":"Tautulli (Tautulli), by JonnyWong16, is a web-based application runs alongside the Plex Media Server to monitor activity and track various statistics (eg most watched media). Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/tautulli/#2-url","text":"To access Tautulli, visit https://tautulli._yourdomain_.com","title":"2. URL"},{"location":"apps/tautulli/#3-setup-wizard","text":"First time you go to the Tautulli site, you will be presented with the \"Tautulli Setup Wizard\". Click Next . On the \"Plex Authentication\" page, sign in with your Plex username and password, and click Authenticate . When you see the \"Authentication successful.\" message, click Next . On the \"Plex Media Server\" page, set the following: \"Plex IP or Hostname\": plex \"Port Number\": 32400 \"Use SSL\": disabled \"Remote Server\": disabled Click Verify . When you see the \"Server found!\" message, click Next . On the \"Activity Logging\" page, select your preferences (default is OK) and click Next . On the \"Notifications\" page, simply click Next . On the \"Database Import\" page, click Finish to complete the setup.","title":"3. Setup Wizard"},{"location":"apps/tautulli/#4-settings","text":"Once the Tautulli page comes up, go to \"Settings\". Click \"Web Interface\" on the left. Fill in \"HTTP Username\" and \"HTTP Password (this will be the login for your Tautulli site), but don't click Save yet. Click \"Plex Media Server\" on the left. Click \"Show Advanced\" at the top. Under \"Logs Folder\", type in /logs . Now you can click Save . Also verify 'Use SSL' and 'Remote Server` are unchecked. On the \"Restart\" popup window, click Restart .","title":"4. Settings"},{"location":"apps/tautulli/#5-next","text":"Are you setting Saltbox up for the first time? Continue to Overseerr .","title":"5. Next"},{"location":"apps/transfer/","text":"transfer.sh \u00b6 What is it? \u00b6 transfer.sh is an easy and fast file sharing from the command-line or web gui app. Details Project home Docs Github Docker 1. Installation \u00b6 sb install transfer 2. URL \u00b6 To access transfer.sh, visit https://transfer._yourdomain.com_ 3. Setup \u00b6 The pre-configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml . Documentation","title":"Transfer"},{"location":"apps/transfer/#transfersh","text":"","title":"transfer.sh"},{"location":"apps/transfer/#what-is-it","text":"transfer.sh is an easy and fast file sharing from the command-line or web gui app. Details Project home Docs Github Docker","title":"What is it?"},{"location":"apps/transfer/#1-installation","text":"sb install transfer","title":"1. Installation"},{"location":"apps/transfer/#2-url","text":"To access transfer.sh, visit https://transfer._yourdomain.com_","title":"2. URL"},{"location":"apps/transfer/#3-setup","text":"The pre-configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml . Documentation","title":"3. Setup"},{"location":"faq/Backup%20and%20Restore/","text":"IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED PLEASE OPEN ISSUES What is backed up? \u00b6 Only app data located in /opt and relevant config files (as listed below) are backed up. The backup script does this by creating tarball files ( .tar) for each folder in /opt / and placing them into your backup folder (as set in backup_config.yml ). The folders in /opt are all* backed up without regard for whether Saltbox created them in the first place. For example, if you create /opt/bingbangboing it will be backed up and restored by Saltbox. If you have set it up, the community repo is located in /opt , so it will get backed up [this includes any changes you've made in that repo to the config or roles]. There is no catalog kept of what community roles you may have run, so none of the roles themselves will be run automatically on restore, but the data will be backed up and restored. Service files from /etc/systemd/system are synced to /opt/systemd-backup as part of the backup, so they are included in the tarball creation. This includes things like the rclone_vfs , mergerfs , cloudplow , plex_autoscan , and other system service files. If you have added additional mounts and the like via your own service files [perhaps with tip #44 or samount or the like], these extra service files will be backed up, but will not be automatically restored. Torrent seeding content, NZBGet queue, anything in /mnt/ , /home/ , or anywhere else other than the /opt/ folder, will NOT be backed up (media files are moved to the cloud via Cloudplow , anyway). If you do want to backup your seeding data, check out the scripts located in /opt/scripts/rclone/ folder. If Rclone/Rsync are enabled, the backup will be uploaded to a remote destination. If keep_local_copy is enabled, the backup will remain locally in the backup folder; If NOT, the backup will be deleted. If you decide to disable Rclone/Sync, then at least have keep_local_copy enabled, or else the backup will be created and then deleted right after. The config files that are backed up are: ansible.cfg accounts.yml settings.yml adv_settings.yml rclone.conf backup_excludes.txt (if one exists in the saltbox folder). These files are kept separately from the backup tarball files to allow for easy access. Note that the .ansible_vault file is NOT backed up. Nice table to see what is restored during simple backup/restore: Items Backed UP Backed Up From Restored To Application Data /opt/ /opt/ Ansible Config /srv/git/saltbox/ansible.cfg Account Settings /srv/git/saltbox/accounts.yml Saltbox Settings /srv/git/saltbox/settings.yml Saltbox Advanced Settings /srv/git/saltbox/adv_settings.yml Backup Excludes List (custom) /srv/git/saltbox/backup_excludes_list.txt ~/saltbox/backup_excludes_list.txt Rclone Config ~/.config/rclone/rclone.conf ~/.config/rclone/rclone.conf What is Saltbox Restore Service? \u00b6 An optional service that allows for easy backing up and restoring of CLIENT-SIDE ENCRYPTED config files. The config files that are backed up are: ansible.cfg accounts.yml settings.yml adv_settings.yml backup_config.yml rclone.conf These files are the ones needed to run a successful restore. Note: backup_excludes_list.txt are not backed up into the Restore Service, simply because it is not important for a restore to work and also because it IS automatically restored during the restore process itself. How does this work? User fills in a username and password for Restore Service in the [[backup config |Saltbox-Backup-and-Restore-Settings]]. During backup, config files are encrypted on the client-side, using a salt-hashed version of the username and password (your raw username is never sent to the Restore Service), and then uploaded to the Restore Service. When a user needs to restore their backup on a new box, they can pull their backed up config files from the Restore Service with a single command. The source code for the Restore Service Scripts are listed below: - https://github.com/saltyorg/Saltbox/blob/master/roles/backup/tasks/restore_service.yml (Backup Script) - https://github.com/saltyorg/scripts/blob/master/restore.sh (Restore Script)","title":"Backup and Restore"},{"location":"faq/Backup%20and%20Restore/#what-is-backed-up","text":"Only app data located in /opt and relevant config files (as listed below) are backed up. The backup script does this by creating tarball files ( .tar) for each folder in /opt / and placing them into your backup folder (as set in backup_config.yml ). The folders in /opt are all* backed up without regard for whether Saltbox created them in the first place. For example, if you create /opt/bingbangboing it will be backed up and restored by Saltbox. If you have set it up, the community repo is located in /opt , so it will get backed up [this includes any changes you've made in that repo to the config or roles]. There is no catalog kept of what community roles you may have run, so none of the roles themselves will be run automatically on restore, but the data will be backed up and restored. Service files from /etc/systemd/system are synced to /opt/systemd-backup as part of the backup, so they are included in the tarball creation. This includes things like the rclone_vfs , mergerfs , cloudplow , plex_autoscan , and other system service files. If you have added additional mounts and the like via your own service files [perhaps with tip #44 or samount or the like], these extra service files will be backed up, but will not be automatically restored. Torrent seeding content, NZBGet queue, anything in /mnt/ , /home/ , or anywhere else other than the /opt/ folder, will NOT be backed up (media files are moved to the cloud via Cloudplow , anyway). If you do want to backup your seeding data, check out the scripts located in /opt/scripts/rclone/ folder. If Rclone/Rsync are enabled, the backup will be uploaded to a remote destination. If keep_local_copy is enabled, the backup will remain locally in the backup folder; If NOT, the backup will be deleted. If you decide to disable Rclone/Sync, then at least have keep_local_copy enabled, or else the backup will be created and then deleted right after. The config files that are backed up are: ansible.cfg accounts.yml settings.yml adv_settings.yml rclone.conf backup_excludes.txt (if one exists in the saltbox folder). These files are kept separately from the backup tarball files to allow for easy access. Note that the .ansible_vault file is NOT backed up. Nice table to see what is restored during simple backup/restore: Items Backed UP Backed Up From Restored To Application Data /opt/ /opt/ Ansible Config /srv/git/saltbox/ansible.cfg Account Settings /srv/git/saltbox/accounts.yml Saltbox Settings /srv/git/saltbox/settings.yml Saltbox Advanced Settings /srv/git/saltbox/adv_settings.yml Backup Excludes List (custom) /srv/git/saltbox/backup_excludes_list.txt ~/saltbox/backup_excludes_list.txt Rclone Config ~/.config/rclone/rclone.conf ~/.config/rclone/rclone.conf","title":"What is backed up?"},{"location":"faq/Backup%20and%20Restore/#what-is-saltbox-restore-service","text":"An optional service that allows for easy backing up and restoring of CLIENT-SIDE ENCRYPTED config files. The config files that are backed up are: ansible.cfg accounts.yml settings.yml adv_settings.yml backup_config.yml rclone.conf These files are the ones needed to run a successful restore. Note: backup_excludes_list.txt are not backed up into the Restore Service, simply because it is not important for a restore to work and also because it IS automatically restored during the restore process itself. How does this work? User fills in a username and password for Restore Service in the [[backup config |Saltbox-Backup-and-Restore-Settings]]. During backup, config files are encrypted on the client-side, using a salt-hashed version of the username and password (your raw username is never sent to the Restore Service), and then uploaded to the Restore Service. When a user needs to restore their backup on a new box, they can pull their backed up config files from the Restore Service with a single command. The source code for the Restore Service Scripts are listed below: - https://github.com/saltyorg/Saltbox/blob/master/roles/backup/tasks/restore_service.yml (Backup Script) - https://github.com/saltyorg/scripts/blob/master/restore.sh (Restore Script)","title":"What is Saltbox Restore Service?"},{"location":"faq/Cloud%20Storage/","text":"Cloud Storage \u00b6 Does Saltbox support encrypted data on the cloud? \u00b6 In short, no. Saltbox does not come with encryption support out-of-box. Why does Saltbox not support encryption data on the cloud? \u00b6 While there are pro's and cons for using either encrypted or unencrypted data on cloud services, we've decided to not deal with encryption for the out of box setup. However, since Saltbox uses Rclone VFS to mount cloud data, you can tweak the mounts and remotes to do this yourself. But doing so comes with no support/help from us. Don't see your remote files in /mnt/remote? \u00b6 See here","title":"Cloud Storage"},{"location":"faq/Cloud%20Storage/#cloud-storage","text":"","title":"Cloud Storage"},{"location":"faq/Cloud%20Storage/#does-saltbox-support-encrypted-data-on-the-cloud","text":"In short, no. Saltbox does not come with encryption support out-of-box.","title":"Does Saltbox support encrypted data on the cloud?"},{"location":"faq/Cloud%20Storage/#why-does-saltbox-not-support-encryption-data-on-the-cloud","text":"While there are pro's and cons for using either encrypted or unencrypted data on cloud services, we've decided to not deal with encryption for the out of box setup. However, since Saltbox uses Rclone VFS to mount cloud data, you can tweak the mounts and remotes to do this yourself. But doing so comes with no support/help from us.","title":"Why does Saltbox not support encryption data on the cloud?"},{"location":"faq/Cloud%20Storage/#dont-see-your-remote-files-in-mntremote","text":"See here","title":"Don't see your remote files in /mnt/remote?"},{"location":"faq/Cloudflare/","text":"Cloudflare \u00b6 API request not authenticated \u00b6 If you get this error during SB Install: fatal: [localhost]: FAILED! => {\"changed\": false, \"msg\": \"API request not authenticated; Status: 403; Method: GET: Call: /zones?name=; Error details: code: 9103, error: Unknown X-Auth-Key or X-Auth-Email; \"} Make sure: The email in settings.yml matches the one you have listed for your Cloudflare.com account. The cloudflare_api_key in settings.yml matches your domain 's Cloudflare Global API Key . TLD domain not supported \u00b6 If you get this error during SB Install: fatal: [localhost]: FAILED! => {\"changed\": false, \"msg\": \"API request not authenticated; Status: 403; Method: POST: Call: /zones/BINGBANGBOING/dns_records\"} It's probably due to using a top-level domain that isn't supported by the Cloudflare API. Refer to this page . As of 2022/11/03: \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\"","title":"CloudFlare"},{"location":"faq/Cloudflare/#cloudflare","text":"","title":"Cloudflare"},{"location":"faq/Cloudflare/#api-request-not-authenticated","text":"If you get this error during SB Install: fatal: [localhost]: FAILED! => {\"changed\": false, \"msg\": \"API request not authenticated; Status: 403; Method: GET: Call: /zones?name=; Error details: code: 9103, error: Unknown X-Auth-Key or X-Auth-Email; \"} Make sure: The email in settings.yml matches the one you have listed for your Cloudflare.com account. The cloudflare_api_key in settings.yml matches your domain 's Cloudflare Global API Key .","title":"API request not authenticated"},{"location":"faq/Cloudflare/#tld-domain-not-supported","text":"If you get this error during SB Install: fatal: [localhost]: FAILED! => {\"changed\": false, \"msg\": \"API request not authenticated; Status: 403; Method: POST: Call: /zones/BINGBANGBOING/dns_records\"} It's probably due to using a top-level domain that isn't supported by the Cloudflare API. Refer to this page . As of 2022/11/03: \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\"","title":"TLD domain not supported"},{"location":"faq/Cloudplow/","text":"Cloudplow FAQs \u00b6 Stuck on \"Waiting for running upload to finish before proceeding...\" \u00b6 If the activity log is stuck on: 2018-06-03 13:44:59,659 - INFO - cloudplow - do_upload - Waiting for running upload to finish before proceeding... This means that an upload task was prematurely canceled and it left lock file(s) to prevent another upload. To fix this, run this command: rm -rf /opt/cloudplow/locks/* or sudo systemctl restart cloudplow","title":"Cloudplow"},{"location":"faq/Cloudplow/#cloudplow-faqs","text":"","title":"Cloudplow FAQs"},{"location":"faq/Cloudplow/#stuck-on-waiting-for-running-upload-to-finish-before-proceeding","text":"If the activity log is stuck on: 2018-06-03 13:44:59,659 - INFO - cloudplow - do_upload - Waiting for running upload to finish before proceeding... This means that an upload task was prematurely canceled and it left lock file(s) to prevent another upload. To fix this, run this command: rm -rf /opt/cloudplow/locks/* or sudo systemctl restart cloudplow","title":"Stuck on \"Waiting for running upload to finish before proceeding...\""},{"location":"faq/Docker/","text":"Docker \u00b6 Why does Saltbox use the Docker network \"saltbox\" instead of bridge? \u00b6 (1) keeps all Saltbox containers organized under one network; and (2), bridge network does not allow network aliases.","title":"Docker"},{"location":"faq/Docker/#docker","text":"","title":"Docker"},{"location":"faq/Docker/#why-does-saltbox-use-the-docker-network-saltbox-instead-of-bridge","text":"(1) keeps all Saltbox containers organized under one network; and (2), bridge network does not allow network aliases.","title":"Why does Saltbox use the Docker network \"saltbox\" instead of bridge?"},{"location":"faq/Hetzner/","text":"Hetzner & Google IPv6 \u00b6 From time to time Hetzner seems to have problems with IPv6 routing to Google so these are ways you can work around that problem. Disable IPv6 Temporarily \u00b6 sudo sysctl -w net.ipv6.conf.all.disable_ipv6 = 1 sudo sysctl -w net.ipv6.conf.default.disable_ipv6 = 1 sudo sysctl -w net.ipv6.conf.lo.disable_ipv6 = 1 Disable IPv6 permanently \u00b6 Add the following to /etc/sysctl.conf net.ipv6.conf.all.disable_ipv6=1 net.ipv6.conf.default.disable_ipv6=1 net.ipv6.conf.lo.disable_ipv6=1 Then run sudo sysctl -p Alternately you can disable IPv6 using GRUB by editing /etc/default/grub and adding the following to GRUB_CMDLINE_LINUX_DEFAULT and GRUB_CMDLINE_LINUX ipv6.disable=1 External resource: here Make Rclone use IPv4 \u00b6 For the mount this is done by toggling ipv4_only in /srv/git/saltbox/adv_settings.yml like so: mounts : remote : rclone_vfs ipv4_only : yes feeder : no Then run sb install mounts_override For Cloudplow you could add something like: \"rclone_extras\" : { \"--user-agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" , \"--checkers\" : 16 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 , \"--skip-links\" : null , \"--retries\" : 1 , \"--low-level-retries\" : 2 , \"--drive-stop-on-upload-limit\" : null , \"--bind\" : \"<Insert Your WAN IP>\" }, For crop you would add the following to the global params that you are utilizing: - '--bind=<Insert Your WAN IP>' After doing any changes to Cloudplow or crop configuration remember to restart their respective service. Use a script to bind traffic to Google API endpoints to a specific IP \u00b6 Setup this script and let it modify your hosts file. Markschrik has created a version of the script that will do the required setup for you if you are using the default Saltbox setup; it can be found here . Download it, mark it executable, and run it. wget https://raw.githubusercontent.com/markschrik/Saltbox-GoogleBandwith/main/bandwithtest.sh chmod +x bandwithtest.sh ./bandwithtest.sh You can also add this to your crontab to execute it automatically.","title":"Hetzner & Google IPv6"},{"location":"faq/Hetzner/#hetzner-google-ipv6","text":"From time to time Hetzner seems to have problems with IPv6 routing to Google so these are ways you can work around that problem.","title":"Hetzner &amp; Google IPv6"},{"location":"faq/Hetzner/#disable-ipv6-temporarily","text":"sudo sysctl -w net.ipv6.conf.all.disable_ipv6 = 1 sudo sysctl -w net.ipv6.conf.default.disable_ipv6 = 1 sudo sysctl -w net.ipv6.conf.lo.disable_ipv6 = 1","title":"Disable IPv6 Temporarily"},{"location":"faq/Hetzner/#disable-ipv6-permanently","text":"Add the following to /etc/sysctl.conf net.ipv6.conf.all.disable_ipv6=1 net.ipv6.conf.default.disable_ipv6=1 net.ipv6.conf.lo.disable_ipv6=1 Then run sudo sysctl -p Alternately you can disable IPv6 using GRUB by editing /etc/default/grub and adding the following to GRUB_CMDLINE_LINUX_DEFAULT and GRUB_CMDLINE_LINUX ipv6.disable=1 External resource: here","title":"Disable IPv6 permanently"},{"location":"faq/Hetzner/#make-rclone-use-ipv4","text":"For the mount this is done by toggling ipv4_only in /srv/git/saltbox/adv_settings.yml like so: mounts : remote : rclone_vfs ipv4_only : yes feeder : no Then run sb install mounts_override For Cloudplow you could add something like: \"rclone_extras\" : { \"--user-agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36\" , \"--checkers\" : 16 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 , \"--skip-links\" : null , \"--retries\" : 1 , \"--low-level-retries\" : 2 , \"--drive-stop-on-upload-limit\" : null , \"--bind\" : \"<Insert Your WAN IP>\" }, For crop you would add the following to the global params that you are utilizing: - '--bind=<Insert Your WAN IP>' After doing any changes to Cloudplow or crop configuration remember to restart their respective service.","title":"Make Rclone use IPv4"},{"location":"faq/Hetzner/#use-a-script-to-bind-traffic-to-google-api-endpoints-to-a-specific-ip","text":"Setup this script and let it modify your hosts file. Markschrik has created a version of the script that will do the required setup for you if you are using the default Saltbox setup; it can be found here . Download it, mark it executable, and run it. wget https://raw.githubusercontent.com/markschrik/Saltbox-GoogleBandwith/main/bandwithtest.sh chmod +x bandwithtest.sh ./bandwithtest.sh You can also add this to your crontab to execute it automatically.","title":"Use a script to bind traffic to Google API endpoints to a specific IP"},{"location":"faq/Install/","text":"IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED PLEASE OPEN ISSUES Ansible Tags \u00b6 Multiple Tags \u00b6 Run multiple tags together by separating them with commas, no spaces. Quotes are optional. Order is not important. Use this to install containers or roles that are not included in \"default\" install types. Example: sb install core,emby,sonarr,radarr,nzbget,nzbhydra2 Skip Tags \u00b6 Skip tags you dont want to run by listing them with --skip-tags and separated by commas. Quotes are optional. Order is not important. Use this to skip containers or roles that are included in the \"default\" install types. Example: sb install saltbox --skip-tags rutorrent,jackett Note: But be careful on what you skip, as some things are needed by Saltbox to function properly. Merging Tags and Skip-Tags \u00b6 You can even merge --tags and --skip-tags into one command. Order is not important (e.g. skip tags can come before tags). Example: sb install saltbox,sabnzbd --skip-tags rutorrent,jackett Persistent Skip Tags \u00b6 You can \"permanently\" skip tags by adding the following lines to /srv/git/saltbox/ansible.cfg . Format: [tags] skip = TAG1,TAG2,etc And then continue to install with the normal --tags command. Example: cat /srv/git/saltbox/ansible.cfg [tags] skip = rutorrent,jackett sb install saltbox,sabnzbd In this example, the Saltbox installer will install with all the default items and sabnzbd, but will not install rutorrent and jackett. Error while fetching server API version \u00b6 Full error message: Error Connecting: Error while fetching server API version: Timeout value connect was Timeout(connect=60, read=60, total=None), but it must be an int or float. Run sudo pip install requests==2.10.0 and retry. 403 Client Error: Forbidden: endpoint with name \\<container name> already exists in network \\<network name> \u00b6 Example: fatal: [localhost]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"Error starting container 6fb60d4cdabe938986042e06ef482012a1d85a66a099d861f08062d8262c2ef7: 403 Client Error: Forbidden (\\\"{\\\"message\\\":\\\"endpoint with name jackett already exists in network bridge\\\"}\\\")\"} to retry, use: --limit @/home/seed/saltbox/saltbox.retry PLAY RECAP ********************************************************************* localhost : ok=2 changed=1 unreachable=0 failed=1 You have a remnant of the container in the Docker's network. You can verify with the command below (replace <network name> and <container name> is replaced with the network name and container name mentioned in the error, respectively): docker inspect network <network name> | grep <container name> To remove the remnant, run this command and try again: docker network disconnect -f <network name> <container name> 500 Server Error: Internal Server Error: driver failed programming external connectivity on endpoint \\<container name> bind for 0.0.0.0:\\<port number> failed: port is already allocated \u00b6 sudo service docker stop sudo service docker start Updating Saltbox \u00b6 Follow the appropriate steps from this page","title":"Install"},{"location":"faq/Install/#ansible-tags","text":"","title":"Ansible Tags"},{"location":"faq/Install/#multiple-tags","text":"Run multiple tags together by separating them with commas, no spaces. Quotes are optional. Order is not important. Use this to install containers or roles that are not included in \"default\" install types. Example: sb install core,emby,sonarr,radarr,nzbget,nzbhydra2","title":"Multiple Tags"},{"location":"faq/Install/#skip-tags","text":"Skip tags you dont want to run by listing them with --skip-tags and separated by commas. Quotes are optional. Order is not important. Use this to skip containers or roles that are included in the \"default\" install types. Example: sb install saltbox --skip-tags rutorrent,jackett Note: But be careful on what you skip, as some things are needed by Saltbox to function properly.","title":"Skip Tags"},{"location":"faq/Install/#merging-tags-and-skip-tags","text":"You can even merge --tags and --skip-tags into one command. Order is not important (e.g. skip tags can come before tags). Example: sb install saltbox,sabnzbd --skip-tags rutorrent,jackett","title":"Merging Tags and Skip-Tags"},{"location":"faq/Install/#persistent-skip-tags","text":"You can \"permanently\" skip tags by adding the following lines to /srv/git/saltbox/ansible.cfg . Format: [tags] skip = TAG1,TAG2,etc And then continue to install with the normal --tags command. Example: cat /srv/git/saltbox/ansible.cfg [tags] skip = rutorrent,jackett sb install saltbox,sabnzbd In this example, the Saltbox installer will install with all the default items and sabnzbd, but will not install rutorrent and jackett.","title":"Persistent Skip Tags"},{"location":"faq/Install/#error-while-fetching-server-api-version","text":"Full error message: Error Connecting: Error while fetching server API version: Timeout value connect was Timeout(connect=60, read=60, total=None), but it must be an int or float. Run sudo pip install requests==2.10.0 and retry.","title":"Error while fetching server API version"},{"location":"faq/Install/#403-client-error-forbidden-endpoint-with-name-container-name-already-exists-in-network-network-name","text":"Example: fatal: [localhost]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"Error starting container 6fb60d4cdabe938986042e06ef482012a1d85a66a099d861f08062d8262c2ef7: 403 Client Error: Forbidden (\\\"{\\\"message\\\":\\\"endpoint with name jackett already exists in network bridge\\\"}\\\")\"} to retry, use: --limit @/home/seed/saltbox/saltbox.retry PLAY RECAP ********************************************************************* localhost : ok=2 changed=1 unreachable=0 failed=1 You have a remnant of the container in the Docker's network. You can verify with the command below (replace <network name> and <container name> is replaced with the network name and container name mentioned in the error, respectively): docker inspect network <network name> | grep <container name> To remove the remnant, run this command and try again: docker network disconnect -f <network name> <container name>","title":"403 Client Error: Forbidden: endpoint with name \\&lt;container name> already exists in network \\&lt;network name>"},{"location":"faq/Install/#500-server-error-internal-server-error-driver-failed-programming-external-connectivity-on-endpoint-container-name-bind-for-0000port-number-failed-port-is-already-allocated","text":"sudo service docker stop sudo service docker start","title":"500 Server Error: Internal Server Error: driver failed programming external connectivity on endpoint \\&lt;container name> bind for 0.0.0.0:\\&lt;port number> failed: port is already allocated"},{"location":"faq/Install/#updating-saltbox","text":"Follow the appropriate steps from this page","title":"Updating Saltbox"},{"location":"faq/Misc/","text":"IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED PLEASE OPEN ISSUES Backup/Restore NextcloudDB \u00b6 DB data is stored in /opt/mariadb and backed up along with Saltbox Backup. However, you can separately make a backup of the DB into a single nextcloud_backup.sql file, by running the following command. docker exec mariadb /usr/bin/mysqldump -u root --password=password321 nextcloud > nextcloud_backup.sql And restoring it back: cat nextcloud_backup.sql | docker exec -i mariadb /usr/bin/mysql -u root --password=password321 nextcloud JSON Format Errors \u00b6 Python or script errors mentioning an issue with the config file is usually due to an invalid JSON format in the file. Examples: Traceback ( most recent call last ): File \"scan.py\" , line 52 , in < module > conf . load () File \"/opt/plex_autoscan/config.py\" , line 157 , in load cfg = self . upgrade ( json . load ( fp )) File \"/usr/lib/python2.7/json/__init__.py\" , line 291 , in load ** kw ) File \"/usr/lib/python2.7/json/__init__.py\" , line 339 , in loads return _default_decoder . decode ( s ) File \"/usr/lib/python2.7/json/decoder.py\" , line 364 , in decode obj , end = self . raw_decode ( s , idx = _w ( s , 0 ) . end ()) File \"/usr/lib/python2.7/json/decoder.py\" , line 380 , in raw_decode obj , end = self . scan_once ( s , idx ) ValueError : Expecting , delimiter : line 20 column 2 ( char 672 ) Traceback ( most recent call last ): File \"/opt/plex_autoscan/scan.py\" , line 52 , in < module > conf . load () File \"/opt/plex_autoscan/config.py\" , line 157 , in load cfg = self . upgrade ( json . load ( fp )) File \"/usr/lib/python2.7/json/init.py\" , line 291 , in load ** kw ) File \"/usr/lib/python2.7/json/init.py\" , line 339 , in loads return _default_decoder . decode ( s ) File \"/usr/lib/python2.7/json/decoder.py\" , line 364 , in decode obj , end = self . raw_decode ( s , idx = _w ( s , 0 ) . end ()) File \"/usr/lib/python2.7/json/decoder.py\" , line 382 , in raw_decode raise ValueError ( \"No JSON object could be decoded\" ) ValueError : No JSON object could be decoded Traceback ( most recent call last ): File \"/usr/local/bin/cloudplow\" , line 60 , in < module > conf . load () File \"/opt/cloudplow/utils/config.py\" , line 227 , in load cfg , upgraded = self . upgrade_settings ( json . load ( fp )) File \"/usr/lib/python3.5/json/__init__.py\" , line 268 , in load parse_constant = parse_constant , object_pairs_hook = object_pairs_hook , ** kw ) File \"/usr/lib/python3.5/json/__init__.py\" , line 319 , in loads return _default_decoder . decode ( s ) File \"/usr/lib/python3.5/json/decoder.py\" , line 339 , in decode obj , end = self . raw_decode ( s , idx = _w ( s , 0 ) . end ()) File \"/usr/lib/python3.5/json/decoder.py\" , line 355 , in raw_decode obj , end = self . scan_once ( s , idx ) json . decoder . JSONDecodeError : Expecting ',' delimiter : line 46 column 13 ( char 1354 ) Fixes: Paste the JSON file at jsonformatter.curiousconcept.com and click process . This will tell you what the issue is and fix it for you. or Run: jq '.' config.json If there are no issues, it will simply print out the full JSON file. If there is an issue, a msg will display the location of the issue: parse error: Expected separator between values at line 7, column 10","title":"Misc"},{"location":"faq/Misc/#backuprestore-nextclouddb","text":"DB data is stored in /opt/mariadb and backed up along with Saltbox Backup. However, you can separately make a backup of the DB into a single nextcloud_backup.sql file, by running the following command. docker exec mariadb /usr/bin/mysqldump -u root --password=password321 nextcloud > nextcloud_backup.sql And restoring it back: cat nextcloud_backup.sql | docker exec -i mariadb /usr/bin/mysql -u root --password=password321 nextcloud","title":"Backup/Restore NextcloudDB"},{"location":"faq/Misc/#json-format-errors","text":"Python or script errors mentioning an issue with the config file is usually due to an invalid JSON format in the file. Examples: Traceback ( most recent call last ): File \"scan.py\" , line 52 , in < module > conf . load () File \"/opt/plex_autoscan/config.py\" , line 157 , in load cfg = self . upgrade ( json . load ( fp )) File \"/usr/lib/python2.7/json/__init__.py\" , line 291 , in load ** kw ) File \"/usr/lib/python2.7/json/__init__.py\" , line 339 , in loads return _default_decoder . decode ( s ) File \"/usr/lib/python2.7/json/decoder.py\" , line 364 , in decode obj , end = self . raw_decode ( s , idx = _w ( s , 0 ) . end ()) File \"/usr/lib/python2.7/json/decoder.py\" , line 380 , in raw_decode obj , end = self . scan_once ( s , idx ) ValueError : Expecting , delimiter : line 20 column 2 ( char 672 ) Traceback ( most recent call last ): File \"/opt/plex_autoscan/scan.py\" , line 52 , in < module > conf . load () File \"/opt/plex_autoscan/config.py\" , line 157 , in load cfg = self . upgrade ( json . load ( fp )) File \"/usr/lib/python2.7/json/init.py\" , line 291 , in load ** kw ) File \"/usr/lib/python2.7/json/init.py\" , line 339 , in loads return _default_decoder . decode ( s ) File \"/usr/lib/python2.7/json/decoder.py\" , line 364 , in decode obj , end = self . raw_decode ( s , idx = _w ( s , 0 ) . end ()) File \"/usr/lib/python2.7/json/decoder.py\" , line 382 , in raw_decode raise ValueError ( \"No JSON object could be decoded\" ) ValueError : No JSON object could be decoded Traceback ( most recent call last ): File \"/usr/local/bin/cloudplow\" , line 60 , in < module > conf . load () File \"/opt/cloudplow/utils/config.py\" , line 227 , in load cfg , upgraded = self . upgrade_settings ( json . load ( fp )) File \"/usr/lib/python3.5/json/__init__.py\" , line 268 , in load parse_constant = parse_constant , object_pairs_hook = object_pairs_hook , ** kw ) File \"/usr/lib/python3.5/json/__init__.py\" , line 319 , in loads return _default_decoder . decode ( s ) File \"/usr/lib/python3.5/json/decoder.py\" , line 339 , in decode obj , end = self . raw_decode ( s , idx = _w ( s , 0 ) . end ()) File \"/usr/lib/python3.5/json/decoder.py\" , line 355 , in raw_decode obj , end = self . scan_once ( s , idx ) json . decoder . JSONDecodeError : Expecting ',' delimiter : line 46 column 13 ( char 1354 ) Fixes: Paste the JSON file at jsonformatter.curiousconcept.com and click process . This will tell you what the issue is and fix it for you. or Run: jq '.' config.json If there are no issues, it will simply print out the full JSON file. If there is an issue, a msg will display the location of the issue: parse error: Expected separator between values at line 7, column 10","title":"JSON Format Errors"},{"location":"faq/Plex-Autoscan/","text":"IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED PLEASE OPEN ISSUES Newly downloaded media from Sonarr and Radarr are not being added to Plex? \u00b6 Test another download and run the following command: tail -f /opt/plex_autoscan/plex_autoscan.log If you see this... terminate called after throwing an instance of 'boost::filesystem::filesystem_error' boost::filesystem::create_directories: Permission denied: \"/config/Library/Logs\" There is an issue with the permissions on that folder that you'll need to fix manually (Saltbox can't fix this as Plex creates this folder after the first scan) To fix this, Run the following command. Replace user and group to match yours (see here ). docker stop plex sudo chown -R user:group /opt/plex docker start plex Example of a successful scan: 2017-10-10 17:48:26,429 - DEBUG - PLEX [ 6185]: Waiting for turn in the scan request backlog... 2017-10-10 17:48:26,429 - INFO - PLEX [ 6185]: Scan request is now being processed 2017-10-10 17:48:26,474 - INFO - PLEX [ 6185]: No 'Plex Media Scanner' processes were found. 2017-10-10 17:48:26,474 - INFO - PLEX [ 6185]: Starting Plex Scanner 2017-10-10 17:48:26,475 - DEBUG - PLEX [ 6185]: docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 1 --directory '\"'\"'/data/Movies/Ravenous (1999)'\"'\"'' 2017-10-10 17:48:33,712 - INFO - UTILS [ 6185]: GUI: Scanning Ravenous (1999) 2017-10-10 17:48:33,959 - INFO - UTILS [ 6185]: GUI: Matching 'Ravenous' 2017-10-10 17:48:38,556 - INFO - UTILS [ 6185]: GUI: Score for 'Ravenous' (1999) is 117 2017-10-10 17:48:38,607 - INFO - UTILS [ 6185]: GUI: Requesting metadata for 'Ravenous' 2017-10-10 17:48:38,705 - INFO - UTILS [ 6185]: GUI: Background media analysis on Ravenous 2017-10-10 17:48:39,201 - INFO - PLEX [ 6185]: Finished scan! Plex Autoscan log shows error during empty trash request \u00b6 ERROR - PLEX [10490]: Unexpected response status_code for empty trash request: 401 You need to generate another token and re-add that back into the config. See Plex Autoscan . Plex Autoscan error with metadata item id \u00b6 Example Log: 2017-11-21 04:26:32,619 - ERROR - PLEX [ 7089]: Exception finding metadata_item_id for '/data/TV/Gotham/Season 01/Gotham - S01E01 - Pilot.mkv': 2017-11-21 04:26:32,619 - INFO - PLEX [ 7089]: Aborting analyze of '/data/TV/Gotham/Season 01/Gotham - S01E01 - Pilot.mkv' because could not find a metadata_item_id for it Possible Issues: One of the mounts has changed (e.g. Rclone_VFS or MergerFS was restarted). Permission issues (see [here]). Solution 1: Make sure the remote mount is working OK (pick the relevant one below). The current default used for mounting cloud storage is Rclone VFS: sudo systemctl status rclone_vfs Make sure the union mount is working OK. The current default used for creating the union mount is MergerFS: sudo systemctl status mergerfs Restart Plex: docker stop plex && docker start plex Solution 2: If all else fails, disable analyze in config. Open /opt/plex_autoscan/config/config.json nano /opt/plex_autoscan/config/config.json Make the following edit: \"PLEX_ANALYZE_TYPE\": \"off\", Restart Plex Autoscan sudo systemctl restart plex_autoscan Purpose of a Control File in Plex Autoscan \u00b6 Every time Sonarr or Radarr downloads a new file, or upgrades a previous one, a request is sent to Plex via Plex Autoscan to scan the movie folder or TV season path and look for changes. Since Sonarr and Radarr delete previous files on upgrades, the scan will cause the new media to show up in your Plex Library, however, the deleted files would be missing, and instead, marked as \"unavailable\" (i.e. trash icon). When the control file is present and the option in the Plex Autoscan config is enabled (default), Plex Autoscan will empty the trash for you, thereby, removing the deleted media from the library. If the remote mount for you cloud storage provider (e.g. Google Drive) ever disconnected during a Plex scan of your media, Plex would mark the missing files as unavailable and emptying the trash would cause them to be removed out of the library. To avoid this from happening, Plex Autoscan checks for a control file in the unionfs path (i.e. /mnt/unionfs/mounted.bin) before running any empty trash commands. The control file is just a blank file that resides on the root folder of your Rclone remote (i.e. cloud storage provider) and let's Plex Autoscan know that it is still mounted. Once the remote is remounted, all the files marked unavailable in Plex will be playable again and Plex Autoscan will resume its emptying trash duties post-scan. To learn more about Plex Autoscan, visit https://github.com/l3uddz/plex_autoscan. TLDR: Plex Autoscan will not remove deleted media out of Plex without it. Plex Autoscan Localhost Setup \u00b6 If you are using an all-in-one Saltbox and don't want to have the Plex Autoscan port open, you may set it up so that it runs on the localhost only. To do so, follow these steps: Option 1 Plex Autoscan: (only if changed from default) Open /opt/plex_autoscan/config/config.json nano /opt/plex_autoscan/config/config.json Make the following edit: \"SERVER_IP\": \"0.0.0.0\", Note: This is the default config. Restart Plex Autoscan sudo systemctl restart plex_autoscan Sonarr/Radarr: Retrieve the 'Docker Gateway IP Address' by running the following: docker inspect -f '{{ .NetworkSettings.Networks.saltbox.Gateway }}' sonarr Replace the Plex Autoscan URL with: http://docker_gateway_ip_address:3468/yourserverpass You Plex Autoscan URL will now look like this: http://172.18.0.1:3468/yourserverpass Option 2 Alternatively, you can set it up this way: Note: This method benefits from completely closing off Plex Autoscan to the outside. Plex Autoscan: Retrieve the 'Docker Gateway IP Address' by running the following: docker inspect -f '{{ .NetworkSettings.Networks.saltbox.Gateway }}' sonarr Open /opt/plex_autoscan/config/config.json nano /opt/plex_autoscan/config/config.json Make the following edit: \"SERVER_IP\": \"docker_network_gateway_ip_address\", This will now look like this: \"SERVER_IP\": \"172.18.0.1\", Restart Plex Autoscan sudo systemctl restart plex_autoscan Sonarr/Radarr: Replace the Plex Autoscan URL with: http://docker_gateway_ip_address:3468/yourserverpass You Plex Autoscan URL will now look like this: http://172.18.0.1:3468/yourserverpass Why is SERVER_SCAN_DELAY set to 180 seconds by default? \u00b6 When Plex Autoscan gets a scan request from Sonarr, it tells Plex to scan the relevant TV Show season folder. So to avoid multiple Plex scans of the same season when more episodes of that same season come in, Plex Autoscan can wait (ala SERVER_SCAN_DELAY) and merge multiple scan requests into a single one. This is particularly noticeable when consecutive episodes are being downloaded/imported into Sonarr. During this SERVER_SCAN_DELAY, if another request comes in for the same season folder, it will restart the delay timer again, thus allowing for even more time for new items to come in. SERVER_SCAN_DELAY of 180 seconds was calculated with an average episode download time of a few minutes each. There is no harm in multiple Plex scans of the same season folder, except for more busyness of Plex, and perhaps more stress to it, so this delay will try to alleviate that. Alternative recommended settings are: 120 and 90 seconds.","title":"Plex Autoscan"},{"location":"faq/Plex-Autoscan/#newly-downloaded-media-from-sonarr-and-radarr-are-not-being-added-to-plex","text":"Test another download and run the following command: tail -f /opt/plex_autoscan/plex_autoscan.log If you see this... terminate called after throwing an instance of 'boost::filesystem::filesystem_error' boost::filesystem::create_directories: Permission denied: \"/config/Library/Logs\" There is an issue with the permissions on that folder that you'll need to fix manually (Saltbox can't fix this as Plex creates this folder after the first scan) To fix this, Run the following command. Replace user and group to match yours (see here ). docker stop plex sudo chown -R user:group /opt/plex docker start plex Example of a successful scan: 2017-10-10 17:48:26,429 - DEBUG - PLEX [ 6185]: Waiting for turn in the scan request backlog... 2017-10-10 17:48:26,429 - INFO - PLEX [ 6185]: Scan request is now being processed 2017-10-10 17:48:26,474 - INFO - PLEX [ 6185]: No 'Plex Media Scanner' processes were found. 2017-10-10 17:48:26,474 - INFO - PLEX [ 6185]: Starting Plex Scanner 2017-10-10 17:48:26,475 - DEBUG - PLEX [ 6185]: docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 1 --directory '\"'\"'/data/Movies/Ravenous (1999)'\"'\"'' 2017-10-10 17:48:33,712 - INFO - UTILS [ 6185]: GUI: Scanning Ravenous (1999) 2017-10-10 17:48:33,959 - INFO - UTILS [ 6185]: GUI: Matching 'Ravenous' 2017-10-10 17:48:38,556 - INFO - UTILS [ 6185]: GUI: Score for 'Ravenous' (1999) is 117 2017-10-10 17:48:38,607 - INFO - UTILS [ 6185]: GUI: Requesting metadata for 'Ravenous' 2017-10-10 17:48:38,705 - INFO - UTILS [ 6185]: GUI: Background media analysis on Ravenous 2017-10-10 17:48:39,201 - INFO - PLEX [ 6185]: Finished scan!","title":"Newly downloaded media from Sonarr and Radarr are not being added to Plex?"},{"location":"faq/Plex-Autoscan/#plex-autoscan-log-shows-error-during-empty-trash-request","text":"ERROR - PLEX [10490]: Unexpected response status_code for empty trash request: 401 You need to generate another token and re-add that back into the config. See Plex Autoscan .","title":"Plex Autoscan log shows error during empty trash request"},{"location":"faq/Plex-Autoscan/#plex-autoscan-error-with-metadata-item-id","text":"Example Log: 2017-11-21 04:26:32,619 - ERROR - PLEX [ 7089]: Exception finding metadata_item_id for '/data/TV/Gotham/Season 01/Gotham - S01E01 - Pilot.mkv': 2017-11-21 04:26:32,619 - INFO - PLEX [ 7089]: Aborting analyze of '/data/TV/Gotham/Season 01/Gotham - S01E01 - Pilot.mkv' because could not find a metadata_item_id for it Possible Issues: One of the mounts has changed (e.g. Rclone_VFS or MergerFS was restarted). Permission issues (see [here]). Solution 1: Make sure the remote mount is working OK (pick the relevant one below). The current default used for mounting cloud storage is Rclone VFS: sudo systemctl status rclone_vfs Make sure the union mount is working OK. The current default used for creating the union mount is MergerFS: sudo systemctl status mergerfs Restart Plex: docker stop plex && docker start plex Solution 2: If all else fails, disable analyze in config. Open /opt/plex_autoscan/config/config.json nano /opt/plex_autoscan/config/config.json Make the following edit: \"PLEX_ANALYZE_TYPE\": \"off\", Restart Plex Autoscan sudo systemctl restart plex_autoscan","title":"Plex Autoscan error with metadata item id"},{"location":"faq/Plex-Autoscan/#purpose-of-a-control-file-in-plex-autoscan","text":"Every time Sonarr or Radarr downloads a new file, or upgrades a previous one, a request is sent to Plex via Plex Autoscan to scan the movie folder or TV season path and look for changes. Since Sonarr and Radarr delete previous files on upgrades, the scan will cause the new media to show up in your Plex Library, however, the deleted files would be missing, and instead, marked as \"unavailable\" (i.e. trash icon). When the control file is present and the option in the Plex Autoscan config is enabled (default), Plex Autoscan will empty the trash for you, thereby, removing the deleted media from the library. If the remote mount for you cloud storage provider (e.g. Google Drive) ever disconnected during a Plex scan of your media, Plex would mark the missing files as unavailable and emptying the trash would cause them to be removed out of the library. To avoid this from happening, Plex Autoscan checks for a control file in the unionfs path (i.e. /mnt/unionfs/mounted.bin) before running any empty trash commands. The control file is just a blank file that resides on the root folder of your Rclone remote (i.e. cloud storage provider) and let's Plex Autoscan know that it is still mounted. Once the remote is remounted, all the files marked unavailable in Plex will be playable again and Plex Autoscan will resume its emptying trash duties post-scan. To learn more about Plex Autoscan, visit https://github.com/l3uddz/plex_autoscan. TLDR: Plex Autoscan will not remove deleted media out of Plex without it.","title":"Purpose of a Control File in Plex Autoscan"},{"location":"faq/Plex-Autoscan/#plex-autoscan-localhost-setup","text":"If you are using an all-in-one Saltbox and don't want to have the Plex Autoscan port open, you may set it up so that it runs on the localhost only. To do so, follow these steps: Option 1 Plex Autoscan: (only if changed from default) Open /opt/plex_autoscan/config/config.json nano /opt/plex_autoscan/config/config.json Make the following edit: \"SERVER_IP\": \"0.0.0.0\", Note: This is the default config. Restart Plex Autoscan sudo systemctl restart plex_autoscan Sonarr/Radarr: Retrieve the 'Docker Gateway IP Address' by running the following: docker inspect -f '{{ .NetworkSettings.Networks.saltbox.Gateway }}' sonarr Replace the Plex Autoscan URL with: http://docker_gateway_ip_address:3468/yourserverpass You Plex Autoscan URL will now look like this: http://172.18.0.1:3468/yourserverpass Option 2 Alternatively, you can set it up this way: Note: This method benefits from completely closing off Plex Autoscan to the outside. Plex Autoscan: Retrieve the 'Docker Gateway IP Address' by running the following: docker inspect -f '{{ .NetworkSettings.Networks.saltbox.Gateway }}' sonarr Open /opt/plex_autoscan/config/config.json nano /opt/plex_autoscan/config/config.json Make the following edit: \"SERVER_IP\": \"docker_network_gateway_ip_address\", This will now look like this: \"SERVER_IP\": \"172.18.0.1\", Restart Plex Autoscan sudo systemctl restart plex_autoscan Sonarr/Radarr: Replace the Plex Autoscan URL with: http://docker_gateway_ip_address:3468/yourserverpass You Plex Autoscan URL will now look like this: http://172.18.0.1:3468/yourserverpass","title":"Plex Autoscan Localhost Setup"},{"location":"faq/Plex-Autoscan/#why-is-server_scan_delay-set-to-180-seconds-by-default","text":"When Plex Autoscan gets a scan request from Sonarr, it tells Plex to scan the relevant TV Show season folder. So to avoid multiple Plex scans of the same season when more episodes of that same season come in, Plex Autoscan can wait (ala SERVER_SCAN_DELAY) and merge multiple scan requests into a single one. This is particularly noticeable when consecutive episodes are being downloaded/imported into Sonarr. During this SERVER_SCAN_DELAY, if another request comes in for the same season folder, it will restart the delay timer again, thus allowing for even more time for new items to come in. SERVER_SCAN_DELAY of 180 seconds was calculated with an average episode download time of a few minutes each. There is no harm in multiple Plex scans of the same season folder, except for more busyness of Plex, and perhaps more stress to it, so this delay will try to alleviate that. Alternative recommended settings are: 120 and 90 seconds.","title":"Why is SERVER_SCAN_DELAY set to 180 seconds by default?"},{"location":"faq/Plex/","text":"IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED PLEASE OPEN ISSUES If you are unable to find your Plex server \u00b6 You may resolve this by either Installing Saltbox again (do this for new Plex DBs/installs): THIS WILL DELETE ANY EXISTING PLEX CONFIGURATION SUCH AS LIBRARIES Remove Plex Container (it may show \"Error response from daemon: No such container\" if not created yet): sudo docker rm -f plex Remove the Plex folder: sudo rm -rf /opt/plex Reinstall the Plex container: sb install plex Installing Saltbox again (do this for existing Plex DBs/installs): THIS WILL LEAVE ANY EXISTING PLEX LIBRARIES AND METADATA INTACT Remove Plex Preferences file. sudo rm \"/opt/plex/Library/Application Support/Plex Media Server/Preferences.xml\" Reinstall the Plex container by running the following command: sb install plex Using SSH Tunneling to log into Plex and set your credentials: On your host PC (replace <user> with your user name and <yourserveripaddress> with your serveripaddress - no arrows): ssh <user>@<yourserveripaddress> -L 32400:0.0.0.0:32400 -N This will just hang there without any message. That is normal. In a browser, go to http://localhost:32400/web. Log in with your Plex account. On the \"How Plex Works\" page, click \u201cGOT IT!\u201d. Close the \"Plex Pass\" pop-up if you see it. Under \"Server Setup\", you will see \"Great, we found a server!\". Give your server a name and tick \u201cAllow me to access my media outside my home\u201d. Click \"NEXT\". On \"Organize Your Media\", hit \"NEXT\" (you will do this later). Then hit \"DONE\". At this point, you may Ctrl + c on the SSH Tunnel to close it. If Plex shows you an incorrect title with the filename (eg RARBG releases) Reorder the Plex agents for TV/Movies so that local assets are at the bottom. Fix permission issues with Plex logs \u00b6 Replace user and group to match yours' (see here ). sudo chown -R user:group /opt/plex/Library/Logs sudo chmod -R g+s /opt/plex/Library/Logs Note: If you have a separate Plex and Feeder setup, this will be done on the server where Plex is installed.","title":"Plex"},{"location":"faq/Plex/#if-you-are-unable-to-find-your-plex-server","text":"You may resolve this by either Installing Saltbox again (do this for new Plex DBs/installs): THIS WILL DELETE ANY EXISTING PLEX CONFIGURATION SUCH AS LIBRARIES Remove Plex Container (it may show \"Error response from daemon: No such container\" if not created yet): sudo docker rm -f plex Remove the Plex folder: sudo rm -rf /opt/plex Reinstall the Plex container: sb install plex Installing Saltbox again (do this for existing Plex DBs/installs): THIS WILL LEAVE ANY EXISTING PLEX LIBRARIES AND METADATA INTACT Remove Plex Preferences file. sudo rm \"/opt/plex/Library/Application Support/Plex Media Server/Preferences.xml\" Reinstall the Plex container by running the following command: sb install plex Using SSH Tunneling to log into Plex and set your credentials: On your host PC (replace <user> with your user name and <yourserveripaddress> with your serveripaddress - no arrows): ssh <user>@<yourserveripaddress> -L 32400:0.0.0.0:32400 -N This will just hang there without any message. That is normal. In a browser, go to http://localhost:32400/web. Log in with your Plex account. On the \"How Plex Works\" page, click \u201cGOT IT!\u201d. Close the \"Plex Pass\" pop-up if you see it. Under \"Server Setup\", you will see \"Great, we found a server!\". Give your server a name and tick \u201cAllow me to access my media outside my home\u201d. Click \"NEXT\". On \"Organize Your Media\", hit \"NEXT\" (you will do this later). Then hit \"DONE\". At this point, you may Ctrl + c on the SSH Tunnel to close it. If Plex shows you an incorrect title with the filename (eg RARBG releases) Reorder the Plex agents for TV/Movies so that local assets are at the bottom.","title":"If you are unable to find your Plex server"},{"location":"faq/Plex/#fix-permission-issues-with-plex-logs","text":"Replace user and group to match yours' (see here ). sudo chown -R user:group /opt/plex/Library/Logs sudo chmod -R g+s /opt/plex/Library/Logs Note: If you have a separate Plex and Feeder setup, this will be done on the server where Plex is installed.","title":"Fix permission issues with Plex logs"},{"location":"faq/Rclone/","text":"Rclone \u00b6 Rclone error: Failed to save config file: open /home/\\<user>/.config/rclone/rclone.conf: permission denied \u00b6 Replace user and group to match yours (see here ). sudo chown -R user:group ~/.config/rclone/ sudo chmod -R 0755 ~/.config/rclone/","title":"Rclone"},{"location":"faq/Rclone/#rclone","text":"","title":"Rclone"},{"location":"faq/Rclone/#rclone-error-failed-to-save-config-file-open-homeuserconfigrclonercloneconf-permission-denied","text":"Replace user and group to match yours (see here ). sudo chown -R user:group ~/.config/rclone/ sudo chmod -R 0755 ~/.config/rclone/","title":"Rclone error: Failed to save config file: open /home/\\&lt;user>/.config/rclone/rclone.conf: permission denied"},{"location":"faq/System/","text":"IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED PLEASE OPEN ISSUES System \u00b6 Can I install this on an ARM machine? \u00b6 ARM is not supported. If you are using a Scaleway server... \u00b6 Choose an X86 server (vs ARM). Select \"Ubuntu Xenial\" as the distribution. Click the server on the list. Under \"ADVANCED OPTIONS\", click \"SHOW\". Set \"ENABLE LOCAL BOOT\" to off . Click the \"BOOTSCRIPT\" link and select one above > 4.10. Start the server. Reference: https://www.scaleway.com/docs/bootscript-and-how-to-use-it/ If you are using an OVH server... \u00b6 If you are having issues upgrading the kernel on ovh, where the kernel upgrade is not taking effect.. uname -r to see if you have grs in kernel version string... if so, see https://pterodactyl.io/daemon/0.6/kernel_modifications.html on how to update the kernel. Find your User ID (UID) and Group ID (GID) \u00b6 Use the following commands to find out your account's user name and group info: id or id `whoami` You'll see a line like the following: uid=XXXX(yourusername) gid=XXXX(yourgroup) groups=XXXX(yourgroup) How to create a user account \u00b6 Run the following commands line by line: sudo useradd -m <username> sudo usermod -aG sudo <username> sudo passwd <username> sudo chsh -s /bin/bash <username> su <username> Change shell of user account to bash \u00b6 How to check current shell: echo $0 -sh or echo ${ SHELL } /bin/sh Run this command to set bash as your shell (where <user> is replaced with your username): sudo chsh -s /bin/bash <user> sudo reboot How to fix permission issues \u00b6 /opt folder Stop all docker containers docker stop $(docker ps -a -q) Change ownership of /opt. Replace user and group to match yours' (see here ). sudo chown -R user:group /opt Change permission inheritance of /opt. sudo chmod -R ugo+X /opt Start all docker containers docker start $(docker ps -a -q) /mnt folder Run the mounts tag sb install mounts","title":"System"},{"location":"faq/System/#system","text":"","title":"System"},{"location":"faq/System/#can-i-install-this-on-an-arm-machine","text":"ARM is not supported.","title":"Can I install this on an ARM machine?"},{"location":"faq/System/#if-you-are-using-a-scaleway-server","text":"Choose an X86 server (vs ARM). Select \"Ubuntu Xenial\" as the distribution. Click the server on the list. Under \"ADVANCED OPTIONS\", click \"SHOW\". Set \"ENABLE LOCAL BOOT\" to off . Click the \"BOOTSCRIPT\" link and select one above > 4.10. Start the server. Reference: https://www.scaleway.com/docs/bootscript-and-how-to-use-it/","title":"If you are using a Scaleway server..."},{"location":"faq/System/#if-you-are-using-an-ovh-server","text":"If you are having issues upgrading the kernel on ovh, where the kernel upgrade is not taking effect.. uname -r to see if you have grs in kernel version string... if so, see https://pterodactyl.io/daemon/0.6/kernel_modifications.html on how to update the kernel.","title":"If you are using an OVH server..."},{"location":"faq/System/#find-your-user-id-uid-and-group-id-gid","text":"Use the following commands to find out your account's user name and group info: id or id `whoami` You'll see a line like the following: uid=XXXX(yourusername) gid=XXXX(yourgroup) groups=XXXX(yourgroup)","title":"Find your User ID (UID) and Group ID (GID)"},{"location":"faq/System/#how-to-create-a-user-account","text":"Run the following commands line by line: sudo useradd -m <username> sudo usermod -aG sudo <username> sudo passwd <username> sudo chsh -s /bin/bash <username> su <username>","title":"How to create a user account"},{"location":"faq/System/#change-shell-of-user-account-to-bash","text":"How to check current shell: echo $0 -sh or echo ${ SHELL } /bin/sh Run this command to set bash as your shell (where <user> is replaced with your username): sudo chsh -s /bin/bash <user> sudo reboot","title":"Change shell of user account to bash"},{"location":"faq/System/#how-to-fix-permission-issues","text":"/opt folder Stop all docker containers docker stop $(docker ps -a -q) Change ownership of /opt. Replace user and group to match yours' (see here ). sudo chown -R user:group /opt Change permission inheritance of /opt. sudo chmod -R ugo+X /opt Start all docker containers docker start $(docker ps -a -q) /mnt folder Run the mounts tag sb install mounts","title":"How to fix permission issues"},{"location":"faq/ruTorrent/","text":"IT IS QUITE PROBABLE THAT SOME INFORMATION HERE IS OUTDATED PLEASE OPEN ISSUES Change ruTorrent download path after installation \u00b6 Stop ruTorrent Docker container: docker stop rutorrent Edit the rtorrent.rc file: /opt/rutorrent/rtorrent/rtorrent.rc Set the following options: directory = /downloads/rutorrent Start ruTorrent Docker container: docker restart rutorrent Enable access to public torrent trackers \u00b6 By default access to DHT, UDP, and PEX are disabled since most private trackers (and some server providers) do not allow this. Attempting to add a torrent from a public tracker would result in the torrent being stuck, like this: To enable access to public trackers, do the following: Stop ruTorrent Docker container: docker stop rutorrent Edit the rtorrent.rc file: /opt/rutorrent/rtorrent/rtorrent.rc Set the following options: dht.mode.set = on trackers.use_udp.set = yes protocol.pex.set = yes Start ruTorrent Docker container: docker start rutorrent","title":"ruTorrent"},{"location":"faq/ruTorrent/#change-rutorrent-download-path-after-installation","text":"Stop ruTorrent Docker container: docker stop rutorrent Edit the rtorrent.rc file: /opt/rutorrent/rtorrent/rtorrent.rc Set the following options: directory = /downloads/rutorrent Start ruTorrent Docker container: docker restart rutorrent","title":"Change ruTorrent download path after installation"},{"location":"faq/ruTorrent/#enable-access-to-public-torrent-trackers","text":"By default access to DHT, UDP, and PEX are disabled since most private trackers (and some server providers) do not allow this. Attempting to add a torrent from a public tracker would result in the torrent being stuck, like this: To enable access to public trackers, do the following: Stop ruTorrent Docker container: docker stop rutorrent Edit the rtorrent.rc file: /opt/rutorrent/rtorrent/rtorrent.rc Set the following options: dht.mode.set = on trackers.use_udp.set = yes protocol.pex.set = yes Start ruTorrent Docker container: docker start rutorrent","title":"Enable access to public torrent trackers"},{"location":"reference/accounts/","text":"Warning This is a reference discussing an aspect of the install process . If you are looking for the steps to follow to install, they are here . Options in accounts.yml \u00b6 Note : There must always be a space betwen the key and the value in YAML files. key: value NOT key:value user : User information. name : User name for the server. If user account with this name does not already exist, it will be created during install. Also used to create first-time logins for NZBGet, ruTorrent, NZBHydra2, and potentially other apps. Default is seed . This parameter is required . pass : Password for the user account and for misc apps. Sets password for the server's user account when creating a new account. This will not change the password of an existing account. Also used to create first-time logins for NZBGet, ruTorrent, NZBHydra2, and potentially other apps. This parameter is required . Don't leave it blank. Even if you are planning to use SSH keys to connect to your box. This user and password are used to set up authentication for some applications in this repo and Community, and a blank password may cause trouble there. Relevant XKCD See the password considerations below. domain : Domain name for the Saltbox server. If you don't have one, see here . This should be the domain \"below\" the saltbox subdomains. For example, if you want to access Sonarr at \"sonarr.domain.tld\", enter \"domain.tld\". If you want \"sonarr.foo.domain.tld\", enter \"foo.domain.tld\". email : E-mail address. This is used for the Let's Encrypt SSL certificates. It does not have to be an email address at the domain above. This parameter is required if you're using the reverse proxy. ssh_key : SSH Key This parameter is optional This is used to provision a SSH key in your user's authorized_keys file This parameter accepts either the public key or a GitHub url (i.e. https://github.com/charlie.keys ) which will pull the keys you have added to your GitHub account. cloudflare : Cloudflare Account email : E-mail address used for the Cloudflare account. api : Global API Key . This parameter is optional. Default is blank. Fill this in to have Saltbox add subdomains on Cloudflare, automatically; leave it blank, to have all Cloudflare related functions disabled. Note: if you are using a subdomain, like WHATEVER.DOMAIN.TLD, as your domain above, leave these blank. The Cloudflare automation does not work in that case and the install will stop with an error. Cloudflare does not support all top-level domains though its API. Refer to this page . As of 2022/11/03: \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\" plex : Plex.tv account credentials. This will be used to: claim the Plex server under your username, and generate Plex Access Tokens for apps such as Autoscan, etc. user - Plex username or email address on the profile. pass - Plex password. See the password considerations below. tfa - \"yes\" or \"no\" depending on whether you want to use the two-factor authentication [TFA] compatible Plex connection system. This parameter is required. Note: The \"tfa\" setting controls whether Saltbox uses the newer authentication method or not; this newer method is required for use with TFA, but will work even with it off; it's the \"Open an URL, log into Plex, grant access to this app\" workflow you may be familiar with from other contexts. If you use the tfa workflow, a random client ID and a Plex Access Token will be stored in /opt/saltbox/plex.ini for later use. Consider securing this file if you are running Saltbox on a shared machine. dockerhub : DockerHub account credentials. Entering Dockerhub credentials increases the number of images one can pull user - Docker Hub username. token - Docker Hub access token. apprise : apprise url. Information about constructing the URL can be found here . This will be used to send out messages during certain tasks (e.g. backup). This parameter is not nested like the others in this file. apprise: somescheme://something_else_here/perhaps_a_token not apprise: somescheme://something_else_here/perhaps_a_token This parameter is optional. Options in settings.yml \u00b6 Note: Having {{user}} in the path tells Ansible to fill in the username, automatically. You do not need to fill in your actual username. Note : There must always be a space betwen the key and the value in YAML files. key: value NOT key:value downloads : Where downloads go. Default is /mnt/unionfs/downloads . transcodes : Path of temporary transcoding files. Default is \"/mnt/local/transcodes\" . Note: It is recommended to not use /tmp or /dev/shm as a transcode location because the paths are cleared on reboots, causing Docker to create the folder as root and Plex transcoder to crash. Another reason why not to: https://forums.plex.tv/discussion/comment/1502936/#Comment_1502936 . rclone : Rclone options. version : Rclone version that is installed by Saltbox. Choices are latest , current , beta , or a specific version number (e.g. 1.42 ). Default is latest . remote : Rclone remote that Saltbox will use to setup Rclone VFS mount and Cloudplow. Default is google . Can be left blank to run without cloud storage]. shell : Type of shell to use. Choices are bash or zsh . Default is bash . authelia : Authelia options. subdomain : subdomain for the Authelia login page Default is login . Options in adv_settings.yml \u00b6 Note : There must always be a space betwen the key and the value in YAML files. key: value NOT key:value system : Various system-level settings. timezone : Timezone to use on the server. Default is auto , which will pick the timezone based on geolocation of the server. Enter a \"TZ database name\" as shown in this table . For example, \"America/Costa_Rica\". timedatectl list-timezones at your server's command prompt will also list the options. dns : DNS-related settings. enabled : Controls whether subdomains are created at Cloudflare Default is yes . proxied : Controls whether Cloudflare records should be \"proxied\" or \"DNS only\". Default is no . ipv6 : Enable/disable ipv6 configuration. Default is no . zerossl : Controls whether zerossl is used. Default is no . traefik : traefik-related settings. tls : Use TLS (ALPN-01) certificate validation method. Default is no . http : Use HTTP (HTTP-01) certificate validation method. Default is no . metrics : enable metrics subdomain. Default is no . tracing : Enable tracing. Default is no . hsts : enable hsts. Default is no . provider : DNS provider. Default is cloudflare . subdomains : traefik subdomains. dash : traefik dashboard subdomain. Default is dash . metrics : traefik metrics subdomain. Default is metrics . jaeger : traefik jaeger subdomain. Default is jaeger . error_pages : enable styled error pages. Default is no . see here for configuration details. mounts : cloud storage mount settings. remote : What type of remote to use. Default is rclone_vfs . feeder : Should a feeder mount be created? Default is no . gpu : GPU settings. intel : Should system be set up for Intel GPU? Default is yes . nvidia : Should system be set up for NVidia GPU? Default is no . Password considerations \u00b6 These are a YAML files, and values you enter here are subject to YAML file format rules. If you use special characters in your password, wrap the password in quotes [or escape the characters correctly, if you are familiar with that concept]. It would be easiest to avoid using quote characters themselves within your password. For example: pass: MyP4s5w0rd1s4w350m3 pass: \"!@#$%^&*\" pass: multiple words work fine unquoted pass: \"or quote them to be safe\"","title":"Accounts and Settings"},{"location":"reference/accounts/#options-in-accountsyml","text":"Note : There must always be a space betwen the key and the value in YAML files. key: value NOT key:value user : User information. name : User name for the server. If user account with this name does not already exist, it will be created during install. Also used to create first-time logins for NZBGet, ruTorrent, NZBHydra2, and potentially other apps. Default is seed . This parameter is required . pass : Password for the user account and for misc apps. Sets password for the server's user account when creating a new account. This will not change the password of an existing account. Also used to create first-time logins for NZBGet, ruTorrent, NZBHydra2, and potentially other apps. This parameter is required . Don't leave it blank. Even if you are planning to use SSH keys to connect to your box. This user and password are used to set up authentication for some applications in this repo and Community, and a blank password may cause trouble there. Relevant XKCD See the password considerations below. domain : Domain name for the Saltbox server. If you don't have one, see here . This should be the domain \"below\" the saltbox subdomains. For example, if you want to access Sonarr at \"sonarr.domain.tld\", enter \"domain.tld\". If you want \"sonarr.foo.domain.tld\", enter \"foo.domain.tld\". email : E-mail address. This is used for the Let's Encrypt SSL certificates. It does not have to be an email address at the domain above. This parameter is required if you're using the reverse proxy. ssh_key : SSH Key This parameter is optional This is used to provision a SSH key in your user's authorized_keys file This parameter accepts either the public key or a GitHub url (i.e. https://github.com/charlie.keys ) which will pull the keys you have added to your GitHub account. cloudflare : Cloudflare Account email : E-mail address used for the Cloudflare account. api : Global API Key . This parameter is optional. Default is blank. Fill this in to have Saltbox add subdomains on Cloudflare, automatically; leave it blank, to have all Cloudflare related functions disabled. Note: if you are using a subdomain, like WHATEVER.DOMAIN.TLD, as your domain above, leave these blank. The Cloudflare automation does not work in that case and the install will stop with an error. Cloudflare does not support all top-level domains though its API. Refer to this page . As of 2022/11/03: \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\" plex : Plex.tv account credentials. This will be used to: claim the Plex server under your username, and generate Plex Access Tokens for apps such as Autoscan, etc. user - Plex username or email address on the profile. pass - Plex password. See the password considerations below. tfa - \"yes\" or \"no\" depending on whether you want to use the two-factor authentication [TFA] compatible Plex connection system. This parameter is required. Note: The \"tfa\" setting controls whether Saltbox uses the newer authentication method or not; this newer method is required for use with TFA, but will work even with it off; it's the \"Open an URL, log into Plex, grant access to this app\" workflow you may be familiar with from other contexts. If you use the tfa workflow, a random client ID and a Plex Access Token will be stored in /opt/saltbox/plex.ini for later use. Consider securing this file if you are running Saltbox on a shared machine. dockerhub : DockerHub account credentials. Entering Dockerhub credentials increases the number of images one can pull user - Docker Hub username. token - Docker Hub access token. apprise : apprise url. Information about constructing the URL can be found here . This will be used to send out messages during certain tasks (e.g. backup). This parameter is not nested like the others in this file. apprise: somescheme://something_else_here/perhaps_a_token not apprise: somescheme://something_else_here/perhaps_a_token This parameter is optional.","title":"Options in accounts.yml"},{"location":"reference/accounts/#options-in-settingsyml","text":"Note: Having {{user}} in the path tells Ansible to fill in the username, automatically. You do not need to fill in your actual username. Note : There must always be a space betwen the key and the value in YAML files. key: value NOT key:value downloads : Where downloads go. Default is /mnt/unionfs/downloads . transcodes : Path of temporary transcoding files. Default is \"/mnt/local/transcodes\" . Note: It is recommended to not use /tmp or /dev/shm as a transcode location because the paths are cleared on reboots, causing Docker to create the folder as root and Plex transcoder to crash. Another reason why not to: https://forums.plex.tv/discussion/comment/1502936/#Comment_1502936 . rclone : Rclone options. version : Rclone version that is installed by Saltbox. Choices are latest , current , beta , or a specific version number (e.g. 1.42 ). Default is latest . remote : Rclone remote that Saltbox will use to setup Rclone VFS mount and Cloudplow. Default is google . Can be left blank to run without cloud storage]. shell : Type of shell to use. Choices are bash or zsh . Default is bash . authelia : Authelia options. subdomain : subdomain for the Authelia login page Default is login .","title":"Options in settings.yml"},{"location":"reference/accounts/#options-in-adv_settingsyml","text":"Note : There must always be a space betwen the key and the value in YAML files. key: value NOT key:value system : Various system-level settings. timezone : Timezone to use on the server. Default is auto , which will pick the timezone based on geolocation of the server. Enter a \"TZ database name\" as shown in this table . For example, \"America/Costa_Rica\". timedatectl list-timezones at your server's command prompt will also list the options. dns : DNS-related settings. enabled : Controls whether subdomains are created at Cloudflare Default is yes . proxied : Controls whether Cloudflare records should be \"proxied\" or \"DNS only\". Default is no . ipv6 : Enable/disable ipv6 configuration. Default is no . zerossl : Controls whether zerossl is used. Default is no . traefik : traefik-related settings. tls : Use TLS (ALPN-01) certificate validation method. Default is no . http : Use HTTP (HTTP-01) certificate validation method. Default is no . metrics : enable metrics subdomain. Default is no . tracing : Enable tracing. Default is no . hsts : enable hsts. Default is no . provider : DNS provider. Default is cloudflare . subdomains : traefik subdomains. dash : traefik dashboard subdomain. Default is dash . metrics : traefik metrics subdomain. Default is metrics . jaeger : traefik jaeger subdomain. Default is jaeger . error_pages : enable styled error pages. Default is no . see here for configuration details. mounts : cloud storage mount settings. remote : What type of remote to use. Default is rclone_vfs . feeder : Should a feeder mount be created? Default is no . gpu : GPU settings. intel : Should system be set up for Intel GPU? Default is yes . nvidia : Should system be set up for NVidia GPU? Default is no .","title":"Options in adv_settings.yml"},{"location":"reference/accounts/#password-considerations","text":"These are a YAML files, and values you enter here are subject to YAML file format rules. If you use special characters in your password, wrap the password in quotes [or escape the characters correctly, if you are familiar with that concept]. It would be easiest to avoid using quote characters themselves within your password. For example: pass: MyP4s5w0rd1s4w350m3 pass: \"!@#$%^&*\" pass: multiple words work fine unquoted pass: \"or quote them to be safe\"","title":"Password considerations"},{"location":"reference/cloud/","text":"Cloud Storage \u00b6 Provider \u00b6 If you want to forego cloud storage and put your media on something like your own NAS, there are some notes here . Saltbox can be set up to use any cloud storage provider that Rclone supports. However, Google Drive via G-Suite Business is the popular choice among users. Some of the components are designed expressly for Google Drive, like the Google Drive monitoring in plex-autoscan and the service-account rotation in cloudplow. It is advised that you do NOT use a educational GSuite account or any GSuite account or Shared Drive you may buy on the secondary market [eBay and the like], unless you are aware of and planning for the likelihood that it disappears one day. Note that rclone offering support for a storage backend does not mean that backend is suitable for the Saltbox use case. The only backend that sees any significant testing and use is Google Drive. Basics \u00b6 Out of the box, Saltbox stores the media unencrypted in cloud storage utilizing an Rclone VFS mount to access it. If you prefer your data is stored encrypted, you will need to do some tweaking to the Rclone config. There are no plans to document these tweaks here. Media will be stored in Movies and TV folders, all within a Media folder in root (i.e. /Media ). [1] Saltbox is opinionated about this /Media/<type> file structure; changing it is not trivial. Setup \u00b6 Media \u251c\u2500\u2500 Movies \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV Example from Google Drive: If you have media in other folders, you can simply move them into these folders via the Cloud Storage Provider's web site. Note 1: For Google Drive, you can use the Shift-Z trick to \"symlink\" folders here. Note 2: All the paths/folders mentioned here, and elsewhere, are CASE SENSITIVE (see Saltbox Paths ). Google \"My Drive\" vs. \"Shared Drives\" \u00b6 Google provides two \"types\" of storage in a GSuite account: \"My Drive\" and \"Shared Drives\". Shared Drives provide advantages for our purposes over My Drive, while My Drive offers no advantages over Shared Drives. The primary advantage of Shared Drives is that access to them can be controlled via Service accounts, which allows credential rotation to increase upload limits and reduce likelihood of usage-based server-side bans. Some newer related utilities [like the Golang \"Autoscan\" replacement for plex-autoscan] have features that work exclusively with Shared Drives. The primary disadvantage of Shared Drives is that they have a fixed limit of 400,000 files. For this reason one common strategy is to create separate Shared Drives for each media type. For those reasons, this documentation will discuss ONLY Shared Drives. However, if your data is currently on My Drive and you want to keep it there, Saltbox works fine with that as well. Rather than littering the docs with \"If you're using My Drive to this, Shared drives do that\" decision points, we standardized on Shared Drives. You'll just need to skip some stuff that refers to shared drives. As a note, if you are unable to create Shared Drives in the Google Drive Web UI, that's a sign that you have the wrong type of Google Drive account. Running Saltbox without cloud storage \u00b6 While the typical use case for Saltbox includes cloud storage, nothing prevents using it without cloud storage. If, in settings.yml , you leave the rclone remote name blank, neither cloudplow nor the rclone_vfs mount will be configured. Your media will be imported to /mnt/local and stay there. You can mount whatever storage you wish to use at /mnt/local . Alternatively, you can configure an rclone remote pointing at your primary storage [named \"google\"], then install normally. Everything would then work as it typically does, except that cloudplow would move media from the local system to your NAS or whatever. Perhaps that would allow downloads and imports to go faster. 1 If you would like to customize your Plex libraries beyond what is listed above, see Customizing Plex Libraries .","title":"Cloud Storage"},{"location":"reference/cloud/#cloud-storage","text":"","title":"Cloud Storage"},{"location":"reference/cloud/#provider","text":"If you want to forego cloud storage and put your media on something like your own NAS, there are some notes here . Saltbox can be set up to use any cloud storage provider that Rclone supports. However, Google Drive via G-Suite Business is the popular choice among users. Some of the components are designed expressly for Google Drive, like the Google Drive monitoring in plex-autoscan and the service-account rotation in cloudplow. It is advised that you do NOT use a educational GSuite account or any GSuite account or Shared Drive you may buy on the secondary market [eBay and the like], unless you are aware of and planning for the likelihood that it disappears one day. Note that rclone offering support for a storage backend does not mean that backend is suitable for the Saltbox use case. The only backend that sees any significant testing and use is Google Drive.","title":"Provider"},{"location":"reference/cloud/#basics","text":"Out of the box, Saltbox stores the media unencrypted in cloud storage utilizing an Rclone VFS mount to access it. If you prefer your data is stored encrypted, you will need to do some tweaking to the Rclone config. There are no plans to document these tweaks here. Media will be stored in Movies and TV folders, all within a Media folder in root (i.e. /Media ). [1] Saltbox is opinionated about this /Media/<type> file structure; changing it is not trivial.","title":"Basics"},{"location":"reference/cloud/#setup","text":"Media \u251c\u2500\u2500 Movies \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV Example from Google Drive: If you have media in other folders, you can simply move them into these folders via the Cloud Storage Provider's web site. Note 1: For Google Drive, you can use the Shift-Z trick to \"symlink\" folders here. Note 2: All the paths/folders mentioned here, and elsewhere, are CASE SENSITIVE (see Saltbox Paths ).","title":"Setup"},{"location":"reference/cloud/#google-my-drive-vs-shared-drives","text":"Google provides two \"types\" of storage in a GSuite account: \"My Drive\" and \"Shared Drives\". Shared Drives provide advantages for our purposes over My Drive, while My Drive offers no advantages over Shared Drives. The primary advantage of Shared Drives is that access to them can be controlled via Service accounts, which allows credential rotation to increase upload limits and reduce likelihood of usage-based server-side bans. Some newer related utilities [like the Golang \"Autoscan\" replacement for plex-autoscan] have features that work exclusively with Shared Drives. The primary disadvantage of Shared Drives is that they have a fixed limit of 400,000 files. For this reason one common strategy is to create separate Shared Drives for each media type. For those reasons, this documentation will discuss ONLY Shared Drives. However, if your data is currently on My Drive and you want to keep it there, Saltbox works fine with that as well. Rather than littering the docs with \"If you're using My Drive to this, Shared drives do that\" decision points, we standardized on Shared Drives. You'll just need to skip some stuff that refers to shared drives. As a note, if you are unable to create Shared Drives in the Google Drive Web UI, that's a sign that you have the wrong type of Google Drive account.","title":"Google \"My Drive\" vs. \"Shared Drives\""},{"location":"reference/cloud/#running-saltbox-without-cloud-storage","text":"While the typical use case for Saltbox includes cloud storage, nothing prevents using it without cloud storage. If, in settings.yml , you leave the rclone remote name blank, neither cloudplow nor the rclone_vfs mount will be configured. Your media will be imported to /mnt/local and stay there. You can mount whatever storage you wish to use at /mnt/local . Alternatively, you can configure an rclone remote pointing at your primary storage [named \"google\"], then install normally. Everything would then work as it typically does, except that cloudplow would move media from the local system to your NAS or whatever. Perhaps that would allow downloads and imports to go faster. 1 If you would like to customize your Plex libraries beyond what is listed above, see Customizing Plex Libraries .","title":"Running Saltbox without cloud storage"},{"location":"reference/cloudplow-config/","text":"The default Cloudplow setup uploads to the google remote using a single account, which limits you to 750GB/day of upload. To utilize rotating service accounts to upload more than this, you'll need to configure cloudplow to upload to the individual shared drives. If you used the scripted rclone method , there is a script in the sb_gd repo that will make the required modifications to the cloudplow config. NOTE: This script is assuming that your service account file are in /opt/sa/all , which is where the scripted rclone method puts them. The script is also assuming a totally stock Cloudplow config.json as it comes from the original saltbox install. If you have added remote s or uploader s it will fail with an error. This script is only useful if you have used the scripted rclone method . AGAIN: This script is only useful if you have used the scripted rclone method . This script is going to load the config from the last script in that process, and if it finds that config unmodified [specifically the prefix found in the config, which you create as part of that process] it will exit with a message to that effect. There is no point in trying to circumvent this, since it is going to look for rclone remotes with specific names based on that prefix, which point at shared drives that it created with that prefix, etc. You will have to have completed sb install saltbox before using this script. Run the script cd /opt/sb_gd source sb_gd/bin/activate python sb_cp.py If that doesn't work, update to the latest version of the files from the repo with git pull and try again. Restart the cloudplow service: sudo systemctl restart cloudplow Deactivate the virtual environment: deactivate","title":"Shared-Drive Cloudplow Setup"},{"location":"reference/cloudplow/","text":"Example Cloudplow configs \u00b6 Cloudplow with Default Config \u00b6 This is the default config; it contains a single remote/uploader pair. This set uploads everything from /mnt/local/Media to google:/Media once there is 200GB in /mnt/local/Media . Example config.json (click to expand) { \"core\" : { \"dry_run\" : false , \"rclone_config_path\" : \"/home/seed/.config/rclone/rclone.conf\" }, \"hidden\" : {}, \"notifications\" : { }, \"remotes\" : { \"google\" : { \"hidden_remote\" : \"google:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 16 , \"--drive-chunk-size\" : \"64M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 25 , \"timeout\" : 3600 } }, \"remove_empty_dir_depth\" : 2 , \"sync_remote\" : \"google:/Media\" , \"upload_folder\" : \"/mnt/local/Media\" , \"upload_remote\" : \"google:/Media\" } }, \"syncer\" : { }, \"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 200 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] } } } Cloudplow with Multiple Remotes \u00b6 A couple points: Uploader tasks run sequentially (vs in parallel) Each uploader task needs a separate remote . You can't have two \u201cuploaders\u201d referencing one \u201cremote\u201d. Example config.json (click to expand) { \"core\" : { \"dry_run\" : false , \"rclone_binary_path\" : \"/usr/bin/rclone\" , \"rclone_config_path\" : \"/home/seed/.config/rclone/rclone.conf\" }, \"hidden\" : {}, \"notifications\" : { \"Pushover\" : { \"app_token\" : \"xxxxx\" , \"priority\" : 0 , \"service\" : \"pushover\" , \"user_token\" : \"xxxxx\" } }, \"nzbget\" : { \"enabled\" : false , \"url\" : \"https://user:password@nzbget.domain.com\" }, \"plex\" : { \"enabled\" : false , \"max_streams_before_throttle\" : 1 , \"poll_interval\" : 30 , \"rclone\" : { \"throttle_speeds\" : { \"1\" : \"50M\" , \"2\" : \"40M\" , \"3\" : \"30M\" , \"4\" : \"20M\" , \"5\" : \"10M\" }, \"url\" : \"http://localhost:7949\" }, \"token\" : \"xxxxxx\" , \"url\" : \"https://plex.domain.com\" , \"verbose_notifications\" : false }, \"remotes\" : { \"google\" : { \"hidden_remote\" : \"google:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 8 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 6 , \"timeout\" : 7200 } }, \"rclone_command\" : \"copy\" , \"remove_empty_dir_depth\" : 1 , \"upload_folder\" : \"/mnt/local/Media/\" , \"upload_remote\" : \"google:/Media/\" }, \"dropbox\" : { \"hidden_remote\" : \"dropbox:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 8 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { }, \"rclone_command\" : \"move\" , \"remove_empty_dir_depth\" : 1 , \"upload_folder\" : \"/mnt/local/Media/\" , \"upload_remote\" : \"dropbox:/Media/\" } }, \"syncer\" : {}, \"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 100 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] }, \"dropbox\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 50 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [] } } } Cloudplow with Multiple Folders \u00b6 This config uploads everything from /mnt/local/Media to google:/Media [triggered at 100GB] and everything in /mnt/local/downloads/torrents/rutorrent/completed/ to google:/Downloads/ [triggered at 50GB]. Example config.json (click to expand) { \"core\" : { \"dry_run\" : false , \"rclone_binary_path\" : \"/usr/bin/rclone\" , \"rclone_config_path\" : \"/home/seed/.config/rclone/rclone.conf\" }, \"hidden\" : {}, \"notifications\" : { \"Pushover\" : { \"app_token\" : \"xxxxx\" , \"priority\" : 0 , \"service\" : \"pushover\" , \"user_token\" : \"xxxxx\" } }, \"nzbget\" : { \"enabled\" : false , \"url\" : \"https://user:password@nzbget.domain.com\" }, \"plex\" : { \"enabled\" : false , \"max_streams_before_throttle\" : 1 , \"poll_interval\" : 30 , \"rclone\" : { \"throttle_speeds\" : { \"1\" : \"50M\" , \"2\" : \"40M\" , \"3\" : \"30M\" , \"4\" : \"20M\" , \"5\" : \"10M\" }, \"url\" : \"http://localhost:7949\" }, \"token\" : \"xxxxxx\" , \"url\" : \"https://plex.domain.com\" , \"verbose_notifications\" : false }, \"remotes\" : { \"media_to_google\" : { \"hidden_remote\" : \"google:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 8 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 6 , \"timeout\" : 7200 } }, \"remove_empty_dir_depth\" : 1 , \"upload_folder\" : \"/mnt/local/Media/\" , \"upload_remote\" : \"google:/Media/\" }, \"downloads_to_google\" : { \"hidden_remote\" : \"\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 8 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 25 , \"timeout\" : 7200 } }, \"remove_empty_dir_depth\" : 1 , \"upload_folder\" : \"/mnt/local/downloads/torrents/rutorrent/completed/\" , \"upload_remote\" : \"google:/Downloads/\" } }, \"syncer\" : {}, \"uploader\" : { \"media_to_google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 100 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] }, \"downloads_to_google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 50 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [] } } } Cloudplow with Notifications Enabled \u00b6 This is the default config with Pushover notifications configured. Example config.json (click to expand) { \"core\" : { \"dry_run\" : false , \"rclone_config_path\" : \"/home/seed/.config/rclone/rclone.conf\" }, \"hidden\" : {}, \"notifications\" : { \"Pushover\" : { \"app_token\" : \"XXXXXXXXXXX\" , \"service\" : \"pushover\" , \"user_token\" : \"XXXXXXXXXXXX\" , \"priority\" : 0 } }, \"remotes\" : { \"google\" : { \"hidden_remote\" : \"google:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 16 , \"--drive-chunk-size\" : \"64M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 25 , \"timeout\" : 3600 } }, \"remove_empty_dir_depth\" : 2 , \"sync_remote\" : \"google:/Media\" , \"upload_folder\" : \"/mnt/local/Media\" , \"upload_remote\" : \"google:/Media\" } }, \"syncer\" : { }, \"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 200 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] } } }","title":"Cloudplow Examples"},{"location":"reference/cloudplow/#example-cloudplow-configs","text":"","title":"Example Cloudplow configs"},{"location":"reference/cloudplow/#cloudplow-with-default-config","text":"This is the default config; it contains a single remote/uploader pair. This set uploads everything from /mnt/local/Media to google:/Media once there is 200GB in /mnt/local/Media . Example config.json (click to expand) { \"core\" : { \"dry_run\" : false , \"rclone_config_path\" : \"/home/seed/.config/rclone/rclone.conf\" }, \"hidden\" : {}, \"notifications\" : { }, \"remotes\" : { \"google\" : { \"hidden_remote\" : \"google:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 16 , \"--drive-chunk-size\" : \"64M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 25 , \"timeout\" : 3600 } }, \"remove_empty_dir_depth\" : 2 , \"sync_remote\" : \"google:/Media\" , \"upload_folder\" : \"/mnt/local/Media\" , \"upload_remote\" : \"google:/Media\" } }, \"syncer\" : { }, \"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 200 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] } } }","title":"Cloudplow with Default Config"},{"location":"reference/cloudplow/#cloudplow-with-multiple-remotes","text":"A couple points: Uploader tasks run sequentially (vs in parallel) Each uploader task needs a separate remote . You can't have two \u201cuploaders\u201d referencing one \u201cremote\u201d. Example config.json (click to expand) { \"core\" : { \"dry_run\" : false , \"rclone_binary_path\" : \"/usr/bin/rclone\" , \"rclone_config_path\" : \"/home/seed/.config/rclone/rclone.conf\" }, \"hidden\" : {}, \"notifications\" : { \"Pushover\" : { \"app_token\" : \"xxxxx\" , \"priority\" : 0 , \"service\" : \"pushover\" , \"user_token\" : \"xxxxx\" } }, \"nzbget\" : { \"enabled\" : false , \"url\" : \"https://user:password@nzbget.domain.com\" }, \"plex\" : { \"enabled\" : false , \"max_streams_before_throttle\" : 1 , \"poll_interval\" : 30 , \"rclone\" : { \"throttle_speeds\" : { \"1\" : \"50M\" , \"2\" : \"40M\" , \"3\" : \"30M\" , \"4\" : \"20M\" , \"5\" : \"10M\" }, \"url\" : \"http://localhost:7949\" }, \"token\" : \"xxxxxx\" , \"url\" : \"https://plex.domain.com\" , \"verbose_notifications\" : false }, \"remotes\" : { \"google\" : { \"hidden_remote\" : \"google:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 8 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 6 , \"timeout\" : 7200 } }, \"rclone_command\" : \"copy\" , \"remove_empty_dir_depth\" : 1 , \"upload_folder\" : \"/mnt/local/Media/\" , \"upload_remote\" : \"google:/Media/\" }, \"dropbox\" : { \"hidden_remote\" : \"dropbox:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 8 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { }, \"rclone_command\" : \"move\" , \"remove_empty_dir_depth\" : 1 , \"upload_folder\" : \"/mnt/local/Media/\" , \"upload_remote\" : \"dropbox:/Media/\" } }, \"syncer\" : {}, \"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 100 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] }, \"dropbox\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 50 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [] } } }","title":"Cloudplow with Multiple Remotes"},{"location":"reference/cloudplow/#cloudplow-with-multiple-folders","text":"This config uploads everything from /mnt/local/Media to google:/Media [triggered at 100GB] and everything in /mnt/local/downloads/torrents/rutorrent/completed/ to google:/Downloads/ [triggered at 50GB]. Example config.json (click to expand) { \"core\" : { \"dry_run\" : false , \"rclone_binary_path\" : \"/usr/bin/rclone\" , \"rclone_config_path\" : \"/home/seed/.config/rclone/rclone.conf\" }, \"hidden\" : {}, \"notifications\" : { \"Pushover\" : { \"app_token\" : \"xxxxx\" , \"priority\" : 0 , \"service\" : \"pushover\" , \"user_token\" : \"xxxxx\" } }, \"nzbget\" : { \"enabled\" : false , \"url\" : \"https://user:password@nzbget.domain.com\" }, \"plex\" : { \"enabled\" : false , \"max_streams_before_throttle\" : 1 , \"poll_interval\" : 30 , \"rclone\" : { \"throttle_speeds\" : { \"1\" : \"50M\" , \"2\" : \"40M\" , \"3\" : \"30M\" , \"4\" : \"20M\" , \"5\" : \"10M\" }, \"url\" : \"http://localhost:7949\" }, \"token\" : \"xxxxxx\" , \"url\" : \"https://plex.domain.com\" , \"verbose_notifications\" : false }, \"remotes\" : { \"media_to_google\" : { \"hidden_remote\" : \"google:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 8 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 6 , \"timeout\" : 7200 } }, \"remove_empty_dir_depth\" : 1 , \"upload_folder\" : \"/mnt/local/Media/\" , \"upload_remote\" : \"google:/Media/\" }, \"downloads_to_google\" : { \"hidden_remote\" : \"\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 8 , \"--drive-chunk-size\" : \"128M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 25 , \"timeout\" : 7200 } }, \"remove_empty_dir_depth\" : 1 , \"upload_folder\" : \"/mnt/local/downloads/torrents/rutorrent/completed/\" , \"upload_remote\" : \"google:/Downloads/\" } }, \"syncer\" : {}, \"uploader\" : { \"media_to_google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 100 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] }, \"downloads_to_google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 50 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [] } } }","title":"Cloudplow with Multiple Folders"},{"location":"reference/cloudplow/#cloudplow-with-notifications-enabled","text":"This is the default config with Pushover notifications configured. Example config.json (click to expand) { \"core\" : { \"dry_run\" : false , \"rclone_config_path\" : \"/home/seed/.config/rclone/rclone.conf\" }, \"hidden\" : {}, \"notifications\" : { \"Pushover\" : { \"app_token\" : \"XXXXXXXXXXX\" , \"service\" : \"pushover\" , \"user_token\" : \"XXXXXXXXXXXX\" , \"priority\" : 0 } }, \"remotes\" : { \"google\" : { \"hidden_remote\" : \"google:\" , \"rclone_excludes\" : [ \"**partial~\" , \"**_HIDDEN~\" , \".unionfs/**\" , \".unionfs-fuse/**\" ], \"rclone_extras\" : { \"--checkers\" : 16 , \"--drive-chunk-size\" : \"64M\" , \"--stats\" : \"60s\" , \"--transfers\" : 8 , \"--verbose\" : 1 }, \"rclone_sleeps\" : { \"Failed to copy: googleapi: Error 403: User rate limit exceeded\" : { \"count\" : 5 , \"sleep\" : 25 , \"timeout\" : 3600 } }, \"remove_empty_dir_depth\" : 2 , \"sync_remote\" : \"google:/Media\" , \"upload_folder\" : \"/mnt/local/Media\" , \"upload_remote\" : \"google:/Media\" } }, \"syncer\" : { }, \"uploader\" : { \"google\" : { \"check_interval\" : 30 , \"exclude_open_files\" : true , \"max_size_gb\" : 200 , \"opened_excludes\" : [ \"/downloads/\" ], \"size_excludes\" : [ \"downloads/*\" ] } } }","title":"Cloudplow with Notifications Enabled"},{"location":"reference/customizing-plex-libs/","text":"Customizing Plex Libraries \u00b6 Basics \u00b6 In the default Saltbox install, there only two main Plex libraries: one for Movies and one for TV Shows. The idea being that all movies are to be placed within the /Media/Movies folder in Google Drive. and all TV shows under /Media/TV . Default Paths: Media \u251c\u2500\u2500 Movies \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV If you would like to have custom libraries in Plex, you may do so with this guide. But regardless of whatever scenario you choose below, the media folders will ALWAYS be located within the Media folder ( /Media/ on Google Drive and /mnt/unionfs/Media/ on the server). Note: This guide discusses the setup in terms of movies. You can of course do the same with TV shows using the same concepts with your Media/TV directory and Sonarr, but to keep this document simple we're not covering both cases since they're just about identical. Scenarios \u00b6 Adding folders (i.e. libraries) directly under Media/Movies/ (or Media/TV/ ) (i.e. the standard paths) \u2192 Scenario 1 . This is the recommended option. Adding folders (i.e. libraries) directly under Media/ \u2192 Scenario 2 . Example \u00b6 Here is an example library setup, which is based on Scenario 1 . Media \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Movies-4K \u2502 \u251c\u2500\u2500 Movies-Anime \u2502 \u2514\u2500\u2500 Movies-Kids \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV \u251c\u2500\u2500 TV \u2514\u2500\u2500 TV-4K The general location movies in this example is /Movies/Movies . Note: This can be called anything else, such as /Movies/Movies-Main or /Movies/Movies-All . /Movies/Movies-Kids/ folder is for family rated, animated films. /Movies/Movies-Anime/ folder is for Japanese, animated films. Scenario 1 \u00b6 Movie libraries under /Media/Movies . This setup is recommended over Scenario 2 as it is somewhat user-friendly and requires a lot less setup. Example: Media \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Movies-4K \u2502 \u251c\u2500\u2500 Movies-Anime \u2502 \u251c\u2500\u2500 Movies-Foreign \u2502 \u2514\u2500\u2500 Movies-Kids \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV 1. Create Folders in Google Drive \u00b6 Let's say you wanted to have separate movie libraries for: General Movies 4K Movies Anime Movies Foreign Movies Movies for Kids You would first have to create these folders within the /Media/Movies path in Google Drive. However, the root folder of /Media/Movies will NOT contain anything but these folders. Note: Remember, folders are case sensitive in Google Drive and in Linux (e.g. 4K and 4k are 2 different folders). For our example, we will create the following folders in Google Drive: /Media/Movies/Movies * /Media/Movies/Movies-4K /Media/Movies/Movies-Anime /Media/Movies/Movies-Foreign /Media/Movies/Movies-Kids * Note: This can be called anything else, such as /Media/Movies/Movies-Main or /Media/Movies/Movies-All . Screenshots: 2. Add Libraries to Plex \u00b6 You will add each of these folders as separate libraries within Plex (see [[example|Install: Plex-Media-Server#adding-the-movie-library]]). You may name these libraries as whatever you want. The folders will be located under /mnt/unionfs/Media/Movies folder within Plex (see [[Paths|Basics: Saltbox Paths#plex]]). In our example, this will be: /mnt/unionfs/Media/Movies/Movies * /mnt/unionfs/Media/Movies/Movies-4K /mnt/unionfs/Media/Movies/Movies-Anime /mnt/unionfs/Media/Movies/Movies-Foreign /mnt/unionfs/Media/Movies/Movies-Kids * Note: This can be called anything else, such as /mnt/unionfs/Media/Movies-Main or /mnt/unionfs/Media/Movies-All . 3. Modify Cloudplow Config \u00b6 Note 1: For Mediabox / Feederbox setups, this will be done on the Feederbox. Note 2: This is the default setting and may be skipped if you haven't changed it before. On the server's shell, run the following command: nano /opt/cloudplow/config.json Set the following for remove_empty_dir_depth : \"remove_empty_dir_depth\" : 2 , Ctrl + X Y Enter to save. Restart Cloudplow: sudo systemctl restart cloudplow . 4. Change Root Paths in Radarr \u00b6 Set your Movie Paths in [[Radarr|Install: Radarr#8-adding-the-movies-path]] to reflect the new sub-dirs (e.g. /mnt/unionfs/Media/Movies/3D ). 6. Misc \u00b6 Scenario 2 \u00b6 Movie libraries under /Media . This setup is not recommended as it requires more config setup than Scenario 1. It also the changing of Sonarr/Radarr root paths and updating of those root paths for existing movies. Example: Media \u251c\u2500\u2500 Movies \u251c\u2500\u2500 Movies-4K \u251c\u2500\u2500 Movies-Anime \u251c\u2500\u2500 Movies-Foreign \u251c\u2500\u2500 Movies-Kids \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV 1. Create Folders in Google Drive \u00b6 Let's say you wanted to have separate movie libraries for: General Movies 4K Movies Anime Movies Foreign Movies Movies for Kids You would first have to create these folders within the /Media/ path in Google Drive. However, the root folder of /Media/ will NOT contain anything but these folders (and Music and TV folders). Note: Remember, folders are case sensitive in Google Drive and in Linux (e.g. 4K and 4k are 2 different folders). For our example, we will create the following folders in Google Drive: /Media/Movies * /Media/Movies-4K /Media/Movies-Anime /Media/Movies-Foreign /Media/Movies-Kids * Note: This can be called anything else, such as /Media/Movies-Main or /Media/Movies-All . Screenshot: 2. Add Libraries to Plex \u00b6 You will add each of these folders as separate libraries within Plex (see [[example|Install: Plex-Media-Server#adding-the-movie-library]]). You may name these libraries as whatever you want. The folders will be located under /mnt/unionfs/Media folder within Plex (see [[Paths|Basics: Saltbox Paths#plex]]). In our example, this will be: /mnt/unionfs/Media/Movies * /mnt/unionfs/Media/Movies-4K /mnt/unionfs/Media/Movies-Anime /mnt/unionfs/Media/Movies-Foreign /mnt/unionfs/Media/Movies-Kids * Note: This can be called anything else, such as /mnt/unionfs/Media/Movies-Main or /mnt/unionfs/Media/Movies-All . 3. Modify Plex Autoscan Config \u00b6 Note: For Mediabox / Feederbox setups, this will be done on the Mediabox. On the server's shell, run the following command: nano /opt/plex_autoscan/config/config.json Scroll down to the SERVER_PATH_MAPPINGS section. Under this section, you will need to add library paths (as seen from within Plex) with the corresponding /mnt/unionfs/Media/ path. The format will look like: \"/data/<folder>\": [ <----- Plex Library Path \"/mnt/unionfs/Media/<folder>\", <----- Incoming folder path from webhooks (e.g. Radarr root path) \"My Drive/Media/<folder>/\" <----- Incoming folder path from Google Drive Monitoring (optional) ], Note: Make sure the folder paths are within quotes (e.g. \"/data/Movies/\" ) and there is a comma ( , ) after the close bracket ( ] ) - all except the last one (see example below). After the changes, the section will now look similar to this: \"SERVER_PATH_MAPPINGS\" : { \"/data/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , \"My Drive/Media/Movies/\" ], \"/data/Movies-4K/\" : [ \"/mnt/unionfs/Media/Movies-4K/\" , \"My Drive/Media/Movies-4K/\" ], \"/data/Movies-Anime/\" : [ \"/mnt/unionfs/Media/Movies-Anime/\" , \"My Drive/Media/Movies-Anime/\" ], \"/data/Movies-Foreign/\" : [ \"/mnt/unionfs/Media/Movies-Foreign/\" , \"My Drive/Media/Movies-Foreign/\" ], \"/data/Movies-Kids/\" : [ \"/mnt/unionfs/Media/Movies-Kids/\" , \"My Drive/Media/Movies-Kids/\" ], \"/data/TV/\" : [ \"/tv/\" , \"/mnt/unionfs/Media/TV/\" \"My Drive/Media/TV/\" ], \"/data/Music/\" : [ \"/music/\" , \"/mnt/unionfs/Media/Music/\" , \"My Drive/Media/Music/\" ] }, Note: There may be paths such as \"My Drive/Media/Movies/\" filled in for [[Google Drive monitoring|Plex Autoscan Extras#google-drive-monitoring]]. If you are not planning on using this feature of Plex Autoscan, you can simply ignore them. If you do want to use it, you will then need to tweak the folders to match your Google Drive folder paths. See [[Plex Autoscan Extras|Plex Autoscan Extras#google-drive-monitoring]] for more info. Ctrl + X Y Enter to save. Restart Plex Autoscan: sudo systemctl restart plex_autoscan 4. Modify Cloudplow Config \u00b6 Note: For Mediabox / Feederbox setups, this will be done on the Feederbox. On the server's shell, run the following command: nano /opt/cloudplow/config.json Set the following for remove_empty_dir_depth : \"remove_empty_dir_depth\" : 1 , Ctrl + X Y Enter to save. Restart Cloudplow: sudo systemctl restart cloudplow . 5. Change Root Paths in Radarr \u00b6 Set your Movie Paths in [[Radarr|Install: Radarr#8-adding-the-movies-path]] to reflect the new sub-dirs (e.g. /mnt/unionfs/Media/Movies-3D ).","title":"Customizing Plex Libraries"},{"location":"reference/customizing-plex-libs/#customizing-plex-libraries","text":"","title":"Customizing Plex Libraries"},{"location":"reference/customizing-plex-libs/#basics","text":"In the default Saltbox install, there only two main Plex libraries: one for Movies and one for TV Shows. The idea being that all movies are to be placed within the /Media/Movies folder in Google Drive. and all TV shows under /Media/TV . Default Paths: Media \u251c\u2500\u2500 Movies \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV If you would like to have custom libraries in Plex, you may do so with this guide. But regardless of whatever scenario you choose below, the media folders will ALWAYS be located within the Media folder ( /Media/ on Google Drive and /mnt/unionfs/Media/ on the server). Note: This guide discusses the setup in terms of movies. You can of course do the same with TV shows using the same concepts with your Media/TV directory and Sonarr, but to keep this document simple we're not covering both cases since they're just about identical.","title":"Basics"},{"location":"reference/customizing-plex-libs/#scenarios","text":"Adding folders (i.e. libraries) directly under Media/Movies/ (or Media/TV/ ) (i.e. the standard paths) \u2192 Scenario 1 . This is the recommended option. Adding folders (i.e. libraries) directly under Media/ \u2192 Scenario 2 .","title":"Scenarios"},{"location":"reference/customizing-plex-libs/#example","text":"Here is an example library setup, which is based on Scenario 1 . Media \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Movies-4K \u2502 \u251c\u2500\u2500 Movies-Anime \u2502 \u2514\u2500\u2500 Movies-Kids \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV \u251c\u2500\u2500 TV \u2514\u2500\u2500 TV-4K The general location movies in this example is /Movies/Movies . Note: This can be called anything else, such as /Movies/Movies-Main or /Movies/Movies-All . /Movies/Movies-Kids/ folder is for family rated, animated films. /Movies/Movies-Anime/ folder is for Japanese, animated films.","title":"Example"},{"location":"reference/customizing-plex-libs/#scenario-1","text":"Movie libraries under /Media/Movies . This setup is recommended over Scenario 2 as it is somewhat user-friendly and requires a lot less setup. Example: Media \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Movies-4K \u2502 \u251c\u2500\u2500 Movies-Anime \u2502 \u251c\u2500\u2500 Movies-Foreign \u2502 \u2514\u2500\u2500 Movies-Kids \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV","title":"Scenario 1"},{"location":"reference/customizing-plex-libs/#1-create-folders-in-google-drive","text":"Let's say you wanted to have separate movie libraries for: General Movies 4K Movies Anime Movies Foreign Movies Movies for Kids You would first have to create these folders within the /Media/Movies path in Google Drive. However, the root folder of /Media/Movies will NOT contain anything but these folders. Note: Remember, folders are case sensitive in Google Drive and in Linux (e.g. 4K and 4k are 2 different folders). For our example, we will create the following folders in Google Drive: /Media/Movies/Movies * /Media/Movies/Movies-4K /Media/Movies/Movies-Anime /Media/Movies/Movies-Foreign /Media/Movies/Movies-Kids * Note: This can be called anything else, such as /Media/Movies/Movies-Main or /Media/Movies/Movies-All . Screenshots:","title":"1. Create Folders in Google Drive"},{"location":"reference/customizing-plex-libs/#2-add-libraries-to-plex","text":"You will add each of these folders as separate libraries within Plex (see [[example|Install: Plex-Media-Server#adding-the-movie-library]]). You may name these libraries as whatever you want. The folders will be located under /mnt/unionfs/Media/Movies folder within Plex (see [[Paths|Basics: Saltbox Paths#plex]]). In our example, this will be: /mnt/unionfs/Media/Movies/Movies * /mnt/unionfs/Media/Movies/Movies-4K /mnt/unionfs/Media/Movies/Movies-Anime /mnt/unionfs/Media/Movies/Movies-Foreign /mnt/unionfs/Media/Movies/Movies-Kids * Note: This can be called anything else, such as /mnt/unionfs/Media/Movies-Main or /mnt/unionfs/Media/Movies-All .","title":"2. Add Libraries to Plex"},{"location":"reference/customizing-plex-libs/#3-modify-cloudplow-config","text":"Note 1: For Mediabox / Feederbox setups, this will be done on the Feederbox. Note 2: This is the default setting and may be skipped if you haven't changed it before. On the server's shell, run the following command: nano /opt/cloudplow/config.json Set the following for remove_empty_dir_depth : \"remove_empty_dir_depth\" : 2 , Ctrl + X Y Enter to save. Restart Cloudplow: sudo systemctl restart cloudplow .","title":"3. Modify Cloudplow Config"},{"location":"reference/customizing-plex-libs/#4-change-root-paths-in-radarr","text":"Set your Movie Paths in [[Radarr|Install: Radarr#8-adding-the-movies-path]] to reflect the new sub-dirs (e.g. /mnt/unionfs/Media/Movies/3D ).","title":"4. Change Root Paths in Radarr"},{"location":"reference/customizing-plex-libs/#6-misc","text":"","title":"6. Misc"},{"location":"reference/customizing-plex-libs/#scenario-2","text":"Movie libraries under /Media . This setup is not recommended as it requires more config setup than Scenario 1. It also the changing of Sonarr/Radarr root paths and updating of those root paths for existing movies. Example: Media \u251c\u2500\u2500 Movies \u251c\u2500\u2500 Movies-4K \u251c\u2500\u2500 Movies-Anime \u251c\u2500\u2500 Movies-Foreign \u251c\u2500\u2500 Movies-Kids \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV","title":"Scenario 2"},{"location":"reference/customizing-plex-libs/#1-create-folders-in-google-drive_1","text":"Let's say you wanted to have separate movie libraries for: General Movies 4K Movies Anime Movies Foreign Movies Movies for Kids You would first have to create these folders within the /Media/ path in Google Drive. However, the root folder of /Media/ will NOT contain anything but these folders (and Music and TV folders). Note: Remember, folders are case sensitive in Google Drive and in Linux (e.g. 4K and 4k are 2 different folders). For our example, we will create the following folders in Google Drive: /Media/Movies * /Media/Movies-4K /Media/Movies-Anime /Media/Movies-Foreign /Media/Movies-Kids * Note: This can be called anything else, such as /Media/Movies-Main or /Media/Movies-All . Screenshot:","title":"1. Create Folders in Google Drive"},{"location":"reference/customizing-plex-libs/#2-add-libraries-to-plex_1","text":"You will add each of these folders as separate libraries within Plex (see [[example|Install: Plex-Media-Server#adding-the-movie-library]]). You may name these libraries as whatever you want. The folders will be located under /mnt/unionfs/Media folder within Plex (see [[Paths|Basics: Saltbox Paths#plex]]). In our example, this will be: /mnt/unionfs/Media/Movies * /mnt/unionfs/Media/Movies-4K /mnt/unionfs/Media/Movies-Anime /mnt/unionfs/Media/Movies-Foreign /mnt/unionfs/Media/Movies-Kids * Note: This can be called anything else, such as /mnt/unionfs/Media/Movies-Main or /mnt/unionfs/Media/Movies-All .","title":"2. Add Libraries to Plex"},{"location":"reference/customizing-plex-libs/#3-modify-plex-autoscan-config","text":"Note: For Mediabox / Feederbox setups, this will be done on the Mediabox. On the server's shell, run the following command: nano /opt/plex_autoscan/config/config.json Scroll down to the SERVER_PATH_MAPPINGS section. Under this section, you will need to add library paths (as seen from within Plex) with the corresponding /mnt/unionfs/Media/ path. The format will look like: \"/data/<folder>\": [ <----- Plex Library Path \"/mnt/unionfs/Media/<folder>\", <----- Incoming folder path from webhooks (e.g. Radarr root path) \"My Drive/Media/<folder>/\" <----- Incoming folder path from Google Drive Monitoring (optional) ], Note: Make sure the folder paths are within quotes (e.g. \"/data/Movies/\" ) and there is a comma ( , ) after the close bracket ( ] ) - all except the last one (see example below). After the changes, the section will now look similar to this: \"SERVER_PATH_MAPPINGS\" : { \"/data/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , \"My Drive/Media/Movies/\" ], \"/data/Movies-4K/\" : [ \"/mnt/unionfs/Media/Movies-4K/\" , \"My Drive/Media/Movies-4K/\" ], \"/data/Movies-Anime/\" : [ \"/mnt/unionfs/Media/Movies-Anime/\" , \"My Drive/Media/Movies-Anime/\" ], \"/data/Movies-Foreign/\" : [ \"/mnt/unionfs/Media/Movies-Foreign/\" , \"My Drive/Media/Movies-Foreign/\" ], \"/data/Movies-Kids/\" : [ \"/mnt/unionfs/Media/Movies-Kids/\" , \"My Drive/Media/Movies-Kids/\" ], \"/data/TV/\" : [ \"/tv/\" , \"/mnt/unionfs/Media/TV/\" \"My Drive/Media/TV/\" ], \"/data/Music/\" : [ \"/music/\" , \"/mnt/unionfs/Media/Music/\" , \"My Drive/Media/Music/\" ] }, Note: There may be paths such as \"My Drive/Media/Movies/\" filled in for [[Google Drive monitoring|Plex Autoscan Extras#google-drive-monitoring]]. If you are not planning on using this feature of Plex Autoscan, you can simply ignore them. If you do want to use it, you will then need to tweak the folders to match your Google Drive folder paths. See [[Plex Autoscan Extras|Plex Autoscan Extras#google-drive-monitoring]] for more info. Ctrl + X Y Enter to save. Restart Plex Autoscan: sudo systemctl restart plex_autoscan","title":"3. Modify Plex Autoscan Config"},{"location":"reference/customizing-plex-libs/#4-modify-cloudplow-config","text":"Note: For Mediabox / Feederbox setups, this will be done on the Feederbox. On the server's shell, run the following command: nano /opt/cloudplow/config.json Set the following for remove_empty_dir_depth : \"remove_empty_dir_depth\" : 1 , Ctrl + X Y Enter to save. Restart Cloudplow: sudo systemctl restart cloudplow .","title":"4. Modify Cloudplow Config"},{"location":"reference/customizing-plex-libs/#5-change-root-paths-in-radarr","text":"Set your Movie Paths in [[Radarr|Install: Radarr#8-adding-the-movies-path]] to reflect the new sub-dirs (e.g. /mnt/unionfs/Media/Movies-3D ).","title":"5. Change Root Paths in Radarr"},{"location":"reference/dependencies/","text":"Warning This is a reference discussing an aspect of the install process . If you are looking for the steps to follow to install, they are here . If you want to examine the dependencies script before running it: curl -sL https://install.saltbox.dev | more This script will: install git delete an existing repo clone the saltbox repo to the system [default location /srv/git/sb ] create some script aliases run sb_dep.sh run sb_repo.sh At the end of this you will have a local copy of the Saltbox repo, and all the things that Saltbox relies on to install will be available. Go back to the install process .","title":"Dependencies"},{"location":"reference/domain/","text":"Domain Name \u00b6 You will need a domain name as Saltbox apps are only accessed via https://appname. yourdomain.com (see Accessing Saltbox Apps ). The steps below will help you set up a domain and DNS settings for use with Saltbox. Ports are [for the most part] bound only to the internal saltbox docker network, which means they are not visible on the host; you won't be able to connect externally to the apps using IP:PORT . 1. Domain Provider \u00b6 Get a domain name from any domain name registry (e.g. Namecheap , Godaddy , Namesilo , etc). If you already have one, you may skip this step. Note: Free domain name providers, such as Freenom , do not support wildcard DNS settings, and paid domain names can be had for less than a dollar per year (see promo deals on various sites). However, you can add them to Cloudflare and not have to worry about it. If you are planning to use the automatic Cloudflare integration, there are some top-level domains [TLDs] that will not work with it. Refer to this page . As of 2022/11/03: \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\" 2. DNS Setup \u00b6 Pick one of the setups below. Your choice will depend on whether you meet certain criteria, as listed under the \"Notes\" section. i. Wildcard DNS Setup \u00b6 Notes: For DNS providers that allow wildcards. For [[Saltbox install type|Basics: Saltbox Install Types]]. Steps: Created an A Record for your subdomains with * for host and set the value to your server IP address. Type Host Value TTL A Record * Server IP Address 300 Example Namecheap > Domain List > Manage > Advanced DNS > Add New Record > A Record > `*` for Host > Server IP for Value. ![](../images/cloudflare/cloudflare-a-record.png) ii. Non-Wildcard DNS Setup \u00b6 Notes: For DNS providers that do not allow wildcards (e.g. Freenom). For Mediabox / Feederbox install types . For Cloudflare users. Note: if you provide a Cloudflare email and API Key in your settings, the Saltbox installer will set this up for you automatically, provided you enter a top-level domain in the settings [i.e. DOMAIN.TLD , not WHATEVER.DOMAIN.TLD ] Saltbox Install Type Mediabox / Feederbox Install Type You will need to create A Records for all Saltbox subdomains. Type Host Value TTL A Record plex Saltbox IP Address 300 A Record tautulli Saltbox IP Address 300 A Record jackett Saltbox IP Address 300 A Record radarr Saltbox IP Address 300 A Record sonarr Saltbox IP Address 300 A Record rutorrent Saltbox IP Address 300 A Record nzbget Saltbox IP Address 300 A Record nzbhydra2 Saltbox IP Address 300 A Record organizr Saltbox IP Address 300 A Record portainer Saltbox IP Address 300 You will need to create A Records for both IP addresses (Media and Feeder boxes) and set them to their respective subdomains. Mediabox Type Host Value TTL A Record plex Mediabox IP Address 300 A Record tautulli Mediabox IP Address 300 Feederbox Type Host Value TTL A Record jackett Feederbox IP Address 300 A Record radarr Feederbox IP Address 300 A Record sonarr Feederbox IP Address 300 A Record rutorrent Feederbox IP Address 300 A Record nzbget Feederbox IP Address 300 A Record nzbhydra2 Feederbox IP Address 300 A Record organizr Feederbox IP Address 300 A Record portainer Feederbox IP Address 300 Cloudflare \u00b6 Intro \u00b6 Cloudflare a service that, among other things, protects and accelerates a wide network of websites. By being the \"man in the middle\", it can act like a free DNS provider. Saltbox makes adding subdomains to Cloudflare's DNS settings a breeze via automation. All you need is the API key. Note that there are some top-level domains [TLDs] that will not work with this automation. Refer to this page . As of 2020/07/26: \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\" Although Cloudflare is not required for Saltbox, it is still recommended because: DNS changes propagate almost instantly (a lot faster than a domain provider's DNS service). Hide your server's IP behind Cloudflare's. Makes setting up Mediabox / Feederbox a lot quicker. Allows for automated setup of subdomains for Saltbox add-on apps. It's free. Note: Saltbox does not enable CDN / Proxy by default, but you may do so yourself after installing Saltbox (see section [[below|Prerequisites: Cloudflare#post-setup]]). Sign Up \u00b6 Sign up for a free Cloudflare account. On your Domain Registrar's website (e.g. GoDaddy, Namecheap, etc), set the Name Servers to what Cloudflare instructs you to. Namecheap.com Namesilo.com \"Dashboard\" -> your domain.tld -> \"Manage\" -> \"Name Servers\" -> \"Custom DNS\" -> add the nameservers in. \"Manage My Domains\" -> your domain.tld -> \"NameServers\" -> \"Change\" -> add the nameservers in. Setup \u00b6 Go to Cloudflare.com . Here you will see that your domain will have an \"Active\" status. Click on your domain to continue. Click the SSL/TLS tab. Set SSL to Full (strict) . Cloudflare API Key \u00b6 Go to Cloudflare.com . Click the Overview tab. Click Get your API token . Under API Keys and then Global API Key click View . On the login popup, type in your password and click View . Save your API key. Post-Setup \u00b6 After Saltbox has added in the subdomains, you may go back in and turn on CDN for for them if you like. NOte, however, that enabling proxying on your plex or emby subdomains [or more generally proxying large amounts of non-HTML content] is against Cloudflare TOS and may end up getting your Cloudflare account banned. Do this AFTER all your certs have been assigned and you have confirmed that all the Saltbox app sites are loading OK. This also applies to any app/subdomains you add in the future - wait till after you get certs before enabling CDN. Note 1: Leave the subdomains saltbox , mediabox , and feederbox as DNS Only , as they were created to reach your servers directly and not behind a CDN proxy (i.e. they need to resolve to the server's IP and not Cloudflare's). Note 2: If you enable proxying on plex/emby subdomains despite it being against TOS, you may find that performance suffers badly. You can do this by: Going to Cloudflare.com . Clicking the DNS tab. Find the subdomain of interest. Under \"Status\", click the switch next to the gray cloud icon (i.e. DNS Only ) to switch to an orange one (i.e. DNS and HTTP proxy (CDN) ).","title":"Domain Name"},{"location":"reference/domain/#domain-name","text":"You will need a domain name as Saltbox apps are only accessed via https://appname. yourdomain.com (see Accessing Saltbox Apps ). The steps below will help you set up a domain and DNS settings for use with Saltbox. Ports are [for the most part] bound only to the internal saltbox docker network, which means they are not visible on the host; you won't be able to connect externally to the apps using IP:PORT .","title":"Domain Name"},{"location":"reference/domain/#1-domain-provider","text":"Get a domain name from any domain name registry (e.g. Namecheap , Godaddy , Namesilo , etc). If you already have one, you may skip this step. Note: Free domain name providers, such as Freenom , do not support wildcard DNS settings, and paid domain names can be had for less than a dollar per year (see promo deals on various sites). However, you can add them to Cloudflare and not have to worry about it. If you are planning to use the automatic Cloudflare integration, there are some top-level domains [TLDs] that will not work with it. Refer to this page . As of 2022/11/03: \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\"","title":"1. Domain Provider"},{"location":"reference/domain/#2-dns-setup","text":"Pick one of the setups below. Your choice will depend on whether you meet certain criteria, as listed under the \"Notes\" section.","title":"2. DNS Setup"},{"location":"reference/domain/#i-wildcard-dns-setup","text":"Notes: For DNS providers that allow wildcards. For [[Saltbox install type|Basics: Saltbox Install Types]]. Steps: Created an A Record for your subdomains with * for host and set the value to your server IP address. Type Host Value TTL A Record * Server IP Address 300 Example Namecheap > Domain List > Manage > Advanced DNS > Add New Record > A Record > `*` for Host > Server IP for Value. ![](../images/cloudflare/cloudflare-a-record.png)","title":"i. Wildcard DNS Setup"},{"location":"reference/domain/#ii-non-wildcard-dns-setup","text":"Notes: For DNS providers that do not allow wildcards (e.g. Freenom). For Mediabox / Feederbox install types . For Cloudflare users. Note: if you provide a Cloudflare email and API Key in your settings, the Saltbox installer will set this up for you automatically, provided you enter a top-level domain in the settings [i.e. DOMAIN.TLD , not WHATEVER.DOMAIN.TLD ] Saltbox Install Type Mediabox / Feederbox Install Type You will need to create A Records for all Saltbox subdomains. Type Host Value TTL A Record plex Saltbox IP Address 300 A Record tautulli Saltbox IP Address 300 A Record jackett Saltbox IP Address 300 A Record radarr Saltbox IP Address 300 A Record sonarr Saltbox IP Address 300 A Record rutorrent Saltbox IP Address 300 A Record nzbget Saltbox IP Address 300 A Record nzbhydra2 Saltbox IP Address 300 A Record organizr Saltbox IP Address 300 A Record portainer Saltbox IP Address 300 You will need to create A Records for both IP addresses (Media and Feeder boxes) and set them to their respective subdomains. Mediabox Type Host Value TTL A Record plex Mediabox IP Address 300 A Record tautulli Mediabox IP Address 300 Feederbox Type Host Value TTL A Record jackett Feederbox IP Address 300 A Record radarr Feederbox IP Address 300 A Record sonarr Feederbox IP Address 300 A Record rutorrent Feederbox IP Address 300 A Record nzbget Feederbox IP Address 300 A Record nzbhydra2 Feederbox IP Address 300 A Record organizr Feederbox IP Address 300 A Record portainer Feederbox IP Address 300","title":"ii. Non-Wildcard DNS Setup"},{"location":"reference/domain/#cloudflare","text":"","title":"Cloudflare"},{"location":"reference/domain/#intro","text":"Cloudflare a service that, among other things, protects and accelerates a wide network of websites. By being the \"man in the middle\", it can act like a free DNS provider. Saltbox makes adding subdomains to Cloudflare's DNS settings a breeze via automation. All you need is the API key. Note that there are some top-level domains [TLDs] that will not work with this automation. Refer to this page . As of 2020/07/26: \"DNS API cannot be used for domains with .cf, .ga, .gq, .ml, or .tk TLDs.\" Although Cloudflare is not required for Saltbox, it is still recommended because: DNS changes propagate almost instantly (a lot faster than a domain provider's DNS service). Hide your server's IP behind Cloudflare's. Makes setting up Mediabox / Feederbox a lot quicker. Allows for automated setup of subdomains for Saltbox add-on apps. It's free. Note: Saltbox does not enable CDN / Proxy by default, but you may do so yourself after installing Saltbox (see section [[below|Prerequisites: Cloudflare#post-setup]]).","title":"Intro"},{"location":"reference/domain/#sign-up","text":"Sign up for a free Cloudflare account. On your Domain Registrar's website (e.g. GoDaddy, Namecheap, etc), set the Name Servers to what Cloudflare instructs you to. Namecheap.com Namesilo.com \"Dashboard\" -> your domain.tld -> \"Manage\" -> \"Name Servers\" -> \"Custom DNS\" -> add the nameservers in. \"Manage My Domains\" -> your domain.tld -> \"NameServers\" -> \"Change\" -> add the nameservers in.","title":"Sign Up"},{"location":"reference/domain/#setup","text":"Go to Cloudflare.com . Here you will see that your domain will have an \"Active\" status. Click on your domain to continue. Click the SSL/TLS tab. Set SSL to Full (strict) .","title":"Setup"},{"location":"reference/domain/#cloudflare-api-key","text":"Go to Cloudflare.com . Click the Overview tab. Click Get your API token . Under API Keys and then Global API Key click View . On the login popup, type in your password and click View . Save your API key.","title":"Cloudflare API Key"},{"location":"reference/domain/#post-setup","text":"After Saltbox has added in the subdomains, you may go back in and turn on CDN for for them if you like. NOte, however, that enabling proxying on your plex or emby subdomains [or more generally proxying large amounts of non-HTML content] is against Cloudflare TOS and may end up getting your Cloudflare account banned. Do this AFTER all your certs have been assigned and you have confirmed that all the Saltbox app sites are loading OK. This also applies to any app/subdomains you add in the future - wait till after you get certs before enabling CDN. Note 1: Leave the subdomains saltbox , mediabox , and feederbox as DNS Only , as they were created to reach your servers directly and not behind a CDN proxy (i.e. they need to resolve to the server's IP and not Cloudflare's). Note 2: If you enable proxying on plex/emby subdomains despite it being against TOS, you may find that performance suffers badly. You can do this by: Going to Cloudflare.com . Clicking the DNS tab. Find the subdomain of interest. Under \"Status\", click the switch next to the gray cloud icon (i.e. DNS Only ) to switch to an orange one (i.e. DNS and HTTP proxy (CDN) ).","title":"Post-Setup"},{"location":"reference/google-account-perms/","text":"This guide will show you how to verify that your Google account has the correct permissions required for the shared drive creation. It's assuming you're working through the steps from here . NOTE: This guide is assuming a Google Gsuite Business/Workspace account. Go to https://admin.google.com; from the left-hand menu select \"Apps > Google Workspace > Drive and Docs\": Verify that Drive is turned on for your organization: If it is not, click on the triangle on the right of that section and enable it if needed. After clicking \"SAVE\" [if you changed the setting] click back to \"Settings for Drive and Docs\": Back on the that screen, click on the \"Sharing settings\" section: Scroll down and verify that your \"Shared Drive Settings\" match these. Change them if required and save: Scroll down to \"Shared drive creation\" and verify that your settings match these: You're done. If you are going through the manual rclone instructions, continue with the next step","title":"Google Permissions"},{"location":"reference/google-gcloud-tools-install/","text":"This guide will show you how to set up the Google SDK tools. These tools are used by scripts in the next two steps that have to interact with google. Unfortunately, these can't be installed in an automated fashion, so you will have to go through these manual steps, which are largely copy-paste. It's assuming you're working through the steps from here and have completed the following steps: verified account drive permissions created the required project created the required group This is a simplified extract from the original docs, which can be found here : Run the following commands, one at a time: sudo apt-get install apt-transport-https ca-certificates gnupg echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main\" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add - sudo apt-get update && sudo apt-get install google-cloud-sdk -y Run the following command: gcloud init --console-only Follow the prompts: Welcome! This command will take you through the configuration of gcloud. ... You must log in to continue. Would you like to log in (Y/n)? Y Go to the following link in your browser: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32...X4&code_challenge_method=S256 3. Log into your Google account and approve the access request: Copy the verification code. Continue in the terminal: Enter verification code: 4/1AX4XfWjkg8C8r...ujs332G8 You are logged in as: [YOUR_GOOGLE_ACCOUNT]. You will now be asked to choose a default project. Choose the one you created earlier. Pick cloud project to use: [1] THE_PROJECT_YOUR_CREATED_FOR_SALTBOX [2] Create a new project Please enter numeric choice or text value (must exactly match list item): 1 Your current project has been set to: [THE_PROJECT_YOUR_CREATED_FOR_SALTBOX]. You may be asked to choose a default zone/region. If so, you can choose the closest to you. Run the following command: gcloud organizations list Your organization ID will be displayed in the table: DISPLAY_NAME ID DIRECTORY_CUSTOMER_ID YOUR-DOMAIN 123456789098 XXXXXXXXX ^^^ HERE ^^^ Make a note of that ID; if you're going through the manual rclone instructions you'll need it in the next step. Google SDK is installed and configured. If you are going through the manual rclone instructions, continue with the next step","title":"Google SDK"},{"location":"reference/google-group-setup/","text":"This guide will show you how to set up a Google Group for use with service accounts. It's assuming you're working through the steps from here and have completed the following steps: verified account drive permissions created the required project NOTE: This guide is assuming a Google Gsuite Business/Workspace account. Open the Google Admin site: https://admin.google.com/ and login with your Google account. Click on the groups heading: You should now see a list of your groups [which may be empty]. Click on \"Create Group\": Enter a name, description and email address for the group; choose an owner [this should be the account with which you just logged in]. Click \"Next\". Scroll down, change \"Who can join\" to \"Only invited users\", and toggle \"Allow members outside your organization\". Click \"Create Group\". Click \"Done\". If you are going through the manual rclone instructions, continue with the next step","title":"Google Group"},{"location":"reference/google-project-setup/","text":"This guide will show you how to set up a Google Project and create credentials that will work for safire or sa-gen or similar tools. It's assuming you're working through the steps from here and have completed the following steps: verified account drive permissions This guide is assuming you are using a standard GSuite Business or GSuite Workspace account. IF YOU HAVE DONE THIS BEFORE, THERE IS NO REASON TO REPEAT IT. Open Google APIs Console site: https://console.developers.google.com and login with your Google account. Click on the project or organization at the top: Click \"New Project\": Name the project. Click \"Create\". You'll see a progress dialog, when it's complete, click \"Select Project\" Click \"Go to APIs overview\". Click \"ENABLE APIS AND SERVICES\" at the top. You'll be taken to the \"API Library\": Search for \"Admin\". Click \"Admin SDK API\". Click the button to enable the API: You'll go to a API Overview page. Click the browser back button twice: Repeat this process for six more APIs: - Google Drive API - Identity and Access Management (IAM) API - Cloud Resource Manager API - Service Usage API - Service Management API - Google Sheets API You may find that some of these APIs have been enabled already as dependencies of others, like Service Management here: In that case, click the website back arrow once and move on to the next one. Now click \"APIS and Services\" then \"Credentials\" in the left column to go to the credentials dash: Click \"Configure consent screen\" over on the right: Choose \"External\" user type and click \"Create\": On this screen: type in the App Name (e.g. Rclone) Enter a \"User support email\" Scroll to the bottom Enter an email address under \"Developer contact information\" Click \"SAVE AND CONTINUE\". Click \"SAVE AND CONTINUE\" on the scopes screen: And \"BACK TO DASHBOARD\" on the final summary: Click \"SAVE AND CONTINUE\" on the test users screen: And \"BACK TO DASHBOARD\" on the final summary: Click \"PUBLISH APP\" on the dashboard : Then \"CONFIRM\": Click \"Credentials\" in the sidebar: Click \"Create Credentials\", then \"OAuth client ID\": Choose \"Desktop App\", give the app a name, and click \"CREATE\": You'll be presented with the Client ID and Secret. Copy and save them somewhere; you may need them to configure other tools later. Click on \"DOWNLOAD JSON\" to download the credential file: Later on, I'm going to assume you put it on the saltbox server in /opt/sa/ and named it project-creds.json . If you are going through the manual rclone instructions, continue with the next step","title":"Google Project"},{"location":"reference/google-service-accounts/","text":"This guide will show you how to create projects and service accounts using sa-gen and add them to a Google Group. It's assuming you're working through the steps from here and have completed the following steps: verified account drive permissions created the required project created the required group installed the gcloud SDK tools NOTE: This guide is assuming a Google Gsuite Business/Workspace account. IF YOU HAVE DONE THIS BEFORE, THERE IS NO REASON TO REPEAT IT. USE THE SAME 300 SERVICE ACCOUNTS CREATED THE FIRST TIME. Create /opt/sa and make sure it's writable by you. sudo mkdir -p /opt/sa sudo chown -R <user>:<group> /opt/sa What do I put in for `user` and `group`? Enter the user name that you entered in `accounts.yml`; group is the same as the user. Don't enter the ` < ` and `>`. --- user: name: seed # <<< THIS VALUE ... You can also run `id` to get this information: ~ id uid=1000(marco) gid=1000(marco) groups=1000(marco),... ^<user> ^<group> Verify that the google project has the right APIs enabled: [copy-paste this into your terminal window] gcloud services list --enabled You should see: NAME TITLE admin.googleapis.com Admin SDK API bigquery.googleapis.com BigQuery API bigquerystorage.googleapis.com BigQuery Storage API cloudapis.googleapis.com Google Cloud APIs clouddebugger.googleapis.com Cloud Debugger API cloudresourcemanager.googleapis.com Cloud Resource Manager API cloudtrace.googleapis.com Cloud Trace API datastore.googleapis.com Cloud Datastore API drive.googleapis.com Google Drive API iam.googleapis.com Identity and Access Management (IAM) API iamcredentials.googleapis.com IAM Service Account Credentials API logging.googleapis.com Cloud Logging API monitoring.googleapis.com Cloud Monitoring API servicemanagement.googleapis.com Service Management API serviceusage.googleapis.com Service Usage API sheets.googleapis.com Google Sheets API sql-component.googleapis.com Cloud SQL storage-api.googleapis.com Google Cloud Storage JSON API storage-component.googleapis.com Cloud Storage storage.googleapis.com Cloud Storage API If any of these are missing from your list, go back to the project setup and add all the APIs shown there to the project. Retrieve the sa-gen code [copy-paste this into your terminal window] cd /opt && git clone https://github.com/88lex/sa-gen && cd sa-gen Edit the sa-gen script: [copy-paste this into your terminal window] nano sa-gen Edit the beginning of the script as indicated by <<<< below: For these edits, you will need: the \"Organization ID\" from gcloud SDK step, the full email address of the group you created a couple steps ago, and the prefix you generated earlier. #!/bin/bash # Running this script requires gcloud command line tools. To install go to https://cloud.google.com/sdk/docs/quickstarts # See readme.md to understand the variables used in this script KEYS_DIR=/opt/sa/all ORGANIZATION_ID=\"123456789098\" <<<< organization ID from gcloud SDK step GROUP_NAME=\"mygroup@mydomain.com\" <<<< the group [full email address as shown] you created previously PROJECT_BASE_NAME=\"mgbtbnfkkt\" <<<< the prefix you generated previously FIRST_PROJECT_NUM=1 LAST_PROJECT_NUM=3 SA_EMAIL_BASE_NAME=\"mgbtbnfkkt\" <<<< the prefix you generated previously FIRST_SA_NUM=1 NUM_SAS_PER_PROJECT=100 ... Save the file with control-x, y, enter Run the sa-gan script: ./sa-gen sa-gen will create three projects, 300 SAs, and download them to /opt/sa : Total SA json keys before running sa-gen = 0 Creating project = mgbtbnfkkt1 ++ gcloud projects create mgbtbnfkkt1 --organization= Create in progress for [https://cloudresourcemanager.googleapis.com/v1/projects/mgbtbnfkkt1]. Waiting for [operations/cp.5950654100828535641] to finish...done. Enabling service [cloudapis.googleapis.com] on project [mgbtbnfkkt1]... Operation \"operations/acf.p2-672393700722-9443eda2-69db-46a9-8952-5cdaa3b6ed2f\" finished successfully. ++ set +x ... Total SA json keys BEFORE running sa-gen = 0 Total SA json keys AFTER running sa-gen = 300 Total SA jsons CREATED = 300 Download the members.csv file that sa-gen created next to the service account files to your local computer using sftp or whatever other means. Open the Google Admin site: https://admin.google.com/ and login with your Google account. Click on the groups heading: Click on your group: Click on \"BULK UPLOAD MEMBERS\": Click on \"ATTACH CSV\", and find the members.csv you downloaded a moment ago: Click \"UPLOAD\". Status will appear in the upper right: You're done. If you are going through the manual rclone instructions, continue with the next step","title":"Google Service Accounts"},{"location":"reference/google-shared-drives/","text":"This guide will show you how to create default Saltbox Shared Drives and add your group of SAs to them. It's assuming you're working through the steps from here and have completed the following steps: verified account drive permissions created the required project created the required group installed the gcloud SDK tools created the expected projects and service accounts NOTE: This guide is assuming a Google Gsuite Business/Workspace account. IF YOU HAVE DONE THIS BEFORE, THERE IS NO REASON TO REPEAT IT. THIS SCRIPT MAY PRODUCE A SECOND SET OF SHARED DRIVES, AND THERE IS NO REASON FOR THIS. Retrieve the sb-gd code [copy-paste this into your terminal window] cd /opt && git clone https://github.com/chazlarson/sb_gd.git && cd sb_gd Create and activate a virtual environment: [copy-paste this into your terminal window] python3 -m venv sb_gd && source sb_gd/bin/activate If that command produces an error: If you see something like this: The virtual environment was not created successfully because ensurepip is not available. On Debian/Ubuntu systems, you need to install the python3-venv package using the following command. apt install python3.8-venv You may need to use sudo with that command. After installing the python3-venv package, recreate your virtual environment. Failing command: ['/home/YOU/sb_gd/sb_gd/bin/python3', '-Im', 'ensurepip', '--upgrade', '--default-pip'] run the suggested command with sudo : [copy-paste the command from the error into your terminal window] sudo COMMAND FROM ERROR ABOVE Then try the virtual-environment command in step 2 again. Install script requirements: [copy-paste this into your terminal window] python -m pip install -r requirements.txt Edit the config.py script: [copy-paste this into your terminal window] nano config.py Edit as indicated by <<<< below: prefix = 'aZaSjsklaj' # <<<< the prefix you generated previously group_email = \"all-sa@bing.bang\" # <<<< the group you created previously sa_file = \"/opt/sa/all/150.json\" # <<<< edit this path if required; # if you've followed all previous steps correctly # it shouldn't be required. backup_drive = \"automatic\" # <<<< edit this if desired # If this is set to \"automatic\", the backup drive # will be the last shared drive the script sees. # Enter one of the names below to use that one. # Enter anything else to disable. # backup discussed below. # `drive name`: '/directory/on/this/drive` drive_data = { # <<<< add additional drives and media paths here. Media paths must be unique per drive. 'Anime' : '/Media/Anime' , 'Books' : '/Media/Books' , 'Movies' : '/Media/Movies' , 'Movies-4K' : '/Media/Movies-4K' , 'Music' : '/Media/Music' , 'TV' : '/Media/TV' , 'TV-4K' : '/Media/TV-4K' } If you don't want to create some of those shared drives, remove the line. It's safe to go ahead and create them for simplicity later in the event you want to start using them. The list should not have a comma at the end, as shown above. Save the file with control-x, y, enter Copy your credential JSON into this directory: [copy-paste this into your terminal window] cp /opt/sa/project-creds.json client_secrets.json This is the credential file you downloaded a couple steps ago. Recall that in that step I said I would later assume you'd put it at /opt/sa/project_creds.json . Here's that assumption. If you've stored the file elsewhere, copy it from there via whatever means. It just has to end up at /opt/sb_gd/client_secrets.json . Run the sb_sd.py script: IMPORTANT : If you are running a server on your local machine that is listening for HTTP requests on port 8080, disable it before running this script. This process will send you to a localhost URL, and is expecting that this will fail so you can copy the URL. If you have a local server running on this port, you will probably see some other error instead. [copy-paste this into your terminal window] python sb_sd.py You will be asked a bunch of questions about the previous steps. If the answers are not all \"YES\", you'll need to go complete those steps. If you lie and answer YES when you haven't completed those steps, this script will fail in some way. There is no way to avoid performing all the steps. You will be asked to authenticate in the usual Google way. Follow the prompts. For the time being, due to changes in the Google OAuth process, this will try to redirect you to a localhost URL, which will fail. The URL will look like: http://localhost:8000/oauth2callback?code=4/NUMBERS_AND_STUFF&scope=https://www.googleapis.com/auth/drive Copy the ENTIRE URL and paste it at the prompt where the script is waiting. We're working on making this a bit more friendly. This script will create shared drives as listed in the config, add your group email as a manager, create mount files and ID folders on the root of each drive, build the folder structure as defined in the config, and create rclone remotes for the individual shared drives and a union rclone remote for use with Saltbox. It will fill in anything that is missing; if the shared drives are there but the media folders haven't been created, those will be created. If everything has been created but the rclone remotes are missing; those will be filled in. If you defined a \"backup_drive\" in the config [or left it as \"automatic\"], then script will zip up: All your service account JSON files Your rclone config file Your client_secret.json file Your storage.json file The log file of shared drives created and IDs It will zip those files up and upload them to BACKUP_DRIVE\\saltbox_sd_backup\\backup.zip Future runs will delete the current backup and overwrite the remote file. This of course takes the place of the BEFORE YOU DO ANYTHING ELSE admonition at the bottom of this page: You should see output similar to this [of course, you will see more than one shared drive creation; the rest are left out here for space]: [previous shared drive creations removed] ** Team Drive heilung-TV-4K created, ID: AAAAAAAAAAAAAAAAAAA ** user all-sa@XXXXXXXX.com set as organizer, ID: BBBBBBBBBBBBBBBBBBBB ** Created folder -- heilung-TV-4K Shared --, ID CCCCCC-CCCCCCCCCCCCCCCCCCCCCCCCCC ** Created file -- heilung-TV-4K Shared --, ID D-DDDDDDDDDDDD-DDDDDDDDDDDDDDDDDD ** Created folder Media, ID EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE ** Created folder TV-4K, ID FFFFFFFFFFFFFFF-FFFFFFFFFFFFFFFFF Creating rclone remote: heilung-TV-4K rclone remote definition ======== [heilung-TV-4K] type = drive scope = drive service_account_file = /opt/sa/all/150.json team_drive = AAAAAAAAAAAAAAAAAAA Creating rclone union remote 'google': rclone remote definition ======== [google] type = union upstreams = heilung-Anime:/ heilung-Books:/ heilung-Movies:/ heilung-Movies-4K:/ heilung-Music:/ heilung-TV:/ heilung-TV-4K:/ Deleting previous backup files... Preparing backup files... Creating backup archive... Uploading backup archive to heilung-TV-4K/saltbox_sd_backup... Upload Complete! All done. Note: the script uses /opt/sa/all/150.json in the rclone configuration for these remotes; that's not something you have to set or create [you'll note that it hasn't been mentioned much above]. That one is used because it's right in the middle of the SAs you just created, so it's unlikely that SA cycling in cloudplow will ever exhaust enough SAs to hit this one and possibly affect your mounts. Drive names and IDs will be written to drive_create_log . What are those directories and files for? This script creates an empty directory and a zero-byte file on the root of each shared drive. The file will be useful later on when you need \"is this disk mounted?\" flags for things like plex_autoscan or autoscan . The directory is a belt-and-suspenders convenience you can use to see if your union remote and/or mergerfs config is including everything it should. We create both a file and a dir so you will get this information whether you use rclone ls REMOTE or rclone lsd REMOTE or whatever other means: $ rclone lsd google: -1 2021-11-21 17:09:13 -1 -- aZaSjsklaj-Movies Shared -- -1 2021-11-21 17:11:50 -1 -- aZaSjsklaj-Music Shared -- -1 2021-11-21 17:12:09 -1 -- aZaSjsklaj-TV Shared -- -3 2021-11-21 17:12:11 -1 Media $ rclone ls google: 0 azasjsklaj-movies_mounted.bin 0 azasjsklaj-tv_mounted.bin 0 azasjsklaj-music_mounted.bin You're done. Deactivate the virtual env used by this script. deactivate BEFORE YOU DO ANYTHING ELSE: BACK UP /opt/sa TO YOUR LOCAL COMPUTER BACK UP /home/YOU/.config/rclone/rclone.conf TO YOUR LOCAL COMPUTER The automatic backup above would have done this for you. If for some reason you want to wipe your machine and start again OUTSIDE THE USUAL BACKUP/RESTORE you will need those files. You can just restore them rather than going through this whole process again. If you are going through the manual rclone instructions, continue with the next step IF YOU WANT TO RUN THIS AGAIN TO ADD MORE SHARED DRIVES: Go to the directory and activate the virtual environment: [copy-paste this into your terminal window] cd /opt/sb_gd && source sb_gd/bin/activate Edit the config.py script to add the additional shared drives: Run the script: [copy-paste this into your terminal window] python sb_sd.py 4. Deactivate the virtual env used by this script. deactivate","title":"Google Shared Drives"},{"location":"reference/install/","text":"Warning This is a reference discussing an aspect of the install process . If you are looking for the steps to follow to install, they are here . Install Saltbox \u00b6 Saltbox Mediabox Feederbox Core sb install saltbox sb install mediabox sb install feederbox sb install core A lot of logging information will scroll by. Eventually, it will stop, and if successful, will display something like this: PLAY RECAP ************************************************************************************ localhost : ok=713 changed=180 unreachable=0 failed=0 Note the failed=0 . If you don't see that, scroll up and the actual error should not be far away.","title":"Install"},{"location":"reference/install/#install-saltbox","text":"Saltbox Mediabox Feederbox Core sb install saltbox sb install mediabox sb install feederbox sb install core A lot of logging information will scroll by. Eventually, it will stop, and if successful, will display something like this: PLAY RECAP ************************************************************************************ localhost : ok=713 changed=180 unreachable=0 failed=0 Note the failed=0 . If you don't see that, scroll up and the actual error should not be far away.","title":"Install Saltbox"},{"location":"reference/local-storage/","text":"Local Storage \u00b6 Saltbox can be configured to forego the cloud storage requirements discussed here . This article will discuss the simplest case. There are of course a bunch of ways you could possibly do this that you may want to choose based on performance or whatever other requirements you may have, but this is the Simplest Thing That Could Possibly Work. I'm assuming you are using some local NAS for storage and running saltbox on a different machine. First, mount your NAS storage at /mnt/local/Media . Make sure that the user running the saltbox containers has full access to read and write. Then leave the rclone remote entry in the settings blank: rclone: version: latest remote: Saltbox will not do any of the remote mount setup. Once everything is installed and configured, Sonarr/Radarr/etc will move your completed downloads to /mnt/local/Media/WHATEVER , which will be on the NAS. You'll probably need to come up with a strategy for managing seeding torrents; perhaps you want to move those to the NAS as well.","title":"Using Local Storage"},{"location":"reference/local-storage/#local-storage","text":"Saltbox can be configured to forego the cloud storage requirements discussed here . This article will discuss the simplest case. There are of course a bunch of ways you could possibly do this that you may want to choose based on performance or whatever other requirements you may have, but this is the Simplest Thing That Could Possibly Work. I'm assuming you are using some local NAS for storage and running saltbox on a different machine. First, mount your NAS storage at /mnt/local/Media . Make sure that the user running the saltbox containers has full access to read and write. Then leave the rclone remote entry in the settings blank: rclone: version: latest remote: Saltbox will not do any of the remote mount setup. Once everything is installed and configured, Sonarr/Radarr/etc will move your completed downloads to /mnt/local/Media/WHATEVER , which will be on the NAS. You'll probably need to come up with a strategy for managing seeding torrents; perhaps you want to move those to the NAS as well.","title":"Local Storage"},{"location":"reference/logs/","text":"Apps \u00b6 Autoscan \u00b6 Check Status: \u00b6 sudo systemctl status autoscan.service Restart Service: \u00b6 sudo systemctl restart autoscan.service Previous Activity: \u00b6 cat /opt/autoscan/activity.log Live Log: \u00b6 tail -F /opt/autoscan/activity.log Cloudplow \u00b6 Check Status: \u00b6 sudo systemctl status cloudplow.service Previous Activity: \u00b6 cat /opt/cloudplow/cloudplow.log Older logs are named as cloudplow.log.1, cloudplow.log.2, etc. Live Log: \u00b6 tail -F /opt/cloudplow/cloudplow.log or sudo journalctl -o cat -fu cloudplow.service Sometimes, debug-level logging can be useful. To enable this, make this change in the service file and restart the service. In this file: /etc/systemd/system/cloudplow.service , change the log level to \"DEBUG\": ... WorkingDirectory=/opt/cloudplow/ ExecStart=/usr/bin/python3 /opt/cloudplow/cloudplow.py run --loglevel=DEBUG <<<<< RIGHT THERE ExecStopPost=/bin/rm -rf /opt/cloudplow/locks Restart=always ... You should only enable debug logging while you need it to track down a problem. Remote Mount \u00b6 Pick one of these. Rclone VFS \u00b6 Check Status: \u00b6 sudo systemctl status rclone_vfs.service See a live log: \u00b6 sudo journalctl -o cat -fu rclone_vfs.service Rclone Cache \u00b6 Check Status: \u00b6 sudo systemctl status rclone_cache.service See a live log: \u00b6 sudo journalctl -o cat -fu rclone_cache.service Union Mount \u00b6 Check Status: \u00b6 sudo systemctl status mergerfs.service See a live log: \u00b6 sudo journalctl -o cat -fu mergerfs.service Docker \u00b6 Find the container name: docker ps -a Live logs \u00b6 Live log (from the beginning of the log): \u00b6 docker logs --follow <container_name> Live log (from the last 10 lines of the log): \u00b6 docker logs --follow --tail 10 <container_name> Examples: \u00b6 docker logs -f plex Note: --follow = -f","title":"Viewing Logs"},{"location":"reference/logs/#apps","text":"","title":"Apps"},{"location":"reference/logs/#autoscan","text":"","title":"Autoscan"},{"location":"reference/logs/#check-status","text":"sudo systemctl status autoscan.service","title":"Check Status:"},{"location":"reference/logs/#restart-service","text":"sudo systemctl restart autoscan.service","title":"Restart Service:"},{"location":"reference/logs/#previous-activity","text":"cat /opt/autoscan/activity.log","title":"Previous Activity:"},{"location":"reference/logs/#live-log","text":"tail -F /opt/autoscan/activity.log","title":"Live Log:"},{"location":"reference/logs/#cloudplow","text":"","title":"Cloudplow"},{"location":"reference/logs/#check-status_1","text":"sudo systemctl status cloudplow.service","title":"Check Status:"},{"location":"reference/logs/#previous-activity_1","text":"cat /opt/cloudplow/cloudplow.log Older logs are named as cloudplow.log.1, cloudplow.log.2, etc.","title":"Previous Activity:"},{"location":"reference/logs/#live-log_1","text":"tail -F /opt/cloudplow/cloudplow.log or sudo journalctl -o cat -fu cloudplow.service Sometimes, debug-level logging can be useful. To enable this, make this change in the service file and restart the service. In this file: /etc/systemd/system/cloudplow.service , change the log level to \"DEBUG\": ... WorkingDirectory=/opt/cloudplow/ ExecStart=/usr/bin/python3 /opt/cloudplow/cloudplow.py run --loglevel=DEBUG <<<<< RIGHT THERE ExecStopPost=/bin/rm -rf /opt/cloudplow/locks Restart=always ... You should only enable debug logging while you need it to track down a problem.","title":"Live Log:"},{"location":"reference/logs/#remote-mount","text":"Pick one of these.","title":"Remote Mount"},{"location":"reference/logs/#rclone-vfs","text":"","title":"Rclone VFS"},{"location":"reference/logs/#check-status_2","text":"sudo systemctl status rclone_vfs.service","title":"Check Status:"},{"location":"reference/logs/#see-a-live-log","text":"sudo journalctl -o cat -fu rclone_vfs.service","title":"See a live log:"},{"location":"reference/logs/#rclone-cache","text":"","title":"Rclone Cache"},{"location":"reference/logs/#check-status_3","text":"sudo systemctl status rclone_cache.service","title":"Check Status:"},{"location":"reference/logs/#see-a-live-log_1","text":"sudo journalctl -o cat -fu rclone_cache.service","title":"See a live log:"},{"location":"reference/logs/#union-mount","text":"","title":"Union Mount"},{"location":"reference/logs/#check-status_4","text":"sudo systemctl status mergerfs.service","title":"Check Status:"},{"location":"reference/logs/#see-a-live-log_2","text":"sudo journalctl -o cat -fu mergerfs.service","title":"See a live log:"},{"location":"reference/logs/#docker","text":"Find the container name: docker ps -a","title":"Docker"},{"location":"reference/logs/#live-logs","text":"","title":"Live logs"},{"location":"reference/logs/#live-log-from-the-beginning-of-the-log","text":"docker logs --follow <container_name>","title":"Live log (from the beginning of the log):"},{"location":"reference/logs/#live-log-from-the-last-10-lines-of-the-log","text":"docker logs --follow --tail 10 <container_name>","title":"Live log (from the last 10 lines of the log):"},{"location":"reference/logs/#examples","text":"docker logs -f plex Note: --follow = -f","title":"Examples:"},{"location":"reference/multiple-instances/","text":"Multiple App Instances \u00b6 Apps that used to be supported by the \"ArrX\" system which allowed the user to define a set of instances of a given app [as opposed to installing multiple instances one at a time] are being transitioned to a new generalized, inventory-driven approach. The general idea is to move all the configuration into the /srv/git/saltbox/inventories/host_vars/localhost.yml along with other customizations . At the time of writing the roles supported are: bazarr deluge emby jellyfin lidarr nginx overseerr plex qbittorrent radarr readarr sonarr tautulli Ther is a command at the end of this page you can use to get an updated list of roles that support this method. Overview \u00b6 Define a list of all the instances of the container you want to create; if you don't want to customize them beyond that, this is all that's required. Add the list to the inventory file at /srv/git/saltbox/inventories/host_vars/localhost.yml , formatted as so: sonarr_instances : [ \"sonarr\" , \"sonarrbing\" , \"sonarrbang\" , \"sonarrboing\" ] The standard app tag will now set up all those instances. Given the example above, sb install sonarr would install: List entry Container Name Config Directory Subdomain sonarr sonarr /opt/sonarr sonarr.YOURDOMAIN.TLD sonarrbing sonarrbing /opt/sonarrbing sonarrbing.YOURDOMAIN.TLD sonarrbang sonarrbang /opt/sonarrbang sonarrbang.YOURDOMAIN.TLD sonarrboing sonarrboing /opt/sonarrboing sonarrboing.YOURDOMAIN.TLD Those names have to be unique across all of your containers, so it is suggested that you keep with the rolename+suffix pattern for these additional instances. Per-instance customization \u00b6 You can edit the following set of variables on a per instance basis in localhost.yml : Note Replacing \"instance\" with the actual instance name , of course, i.e. sonarrbing_web_subdomain, etc. instance_web_subdomain instance_web_domain instance_web_port instance_traefik_sso_middleware instance_docker_image_repo instance_docker_image_tag instance_docker_ports_defaults instance_docker_ports_ui instance_docker_ports_custom instance_themepark_enabled instance_themepark_domain instance_themepark_theme instance_docker_envs_default instance_docker_envs_custom instance_docker_commands_default instance_docker_docker_commands_custom instance_docker_volumes_default instance_docker_volumes_custom instance_docker_volumes_theme instance_docker_devices_default instance_docker_devices_custom instance_docker_hosts_default instance_docker_hosts_custom instance_docker_labels_default instance_docker_labels_custom instance_docker_networks_default instance_docker_networks_custom instance_docker_capabilities_default instance_docker_capabilities_custom instance_docker_security_opts_default instance_docker_security_opts_custom Getting an updated list of supported roles \u00b6 You can find roles that support this new method with the following command: grep -Ril \"_instances:\" /srv/git/saltbox/roles /opt/sandbox/roles | awk 'BEGIN{RS=\"roles/\"; FS=\"/defaults\"}NF>1{print $1}' | sort -u","title":"Multiple App Instances"},{"location":"reference/multiple-instances/#multiple-app-instances","text":"Apps that used to be supported by the \"ArrX\" system which allowed the user to define a set of instances of a given app [as opposed to installing multiple instances one at a time] are being transitioned to a new generalized, inventory-driven approach. The general idea is to move all the configuration into the /srv/git/saltbox/inventories/host_vars/localhost.yml along with other customizations . At the time of writing the roles supported are: bazarr deluge emby jellyfin lidarr nginx overseerr plex qbittorrent radarr readarr sonarr tautulli Ther is a command at the end of this page you can use to get an updated list of roles that support this method.","title":"Multiple App Instances"},{"location":"reference/multiple-instances/#overview","text":"Define a list of all the instances of the container you want to create; if you don't want to customize them beyond that, this is all that's required. Add the list to the inventory file at /srv/git/saltbox/inventories/host_vars/localhost.yml , formatted as so: sonarr_instances : [ \"sonarr\" , \"sonarrbing\" , \"sonarrbang\" , \"sonarrboing\" ] The standard app tag will now set up all those instances. Given the example above, sb install sonarr would install: List entry Container Name Config Directory Subdomain sonarr sonarr /opt/sonarr sonarr.YOURDOMAIN.TLD sonarrbing sonarrbing /opt/sonarrbing sonarrbing.YOURDOMAIN.TLD sonarrbang sonarrbang /opt/sonarrbang sonarrbang.YOURDOMAIN.TLD sonarrboing sonarrboing /opt/sonarrboing sonarrboing.YOURDOMAIN.TLD Those names have to be unique across all of your containers, so it is suggested that you keep with the rolename+suffix pattern for these additional instances.","title":"Overview"},{"location":"reference/multiple-instances/#per-instance-customization","text":"You can edit the following set of variables on a per instance basis in localhost.yml : Note Replacing \"instance\" with the actual instance name , of course, i.e. sonarrbing_web_subdomain, etc. instance_web_subdomain instance_web_domain instance_web_port instance_traefik_sso_middleware instance_docker_image_repo instance_docker_image_tag instance_docker_ports_defaults instance_docker_ports_ui instance_docker_ports_custom instance_themepark_enabled instance_themepark_domain instance_themepark_theme instance_docker_envs_default instance_docker_envs_custom instance_docker_commands_default instance_docker_docker_commands_custom instance_docker_volumes_default instance_docker_volumes_custom instance_docker_volumes_theme instance_docker_devices_default instance_docker_devices_custom instance_docker_hosts_default instance_docker_hosts_custom instance_docker_labels_default instance_docker_labels_custom instance_docker_networks_default instance_docker_networks_custom instance_docker_capabilities_default instance_docker_capabilities_custom instance_docker_security_opts_default instance_docker_security_opts_custom","title":"Per-instance customization"},{"location":"reference/multiple-instances/#getting-an-updated-list-of-supported-roles","text":"You can find roles that support this new method with the following command: grep -Ril \"_instances:\" /srv/git/saltbox/roles /opt/sandbox/roles | awk 'BEGIN{RS=\"roles/\"; FS=\"/defaults\"}NF>1{print $1}' | sort -u","title":"Getting an updated list of supported roles"},{"location":"reference/plex-autoscan-config/","text":"Info NOTE: plex_autoscan is no longer installed in the default Saltbox setup; it has been replaced by Autoscan. Chances are you do not need to do this setup. The default Plex Autoscan [PAS] setup does not enable Google Drive Monitoring, and the config does not match the automated shared drive setup. To utilize Google Drive Monitoring [GDM], you'll need to make a few changes to the config to account for your own shared drives. If you don't want to enable GDM, you don't need to do this. Info GDM is useful if you are planning to add content to your Google Drive directly, outside of Sonarr/Radarr. It provides a mechanism for PAS to pick up those changes and tell Plex to scan them. If all your content is coming through Sonarr/Radarr, there's no reason for GDM. If you used the scripted rclone method , there is a script in the sb_gd repo that will make the required modifications to the stock Plex Autoscan config. This script is only useful if you have used the scripted rclone method . AGAIN: This script is only useful if you have used the scripted rclone method . This script is going to load the config from the last script in that process, and if it finds that config unmodified [specifically the prefix found in the config, which you create as part of that process] it will exit with a message to that effect. There is no point in trying to circumvent this, since it is going to look for rclone remotes with specific names based on that prefix, which point at shared drives that it created with that prefix, etc. SPECIFICALLY, it's expecting: You've changed the prefix in /opt/sb_gd/config.py /opt/plex_autoscan/config/config.json exists /opt/sb_gd/client_secrets.json exists The SERVER_PATH_MAPPINGS element in /opt/plex_autoscan/config/config.json is empty It is expecting a stock plex_autoscan config file as you will have when you have completed the install. You will have to have completed sb install saltbox before using this script. Run the script cd /opt/sb_gd source sb_gd/bin/activate python sb_pas.py This is assuming you've setup the virtual environment as described in the last step of the scripted rclone method If that doesn't work, update to the latest version of the files from the repo with git pull and try again. Next, you will need to authorize Google Drive. To do so, run the following command: plex_autoscan authorize If this doesn't work for you, update saltbox and rerun the plex_autoscan role: sb update sb install plex_autoscan Visit the link shown to get the authorization code and paste that in and hit enter . Visit https://accounts.google.com/o/oauth2/v2/auth?scope = https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive & redirect_uri = urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob & response_type = code & client_id = & access_type = offline and authorize against the account you wish to use Enter authorization code: When access token retrieval is successful, you'll see this: 2018 -06-24 05 :57:58,252 - INFO - GDRIVE [ 140007964366656 ] : Requesting access token for auth code '4/AAAfPHmX9H_kMkMasfdsdfE4r8ImXI_BddbLF-eoCOPsdfasdfHBBzffKto' 2018 -06-24 05 :57:58,509 - INFO - GDRIVE [ 140007964366656 ] : Retrieved first access token! 2018 -06-24 05 :57:58,511 - INFO - AUTOSCAN [ 140007964366656 ] : Access tokens were successfully retrieved! Note: Ignore any Segmentation fault messages. Restart the Plex Autoscan service: sudo systemctl restart plex_autoscan","title":"Shared-Drive Plex Autoscan Setup"},{"location":"reference/plex-autoscan-extras/","text":"Other options for Plex Autoscan . Google Drive Monitoring \u00b6 Warning Plex Autoscan's Drive monitoring functionality no longer works for users that did not set it up prior to 28th of February. Google deprecated the authentication method used. In addition to Plex Autoscan receiving scan requests from Sonarr/Radarr/Lidarr, it can also monitor Google Drive directly for updates. When a new file is detected, it is checked against the Plex database and if this file is missing, a new scan request is sent to Plex. Note: For details on setting up Teamdrives and/or Rclone-crypted remotes, visit https://github.com/l3uddz/plex_autoscan . If you used the scripted rclone method , there is a script in the sb_gd repo that will help with this setup. To set this up: Edit the config file: nano /opt/plex_autoscan/config/config.json Under the GOOGLE section of the config, enable Google Drive monitoring and fill in your Google Drive API Client ID and Secret [Step 15 of that process]. \"ENABLED\" : true , \"CLIENT_ID\" : \"yourclientid\" , \"CLIENT_SECRET\" : \"yourclientsecret\" , So that the entire section now looks like this (any order is fine): \"GOOGLE\" : { \"ENABLED\" : true , \"CLIENT_ID\" : \"abcdefgh\" , \"CLIENT_SECRET\" : \"1234567\" , \"ALLOWED\" : { \"FILE_PATHS\" : [ \"My Drive/Media/Movies\" , \"My Drive/Media/TV\" , \"My Drive/Media/Music\" ], \"FILE_EXTENSIONS\" : true , \"FILE_EXTENSIONS_LIST\" : [ \"webm\" , \"mkv\" , \"flv\" , \"vob\" , \"ogv\" , \"ogg\" , \"drc\" , \"gif\" , \"gifv\" , \"mng\" , \"avi\" , \"mov\" , \"qt\" , \"wmv\" , \"yuv\" , \"rm\" , \"rmvb\" , \"asf\" , \"amv\" , \"mp4\" , \"m4p\" , \"m4v\" , \"mpg\" , \"mp2\" , \"mpeg\" , \"mpe\" , \"mpv\" , \"m2v\" , \"m4v\" , \"svi\" , \"3gp\" , \"3g2\" , \"mxf\" , \"roq\" , \"nsv\" , \"f4v\" , \"f4p\" , \"f4a\" , \"f4b\" , \"mp3\" , \"flac\" , \"ts\" ], \"MIME_TYPES\" : true , \"MIME_TYPES_LIST\" : [ \"video\" ] }, \"TEAMDRIVE\" : false , \"TEAMDRIVES\" : [], \"POLL_INTERVAL\" : 120 , \"SHOW_CACHE_LOGS\" : false }, Google Drive paths (e.g. \"My Drive/Media/Movies/\" ) go under SERVER_PATH_MAPPINGS and should look like this: Note: This is usually set pre-filled by default. \"SERVER_PATH_MAPPINGS\" : { \"/data/Movies/\" : [ \"/movies/\" , \"/mnt/unionfs/Media/Movies/\" , \"My Drive/Media/Movies/\" ], \"/data/TV/\" : [ \"/tv/\" , \"/mnt/unionfs/Media/TV/\" , \"My Drive/Media/TV/\" ], \"/data/Music/\" : [ \"/music/\" , \"/mnt/unionfs/Media/Music/\" , \"My Drive/Media/Music/\" ] }, Note: If you are using [[Scenario 2 Custom Library Setup|Customizing Plex Libraries#scenario-2]], you will need to tweak this section of the config. Save and Exit. Next, you will need to authorize Google Drive. To do so, run the following command: plex_autoscan authorize If this doesn't work for you, update saltbox and rerun the plex_autoscan role: sb update sb install plex_autoscan Visit the link shown to get the authorization code and paste that in and hit enter . Visit https://accounts.google.com/o/oauth2/v2/auth?scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=&access_type=offline and authorize against the account you wish to use Enter authorization code: When access token retrieval is successful, you'll see this: 2018-06-24 05:57:58,252 - INFO - GDRIVE [140007964366656]: Requesting access token for auth code '4/AAAfPHmX9H_kMkMasfdsdfE4r8ImXI_BddbLF-eoCOPsdfasdfHBBzffKto' 2018-06-24 05:57:58,509 - INFO - GDRIVE [140007964366656]: Retrieved first access token! 2018-06-24 05:57:58,511 - INFO - AUTOSCAN [140007964366656]: Access tokens were successfully retrieved! Note: Ignore any Segmentation fault messages. Restart the service: sudo systemctl restart plex_autoscan Plex Autoscan will now start monitoring Google Drive. Make Plex scan a specific file or folder \u00b6 Web app \u00b6 Setup instructions: Enable SERVER_ALLOW_MANUAL_SCAN in your /opt/plex_autoscan/config/config.json file. \"SERVER_ALLOW_MANUAL_SCAN\" : true , Visit your Plex Autoscan URL webpage. Enter in the path to scan. Note: The path can be in any form (e.g. /data/Media/... , /mnt/unionfs/Media/... , My Drive/Media/.... ). The 'Server Path Mappings' will redirect the scan to the correct location. The request will now show up under Plex Autoscan logs. HTTP \u00b6 Initiate a scan request via curl or equivalent tool: Note: The path can be in any form (e.g. /data/Media/... , /mnt/unionfs/Media/... , My Drive/Media/.... ). The 'Server Path Mappings' will redirect the scan to the correct location. Format: curl -d \"eventType=Manual&filepath=<PATH TO FILE/FOLDER>\" <YOUR PLEX AUTOSCAN URL> Examples: curl -d \"eventType=Manual&filepath=/mnt/unionfs/Media/Movies/Shut In (2016)/Shut In (2016) - Bluray-1080p.x264.DTS-GECKOS.mkv\" http://ipaddress:3468/0c1fa3c9867e48b1bb3aa055cb86 ` curl -d \"eventType=Manual&filepath=/data/Movies/Shut In (2016)/Shut In (2016) - Bluray-1080p.x264.DTS-GECKOS.mkv\" http://ipaddress:3468/0c1fa3c9867e48b1bb3aa055cb86 ` The request will now show up under Plex Autoscan logs. For more details on both options, see [[here|https://github.com/l3uddz/plex_autoscan#misc]]. CLI \u00b6 Note 1: This is only done on the box where Plex is installed. Note 2: The path used here has to be exactly what Plex uses for its library. Note 3: This method does not use Plex Autoscan, and therefore, Plex will immediately start scanning the given paths. Command \u00b6 Note: Replace <section ID> ([[Plex Library Section IDs]]) and <plex library's movie/tv show path> with yours. docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section <section ID> --directory ' \"'\" '<movie or tv show path>' \"'\" '' Examples \u00b6 Movie (Section ID 1) docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 1 --directory ' \"'\" '/data/Movies/The Predator (2018)/' \"'\" '' TV Show (Section ID 2) docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 2 --directory ' \"'\" '/data/TV/The Walking Dead/' \"'\" '' TV Show with specific season scanned (Section ID 2) docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 2 --directory ' \"'\" '/data/TV/Marvels Daredevil/Season 03/' \"'\" ''","title":"Plex Autoscan Extras"},{"location":"reference/plex-autoscan-extras/#google-drive-monitoring","text":"Warning Plex Autoscan's Drive monitoring functionality no longer works for users that did not set it up prior to 28th of February. Google deprecated the authentication method used. In addition to Plex Autoscan receiving scan requests from Sonarr/Radarr/Lidarr, it can also monitor Google Drive directly for updates. When a new file is detected, it is checked against the Plex database and if this file is missing, a new scan request is sent to Plex. Note: For details on setting up Teamdrives and/or Rclone-crypted remotes, visit https://github.com/l3uddz/plex_autoscan . If you used the scripted rclone method , there is a script in the sb_gd repo that will help with this setup. To set this up: Edit the config file: nano /opt/plex_autoscan/config/config.json Under the GOOGLE section of the config, enable Google Drive monitoring and fill in your Google Drive API Client ID and Secret [Step 15 of that process]. \"ENABLED\" : true , \"CLIENT_ID\" : \"yourclientid\" , \"CLIENT_SECRET\" : \"yourclientsecret\" , So that the entire section now looks like this (any order is fine): \"GOOGLE\" : { \"ENABLED\" : true , \"CLIENT_ID\" : \"abcdefgh\" , \"CLIENT_SECRET\" : \"1234567\" , \"ALLOWED\" : { \"FILE_PATHS\" : [ \"My Drive/Media/Movies\" , \"My Drive/Media/TV\" , \"My Drive/Media/Music\" ], \"FILE_EXTENSIONS\" : true , \"FILE_EXTENSIONS_LIST\" : [ \"webm\" , \"mkv\" , \"flv\" , \"vob\" , \"ogv\" , \"ogg\" , \"drc\" , \"gif\" , \"gifv\" , \"mng\" , \"avi\" , \"mov\" , \"qt\" , \"wmv\" , \"yuv\" , \"rm\" , \"rmvb\" , \"asf\" , \"amv\" , \"mp4\" , \"m4p\" , \"m4v\" , \"mpg\" , \"mp2\" , \"mpeg\" , \"mpe\" , \"mpv\" , \"m2v\" , \"m4v\" , \"svi\" , \"3gp\" , \"3g2\" , \"mxf\" , \"roq\" , \"nsv\" , \"f4v\" , \"f4p\" , \"f4a\" , \"f4b\" , \"mp3\" , \"flac\" , \"ts\" ], \"MIME_TYPES\" : true , \"MIME_TYPES_LIST\" : [ \"video\" ] }, \"TEAMDRIVE\" : false , \"TEAMDRIVES\" : [], \"POLL_INTERVAL\" : 120 , \"SHOW_CACHE_LOGS\" : false }, Google Drive paths (e.g. \"My Drive/Media/Movies/\" ) go under SERVER_PATH_MAPPINGS and should look like this: Note: This is usually set pre-filled by default. \"SERVER_PATH_MAPPINGS\" : { \"/data/Movies/\" : [ \"/movies/\" , \"/mnt/unionfs/Media/Movies/\" , \"My Drive/Media/Movies/\" ], \"/data/TV/\" : [ \"/tv/\" , \"/mnt/unionfs/Media/TV/\" , \"My Drive/Media/TV/\" ], \"/data/Music/\" : [ \"/music/\" , \"/mnt/unionfs/Media/Music/\" , \"My Drive/Media/Music/\" ] }, Note: If you are using [[Scenario 2 Custom Library Setup|Customizing Plex Libraries#scenario-2]], you will need to tweak this section of the config. Save and Exit. Next, you will need to authorize Google Drive. To do so, run the following command: plex_autoscan authorize If this doesn't work for you, update saltbox and rerun the plex_autoscan role: sb update sb install plex_autoscan Visit the link shown to get the authorization code and paste that in and hit enter . Visit https://accounts.google.com/o/oauth2/v2/auth?scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&client_id=&access_type=offline and authorize against the account you wish to use Enter authorization code: When access token retrieval is successful, you'll see this: 2018-06-24 05:57:58,252 - INFO - GDRIVE [140007964366656]: Requesting access token for auth code '4/AAAfPHmX9H_kMkMasfdsdfE4r8ImXI_BddbLF-eoCOPsdfasdfHBBzffKto' 2018-06-24 05:57:58,509 - INFO - GDRIVE [140007964366656]: Retrieved first access token! 2018-06-24 05:57:58,511 - INFO - AUTOSCAN [140007964366656]: Access tokens were successfully retrieved! Note: Ignore any Segmentation fault messages. Restart the service: sudo systemctl restart plex_autoscan Plex Autoscan will now start monitoring Google Drive.","title":"Google Drive Monitoring"},{"location":"reference/plex-autoscan-extras/#make-plex-scan-a-specific-file-or-folder","text":"","title":"Make Plex scan a specific file or folder"},{"location":"reference/plex-autoscan-extras/#web-app","text":"Setup instructions: Enable SERVER_ALLOW_MANUAL_SCAN in your /opt/plex_autoscan/config/config.json file. \"SERVER_ALLOW_MANUAL_SCAN\" : true , Visit your Plex Autoscan URL webpage. Enter in the path to scan. Note: The path can be in any form (e.g. /data/Media/... , /mnt/unionfs/Media/... , My Drive/Media/.... ). The 'Server Path Mappings' will redirect the scan to the correct location. The request will now show up under Plex Autoscan logs.","title":"Web app"},{"location":"reference/plex-autoscan-extras/#http","text":"Initiate a scan request via curl or equivalent tool: Note: The path can be in any form (e.g. /data/Media/... , /mnt/unionfs/Media/... , My Drive/Media/.... ). The 'Server Path Mappings' will redirect the scan to the correct location. Format: curl -d \"eventType=Manual&filepath=<PATH TO FILE/FOLDER>\" <YOUR PLEX AUTOSCAN URL> Examples: curl -d \"eventType=Manual&filepath=/mnt/unionfs/Media/Movies/Shut In (2016)/Shut In (2016) - Bluray-1080p.x264.DTS-GECKOS.mkv\" http://ipaddress:3468/0c1fa3c9867e48b1bb3aa055cb86 ` curl -d \"eventType=Manual&filepath=/data/Movies/Shut In (2016)/Shut In (2016) - Bluray-1080p.x264.DTS-GECKOS.mkv\" http://ipaddress:3468/0c1fa3c9867e48b1bb3aa055cb86 ` The request will now show up under Plex Autoscan logs. For more details on both options, see [[here|https://github.com/l3uddz/plex_autoscan#misc]].","title":"HTTP"},{"location":"reference/plex-autoscan-extras/#cli","text":"Note 1: This is only done on the box where Plex is installed. Note 2: The path used here has to be exactly what Plex uses for its library. Note 3: This method does not use Plex Autoscan, and therefore, Plex will immediately start scanning the given paths.","title":"CLI"},{"location":"reference/plex-autoscan-extras/#command","text":"Note: Replace <section ID> ([[Plex Library Section IDs]]) and <plex library's movie/tv show path> with yours. docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section <section ID> --directory ' \"'\" '<movie or tv show path>' \"'\" ''","title":"Command"},{"location":"reference/plex-autoscan-extras/#examples","text":"Movie (Section ID 1) docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 1 --directory ' \"'\" '/data/Movies/The Predator (2018)/' \"'\" '' TV Show (Section ID 2) docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 2 --directory ' \"'\" '/data/TV/The Walking Dead/' \"'\" '' TV Show with specific season scanned (Section ID 2) docker exec -u plex -i plex bash -c 'export LD_LIBRARY_PATH=/usr/lib/plexmediaserver/lib;/usr/lib/plexmediaserver/Plex\\ Media\\ Scanner --scan --refresh --section 2 --directory ' \"'\" '/data/TV/Marvels Daredevil/Season 03/' \"'\" ''","title":"Examples"},{"location":"reference/plex/","text":"Plex or Emby Account \u00b6 Plex \u00b6 You'll need a free Plex account for the setup, if you don't already have one. It's easiest if you have a Plex account even if you're not planning to use Plex . The default saltbox install assumes that you are using Plex, and without a Plex account in the settings, it will fail in various ways as it tries to install Plex and then things that depend on Plex. This can be worked around [1] , and may change in the future, but for now the simplest route is to sign up for that free account, and then disable Plex after install if you don't want to use it. 1 Basically, run the core tag instead of the saltbox tag, then run the tags for the apps you want individually. Emby \u00b6 You can use Emby in lieu of Plex [admonitions above about needing a Plex account for install still apply]. Sign up for a free Emby Connect account at https://emby.media/connect.html, if you don't already have one. You'll need to install Emby manually after the initial install is complete.","title":"Plex Account"},{"location":"reference/plex/#plex-or-emby-account","text":"","title":"Plex or Emby Account"},{"location":"reference/plex/#plex","text":"You'll need a free Plex account for the setup, if you don't already have one. It's easiest if you have a Plex account even if you're not planning to use Plex . The default saltbox install assumes that you are using Plex, and without a Plex account in the settings, it will fail in various ways as it tries to install Plex and then things that depend on Plex. This can be worked around [1] , and may change in the future, but for now the simplest route is to sign up for that free account, and then disable Plex after install if you don't want to use it. 1 Basically, run the core tag instead of the saltbox tag, then run the tags for the apps you want individually.","title":"Plex"},{"location":"reference/plex/#emby","text":"You can use Emby in lieu of Plex [admonitions above about needing a Plex account for install still apply]. Sign up for a free Emby Connect account at https://emby.media/connect.html, if you don't already have one. You'll need to install Emby manually after the initial install is complete.","title":"Emby"},{"location":"reference/plex_auth_token/","text":"Here is a way of obtaining a Plex Access Token for your Plex account. Saltbox Role \u00b6 You will need your Plex credentials filled in ~/saltbox/accounts.yml . If you already do, skip steps 2-4. Go to the Saltbox folder: cd ~/saltbox/ Open the file for editing: nano accounts.yml Fill in your Plex credentials: plex : user : pass : Save and exit: Ctrl + X Y Enter . Run the following command: sb install plex_auth_token You will be shown your Plex Access Token in the log: TASK [ plex_auth_token : Display Plex Auth Token ] *********************************************************************************** Tuesday 29 January 2019 21 :08:33 +0100 ( 0 :00:00.104 ) 0 :00:13.905 ******* ok: [ localhost ] = > { \"msg\" : \"Your Plex Auth Token is: XXXXXXXXXXXXXXXX\" }","title":"Plex Auth Token"},{"location":"reference/plex_auth_token/#saltbox-role","text":"You will need your Plex credentials filled in ~/saltbox/accounts.yml . If you already do, skip steps 2-4. Go to the Saltbox folder: cd ~/saltbox/ Open the file for editing: nano accounts.yml Fill in your Plex credentials: plex : user : pass : Save and exit: Ctrl + X Y Enter . Run the following command: sb install plex_auth_token You will be shown your Plex Access Token in the log: TASK [ plex_auth_token : Display Plex Auth Token ] *********************************************************************************** Tuesday 29 January 2019 21 :08:33 +0100 ( 0 :00:00.104 ) 0 :00:13.905 ******* ok: [ localhost ] = > { \"msg\" : \"Your Plex Auth Token is: XXXXXXXXXXXXXXXX\" }","title":"Saltbox Role"},{"location":"reference/ports/","text":"App Ports Notes Emby Jackett Lidarr Traefik 80, 443 Used by Saltbox apps when reverse-proxy is enabled. NZBGet NZBHydra NZBHydra2 Ombi Organizr Plex (main) 32400 Not needed when using reverse proxy. If 32400 needs to be open, set plex_open_main_ports: true using the inventory system. Plex (extras) TCP: 3005, 8324, 32469 UDP: 1900, 5353, 8324, 32410, 32412, 32413, 32414 Non essential for remote servers. See here . If ports need to be open, add the ones needed to plex_docker_ports_custom: [] using the inventory system. Autoscan 3030 Tautulli Portainer Radarr Resilio Sync 55555 ruTorrent 6881 (UDP), 51413 Sonarr Cloudplow Watchtower WebTools for Plex 33400, 33443","title":"Ports"},{"location":"reference/preinstall/","text":"Warning This is a reference discussing an aspect of the install process . If you are looking for the steps to follow to install, they are here . Preinstall \u00b6 Warning Make sure that you have setup the configuration correctly before proceeding. This step will create the specified user account, add it to sudoers, update the kernel, edit GRUB configuration and install Rclone and reboot the server if needed. sb install preinstall Info From this point you'll want to make sure you run commands as the user specified in the accounts.yml If your server did not need to reboot you can run su username to switch user or reconnect to SSH as the newly created user. Everything after this point will assume you are running as the user entered in accounts.yml","title":"Preinstall"},{"location":"reference/preinstall/#preinstall","text":"Warning Make sure that you have setup the configuration correctly before proceeding. This step will create the specified user account, add it to sudoers, update the kernel, edit GRUB configuration and install Rclone and reboot the server if needed. sb install preinstall Info From this point you'll want to make sure you run commands as the user specified in the accounts.yml If your server did not need to reboot you can run su username to switch user or reconnect to SSH as the newly created user. Everything after this point will assume you are running as the user entered in accounts.yml","title":"Preinstall"},{"location":"reference/rclone-auto/","text":"Automated rclone setup \u00b6 Ultimately, saltbox will have an automated rclone setup that does as much as possible for the user. This software is still under construction. Please follow the partially scripted version of this process .","title":"Rclone auto"},{"location":"reference/rclone-auto/#automated-rclone-setup","text":"Ultimately, saltbox will have an automated rclone setup that does as much as possible for the user. This software is still under construction. Please follow the partially scripted version of this process .","title":"Automated rclone setup"},{"location":"reference/rclone-manual/","text":"document.addEventListener(\"DOMContentLoaded\", function(){ var length = 10; var result = ''; var characters = 'abcdefghijklmnopqrstuvwxyz'; var charactersLength = characters.length; for ( var i = 0; i < length; i++ ) { result += characters.charAt(Math.floor(Math.random() * charactersLength)); } var paragraph = document.getElementById(\"prefix\"); paragraph.textContent = result; }); Rclone (by Nick Craig-Wood) is \"rsync for the cloud\". Basically, it is used to transfer data to or from a variety of supported cloud storage providers (eg Google Drive). Rclone is used by Cloudplow and Backup to upload media and backup Saltbox, respectively. The guide below assumes you are using Google Drive. Rclone supports many cloud provider backends, but the only one routinely used by the Saltbox team is Google Drive. This process will use various scripts to do as much of this for you as possible, but there are some things that can't be scripted easily, like steps 1 and 2 below. It also assumes you are using a Google Workspace account, since it assumes you can create shared drives. You can do some of this without a Workspace account, but the differences are not documented here. You won't be able to directly follow the steps below, and most of the scripts won't work for you. Warning IF YOU ARE HERE TO DO THIS A SECOND TIME, RETHINK THAT. IF YOU SUCCESSFULLY RAN THROUGH THIS PROCESS ONCE, YOU HAVE EVERYTHING YOU NEED TO SET SALTBOX UP AND SHOULD REUSE THOSE SHARED DRIVES, SERVICE ACCOUNTS, AND GROUP. THERE'S RARELY A REASON TO CREATE A SECOND SET. If you already have Rclone configured, you can jump directly to the relevant section . If you already have media on shared drives from your time with Cloudbox or PlexGuide or the like, you most likely DO NOT WANT TO DO THIS. This process is assuming you are starting from scratch without any of this already set up. That said, let's proceed. New Rclone Setup \u00b6 Warning YOU CANNOT SKIP STEPS HERE: EACH OF THESE STEPS IS ASSUMING YOU HAVE PERFORMED THE PREVIOUS ONE. Info IF YOU HAVE EXISTING GOOGLE DRIVES FROM ANOTHER CONTEXT [Cloudbox, PG, etc] USE THAT CONFIG [NOTABLY THE RCLONE CONFIG AND ANY SERVICE ACCOUNTS] IN A MIGRATION. Warning THIS PROCESS DOES NOT ACCOUNT FOR USING YOUR OWN TEAMDRIVES. Step 1: Verify that the Shared Drive permissions are correct on your Google account: \u00b6 Detailed instructions here Step 2: Create a new project and generate a credential file: \u00b6 Detailed instructions here Save that credential file on your server at /opt/sa/project-creds.json Step 3: Create a Google Group to hold service accounts: \u00b6 Detailed instructions here Step 4: Set up the GCloud SDK: \u00b6 Detailed instructions here Step 5: Generate a random prefix \u00b6 Your randomly-generated prefix is: 10 RANDOM CHARACTERS SHOULD APPEAR HERE That says '10 RANDOM CHARACTERS SHOULD APPEAR HERE' Apparently the Javascript didn't work or you have Javascript disabled. Try reloading the page. If that doesn't work, generate it manually: [Type this at a command prompt on your server] prefix=$(head /dev/urandom | tr -dc a-z | head -c10 ;) && echo $prefix Make a note of that prefix; you will use it in the next two steps. Info There is nothing special about that prefix; it is ten random characters. It's not tied to you literally. When you reload this page, the prefix will change. That's fine. The specific prefix doesn't matter; just pick one and use it. Why do I need this? This prefix is used for two purposes: 1. Project names need to be unique across all of Google; a random prefix helps ensure this [the error that results in this case is non-obvious]. 2. It helps these scripts unambiguously identify things that they have created, so they don't affect any projects, service accounts, or drives you may already have created. Step 6: Generate 300 service accounts \u00b6 Detailed instructions here Step 7: Create Shared Drives and related infrastructure \u00b6 Detailed instructions here Step 8: Verify that the union remote shows you the expected contents: \u00b6 Warning IF YOU HAVE SKIPPED ANY OF THE PREVIOUS STEPS THIS VALIDATION WILL NOT WORK. rclone tree google:/ This should display something like [the number and names of the files and folders may vary somewhat depending on your config]: / \u251c\u2500\u2500 -- aZaSjsklaj-Movies Shared -- \u251c\u2500\u2500 -- aZaSjsklaj-Music Shared -- \u251c\u2500\u2500 -- aZaSjsklaj-TV Shared -- \u251c\u2500\u2500 Media \u2502 \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Music \u2502 \u2514\u2500\u2500 TV \u251c\u2500\u2500 azasjsklaj-movies_mounted.bin \u251c\u2500\u2500 azasjsklaj-music_mounted.bin \u2514\u2500\u2500 azasjsklaj-tv_mounted.bin 7 directories, 3 files What if I don't see that? If you see an error like this: Failed to tree: 3 errors: aZaSjsklaj-Movies: failed to get Shared Drive info: googleapi: Error 404: Shared drive not found: BINGBANGBOING, notFound; aZaSjsklaj-Music: failed to get Shared Drive info: googleapi: Error 404: Shared drive not found: BANGBOINGBING, notFound; aZaSjsklaj-TV: failed to get Shared Drive info: googleapi: Error 404: Shared drive not found: BOINGBINGBANG, notFound The most likely cause is that something went wrong in the group setup. Perhaps all the service accounts didn't get added to the group. Repeat the last part of [this step](google-group-setup.md) where you upload the members.csv and verify that the group shows at least 300 members after you're done. You now have shared drives and union combining them; the saltbox install will merge this with your local drive and cloudplow will upload to the union mount, which will distribute media to the shared drives by path. After the saltbox install \u00b6 There is one thing you may wish to do after the saltbox install is complete. You will still be limited to the 750GB/day Google upload limit until you configure cloudplow to upload directly to the individual shared drives. Eventually this will be automated, but for now there is this guide . Go back to the install process . Existing Rclone Setup \u00b6 The default remote specified in settings.yml is google for Google Drive. If the Rclone remote in your config has the same name, then you are OK to skip this page and go on to the next. If you are using Google Drive and the Rclone remote in your config has a different name, then you will need to either: Rename your current Rclone remote to the default one (i.e. google ). Instructions for this are below. Or Edit the Rclone remote entry in settings.yml to reflect yours. If you prefer to use another cloud storage provider, you can add the name of the Rclone remote in to settings.yml . Rename Existing Rclone Remote \u00b6 To rename the Google Drive remote to google : Find and edit your Rclone configuration file. nano $(rclone config file | tail -n 1) 1. Rename the Google Drive drive remote (name between the brackets) to google . It will now look like this: [google] type = drive client_id = JOHNNY.apps.googleusercontent.com client_secret = JOEY token = {\"access_token\":\"ya30.DEEDEE-38ikRIxZvimyoxyKdse$ 1. Save the file and exit: Ctrl + X Y Enter . Copy the config file to ~/.config/rclone/rclone.conf (if it isn't there already): cp -n $(rclone config file | tail -n 1) ~/.config/rclone/rclone.conf Give it the proper ownership and permissions. Replace user and group to match yours (see here ): sudo chown user:group ~/.config/rclone/rclone.conf sudo chmod 755 ~/.config/rclone/rclone.conf","title":"Rclone [Manual]"},{"location":"reference/rclone-manual/#new-rclone-setup","text":"Warning YOU CANNOT SKIP STEPS HERE: EACH OF THESE STEPS IS ASSUMING YOU HAVE PERFORMED THE PREVIOUS ONE. Info IF YOU HAVE EXISTING GOOGLE DRIVES FROM ANOTHER CONTEXT [Cloudbox, PG, etc] USE THAT CONFIG [NOTABLY THE RCLONE CONFIG AND ANY SERVICE ACCOUNTS] IN A MIGRATION. Warning THIS PROCESS DOES NOT ACCOUNT FOR USING YOUR OWN TEAMDRIVES.","title":"New Rclone Setup"},{"location":"reference/rclone-manual/#step-1-verify-that-the-shared-drive-permissions-are-correct-on-your-google-account","text":"Detailed instructions here","title":"Step 1: Verify that the Shared Drive permissions are correct on your Google account:"},{"location":"reference/rclone-manual/#step-2-create-a-new-project-and-generate-a-credential-file","text":"Detailed instructions here Save that credential file on your server at /opt/sa/project-creds.json","title":"Step 2: Create a new project and generate a credential file:"},{"location":"reference/rclone-manual/#step-3-create-a-google-group-to-hold-service-accounts","text":"Detailed instructions here","title":"Step 3: Create a Google Group to hold service accounts:"},{"location":"reference/rclone-manual/#step-4-set-up-the-gcloud-sdk","text":"Detailed instructions here","title":"Step 4: Set up the GCloud SDK:"},{"location":"reference/rclone-manual/#step-5-generate-a-random-prefix","text":"Your randomly-generated prefix is: 10 RANDOM CHARACTERS SHOULD APPEAR HERE That says '10 RANDOM CHARACTERS SHOULD APPEAR HERE' Apparently the Javascript didn't work or you have Javascript disabled. Try reloading the page. If that doesn't work, generate it manually: [Type this at a command prompt on your server] prefix=$(head /dev/urandom | tr -dc a-z | head -c10 ;) && echo $prefix Make a note of that prefix; you will use it in the next two steps. Info There is nothing special about that prefix; it is ten random characters. It's not tied to you literally. When you reload this page, the prefix will change. That's fine. The specific prefix doesn't matter; just pick one and use it. Why do I need this? This prefix is used for two purposes: 1. Project names need to be unique across all of Google; a random prefix helps ensure this [the error that results in this case is non-obvious]. 2. It helps these scripts unambiguously identify things that they have created, so they don't affect any projects, service accounts, or drives you may already have created.","title":"Step 5: Generate a random prefix"},{"location":"reference/rclone-manual/#step-6-generate-300-service-accounts","text":"Detailed instructions here","title":"Step 6: Generate 300 service accounts"},{"location":"reference/rclone-manual/#step-7-create-shared-drives-and-related-infrastructure","text":"Detailed instructions here","title":"Step 7: Create Shared Drives and related infrastructure"},{"location":"reference/rclone-manual/#step-8-verify-that-the-union-remote-shows-you-the-expected-contents","text":"Warning IF YOU HAVE SKIPPED ANY OF THE PREVIOUS STEPS THIS VALIDATION WILL NOT WORK. rclone tree google:/ This should display something like [the number and names of the files and folders may vary somewhat depending on your config]: / \u251c\u2500\u2500 -- aZaSjsklaj-Movies Shared -- \u251c\u2500\u2500 -- aZaSjsklaj-Music Shared -- \u251c\u2500\u2500 -- aZaSjsklaj-TV Shared -- \u251c\u2500\u2500 Media \u2502 \u251c\u2500\u2500 Movies \u2502 \u251c\u2500\u2500 Music \u2502 \u2514\u2500\u2500 TV \u251c\u2500\u2500 azasjsklaj-movies_mounted.bin \u251c\u2500\u2500 azasjsklaj-music_mounted.bin \u2514\u2500\u2500 azasjsklaj-tv_mounted.bin 7 directories, 3 files What if I don't see that? If you see an error like this: Failed to tree: 3 errors: aZaSjsklaj-Movies: failed to get Shared Drive info: googleapi: Error 404: Shared drive not found: BINGBANGBOING, notFound; aZaSjsklaj-Music: failed to get Shared Drive info: googleapi: Error 404: Shared drive not found: BANGBOINGBING, notFound; aZaSjsklaj-TV: failed to get Shared Drive info: googleapi: Error 404: Shared drive not found: BOINGBINGBANG, notFound The most likely cause is that something went wrong in the group setup. Perhaps all the service accounts didn't get added to the group. Repeat the last part of [this step](google-group-setup.md) where you upload the members.csv and verify that the group shows at least 300 members after you're done. You now have shared drives and union combining them; the saltbox install will merge this with your local drive and cloudplow will upload to the union mount, which will distribute media to the shared drives by path.","title":"Step 8: Verify that the union remote shows you the expected contents:"},{"location":"reference/rclone-manual/#after-the-saltbox-install","text":"There is one thing you may wish to do after the saltbox install is complete. You will still be limited to the 750GB/day Google upload limit until you configure cloudplow to upload directly to the individual shared drives. Eventually this will be automated, but for now there is this guide . Go back to the install process .","title":"After the saltbox install"},{"location":"reference/rclone-manual/#existing-rclone-setup","text":"The default remote specified in settings.yml is google for Google Drive. If the Rclone remote in your config has the same name, then you are OK to skip this page and go on to the next. If you are using Google Drive and the Rclone remote in your config has a different name, then you will need to either: Rename your current Rclone remote to the default one (i.e. google ). Instructions for this are below. Or Edit the Rclone remote entry in settings.yml to reflect yours. If you prefer to use another cloud storage provider, you can add the name of the Rclone remote in to settings.yml .","title":"Existing Rclone Setup"},{"location":"reference/rclone-manual/#rename-existing-rclone-remote","text":"To rename the Google Drive remote to google : Find and edit your Rclone configuration file. nano $(rclone config file | tail -n 1) 1. Rename the Google Drive drive remote (name between the brackets) to google . It will now look like this: [google] type = drive client_id = JOHNNY.apps.googleusercontent.com client_secret = JOEY token = {\"access_token\":\"ya30.DEEDEE-38ikRIxZvimyoxyKdse$ 1. Save the file and exit: Ctrl + X Y Enter . Copy the config file to ~/.config/rclone/rclone.conf (if it isn't there already): cp -n $(rclone config file | tail -n 1) ~/.config/rclone/rclone.conf Give it the proper ownership and permissions. Replace user and group to match yours (see here ): sudo chown user:group ~/.config/rclone/rclone.conf sudo chmod 755 ~/.config/rclone/rclone.conf","title":"Rename Existing Rclone Remote"},{"location":"reference/rclone/","text":"This will take you through the configuration of Rclone from a standing start with nothing set up already. If you're migrating from Cloudbox you probably want the Cloudbox migration instructions If you have an existing rclone setup from Cloudbox or PTS or something else you should NOT go through this process. You should reuse that existing setup. There is nothing saltbox specific about this setup aside from the various paths, and you do not need new projects or service accounts or shared drives to address that. If you are reinstalling saltbox there is no reason to do this again provided you have run a Saltbox backup or followed the instructions the first time you did this and have backed up the important files. Overview of what this process is going to do This process is going to perform, with your assistance, these tasks: Note that this is a general overview of the things that are going to happen, not a list of instructions for you to follow. 1. Create a Google project 2. Create a Google group 3. Create 300 service accounts 4. Add those 300 service accounts to the Google group that was just created. 5. Create 3 new shared drives. 6. Add your Google Group to each of those drives as a \"Manager\" 7. Create rclone remotes pointing to each of those shared drives, authenticated using one of those service files. 8. Create a `union` rclone remote called \"google\", with the components set to the shared drive remotes you just created. Instructions: \u00b6 Start here .","title":"Rclone"},{"location":"reference/rclone/#instructions","text":"Start here .","title":"Instructions:"},{"location":"reference/safire/","text":"Saltbox defaults to using service accounts for uploading to multiple teamdrives to allow for future growth. To make the setup more straightforward, this guide will leverage safire to generate as much infrastructure as possible. This will set up three Shared Drives and set up all the infrastructure you need for Saltbox to use them. If you're here, you probably want to go here instead. safire has been acting inconsistently. This script is a work in progress; it probably has rough edges. \u00b6 Assumptions and defaults: \u00b6 You have rclone installed You are running python 3.8 and have run sudo apt install python3.8-venv -y Probably other python3 works, the assumption is that the script can create a venv The script will generate a random prefix and use this for the shared drives, service accounts, and projects. Default is to generate three shared drives: Drive media dir [PREFIX]_Movies /Media/Movies [PREFIX]_Music /Media/Music [PREFIX]_TV /Media/TV This can be modified with a config file. The first half of the script will display the details. Default is to generate three projects with 100 service accounts each. This can be modified at the beginning of the script itself. There are a couple other user settings at the beginning of the script. Google Project and Group Setup \u00b6 There are two pieces that can't be scripted. You will need to create a new project and generate a credential file: Instructions here You will need to create a Google Group to hold service accounts: Instructions here safire Setup: \u00b6 SSH into your server, then copy-paste these commands one by one: curl -fLvO https://raw.githubusercontent.com/chazlarson/sb_gd/main/sb_gd.sh chmod +x sb_gd.sh ./sb_gd.sh Copy the credential JSON you downloaded earlier to ~/safire/creds/creds.json on your server You can do this in a variety of ways; if you are running a linux-like system locally scp /LOCAL/PATH/TO/creds.json USER@DOMAIN.TLD:~/safire/creds/creds.json For example: scp /Users/nacl/Downloads/safire-credentials.json nacl@111.222.333.444:~/safire/creds/creds.json Run the script again. You will be prompted to authenticate to google and copy-paste a token [this will happen twice]. If you didn't enter your google group email address into the script, you will be asked for it. ./sb_gd.sh You should now have three new shared drives ready for use with Saltbox.","title":"SAFire"},{"location":"reference/safire/#this-script-is-a-work-in-progress-it-probably-has-rough-edges","text":"","title":"This script is a work in progress; it probably has rough edges."},{"location":"reference/safire/#assumptions-and-defaults","text":"You have rclone installed You are running python 3.8 and have run sudo apt install python3.8-venv -y Probably other python3 works, the assumption is that the script can create a venv The script will generate a random prefix and use this for the shared drives, service accounts, and projects. Default is to generate three shared drives: Drive media dir [PREFIX]_Movies /Media/Movies [PREFIX]_Music /Media/Music [PREFIX]_TV /Media/TV This can be modified with a config file. The first half of the script will display the details. Default is to generate three projects with 100 service accounts each. This can be modified at the beginning of the script itself. There are a couple other user settings at the beginning of the script.","title":"Assumptions and defaults:"},{"location":"reference/safire/#google-project-and-group-setup","text":"There are two pieces that can't be scripted. You will need to create a new project and generate a credential file: Instructions here You will need to create a Google Group to hold service accounts: Instructions here","title":"Google Project and Group Setup"},{"location":"reference/safire/#safire-setup","text":"SSH into your server, then copy-paste these commands one by one: curl -fLvO https://raw.githubusercontent.com/chazlarson/sb_gd/main/sb_gd.sh chmod +x sb_gd.sh ./sb_gd.sh Copy the credential JSON you downloaded earlier to ~/safire/creds/creds.json on your server You can do this in a variety of ways; if you are running a linux-like system locally scp /LOCAL/PATH/TO/creds.json USER@DOMAIN.TLD:~/safire/creds/creds.json For example: scp /Users/nacl/Downloads/safire-credentials.json nacl@111.222.333.444:~/safire/creds/creds.json Run the script again. You will be prompted to authenticate to google and copy-paste a token [this will happen twice]. If you didn't enter your google group email address into the script, you will be asked for it. ./sb_gd.sh You should now have three new shared drives ready for use with Saltbox.","title":"safire Setup:"},{"location":"reference/saltbox-tools/","text":"Overview Details Overview \u00b6 Saltbox comes with some useful command line tools and scripts. Some are meant to be utilized by Saltbox, automatically (e.g. ncdu, torrentcleanup.py, etc), and some are for your usage. Name Type Description Invoked by Homepage htop application Interactive process viewer for Unix. htop http://hisham.hm/htop/ ctop application Top-like interface for container metrics. ctop https://ctop.sh/ iotop application Top like utility for disk I/O. iotop http://guichaz.free.fr/iotop/ nload application Monitor network traffic and bandwidth usage in real time. nload http://www.roland-riegel.de/nload/ vnstat application Network traffic monitor for that keeps a log of network traffic for the selected interface(s). vnstat http://humdi.net/vnstat/ nethogs application Small 'net top' tool that groups bandwidth by process. nethogs https://github.com/raboof/nethogs ngrok application Secure tunnels to localhost. ngrok https://ngrok.com/ ufw application UFW, or Uncomplicated Firewall, is a front-end to iptables. ufw https://launchpad.net/ufw speedtest-cli application Command line interface for testing internet bandwidth using speedtest.net speedtest https://github.com/sivel/speedtest-cli Rclone application \"rsync for cloud storage\". rclone https://rclone.org/ tree application Displays an indented directory tree, in color. tree http://mama.indstate.edu/users/ice/tree/ ncdu application Disk usage analyzer with an ncurses interface. ncdu https://dev.yorhel.nl/ncdu GNU Midnight Commander application A visual file manager. mc https://midnight-commander.org/ hostess application Tool for tweaking local DNS by managing your /etc/hosts file. hostess https://github.com/cbednarski/hostess logrotate application Utility is designed to simplify the administration of log files. logrotate https://fedorahosted.org/logrotate/ frontail application Node.js application for streaming logs to the browser, like a tail -F with a UI. frontail https://github.com/mthenw/frontail certbot application Fetches and revokes certificates from Let\u2019s Encrypt. Used by revoke_certs.sh. certbot https://certbot.eff.org/ TorrentCleanup.py script Cleans up extracted media files in Rutorrent's downloads folder. Sonarr / Radarr Credit: https://github.com/l3uddz Details \u00b6 -Work in progress- Torrent Cleanup Script \u00b6 TorrentCleanup.py has been explained in the Sonarr section, but in a nutshell, sonarr/radarr launches this script if you set it up, and it will scan the folder of the file that was imported, if rars exist, delete the file that was imported. this is useful for torrent sites that allow rars, as it will only leave you with the imported file (before its uploaded to google) and just the rars for seeding, instead of also leaving the extracted file. NCDU \u00b6 ( cd / && sudo ncdu -x ) Frontail - view logs over http \u00b6 [[frontail|https://github.com/mthenw/frontail]] is a Node.js application for streaming logs to the browser (basically a tail -F with an UI). This is useful in cases you need help and need to show someone from slack support channels your logs. You can mask your IP using ngrok (more on that later). Steps to do so are as follows: Base command \u00b6 frontail --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed <path of log file> & You may change the user and password. The & at the end sends it to the background. You can now see this log at http://serveripaddress:9001. To specify another port, just add: --port <port> To create an alias for this: \u00b6 Determine your default shell in settings.yml For your default shell, add shell_<shell>_<shell>rc_block_custom: to your Inventory file: Example for Bash (default): shell_bash_bashrc_block_custom: | ## Custom frontail alias alias ftail='frontail --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed ' Example for ZSH: shell_zsh_zshrc_block_custom: | ## Custom frontail alias alias ftail='frontail --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed ' Run sb install shell You can now use: ftail --port <port number> <log path> & To quit the frontail \u00b6 pkill -f frontail Examples: \u00b6 Plex Autoscan \u00b6 frontail --port 9001 --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed /opt/plex_autoscan/plex_autoscan.log & or via alias... ftail --port 9001 /opt/plex_autoscan/plex_autoscan.log & or via docker... docker run --restart=always --name \"frontail_plex_autoscan\" -d -p 9001:9001 -v /opt/plex_autoscan:/logs -v /opt/scripts/frontail/frontail_custom_preset.json:/preset/custom.json mthenw/frontail --ui-highlight --ui-highlight-preset /preset/custom.json --theme dark --user <user> --password <pass> /logs/plex_autoscan.log Log: http://serveripaddress:9001 Cloudplow log \u00b6 frontail --ui-highlight --port 9002 --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed /opt/cloudplow/cloudplow.log & Log: http://serveripaddress:9002 or via alias... ftail --port 9002 /opt/cloudplow/cloudplow.log & or via docker... docker run --restart=always --name \"frontail_cloudplow\" -d -p 9002:9001 -v /opt/cloudplow:/logs -v /opt/scripts/frontail/frontail_custom_preset.json:/preset/custom.json mthenw/frontail --ui-highlight --ui-highlight-preset /preset/custom.json --theme dark --user <user> --password <pass> /logs/cloudplow.log Log: http://serveripaddress:9002 Use ngrok to hide your IP \u00b6 If you want to share your log with someone (forums, slack, etc), but don't want to reveal your IP address, you can use ngrok to hide your IP address. ngrok http <port> It will show you something like this... You can now use the http://XXXXXXXX.ngrok.io address to share your log. This will be active as long as ngrok is running. To cancel, ctrl-c .","title":"Saltbox Tools"},{"location":"reference/saltbox-tools/#overview","text":"Saltbox comes with some useful command line tools and scripts. Some are meant to be utilized by Saltbox, automatically (e.g. ncdu, torrentcleanup.py, etc), and some are for your usage. Name Type Description Invoked by Homepage htop application Interactive process viewer for Unix. htop http://hisham.hm/htop/ ctop application Top-like interface for container metrics. ctop https://ctop.sh/ iotop application Top like utility for disk I/O. iotop http://guichaz.free.fr/iotop/ nload application Monitor network traffic and bandwidth usage in real time. nload http://www.roland-riegel.de/nload/ vnstat application Network traffic monitor for that keeps a log of network traffic for the selected interface(s). vnstat http://humdi.net/vnstat/ nethogs application Small 'net top' tool that groups bandwidth by process. nethogs https://github.com/raboof/nethogs ngrok application Secure tunnels to localhost. ngrok https://ngrok.com/ ufw application UFW, or Uncomplicated Firewall, is a front-end to iptables. ufw https://launchpad.net/ufw speedtest-cli application Command line interface for testing internet bandwidth using speedtest.net speedtest https://github.com/sivel/speedtest-cli Rclone application \"rsync for cloud storage\". rclone https://rclone.org/ tree application Displays an indented directory tree, in color. tree http://mama.indstate.edu/users/ice/tree/ ncdu application Disk usage analyzer with an ncurses interface. ncdu https://dev.yorhel.nl/ncdu GNU Midnight Commander application A visual file manager. mc https://midnight-commander.org/ hostess application Tool for tweaking local DNS by managing your /etc/hosts file. hostess https://github.com/cbednarski/hostess logrotate application Utility is designed to simplify the administration of log files. logrotate https://fedorahosted.org/logrotate/ frontail application Node.js application for streaming logs to the browser, like a tail -F with a UI. frontail https://github.com/mthenw/frontail certbot application Fetches and revokes certificates from Let\u2019s Encrypt. Used by revoke_certs.sh. certbot https://certbot.eff.org/ TorrentCleanup.py script Cleans up extracted media files in Rutorrent's downloads folder. Sonarr / Radarr Credit: https://github.com/l3uddz","title":"Overview"},{"location":"reference/saltbox-tools/#details","text":"-Work in progress-","title":"Details"},{"location":"reference/saltbox-tools/#torrent-cleanup-script","text":"TorrentCleanup.py has been explained in the Sonarr section, but in a nutshell, sonarr/radarr launches this script if you set it up, and it will scan the folder of the file that was imported, if rars exist, delete the file that was imported. this is useful for torrent sites that allow rars, as it will only leave you with the imported file (before its uploaded to google) and just the rars for seeding, instead of also leaving the extracted file.","title":"Torrent Cleanup Script"},{"location":"reference/saltbox-tools/#ncdu","text":"( cd / && sudo ncdu -x )","title":"NCDU"},{"location":"reference/saltbox-tools/#frontail-view-logs-over-http","text":"[[frontail|https://github.com/mthenw/frontail]] is a Node.js application for streaming logs to the browser (basically a tail -F with an UI). This is useful in cases you need help and need to show someone from slack support channels your logs. You can mask your IP using ngrok (more on that later). Steps to do so are as follows:","title":"Frontail - view logs over http"},{"location":"reference/saltbox-tools/#base-command","text":"frontail --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed <path of log file> & You may change the user and password. The & at the end sends it to the background. You can now see this log at http://serveripaddress:9001. To specify another port, just add: --port <port>","title":"Base command"},{"location":"reference/saltbox-tools/#to-create-an-alias-for-this","text":"Determine your default shell in settings.yml For your default shell, add shell_<shell>_<shell>rc_block_custom: to your Inventory file: Example for Bash (default): shell_bash_bashrc_block_custom: | ## Custom frontail alias alias ftail='frontail --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed ' Example for ZSH: shell_zsh_zshrc_block_custom: | ## Custom frontail alias alias ftail='frontail --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed ' Run sb install shell You can now use: ftail --port <port number> <log path> &","title":"To create an alias for this:"},{"location":"reference/saltbox-tools/#to-quit-the-frontail","text":"pkill -f frontail","title":"To quit the frontail"},{"location":"reference/saltbox-tools/#examples","text":"","title":"Examples:"},{"location":"reference/saltbox-tools/#plex-autoscan","text":"frontail --port 9001 --ui-highlight --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed /opt/plex_autoscan/plex_autoscan.log & or via alias... ftail --port 9001 /opt/plex_autoscan/plex_autoscan.log & or via docker... docker run --restart=always --name \"frontail_plex_autoscan\" -d -p 9001:9001 -v /opt/plex_autoscan:/logs -v /opt/scripts/frontail/frontail_custom_preset.json:/preset/custom.json mthenw/frontail --ui-highlight --ui-highlight-preset /preset/custom.json --theme dark --user <user> --password <pass> /logs/plex_autoscan.log Log: http://serveripaddress:9001","title":"Plex Autoscan"},{"location":"reference/saltbox-tools/#cloudplow-log","text":"frontail --ui-highlight --port 9002 --ui-highlight-preset /opt/scripts/frontail/frontail_custom_preset.json --theme dark --user seed --password seed /opt/cloudplow/cloudplow.log & Log: http://serveripaddress:9002 or via alias... ftail --port 9002 /opt/cloudplow/cloudplow.log & or via docker... docker run --restart=always --name \"frontail_cloudplow\" -d -p 9002:9001 -v /opt/cloudplow:/logs -v /opt/scripts/frontail/frontail_custom_preset.json:/preset/custom.json mthenw/frontail --ui-highlight --ui-highlight-preset /preset/custom.json --theme dark --user <user> --password <pass> /logs/cloudplow.log Log: http://serveripaddress:9002","title":"Cloudplow log"},{"location":"reference/saltbox-tools/#use-ngrok-to-hide-your-ip","text":"If you want to share your log with someone (forums, slack, etc), but don't want to reveal your IP address, you can use ngrok to hide your IP address. ngrok http <port> It will show you something like this... You can now use the http://XXXXXXXX.ngrok.io address to share your log. This will be active as long as ngrok is running. To cancel, ctrl-c .","title":"Use ngrok to hide your IP"},{"location":"reference/saltbox-vs-cloudbox/","text":"Saltbox vs. Cloudbox \u00b6 Saltbox started out as a branch in Cloudbox while salty was maintaining Cloudbox for about a year and a half so there is a massive carryover from the develop branch of Cloudbox. The main reason it became its own project was due to Cloudbox project owners not feeling comfortable handing over the reins despite them more or less having become disinterested in maintaining their project. There isn't a maintained list of differences as the improvements have happened slowly over time as people request features or functionality changes which have been added when it made sense. In terms of functionality the high points are Validated Ubuntu 20.04 and 22.04 support (Saltbox will try to support newer releases quicker than Cloudbox has) which is useful in terms of hardware acceleration support with newer CPUs. Support for IPv6 (has seen limited testing so far though) within the docker container network using NAT since we still want to keep things behind the reverse proxy. Inventory system for simpler, upgrade-protected customization Authelia single sign-on Choice of SSL provider [Let's Encrypt or ZeroSSL] ability to use a subdomain rather than a TLD ( rolename.subdomain.domain.tld rather than rolename.domain.tld ) support for running without a domain in local installs Generalized support for multiple app instances [replacement for the \"ArrX\" system] Ongoing maintenance and active development In development is an automated system to set up shared drives and service accounts for the user [for Cloudbox users, this is the \"tip 44\" setup].","title":"Saltbox vs Cloudbox"},{"location":"reference/saltbox-vs-cloudbox/#saltbox-vs-cloudbox","text":"Saltbox started out as a branch in Cloudbox while salty was maintaining Cloudbox for about a year and a half so there is a massive carryover from the develop branch of Cloudbox. The main reason it became its own project was due to Cloudbox project owners not feeling comfortable handing over the reins despite them more or less having become disinterested in maintaining their project. There isn't a maintained list of differences as the improvements have happened slowly over time as people request features or functionality changes which have been added when it made sense. In terms of functionality the high points are Validated Ubuntu 20.04 and 22.04 support (Saltbox will try to support newer releases quicker than Cloudbox has) which is useful in terms of hardware acceleration support with newer CPUs. Support for IPv6 (has seen limited testing so far though) within the docker container network using NAT since we still want to keep things behind the reverse proxy. Inventory system for simpler, upgrade-protected customization Authelia single sign-on Choice of SSL provider [Let's Encrypt or ZeroSSL] ability to use a subdomain rather than a TLD ( rolename.subdomain.domain.tld rather than rolename.domain.tld ) support for running without a domain in local installs Generalized support for multiple app instances [replacement for the \"ArrX\" system] Ongoing maintenance and active development In development is an automated system to set up shared drives and service accounts for the user [for Cloudbox users, this is the \"tip 44\" setup].","title":"Saltbox vs. Cloudbox"},{"location":"reference/server/","text":"Server \u00b6 Getting a Server \u00b6 About the requirements: You will need a dedicated server, from a server provider (e.g. Hetzner, kimsufi, OVH, etc), installed with Ubuntu Server 20.04 or 22.04 . The install assumes that this is a fresh setup without anything else installed. If your server has things like Docker preinstalled, chances are the installer will fail with a non-obvious error. Typically this server is remote to you; you can install on a home server, keeping in mind some home server considerations Best results are seen with an actual dedicated server, not a VPS like those available from Linode, Vultr, or the like. Linodes, Vultr \"Cloud Compute\", Hetzner \"Cloud Servers\", and probably others like them, in particular, are known to not work in at least one significant way; NZBGet reports 0 available disk space while Sonarr, Radarr, and tools like df and du report disk space as expected. A commonly-asked question is \"can I run saltbox on this server?\" You will need root access to install Saltbox. The server should be a completely fresh OS install. Do not try to install any dependencies on your own, Saltbox will do that for you. Saltbox only supports x64 (i.e. Intel or AMD 64) machines. ARM based hardware [such as the Raspberry Pi] is not supported. Get a server with at least 100GB+ of hard disk space. Even though media is uploaded to the cloud, there is still a need local storage for things like app data and backups. Practically, you should have more like 500GB of space available at a minimum . Cloudplow's default folder size threshold, to upload media to the cloud, is set at 200GB. If you want to lower that, you can find details here If you are planning to use Usenet, SSD should be considered required, and NVME highly recommended. Usenet is extremely disk I/O intensive. If you are planning to use torrents, you should have much more disk space than that available for seeding. Your seeding torrents will not be moved to your cloud storage; they will consume local disk space as long as they are seeding. If you are installing as a Feederbox/Mediabox setup rather than the all-in-one Saltbox, the disk requirements change a bit. Downloading drives disk requirements on the Feederbox [as discussed above] and primarily the Plex/Emby metadata drives the disk requirements on the Mediabox. Depending on the size of your library, that metadata can be quite large. Home Server considerations \u00b6 If you are setting this up on a home server, verify, before installing Saltbox : Make sure your ISP doesn't block ports 80 and 443 [if your ISP blocks these ports, it won't work.] Make sure that your router supports hairpin NAT [if this isn't supported, you won't be able to access apps via subdomain from inside your network] Open the relevant ports (eg 80 , 443 , etc) in your router /firewall and forward them to the IP of the box on which you want to install Saltbox, before installing Saltbox . Point your domain at your home IP and configure some dynamic DNS software to keep it updated. Saltbox has a dynamic dns client available [it's not installed by default], but there are many ways to set this up. Make sure that DNS has propagated and your domain returns your home IP via ping or something like it, before installing Saltbox . Review the notes about local storage if you're not planning to use cloud storage. Tips \u00b6 Ubuntu 20.04 \u00b6 If you get an option like below, select choose ubuntu-2004-focal-64-minimal . Install OpenSSH server if asked. Partitioning: \u00b6 If you have multiple hard drives on the server (eg. 2 x 4 TB), put them in RAID 0 to maximize space and speed (you don't need redundancy as you can schedule backups of Saltbox). Set all available space to / (remove /home and /data partitions). Leave ample space in /boot (e.g. 2+ GB). putting the /opt directory on a btrfs partition can dramatically reduce the amount of time your containers are down during backup. Examples: IMPORTANT : Note that these examples are just that, examples , and may not reflect currently-available OS versions or the current state of the UI. They were accurate at the time of capture, but things change that are outside saltbox' control. You will need to review for accuracy and possibly adapt them to your specific situation. You're partitioning the disk of your remote server; you generally shouldn't trust that to copy-pasting some text from a web page. Online.net OVH Hetzner What to do with this \"installimage\" Hetzner installimage # Hetzner Online GmbH - installimage # # This file contains the configuration used to install this # system via installimage script. Comments have been removed. # # More information about the installimage script and # automatic installations can be found in our wiki: # # http://wiki.hetzner.de/index.php/Installimage # DRIVE1 /dev/nvme0n1 DRIVE2 /dev/nvme1n1 SWRAID 1 SWRAIDLEVEL 0 HOSTNAME sb.domain.com PART /boot ext4 2G PART lvm vg0 all LV vg0 swap swap swap 8G LV vg0 root / ext4 all IMAGE /root/.oldroot/nfs/install/../images/Ubuntu-2004-focal-64-minimal.tar.gz Hetzner installimage (with a separate 250G partition for /opt utilizing BTRFS for snapshot backups) # Hetzner Online GmbH - installimage # # This file contains the configuration used to install this # system via installimage script. Comments have been removed. # # More information about the installimage script and # automatic installations can be found in our wiki: # # http://wiki.hetzner.de/index.php/Installimage # DRIVE1 /dev/nvme0n1 DRIVE2 /dev/nvme1n1 SWRAID 1 SWRAIDLEVEL 0 HOSTNAME sb.domain.com PART /boot ext4 2G PART lvm vg0 all LV vg0 swap swap swap 8G LV vg0 opt /opt btrfs 250G LV vg0 root / ext4 all IMAGE /root/.oldroot/nfs/install/../images/Ubuntu-2004-focal-64-minimal.tar.gz","title":"Server"},{"location":"reference/server/#server","text":"","title":"Server"},{"location":"reference/server/#getting-a-server","text":"About the requirements: You will need a dedicated server, from a server provider (e.g. Hetzner, kimsufi, OVH, etc), installed with Ubuntu Server 20.04 or 22.04 . The install assumes that this is a fresh setup without anything else installed. If your server has things like Docker preinstalled, chances are the installer will fail with a non-obvious error. Typically this server is remote to you; you can install on a home server, keeping in mind some home server considerations Best results are seen with an actual dedicated server, not a VPS like those available from Linode, Vultr, or the like. Linodes, Vultr \"Cloud Compute\", Hetzner \"Cloud Servers\", and probably others like them, in particular, are known to not work in at least one significant way; NZBGet reports 0 available disk space while Sonarr, Radarr, and tools like df and du report disk space as expected. A commonly-asked question is \"can I run saltbox on this server?\" You will need root access to install Saltbox. The server should be a completely fresh OS install. Do not try to install any dependencies on your own, Saltbox will do that for you. Saltbox only supports x64 (i.e. Intel or AMD 64) machines. ARM based hardware [such as the Raspberry Pi] is not supported. Get a server with at least 100GB+ of hard disk space. Even though media is uploaded to the cloud, there is still a need local storage for things like app data and backups. Practically, you should have more like 500GB of space available at a minimum . Cloudplow's default folder size threshold, to upload media to the cloud, is set at 200GB. If you want to lower that, you can find details here If you are planning to use Usenet, SSD should be considered required, and NVME highly recommended. Usenet is extremely disk I/O intensive. If you are planning to use torrents, you should have much more disk space than that available for seeding. Your seeding torrents will not be moved to your cloud storage; they will consume local disk space as long as they are seeding. If you are installing as a Feederbox/Mediabox setup rather than the all-in-one Saltbox, the disk requirements change a bit. Downloading drives disk requirements on the Feederbox [as discussed above] and primarily the Plex/Emby metadata drives the disk requirements on the Mediabox. Depending on the size of your library, that metadata can be quite large.","title":"Getting a Server"},{"location":"reference/server/#home-server-considerations","text":"If you are setting this up on a home server, verify, before installing Saltbox : Make sure your ISP doesn't block ports 80 and 443 [if your ISP blocks these ports, it won't work.] Make sure that your router supports hairpin NAT [if this isn't supported, you won't be able to access apps via subdomain from inside your network] Open the relevant ports (eg 80 , 443 , etc) in your router /firewall and forward them to the IP of the box on which you want to install Saltbox, before installing Saltbox . Point your domain at your home IP and configure some dynamic DNS software to keep it updated. Saltbox has a dynamic dns client available [it's not installed by default], but there are many ways to set this up. Make sure that DNS has propagated and your domain returns your home IP via ping or something like it, before installing Saltbox . Review the notes about local storage if you're not planning to use cloud storage.","title":"Home Server considerations"},{"location":"reference/server/#tips","text":"","title":"Tips"},{"location":"reference/server/#ubuntu-2004","text":"If you get an option like below, select choose ubuntu-2004-focal-64-minimal . Install OpenSSH server if asked.","title":"Ubuntu 20.04"},{"location":"reference/server/#partitioning","text":"If you have multiple hard drives on the server (eg. 2 x 4 TB), put them in RAID 0 to maximize space and speed (you don't need redundancy as you can schedule backups of Saltbox). Set all available space to / (remove /home and /data partitions). Leave ample space in /boot (e.g. 2+ GB). putting the /opt directory on a btrfs partition can dramatically reduce the amount of time your containers are down during backup. Examples: IMPORTANT : Note that these examples are just that, examples , and may not reflect currently-available OS versions or the current state of the UI. They were accurate at the time of capture, but things change that are outside saltbox' control. You will need to review for accuracy and possibly adapt them to your specific situation. You're partitioning the disk of your remote server; you generally shouldn't trust that to copy-pasting some text from a web page. Online.net OVH Hetzner What to do with this \"installimage\" Hetzner installimage # Hetzner Online GmbH - installimage # # This file contains the configuration used to install this # system via installimage script. Comments have been removed. # # More information about the installimage script and # automatic installations can be found in our wiki: # # http://wiki.hetzner.de/index.php/Installimage # DRIVE1 /dev/nvme0n1 DRIVE2 /dev/nvme1n1 SWRAID 1 SWRAIDLEVEL 0 HOSTNAME sb.domain.com PART /boot ext4 2G PART lvm vg0 all LV vg0 swap swap swap 8G LV vg0 root / ext4 all IMAGE /root/.oldroot/nfs/install/../images/Ubuntu-2004-focal-64-minimal.tar.gz Hetzner installimage (with a separate 250G partition for /opt utilizing BTRFS for snapshot backups) # Hetzner Online GmbH - installimage # # This file contains the configuration used to install this # system via installimage script. Comments have been removed. # # More information about the installimage script and # automatic installations can be found in our wiki: # # http://wiki.hetzner.de/index.php/Installimage # DRIVE1 /dev/nvme0n1 DRIVE2 /dev/nvme1n1 SWRAID 1 SWRAIDLEVEL 0 HOSTNAME sb.domain.com PART /boot ext4 2G PART lvm vg0 all LV vg0 swap swap swap 8G LV vg0 opt /opt btrfs 250G LV vg0 root / ext4 all IMAGE /root/.oldroot/nfs/install/../images/Ubuntu-2004-focal-64-minimal.tar.gz","title":"Partitioning:"},{"location":"reference/subdomain/","text":"Setup instructions are separated based on the DNS Provider you use and the type of install. Cloudflare \u00b6 Saltbox will automatically add the subdomain on Cloudflare and point it to the correct IP address. Note 1: Make sure the Cloudflare API Key is filled in settings.yml and the e-mail address matches the one you have in your Cloudflare account profile. Note 2: There may be some subdomains that you have to add in yourself if Saltbox doesn\u2019t so it for you, such as the Saltbox type ones (eg saltbox , feederbox , mediabox ). Other Domain Hosting Sites \u00b6 For the Saltbox Install Type \u00b6 If your DNS provider allows wildcards \u00b6 You don't need to do anything. If your DNS provider DOES NOT allow wildcards \u00b6 You will need to add the subdomain via your domain's DNS provider's website. For the Mediabox / Feederbox Install Type \u00b6 You will need to add the subdomain via your domain's DNS provider's website. Make sure you use the correct IP address (Mediabox IP or Feederbox IP).","title":"Adding a Subdomain"},{"location":"reference/subdomain/#cloudflare","text":"Saltbox will automatically add the subdomain on Cloudflare and point it to the correct IP address. Note 1: Make sure the Cloudflare API Key is filled in settings.yml and the e-mail address matches the one you have in your Cloudflare account profile. Note 2: There may be some subdomains that you have to add in yourself if Saltbox doesn\u2019t so it for you, such as the Saltbox type ones (eg saltbox , feederbox , mediabox ).","title":"Cloudflare"},{"location":"reference/subdomain/#other-domain-hosting-sites","text":"","title":"Other Domain Hosting Sites"},{"location":"reference/subdomain/#for-the-saltbox-install-type","text":"","title":"For the Saltbox Install Type"},{"location":"reference/subdomain/#if-your-dns-provider-allows-wildcards","text":"You don't need to do anything.","title":"If your DNS provider allows wildcards"},{"location":"reference/subdomain/#if-your-dns-provider-does-not-allow-wildcards","text":"You will need to add the subdomain via your domain's DNS provider's website.","title":"If your DNS provider DOES NOT allow wildcards"},{"location":"reference/subdomain/#for-the-mediabox-feederbox-install-type","text":"You will need to add the subdomain via your domain's DNS provider's website. Make sure you use the correct IP address (Mediabox IP or Feederbox IP).","title":"For the Mediabox / Feederbox Install Type"},{"location":"reference/usenet-torrent/","text":"Usenet vs Bittorrent \u00b6 Probably, you're setting this up because you're planning to download media. To do this, there are requirements dependings on which method[s] you choose to download your media. It can either be Usenet, Torrents, or both . i. Usenet \u00b6 If you plan on using Usenet (i.e. Newsgroups) with Saltbox, you'll need 2 things: a Usenet provider and a Usenet indexer . We recommend you have multiple indexers (and even multiple providers) to better your chances of finding/downloading media. ii. BitTorrent \u00b6 If you plan on using torrents with Saltbox, we recommend you have access to a private torrent tracker as most servers don't allow public ones. However, if you still want to use public torrent trackers with Saltbox, you are free to do so. You will need to make some changes to the configuration TODO ADD LINK TO FAQ to allow access to public trackers, as they are blocked by default.","title":"Media Sources"},{"location":"reference/usenet-torrent/#usenet-vs-bittorrent","text":"Probably, you're setting this up because you're planning to download media. To do this, there are requirements dependings on which method[s] you choose to download your media. It can either be Usenet, Torrents, or both .","title":"Usenet vs Bittorrent"},{"location":"reference/usenet-torrent/#i-usenet","text":"If you plan on using Usenet (i.e. Newsgroups) with Saltbox, you'll need 2 things: a Usenet provider and a Usenet indexer . We recommend you have multiple indexers (and even multiple providers) to better your chances of finding/downloading media.","title":"i. Usenet"},{"location":"reference/usenet-torrent/#ii-bittorrent","text":"If you plan on using torrents with Saltbox, we recommend you have access to a private torrent tracker as most servers don't allow public ones. However, if you still want to use public torrent trackers with Saltbox, you are free to do so. You will need to make some changes to the configuration TODO ADD LINK TO FAQ to allow access to public trackers, as they are blocked by default.","title":"ii. BitTorrent"},{"location":"reference/guides/aliases/","text":"Saltbox Aliases \u00b6 Handy guide to Saltbox Command line aliases. sb update \u00b6 Update Saltbox Usage: sb update sb list \u00b6 List Saltbox packages Usage: sb list sb install <package> \u00b6 Install <package> Usage: sb install plex sb install sandbox- <package> \u00b6 Install Sandbox <package> Usage: sb install sandbox-dozzle","title":"Aliases"},{"location":"reference/guides/aliases/#saltbox-aliases","text":"Handy guide to Saltbox Command line aliases.","title":"Saltbox Aliases"},{"location":"reference/guides/aliases/#sb-update","text":"Update Saltbox Usage: sb update","title":"sb update"},{"location":"reference/guides/aliases/#sb-list","text":"List Saltbox packages Usage: sb list","title":"sb list"},{"location":"reference/guides/aliases/#sb-install-package","text":"Install <package> Usage: sb install plex","title":"sb install &lt;package&gt;"},{"location":"reference/guides/aliases/#sb-install-sandbox-package","text":"Install Sandbox <package> Usage: sb install sandbox-dozzle","title":"sb install sandbox-&lt;package&gt;"},{"location":"reference/guides/app-remove/","text":"Perhaps you want to remove one of the apps that Saltbox installed for you. Maybe you're not planning to ever use rutorrent, or you want to install it fresh, or some other reason. This page describes doing this for something that was installed as a docker container. THIS MAY DESTROY DATA; BACK UP FIRST IF YOU ARE UNSURE WHAT YOU'RE DOING \u00b6 First, stop and remove the docker container: docker stop CONTAINER_NAME docker rm CONTAINER_NAME At this point, the container has been removed; it's not longer running, no longer consuming CPU or RAM resources. Its configuration is still on disk in /opt , however. If you reinstall using the standard saltbox install mechanism, it will come back up with your existing configuration. If you want to remove that configuration for whatever reason [will never use it, want to start fresh, etc.]: rm -fr /opt/CONTAINER_NAME Now it's as if that app was never installed on this machine. Now you can reinstall the container using the standard saltbox tag: sb install TAG_GOES_HERE This will create a brand new /opt/CONTAINERNAME The same concepts apply to sandbox apps. If you're not planning to reinstall and want to save a tiny bit of disk space [or you want to be sure you pull a new image when you reinstall]: docker image prune That will delete the local copy of the image used to create the now-deleted container.","title":"Removing apps"},{"location":"reference/guides/app-remove/#this-may-destroy-data-back-up-first-if-you-are-unsure-what-youre-doing","text":"First, stop and remove the docker container: docker stop CONTAINER_NAME docker rm CONTAINER_NAME At this point, the container has been removed; it's not longer running, no longer consuming CPU or RAM resources. Its configuration is still on disk in /opt , however. If you reinstall using the standard saltbox install mechanism, it will come back up with your existing configuration. If you want to remove that configuration for whatever reason [will never use it, want to start fresh, etc.]: rm -fr /opt/CONTAINER_NAME Now it's as if that app was never installed on this machine. Now you can reinstall the container using the standard saltbox tag: sb install TAG_GOES_HERE This will create a brand new /opt/CONTAINERNAME The same concepts apply to sandbox apps. If you're not planning to reinstall and want to save a tiny bit of disk space [or you want to be sure you pull a new image when you reinstall]: docker image prune That will delete the local copy of the image used to create the now-deleted container.","title":"THIS MAY DESTROY DATA; BACK UP FIRST IF YOU ARE UNSURE WHAT YOU'RE DOING"},{"location":"reference/guides/app-reset/","text":"Perhaps you want to reset an application to a fresh start. See Removing Saltbox Apps","title":"Resetting apps"},{"location":"reference/guides/app-update/","text":"The info below will show you how to update your Saltbox apps, individually. Notes \u00b6 To update Saltbox as a whole (i.e. the core part and all the default roles), see Updating Saltbox . Do not update the following apps within the app itself: Sonarr, Radarr, Lidarr, NZBGet, Ombi, Jackett, NZBHydra2, and Bazarr. If you do you may get the following error: Update process failed: Cannot install update because startup folder '/app' is not writable by the user 'hotio'. Update to a newer version \u00b6 Saltbox Apps How to update Plex Ansible tag Tautulli Ansible tag AutoScan Ansible tag Sonarr Ansible tag Radarr Ansible tag NZBGet Ansible tag ruTorrent Ansible tag Jackett Ansible tag NZBHydra2 Ansible tag Ombi Ansible tag Organizr Update within the app Portainer Ansible tag Cloudplow Ansible tag Emby Ansible tag \"How to update\" options: \"Ansible tag\" See the next section on how to update Saltbox apps via their Ansible tag. \"Update within the app\" You can simply update within the app itself. Changes will persist after docker restarts. \"Container restart\" This means that the Docker container will auto-update the app on container restart. Currently nothing in Saltbox is updated in this way. docker stop <name> && docker start <name> or docker restart <name> Note: It's recommended to use docker stop/start <container> vs docker restart <container> , to prevent corrupting data, especially on apps like ruTorrent. Ansible tags to update apps \u00b6 When in doubt, you can always rerun the relevant Ansible tag to update the app. Apps Ansible Tags Plex plex Tautulli tautulli Sonarr sonarr Radarr radarr NZBGet nzbget ruTorrent rutorrent Jackett jackett NZBHydra2 nzbhydra2 Autoscan autoscan Ombi ombi Organizr organizr Portainer portainer Watchtower watchtower Cloudplow cloudplow Emby emby Traefik traefik Instructions: Run the tag command: sb install TAG Replace TAG with one of the above tags from the table. You can also run multiple tags, by placing them next to each other, separated by a comma, without spaces (e.g. TAG1,TAG2). Note: If the App is a docker container, running the update tag will rebuild and update the container. Note: If you modified the container with flags like plex_name , you'll need to do the same thing here.","title":"Updating apps"},{"location":"reference/guides/app-update/#notes","text":"To update Saltbox as a whole (i.e. the core part and all the default roles), see Updating Saltbox . Do not update the following apps within the app itself: Sonarr, Radarr, Lidarr, NZBGet, Ombi, Jackett, NZBHydra2, and Bazarr. If you do you may get the following error: Update process failed: Cannot install update because startup folder '/app' is not writable by the user 'hotio'.","title":"Notes"},{"location":"reference/guides/app-update/#update-to-a-newer-version","text":"Saltbox Apps How to update Plex Ansible tag Tautulli Ansible tag AutoScan Ansible tag Sonarr Ansible tag Radarr Ansible tag NZBGet Ansible tag ruTorrent Ansible tag Jackett Ansible tag NZBHydra2 Ansible tag Ombi Ansible tag Organizr Update within the app Portainer Ansible tag Cloudplow Ansible tag Emby Ansible tag \"How to update\" options: \"Ansible tag\" See the next section on how to update Saltbox apps via their Ansible tag. \"Update within the app\" You can simply update within the app itself. Changes will persist after docker restarts. \"Container restart\" This means that the Docker container will auto-update the app on container restart. Currently nothing in Saltbox is updated in this way. docker stop <name> && docker start <name> or docker restart <name> Note: It's recommended to use docker stop/start <container> vs docker restart <container> , to prevent corrupting data, especially on apps like ruTorrent.","title":"Update to a newer version"},{"location":"reference/guides/app-update/#ansible-tags-to-update-apps","text":"When in doubt, you can always rerun the relevant Ansible tag to update the app. Apps Ansible Tags Plex plex Tautulli tautulli Sonarr sonarr Radarr radarr NZBGet nzbget ruTorrent rutorrent Jackett jackett NZBHydra2 nzbhydra2 Autoscan autoscan Ombi ombi Organizr organizr Portainer portainer Watchtower watchtower Cloudplow cloudplow Emby emby Traefik traefik Instructions: Run the tag command: sb install TAG Replace TAG with one of the above tags from the table. You can also run multiple tags, by placing them next to each other, separated by a comma, without spaces (e.g. TAG1,TAG2). Note: If the App is a docker container, running the update tag will rebuild and update the container. Note: If you modified the container with flags like plex_name , you'll need to do the same thing here.","title":"Ansible tags to update apps"},{"location":"reference/guides/cloudbox/","text":"Migrating from Cloudbox to Saltbox \u00b6 Saltbox is a continuation of the Cloudbox project and is mostly compatible out of the box. Very little has to be done to bring your old Cloudbox data into Saltbox. Any customisations you have made or special roles are going to require extra work as Saltbox uses Traefik instead of nginx. IMPORTANT: Migration has the same requirements as a new install; Saltbox still expects a clean install of the OS; this means that you cannot upgrade an existing Cloudbox setup to Saltbox in place . You will have to back up, reinstall the OS fresh on the machine, then start the migration. Do not upgrade your Ubuntu 18.04 Cloudbox machine to Ubuntu 20.04 and try to run this migration. It won't work. Before Migration \u00b6 Backup from Cloudbox as you normally would. You will need to make the backup drive available to your new saltbox install via rclone just as you would with a Cloudbox restore. We are really only interested in keeping the data stored in /opt and not the Cloudbox configuration files. We will be using the data from the configuration files so you may find it handy to download those locally to use as a reference. If you have community containers set up you should make a copy of those files as well. We are more interested in the data stored in these files so it is perfectly fine to just copy and paste the information into a text file for your reference as part of the installation process. Cloudbox files to keep handy (these files should be found in ~/cloudbox/ ): accounts.yml You may need to decrypt your accounts.yml file if you used the encryption option. Do this before you shut down or wipe your old server. adv_settings.yml ansible.cfg backup_config.yml If you are using a service account to authenticate your rclone backup remote, you will need to put that service account file in place on the saltbox server before you run the restore. This trips people up frequently, so it bears repeating: If you are using a service account to authenticate your rclone backup remote, you will need to put that service account file in place on the saltbox server before you run the restore. If you don't understand what this means, ask on the Discord before you attempt this migration; doing so will save you a failure that will drive you to the Discord anyway. Community files to keep handy (these files should be found in /opt/community/ ): ansible.cfg hetzner_nfs.yml settings.yml telly.yml Rclone configuration file The rclone.conf file located in ~/.config/rclone/rclone.conf if your configuration uses service accounts to authenticate the remotes you will need make sure the service accounts are accessible. rclone.conf What's this about service accounts? On your cloudbox machine, run: rclone config show REMOTENAME Using an SA: \u279c ~ rclone config show REMOTE [REMOTE] type = drive scope = drive service_account_file = /opt/sa/all/1500.json team_drive = OZZY root_folder_id = Using clientid: \u279c ~ rclone config show REMOTE: [REMOTE] type = drive client_id = OZZY.apps.googleusercontent.com client_secret = TONY server_side_across_configs = true scope = drive token = {\"access_token\":\"GEEZER\",\"token_type\":\"Bearer\",\"refresh_token\":\"BILL\",\"expiry\":\"2022-04-30T17:37:41.485179628-05:00\"} root_folder_id = RONNIE If the rclone remote contains `service_account_file`, you will need to make sure that service account file is available on the saltbox machine at that same path. Migration \u00b6 IMPORTANT: Migration has the same requirements as a new install; Saltbox still expects a clean install of the OS; this means that you cannot upgrade an existing Cloudbox setup to Saltbox in place . You will have to back up, reinstall the OS fresh on the machine, then start the migration. Do not upgrade your Ubuntu 18.04 Cloudbox machine to Ubuntu 20.04 and try to run this migration. It won't work. Do not proceed unless the machine you're using is a fresh install of Ubuntu 20.04 or 22.04. Install the saltbox dependencies curl -sL https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox Copy rclone.conf to /srv/git/saltbox and edit the configuration files as needed. You can follow the saltbox install instructions for saltbox for this Saltbox is going to move this file into the correct location; you're putting it here only so saltbox knows where to find it. You can refer to your Cloudbox configuration files and copy relevant settings over from them, but do not just copy your existing Cloudbox config files into place. Direct compatibility with Cloudbox config files is not guaranteed and will not be maintained going forward. IMPORTANT: DO NOT use your cloudbox configuration files. You can copy and paste individual values [values like your plex username and token, not sections like the entire plex section] from your cloudbox files, but DO NOT use the originals. Things have moved from file to file compared to Cloudbox, there are new values that are required, there are values that have been deprecated. Work on the new default settings files and edit them using your cloudbox files as a reference. Run the preinstall command. This step will create the specified user account, add it to sudoers, update the kernel, edit GRUB configuration, install Rclone, and reboot the server if needed. sb install preinstall switch to the newly created user specified in your configuration. If you are restoring a Cloudbox backup, you should change the default rclone backup path in /srv/git/saltbox/backup_config.yml to point to your Cloudbox backup. Once you've done this initial restore, change it back to the location of your choice. --- backup : ... rclone : enable : true destination : google:/Backups/Saltbox <<< THIS ONE HERE ... run the restore command. sb install restore Remember that if you use a service account file to authenticate an rclone remote, you need to manually put that file into place before running the restore. Then you should be able to install tags as you want. install top-level tag [if desired] sb install saltbox - install individual tags [if desired] sb install emby - install sandbox tags [if required] sb install sandbox-nextcloud","title":"Cloudbox"},{"location":"reference/guides/cloudbox/#migrating-from-cloudbox-to-saltbox","text":"Saltbox is a continuation of the Cloudbox project and is mostly compatible out of the box. Very little has to be done to bring your old Cloudbox data into Saltbox. Any customisations you have made or special roles are going to require extra work as Saltbox uses Traefik instead of nginx. IMPORTANT: Migration has the same requirements as a new install; Saltbox still expects a clean install of the OS; this means that you cannot upgrade an existing Cloudbox setup to Saltbox in place . You will have to back up, reinstall the OS fresh on the machine, then start the migration. Do not upgrade your Ubuntu 18.04 Cloudbox machine to Ubuntu 20.04 and try to run this migration. It won't work.","title":"Migrating from Cloudbox to Saltbox"},{"location":"reference/guides/cloudbox/#before-migration","text":"Backup from Cloudbox as you normally would. You will need to make the backup drive available to your new saltbox install via rclone just as you would with a Cloudbox restore. We are really only interested in keeping the data stored in /opt and not the Cloudbox configuration files. We will be using the data from the configuration files so you may find it handy to download those locally to use as a reference. If you have community containers set up you should make a copy of those files as well. We are more interested in the data stored in these files so it is perfectly fine to just copy and paste the information into a text file for your reference as part of the installation process. Cloudbox files to keep handy (these files should be found in ~/cloudbox/ ): accounts.yml You may need to decrypt your accounts.yml file if you used the encryption option. Do this before you shut down or wipe your old server. adv_settings.yml ansible.cfg backup_config.yml If you are using a service account to authenticate your rclone backup remote, you will need to put that service account file in place on the saltbox server before you run the restore. This trips people up frequently, so it bears repeating: If you are using a service account to authenticate your rclone backup remote, you will need to put that service account file in place on the saltbox server before you run the restore. If you don't understand what this means, ask on the Discord before you attempt this migration; doing so will save you a failure that will drive you to the Discord anyway. Community files to keep handy (these files should be found in /opt/community/ ): ansible.cfg hetzner_nfs.yml settings.yml telly.yml Rclone configuration file The rclone.conf file located in ~/.config/rclone/rclone.conf if your configuration uses service accounts to authenticate the remotes you will need make sure the service accounts are accessible. rclone.conf What's this about service accounts? On your cloudbox machine, run: rclone config show REMOTENAME Using an SA: \u279c ~ rclone config show REMOTE [REMOTE] type = drive scope = drive service_account_file = /opt/sa/all/1500.json team_drive = OZZY root_folder_id = Using clientid: \u279c ~ rclone config show REMOTE: [REMOTE] type = drive client_id = OZZY.apps.googleusercontent.com client_secret = TONY server_side_across_configs = true scope = drive token = {\"access_token\":\"GEEZER\",\"token_type\":\"Bearer\",\"refresh_token\":\"BILL\",\"expiry\":\"2022-04-30T17:37:41.485179628-05:00\"} root_folder_id = RONNIE If the rclone remote contains `service_account_file`, you will need to make sure that service account file is available on the saltbox machine at that same path.","title":"Before Migration"},{"location":"reference/guides/cloudbox/#migration","text":"IMPORTANT: Migration has the same requirements as a new install; Saltbox still expects a clean install of the OS; this means that you cannot upgrade an existing Cloudbox setup to Saltbox in place . You will have to back up, reinstall the OS fresh on the machine, then start the migration. Do not upgrade your Ubuntu 18.04 Cloudbox machine to Ubuntu 20.04 and try to run this migration. It won't work. Do not proceed unless the machine you're using is a fresh install of Ubuntu 20.04 or 22.04. Install the saltbox dependencies curl -sL https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox Copy rclone.conf to /srv/git/saltbox and edit the configuration files as needed. You can follow the saltbox install instructions for saltbox for this Saltbox is going to move this file into the correct location; you're putting it here only so saltbox knows where to find it. You can refer to your Cloudbox configuration files and copy relevant settings over from them, but do not just copy your existing Cloudbox config files into place. Direct compatibility with Cloudbox config files is not guaranteed and will not be maintained going forward. IMPORTANT: DO NOT use your cloudbox configuration files. You can copy and paste individual values [values like your plex username and token, not sections like the entire plex section] from your cloudbox files, but DO NOT use the originals. Things have moved from file to file compared to Cloudbox, there are new values that are required, there are values that have been deprecated. Work on the new default settings files and edit them using your cloudbox files as a reference. Run the preinstall command. This step will create the specified user account, add it to sudoers, update the kernel, edit GRUB configuration, install Rclone, and reboot the server if needed. sb install preinstall switch to the newly created user specified in your configuration. If you are restoring a Cloudbox backup, you should change the default rclone backup path in /srv/git/saltbox/backup_config.yml to point to your Cloudbox backup. Once you've done this initial restore, change it back to the location of your choice. --- backup : ... rclone : enable : true destination : google:/Backups/Saltbox <<< THIS ONE HERE ... run the restore command. sb install restore Remember that if you use a service account file to authenticate an rclone remote, you need to manually put that file into place before running the restore. Then you should be able to install tags as you want. install top-level tag [if desired] sb install saltbox - install individual tags [if desired] sb install emby - install sandbox tags [if required] sb install sandbox-nextcloud","title":"Migration"},{"location":"reference/guides/coder-setup/","text":"Using coder for editing \u00b6 Coder is a version of VS Code that runs on your server. It's friendlier than something like nano , and you can use it anywhere you can get at your domain. install coder \u00b6 sb install sandbox-coder initial setup \u00b6 By default, coder will be available at [https://coder.yourdomain.tld]. The password is the one you set in accounts.yml VSCode will present with a checklist of \"getting started\" items. If you've never used VSCode before, take a few minutes to go through the fundamentals tutorial. You can change the default theme if you wish. I'm going to choose the dark theme. point it at the host /opt dir \u00b6 Probably, you want to edit config files for the apps, which are in /opt . The host /opt dir is mounted into the container as /host_opt/ . Choose File -> Open Folder... from the hamburger menu on the upper left: Navigate to /host_opt/ , click the arrow: and you should be presented with your /opt directory. Most of the things you will want to edit are here. This should stick the next time you load the app. install some extensions \u00b6 I suggest you install a few extensions: Click on the Extensions icon on the left, then type the name of the extension into the search box, and click the \"install\" button. Python: Rainbow-indent: Redhat YAML: Better TOML: Those are just suggestions; install others if you prefer. Now, with these extensions installed, you should have syntax highlighting and indentation coloring for: TOML YAML JSON","title":"Coder for easier file editing"},{"location":"reference/guides/coder-setup/#using-coder-for-editing","text":"Coder is a version of VS Code that runs on your server. It's friendlier than something like nano , and you can use it anywhere you can get at your domain.","title":"Using coder for editing"},{"location":"reference/guides/coder-setup/#install-coder","text":"sb install sandbox-coder","title":"install coder"},{"location":"reference/guides/coder-setup/#initial-setup","text":"By default, coder will be available at [https://coder.yourdomain.tld]. The password is the one you set in accounts.yml VSCode will present with a checklist of \"getting started\" items. If you've never used VSCode before, take a few minutes to go through the fundamentals tutorial. You can change the default theme if you wish. I'm going to choose the dark theme.","title":"initial setup"},{"location":"reference/guides/coder-setup/#point-it-at-the-host-opt-dir","text":"Probably, you want to edit config files for the apps, which are in /opt . The host /opt dir is mounted into the container as /host_opt/ . Choose File -> Open Folder... from the hamburger menu on the upper left: Navigate to /host_opt/ , click the arrow: and you should be presented with your /opt directory. Most of the things you will want to edit are here. This should stick the next time you load the app.","title":"point it at the host /opt dir"},{"location":"reference/guides/coder-setup/#install-some-extensions","text":"I suggest you install a few extensions: Click on the Extensions icon on the left, then type the name of the extension into the search box, and click the \"install\" button. Python: Rainbow-indent: Redhat YAML: Better TOML: Those are just suggestions; install others if you prefer. Now, with these extensions installed, you should have syntax highlighting and indentation coloring for: TOML YAML JSON","title":"install some extensions"},{"location":"reference/guides/google-shared-drive/","text":"Creating a Google Shared Drive \u00b6 This article describes how to create a Google Shared Drive for use with Saltbox. This is a general descrioption of the process. If you go through the document Google Drive setup process you don't have to do this. Prerequisites \u00b6 To go through this process, you will need a Google account capable of creating shared drives. Walkthrough \u00b6 Go to https://drive.google.com in a browser; log in with the relevant account. Right-click on \"Shared Drives\" and choose \"New shared drive...\" Give the drive a name and click \"Create\". You're done. You may need the ID of the Shared Drive for use with some tools; you can find it in the URL: Sharing the Shared Drive \u00b6 Perhaps you want to give access to this shared drive to an individual, service account, or group. Click on \"1 person\" below the Shared Drive name Enter the email address of the individual, service account, or group, and click on the name in the menu that appears. Choose \"Manager\" from the dropdown on the right, uncheck the \"Notify people\" box if you wish, and click \"Share\".","title":"Creating a Shared Drive"},{"location":"reference/guides/google-shared-drive/#creating-a-google-shared-drive","text":"This article describes how to create a Google Shared Drive for use with Saltbox. This is a general descrioption of the process. If you go through the document Google Drive setup process you don't have to do this.","title":"Creating a Google Shared Drive"},{"location":"reference/guides/google-shared-drive/#prerequisites","text":"To go through this process, you will need a Google account capable of creating shared drives.","title":"Prerequisites"},{"location":"reference/guides/google-shared-drive/#walkthrough","text":"Go to https://drive.google.com in a browser; log in with the relevant account. Right-click on \"Shared Drives\" and choose \"New shared drive...\" Give the drive a name and click \"Create\". You're done. You may need the ID of the Shared Drive for use with some tools; you can find it in the URL:","title":"Walkthrough"},{"location":"reference/guides/google-shared-drive/#sharing-the-shared-drive","text":"Perhaps you want to give access to this shared drive to an individual, service account, or group. Click on \"1 person\" below the Shared Drive name Enter the email address of the individual, service account, or group, and click on the name in the menu that appears. Choose \"Manager\" from the dropdown on the right, uncheck the \"Notify people\" box if you wish, and click \"Share\".","title":"Sharing the Shared Drive"},{"location":"reference/guides/hardlinking/","text":"Hardlinking Guide \u00b6 Hardlinking should more or less be in place if you have followed the saltbox setup guide. In short, if your container path mappings match your system mappings match your other container mappings then hardlinking should work fine within your arrs as long as your downloads path is on the same disk as your local media path. A more comprehensive guide will be added soon.","title":"Hardlinking"},{"location":"reference/guides/hardlinking/#hardlinking-guide","text":"Hardlinking should more or less be in place if you have followed the saltbox setup guide. In short, if your container path mappings match your system mappings match your other container mappings then hardlinking should work fine within your arrs as long as your downloads path is on the same disk as your local media path. A more comprehensive guide will be added soon.","title":"Hardlinking Guide"},{"location":"reference/guides/links/","text":"Links \u00b6 Trakt Lists \u00b6 TV \u00b6 TV Shows By Network More TV Shows By Network Animated/Anime Shows By Release Year 4K TV Series (By a925sw) Movies \u00b6 4K Movies 4k Movies (By Brian) Huge Movie Lists by year + Documentaries Rotten Tomatoes Best of 2018 - User also has Best of 2014/2015/2016/2017 Latest Releases Lists by decades (By opposite_lock) Themed Lists \u00b6 50 Best Christmas Movies 50 Best Christmas Movies - Rotten Tomatoes Many Christmas Movies Halloween Movies Misc/Users with many different lists \u00b6 Movies/TV By Genre","title":"Links"},{"location":"reference/guides/links/#links","text":"","title":"Links"},{"location":"reference/guides/links/#trakt-lists","text":"","title":"Trakt Lists"},{"location":"reference/guides/links/#tv","text":"TV Shows By Network More TV Shows By Network Animated/Anime Shows By Release Year 4K TV Series (By a925sw)","title":"TV"},{"location":"reference/guides/links/#movies","text":"4K Movies 4k Movies (By Brian) Huge Movie Lists by year + Documentaries Rotten Tomatoes Best of 2018 - User also has Best of 2014/2015/2016/2017 Latest Releases Lists by decades (By opposite_lock)","title":"Movies"},{"location":"reference/guides/links/#themed-lists","text":"50 Best Christmas Movies 50 Best Christmas Movies - Rotten Tomatoes Many Christmas Movies Halloween Movies","title":"Themed Lists"},{"location":"reference/guides/links/#miscusers-with-many-different-lists","text":"Movies/TV By Genre","title":"Misc/Users with many different lists"},{"location":"reference/guides/plexguide/","text":"Migrating from PlexGuide to Saltbox \u00b6 These are some rough notes on migrating from PlexGuide to Saltbox Some important files and their locations: file PlexGuide location saltbox default location rclone.conf /opt/appdata/plexguide/rclone.conf /home/seed/.config/rclone/rclone.conf SA JSON files /opt/appdata/plexguide/.blitzkeys /opt/sa/all if you are restoring the arrs from pg to saltbox you will need to make these changes in SB sudo mkdir /mnt/gdrive sudo chown $USER : $USER /mnt/gdrive chmod 775 /mnt/gdrive sudo cp \"/etc/systemd/system/rclone_vfs.service\" \"/etc/systemd/system/gdrive.service\" sudo nano \"/etc/systemd/system/gdrive.service\" Changes: google : /mnt/remote becomes google : /mnt/gdrive AND ExecStop = /bin/fusermount -uz /mnt/remote becomes ExecStop = /bin/fusermount -uz /mnt/gdrive sudo systemctl enable gdrive.service sudo systemctl start gdrive.service These notes do not represent everything you need to do to migrate; the two systems are very different and there is no automation around migration. For example, PlexGuide apparently removed the .json extension from its service account files, which it called \"BlitzKeys\". Most things that interact with service accounts in saltbox expect that those files will have the extension.","title":"Plexguide"},{"location":"reference/guides/plexguide/#migrating-from-plexguide-to-saltbox","text":"These are some rough notes on migrating from PlexGuide to Saltbox Some important files and their locations: file PlexGuide location saltbox default location rclone.conf /opt/appdata/plexguide/rclone.conf /home/seed/.config/rclone/rclone.conf SA JSON files /opt/appdata/plexguide/.blitzkeys /opt/sa/all if you are restoring the arrs from pg to saltbox you will need to make these changes in SB sudo mkdir /mnt/gdrive sudo chown $USER : $USER /mnt/gdrive chmod 775 /mnt/gdrive sudo cp \"/etc/systemd/system/rclone_vfs.service\" \"/etc/systemd/system/gdrive.service\" sudo nano \"/etc/systemd/system/gdrive.service\" Changes: google : /mnt/remote becomes google : /mnt/gdrive AND ExecStop = /bin/fusermount -uz /mnt/remote becomes ExecStop = /bin/fusermount -uz /mnt/gdrive sudo systemctl enable gdrive.service sudo systemctl start gdrive.service These notes do not represent everything you need to do to migrate; the two systems are very different and there is no automation around migration. For example, PlexGuide apparently removed the .json extension from its service account files, which it called \"BlitzKeys\". Most things that interact with service accounts in saltbox expect that those files will have the extension.","title":"Migrating from PlexGuide to Saltbox"},{"location":"reference/guides/rclone-remote/","text":"Creating an rclone remote \u00b6 This article describes how to create an rclone remote Prerequisites \u00b6 To go through this process, you will need either one of these for your Google account: ClientID/Secret Service Account JSON file(s) The project associated with these needs to be set to \"external\". See step 9 on this page . You will need rclone and a web browser installed on a machine local to you [this machine needs a GUI]. Walkthrough \u00b6 Run the following command: rclone config Type n for \"New remote\" and press Enter . $ rclone config 2022 /02/26 15 :29:40 NOTICE: Config file \"/Users/geezer/.config/rclone/rclone.conf\" not found - using defaults No remotes found - make a new one n ) New remote s ) Set configuration password q ) Quit config n/s/q> n For \"name\", type in the name of your choice and and press Enter . [This name is arbitrary, aside from rclone's limitations on name; we're using google in this example] n/s/q> n name> google For \"Type of storage\", type in drive , or the corresponding number, and press Enter . Note that this list is constantly changing, will be much longer, and the numbers won't match what's shown here. Read what's on the screen. Option Storage. Type of storage to configure. Enter a string value. Press Enter for the default ( \"\" ) . Choose a number from below, or type in your own value. 1 / 1Fichier \\ \"fichier\" 2 / Alias for an existing remote \\ \"alias\" ... 14 / FTP Connection \\ \"ftp\" 15 / Google Cloud Storage ( this is not Google Drive ) \\ \"google cloud storage\" 16 / Google Drive \\ \"drive\" 17 / Google Photos \\ \"google photos\" 18 / Hadoop distributed file system \\ \"hdfs\" ... 43 / http Connection \\ \"http\" 44 / premiumize.me \\ \"premiumizeme\" 45 / seafile \\ \"seafile\" Storage> drive Client ID and Secret: Using a Client ID and secret to connect Using a service account to connect Enter the Client ID and Client Secret when prompted Storage> drive Option client_id. Google Application Client Id Setting your own is recommended. See https://rclone.org/drive/#making-your-own-client-id for how to create your own. If you leave this blank, it will use an internal key which is low performance. Enter a string value. Press Enter for the default ( \"\" ) . client_id> JOHNNYJOEYDEEDEE Option client_secret. OAuth Client Secret. Leave blank normally. Enter a string value. Press Enter for the default ( \"\" ) . client_secret> OZZYTONYGEEZERBILL Leave the Client ID and Client Secret blank when prompted Storage> drive Option client_id. Google Application Client Id Setting your own is recommended. See https://rclone.org/drive/#making-your-own-client-id for how to create your own. If you leave this blank, it will use an internal key which is low performance. Enter a string value. Press Enter for the default ( \"\" ) . client_id> Option client_secret. OAuth Client Secret. Leave blank normally. Enter a string value. Press Enter for the default ( \"\" ) . client_secret> For the \"Scope that rclone should use when requesting access from drive\", type in drive , or the corresponding number (i.e. 1 ), to select \"Full access all files, excluding Application Data Folder\", and press Enter . Option scope. Scope that rclone should use when requesting access from drive. Enter a string value. Press Enter for the default ( \"\" ) . Choose a number from below, or type in your own value. 1 / Full access all files, excluding Application Data Folder. \\ \"drive\" 2 / Read-only access to file metadata and file contents. \\ \"drive.readonly\" / Access to files created by rclone only. 3 | These are visible in the drive website. | File authorization is revoked when the user deauthorizes the app. \\ \"drive.file\" / Allows read and write access to the Application Data folder. 4 | This is not visible in the drive website. \\ \"drive.appfolder\" / Allows read-only access to file metadata but 5 | does not allow any access to read or download file content. \\ \"drive.metadata.readonly\" scope> 1 For \"ID of the root folder\", leave blank and press Enter . Option root_folder_id. ID of the root folder. Leave blank normally. Fill in to access \"Computers\" folders ( see docs ) , or for rclone to use a non root folder as its starting point. Enter a string value. Press Enter for the default ( \"\" ) . root_folder_id> For \"Service Account Credentials JSON file path\": Using a Client ID and secret to connect Using a service account to connect leave blank and press Enter Option service_account_file. Service Account Credentials JSON file path. Leave blank normally. Needed only if you want use SA instead of interactive login. Leading ` ~ ` will be expanded in the file name as will environment variables such as ` ${ RCLONE_CONFIG_DIR } ` . Enter a string value. Press Enter for the default ( \"\" ) . service_account_file> Enter the path to a service account JSON file and press Enter Option service_account_file. Service Account Credentials JSON file path. Leave blank normally. Needed only if you want use SA instead of interactive login. Leading ` ~ ` will be expanded in the file name as will environment variables such as ` ${ RCLONE_CONFIG_DIR } ` . Enter a string value. Press Enter for the default ( \"\" ) . service_account_file> /path/to/service-account.json For \"Edit advanced config\", type n and press Enter . Edit advanced config? y ) Yes n ) No ( default ) y/n> n For \"Use auto config?\", type n for \"...remote or headless machine\" and press Enter . Use auto config? * Say Y if not sure * Say N if you are working on a remote or headless machine y ) Yes ( default ) n ) No y/n> n In the next section, follow the instructions on your local machine. Option config_token. For this to work, you will need rclone available on a machine that has a web browser available. For more help and alternate methods see: https://rclone.org/remote_setup/ Execute the following on the machine with the web browser ( same rclone version recommended ) : rclone authorize \"drive\" \"eyJjbGllbnRfaWQiOiI2OTUxMzMzNjg1ODMtcmU5MmE3Y3F0cGdqc2JvOGlscGwxamIzN2draXRibmwuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJjbGllbnRfc2VjcmV0IjoiOVRCQ2p2WHBlNlhxaFlPUG5JUGpRTkdIIiwic2NvcGUiOiJkcml2ZSJ9\" Then paste the result. Enter a value. config_token> If asked to login, use the Google Drive account you want to store your data in. Give access by clicking \"Allow\". The browser should report success. And a token should show up in the terminal on your local computer: 2022/05/09 22:56:09 NOTICE: Log in and authorize rclone for access 2022/05/09 22:56:09 NOTICE: Waiting for code... 2022/05/09 22:56:16 NOTICE: Got code Paste the following into your remote machine ---> ROGERPETEJOHNKEITH <---End paste 11. Paste the token at the rclone prompt and press Enter. Enter a value. config_token> ROGERPETEJOHNKEITH For \"Configure this as a team drive?\": Using My Drive Using a shared drive Type n and press Enter . Configure this as a Shared Drive ( Team Drive ) ? y ) Yes n ) No ( default ) y/n> n Type y and press Enter . Configure this as a Shared Drive ( Team Drive ) ? y ) Yes n ) No ( default ) y/n> n You'll be presented with a list of shared drives you have access to. Enter a number and press Enter . Option config_team_drive. Shared Drive Enter a string value. Press Enter for the default ( \"0AF3NBtE4KF_iUk9PVA\" ) . Choose a number from below, or type in an existing value. 1 / 4k \\ \"BINGBANGBOING\" 2 / 1080p \\ \"BANGBOINGBING\" ... 122 / ubrujjpeni-TV \\ \"BOINGBINGBANG\" 123 / Video \\ \"BANGBINGBOING\" config_team_drive> 6 Confirm that the remote details look OK, type y and press Enter . -------------------- [ google ] type = drive client_id = JOHNNYJOEYDEEDEE client_secret = OZZYTONYGEEZERBILL scope = drive token = { \"access_token\" : \"...\" , \"token_type\" : \"Bearer\" , \"refresh_token\" : \"...\" , \"expiry\" : \"2022-02-26T17:56:24.53802-06:00\" } team_drive = BINGBANGBOING root_folder_id = -------------------- y ) Yes this is OK ( default ) e ) Edit this remote d ) Delete this remote y/e/d> y To exit, type q and press Enter . Current remotes: Name Type ==== ==== google drive e ) Edit existing remote n ) New remote d ) Delete remote r ) Rename remote c ) Copy remote s ) Set configuration password q ) Quit config e/n/d/r/c/s/q> q Existing Rclone Setup \u00b6 The default remote specified in [[settings.yml|Install: settings.yml]] is google for Google Drive. If the Rclone remote in your config has the same name, then you are OK to skip this page and go on to the next. If you are using Google Drive and the Rclone remote in your config has a different name, then you will need to either: Rename your current Rclone remote to the default one (i.e. google ). Instructions for this are below. OR Edit the Rclone remote entry in settings.yml with yours.","title":"Creating a remote"},{"location":"reference/guides/rclone-remote/#creating-an-rclone-remote","text":"This article describes how to create an rclone remote","title":"Creating an rclone remote"},{"location":"reference/guides/rclone-remote/#prerequisites","text":"To go through this process, you will need either one of these for your Google account: ClientID/Secret Service Account JSON file(s) The project associated with these needs to be set to \"external\". See step 9 on this page . You will need rclone and a web browser installed on a machine local to you [this machine needs a GUI].","title":"Prerequisites"},{"location":"reference/guides/rclone-remote/#walkthrough","text":"Run the following command: rclone config Type n for \"New remote\" and press Enter . $ rclone config 2022 /02/26 15 :29:40 NOTICE: Config file \"/Users/geezer/.config/rclone/rclone.conf\" not found - using defaults No remotes found - make a new one n ) New remote s ) Set configuration password q ) Quit config n/s/q> n For \"name\", type in the name of your choice and and press Enter . [This name is arbitrary, aside from rclone's limitations on name; we're using google in this example] n/s/q> n name> google For \"Type of storage\", type in drive , or the corresponding number, and press Enter . Note that this list is constantly changing, will be much longer, and the numbers won't match what's shown here. Read what's on the screen. Option Storage. Type of storage to configure. Enter a string value. Press Enter for the default ( \"\" ) . Choose a number from below, or type in your own value. 1 / 1Fichier \\ \"fichier\" 2 / Alias for an existing remote \\ \"alias\" ... 14 / FTP Connection \\ \"ftp\" 15 / Google Cloud Storage ( this is not Google Drive ) \\ \"google cloud storage\" 16 / Google Drive \\ \"drive\" 17 / Google Photos \\ \"google photos\" 18 / Hadoop distributed file system \\ \"hdfs\" ... 43 / http Connection \\ \"http\" 44 / premiumize.me \\ \"premiumizeme\" 45 / seafile \\ \"seafile\" Storage> drive Client ID and Secret: Using a Client ID and secret to connect Using a service account to connect Enter the Client ID and Client Secret when prompted Storage> drive Option client_id. Google Application Client Id Setting your own is recommended. See https://rclone.org/drive/#making-your-own-client-id for how to create your own. If you leave this blank, it will use an internal key which is low performance. Enter a string value. Press Enter for the default ( \"\" ) . client_id> JOHNNYJOEYDEEDEE Option client_secret. OAuth Client Secret. Leave blank normally. Enter a string value. Press Enter for the default ( \"\" ) . client_secret> OZZYTONYGEEZERBILL Leave the Client ID and Client Secret blank when prompted Storage> drive Option client_id. Google Application Client Id Setting your own is recommended. See https://rclone.org/drive/#making-your-own-client-id for how to create your own. If you leave this blank, it will use an internal key which is low performance. Enter a string value. Press Enter for the default ( \"\" ) . client_id> Option client_secret. OAuth Client Secret. Leave blank normally. Enter a string value. Press Enter for the default ( \"\" ) . client_secret> For the \"Scope that rclone should use when requesting access from drive\", type in drive , or the corresponding number (i.e. 1 ), to select \"Full access all files, excluding Application Data Folder\", and press Enter . Option scope. Scope that rclone should use when requesting access from drive. Enter a string value. Press Enter for the default ( \"\" ) . Choose a number from below, or type in your own value. 1 / Full access all files, excluding Application Data Folder. \\ \"drive\" 2 / Read-only access to file metadata and file contents. \\ \"drive.readonly\" / Access to files created by rclone only. 3 | These are visible in the drive website. | File authorization is revoked when the user deauthorizes the app. \\ \"drive.file\" / Allows read and write access to the Application Data folder. 4 | This is not visible in the drive website. \\ \"drive.appfolder\" / Allows read-only access to file metadata but 5 | does not allow any access to read or download file content. \\ \"drive.metadata.readonly\" scope> 1 For \"ID of the root folder\", leave blank and press Enter . Option root_folder_id. ID of the root folder. Leave blank normally. Fill in to access \"Computers\" folders ( see docs ) , or for rclone to use a non root folder as its starting point. Enter a string value. Press Enter for the default ( \"\" ) . root_folder_id> For \"Service Account Credentials JSON file path\": Using a Client ID and secret to connect Using a service account to connect leave blank and press Enter Option service_account_file. Service Account Credentials JSON file path. Leave blank normally. Needed only if you want use SA instead of interactive login. Leading ` ~ ` will be expanded in the file name as will environment variables such as ` ${ RCLONE_CONFIG_DIR } ` . Enter a string value. Press Enter for the default ( \"\" ) . service_account_file> Enter the path to a service account JSON file and press Enter Option service_account_file. Service Account Credentials JSON file path. Leave blank normally. Needed only if you want use SA instead of interactive login. Leading ` ~ ` will be expanded in the file name as will environment variables such as ` ${ RCLONE_CONFIG_DIR } ` . Enter a string value. Press Enter for the default ( \"\" ) . service_account_file> /path/to/service-account.json For \"Edit advanced config\", type n and press Enter . Edit advanced config? y ) Yes n ) No ( default ) y/n> n For \"Use auto config?\", type n for \"...remote or headless machine\" and press Enter . Use auto config? * Say Y if not sure * Say N if you are working on a remote or headless machine y ) Yes ( default ) n ) No y/n> n In the next section, follow the instructions on your local machine. Option config_token. For this to work, you will need rclone available on a machine that has a web browser available. For more help and alternate methods see: https://rclone.org/remote_setup/ Execute the following on the machine with the web browser ( same rclone version recommended ) : rclone authorize \"drive\" \"eyJjbGllbnRfaWQiOiI2OTUxMzMzNjg1ODMtcmU5MmE3Y3F0cGdqc2JvOGlscGwxamIzN2draXRibmwuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJjbGllbnRfc2VjcmV0IjoiOVRCQ2p2WHBlNlhxaFlPUG5JUGpRTkdIIiwic2NvcGUiOiJkcml2ZSJ9\" Then paste the result. Enter a value. config_token> If asked to login, use the Google Drive account you want to store your data in. Give access by clicking \"Allow\". The browser should report success. And a token should show up in the terminal on your local computer: 2022/05/09 22:56:09 NOTICE: Log in and authorize rclone for access 2022/05/09 22:56:09 NOTICE: Waiting for code... 2022/05/09 22:56:16 NOTICE: Got code Paste the following into your remote machine ---> ROGERPETEJOHNKEITH <---End paste 11. Paste the token at the rclone prompt and press Enter. Enter a value. config_token> ROGERPETEJOHNKEITH For \"Configure this as a team drive?\": Using My Drive Using a shared drive Type n and press Enter . Configure this as a Shared Drive ( Team Drive ) ? y ) Yes n ) No ( default ) y/n> n Type y and press Enter . Configure this as a Shared Drive ( Team Drive ) ? y ) Yes n ) No ( default ) y/n> n You'll be presented with a list of shared drives you have access to. Enter a number and press Enter . Option config_team_drive. Shared Drive Enter a string value. Press Enter for the default ( \"0AF3NBtE4KF_iUk9PVA\" ) . Choose a number from below, or type in an existing value. 1 / 4k \\ \"BINGBANGBOING\" 2 / 1080p \\ \"BANGBOINGBING\" ... 122 / ubrujjpeni-TV \\ \"BOINGBINGBANG\" 123 / Video \\ \"BANGBINGBOING\" config_team_drive> 6 Confirm that the remote details look OK, type y and press Enter . -------------------- [ google ] type = drive client_id = JOHNNYJOEYDEEDEE client_secret = OZZYTONYGEEZERBILL scope = drive token = { \"access_token\" : \"...\" , \"token_type\" : \"Bearer\" , \"refresh_token\" : \"...\" , \"expiry\" : \"2022-02-26T17:56:24.53802-06:00\" } team_drive = BINGBANGBOING root_folder_id = -------------------- y ) Yes this is OK ( default ) e ) Edit this remote d ) Delete this remote y/e/d> y To exit, type q and press Enter . Current remotes: Name Type ==== ==== google drive e ) Edit existing remote n ) New remote d ) Delete remote r ) Rename remote c ) Copy remote s ) Set configuration password q ) Quit config e/n/d/r/c/s/q> q","title":"Walkthrough"},{"location":"reference/guides/rclone-remote/#existing-rclone-setup","text":"The default remote specified in [[settings.yml|Install: settings.yml]] is google for Google Drive. If the Rclone remote in your config has the same name, then you are OK to skip this page and go on to the next. If you are using Google Drive and the Rclone remote in your config has a different name, then you will need to either: Rename your current Rclone remote to the default one (i.e. google ). Instructions for this are below. OR Edit the Rclone remote entry in settings.yml with yours.","title":"Existing Rclone Setup"},{"location":"reference/guides/suggested_reading/","text":"Suggested Reading \u00b6 TRaSH Guides \u00b6 TRaSH Guides Discord Servarr \u00b6 The servarr wiki is home to information on Lidarr, Prowlarr, Radarr, Readarr, and Sonarr. Servarr Servarr Discussion Lidarr Official Lidarr Discord Official Lidarr Reddit Prowlarr Official Prowlarr Discord Official Prowlarr Reddit Radarr Official Radarr Discord Official Radarr Reddit Readarr Official Readarr Discord Official Readarr Reddit Sonarr Official Sonarr Discord Official Sonarr Reddit Kasper56's Plex Client End User setup Wiki \u00b6 Media Clients Wiki","title":"Suggested Reading"},{"location":"reference/guides/suggested_reading/#suggested-reading","text":"","title":"Suggested Reading"},{"location":"reference/guides/suggested_reading/#trash-guides","text":"TRaSH Guides Discord","title":"TRaSH Guides"},{"location":"reference/guides/suggested_reading/#servarr","text":"The servarr wiki is home to information on Lidarr, Prowlarr, Radarr, Readarr, and Sonarr. Servarr Servarr Discussion Lidarr Official Lidarr Discord Official Lidarr Reddit Prowlarr Official Prowlarr Discord Official Prowlarr Reddit Radarr Official Radarr Discord Official Radarr Reddit Readarr Official Readarr Discord Official Readarr Reddit Sonarr Official Sonarr Discord Official Sonarr Reddit","title":"Servarr"},{"location":"reference/guides/suggested_reading/#kasper56s-plex-client-end-user-setup-wiki","text":"Media Clients Wiki","title":"Kasper56's Plex Client End User setup Wiki"},{"location":"reference/guides/tautuliscripts/","text":"Introduction \u00b6 This is a quick guide to installing and configuring a Tautulli custom script. It will teach you how to download and configure a Tautulli custom script that drops Plex video streams transcoding from a 4K source. Install the script \u00b6 Access your Saltbox server as your normal non-root user. We'll be installing the Killstream.py script from the JBOPS script collection. Download the script using curl: \u00b6 cd /opt/scripts/tautulli/ curl -O https://raw.githubusercontent.com/blacktwin/JBOPS/master/killstream/kill_stream.py chmod a+x kill_stream.py Verify that the script was downloaded successfully with: \u00b6 ls -la kill_stream.py Configure Tautulli Notification Agent \u00b6 Enter Tautulli settings and find the Notification Agents link on the left side menu.\\ Click Add a new notification agent and scroll down to Script in the selection dialog. Configuration panel \u00b6 Enter /scripts/tautulli/ in the script folder and exit the text input field. Select the script named ./kill_stream.py in the Script File drop-down.\\ Check your previous steps or bug someone on discord if the script is not listed. Enter Terminate 4K transcodes or something of your own choice in the description field. Triggers panel \u00b6 Put a checkmark in Playback Start and Transcode Decision Change Notifications Conditions panel \u00b6 Condition {1}: Video Decision - is - transcode Condition {2}: Library Name - contains - 4K Note: adjust the library name if your 4K libraries does not contain the name 4K . Arguments panel \u00b6 Under Playback Start enter the following: --jbop stream --username {username} --sessionId {session_id} --killMessage 'Transcoding is not allowed from the 4K libraries.' Under Transcode Decision Change enter the following: --jbop stream --username {username} --sessionId {session_id} --killMessage 'Transcoding is not allowed from the 4K libraries.' Finishing up \u00b6 Click the Save button to save the new notification agent. You can test the agent by attempting to play a 4K movie through the Plex web app and downgrade the quality to 2Mbit. It will be transcoding for about 5-10 seconds, after which you should get the stream kill message. There is a list of when a notification agent is triggered in the Notification logs section of Tautulli logs. Credit goes to blacktwin \u00b6 https://github.com/blacktwin/JBOPS","title":"Tautulii Custom Scripts"},{"location":"reference/guides/tautuliscripts/#introduction","text":"This is a quick guide to installing and configuring a Tautulli custom script. It will teach you how to download and configure a Tautulli custom script that drops Plex video streams transcoding from a 4K source.","title":"Introduction"},{"location":"reference/guides/tautuliscripts/#install-the-script","text":"Access your Saltbox server as your normal non-root user. We'll be installing the Killstream.py script from the JBOPS script collection.","title":"Install the script"},{"location":"reference/guides/tautuliscripts/#download-the-script-using-curl","text":"cd /opt/scripts/tautulli/ curl -O https://raw.githubusercontent.com/blacktwin/JBOPS/master/killstream/kill_stream.py chmod a+x kill_stream.py","title":"Download the script using curl:"},{"location":"reference/guides/tautuliscripts/#verify-that-the-script-was-downloaded-successfully-with","text":"ls -la kill_stream.py","title":"Verify that the script was downloaded successfully with:"},{"location":"reference/guides/tautuliscripts/#configure-tautulli-notification-agent","text":"Enter Tautulli settings and find the Notification Agents link on the left side menu.\\ Click Add a new notification agent and scroll down to Script in the selection dialog.","title":"Configure Tautulli Notification Agent"},{"location":"reference/guides/tautuliscripts/#configuration-panel","text":"Enter /scripts/tautulli/ in the script folder and exit the text input field. Select the script named ./kill_stream.py in the Script File drop-down.\\ Check your previous steps or bug someone on discord if the script is not listed. Enter Terminate 4K transcodes or something of your own choice in the description field.","title":"Configuration panel"},{"location":"reference/guides/tautuliscripts/#triggers-panel","text":"Put a checkmark in Playback Start and Transcode Decision Change","title":"Triggers panel"},{"location":"reference/guides/tautuliscripts/#notifications-conditions-panel","text":"Condition {1}: Video Decision - is - transcode Condition {2}: Library Name - contains - 4K Note: adjust the library name if your 4K libraries does not contain the name 4K .","title":"Notifications Conditions panel"},{"location":"reference/guides/tautuliscripts/#arguments-panel","text":"Under Playback Start enter the following: --jbop stream --username {username} --sessionId {session_id} --killMessage 'Transcoding is not allowed from the 4K libraries.' Under Transcode Decision Change enter the following: --jbop stream --username {username} --sessionId {session_id} --killMessage 'Transcoding is not allowed from the 4K libraries.'","title":"Arguments panel"},{"location":"reference/guides/tautuliscripts/#finishing-up","text":"Click the Save button to save the new notification agent. You can test the agent by attempting to play a 4K movie through the Plex web app and downgrade the quality to 2Mbit. It will be transcoding for about 5-10 seconds, after which you should get the stream kill message. There is a list of when a notification agent is triggered in the Notification logs section of Tautulli logs.","title":"Finishing up"},{"location":"reference/guides/tautuliscripts/#credit-goes-to-blacktwin","text":"https://github.com/blacktwin/JBOPS","title":"Credit goes to blacktwin"},{"location":"reference/guides/chazguides/base-domain/","text":"This is a Cloudbox article that has not yet been updated for saltbox. The information therein may not apply to Saltbox. I want some app to load at my base domain.","title":"I want some app to load at my base domain"},{"location":"reference/guides/chazguides/disk-full/","text":"Why is my disk full? \u00b6 First, a quick refresher on how the system works: Your downloader puts files in /mnt/local/downloads . Sonarr/Radarr move [usenet] or copy [default torrent] these files to /mnt/local/Media . [They\u2019re actually moving files to /mnt/unionfs/Media , but the mergerfs config routes them in /mnt/local/Media ] Once /mnt/local/Media hits 200GB, cloudplow uploads the contents to your cloud drive. Once that\u2019s complete they will show up in /mnt/remote/Media as well as /mnt/unionfs/Media . Chances are, if your disk is full, the cause is one of two things: Sonarr/Radarr are not importing downloaded media Cloudplow isn't uploading things to the cloud. If you are using rclone\u2019s --vfs-cache=full, then there\u2019s a third likely cause: Your rclone vfs cache is filling your disk This is written assuming Usenet downloads, so filling your disks with seeding torrents isn't covered. You can use these tools to find out if that's the issue, though. Where is the space going? \u00b6 The first step is to find out where the space is going on your disk; which directories contain all the files. At a command prompt, type: sudo ncdu -x --exclude /opt/plex / What\u2019s that command? sudo run with root privileges ncdu show graphic display of disk usage -x don\u2019t cross filesystem boundaries [this will show only local space used and won't cross over to remote file systems like your google drive] --exclude /opt/plex ignore this directory; it\u2019s full of thousands of tiny files that take forever to scan and MOST LIKELY you\u2019re not going to want to delete anything from here. / starting point of scan You'll probably see something like this: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- / ------------------------------------------------------ 558.0 GiB [##########] /mnt 20.9 GiB [ ] /var 3.5 GiB [ ] /usr Drill into /mnt/local: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- /mnt/local --------------------------------------------- /.. 472.9 GiB [##########] /downloads 43.9 GiB [ ] /Media 37.5 GiB [ ] /Backups 3.7 GiB [ ] /transcodes Here, I have 473 GB of unimported downloads and 44 GB waiting to be uploaded by Cloudplow. Rclone vfs cache is more install-dependent. I\u2019m going to assume that if you\u2019re reading this you didn\u2019t change things from the defaults, and chances are you\u2019ll see something like this: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help ------------------------------------------------------------ 252.3 GiB [##########] /home 119.6 GiB [#### ] /mnt 29.5 GiB [# ] /var 3.4 GiB [ ] /usr Drill into /home/YOUR_USERNAME/: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- /home/seed --------------------------------------------- /.. 203.0 GiB [##########] /.cache 37.9 MiB [ ] /.pkg-cache 34.5 MiB [ ] /.npm And further into .cache/rclone: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- /home/seed/.cache/rclone ------------------------------- /.. 202.9 GiB [##########] /vfs 4.8 MiB [ ] /vfsMeta 16.0 KiB [ ] /webgui That\u2019s your VFS cache. Radarr/Sonarr didn\u2019t import stuff! \u00b6 Drill into downloads to examine what's there in more detail. Chances are you\u2019ll find /mnt/local/nzbs/nzbget/downloads/completed is where all the files are. Those are downloads that Radarr/Sonarr didn\u2019t import. Use Wanted -> Manual Import to find out why particular things weren't imported. Perhaps Radarr couldn\u2019t work out what movie a thing was: Maybe it doesn\u2019t look like an upgrade for one reason or another: That same information is also available in the logs. You can import things from here after telling Radarr what movie it is or the like, or you can delete them from within ncdu or via whatever other means. Cloudplow isn\u2019t uploading stuff! \u00b6 If the bulk of the space is in staged-for-upload files sitting in /mnt/local/Media , then cloudplow hasn\u2019t uploaded those files yet. This is typically due to one of the following: Upload threshold hasn\u2019t been reached. You\u2019ve reached the Google Drive upload cap of 750GB/day The default threshold to start a Google upload is 200GB, so in my case above cloudplow wouldn\u2019t do anything until 150GB more gets put into /mnt/local/Media . At a command prompt, type: tail /opt/cloudplow/cloudplow.log You should see something like: Uploader: google. Local folder size is currently 44 GB. Still have 156 GB remaining before its eligible to begin uploading... If you do, cloudplow is working as expected. If you want cloudplow to start uploading stuff sooner, you can adjust those thresholds in your cloudplow config file. At the bottom of /opt/cloudplow/config.json , you\u2019ll find something like this: \"google\": { \"check_interval\": 30, \"exclude_open_files\": true, \"max_size_gb\": 200, \"opened_excludes\": [ \"/downloads/\" ], \"service_account_path\": \"\", \"size_excludes\": [ \"downloads/*\" ] } That\u2019s going to check every 30 minutes, and start uploading when the folder reaches 200GB. Adjust those values to suit your use case. Restart the cloudplow service if you make changes here. In the default setup, you can upload 750GB per day. To see if you\u2019ve hit that quota, run a cloudplow upload manually. At a command prompt, type: cloudplow upload This will kick off an upload without regard for the threshold. You can run this anytime you want to upload whatever\u2019s pending right this very minute. PAY ATTENTION TO WHAT THE LOG SAYS. The errors should let you know what\u2019s going on. If you want more detail: cloudplow upload --loglevel=DEBUG You'll get a great deal of information about what cloudplow is doing and why. If you find yourself hitting that 750GB cap regularly, you may want to set up service-account uploading . Rclone cache is out of control! \u00b6 If the bulk of the space is in your rclone VFS cache, you\u2019ll want to check the vfs_cache configuration for all your mounts to control this. Perhaps you used a copy-pasted config that is setting the max cache to 200G or so, and applied that to four mounts. That means your rclone cache might grow to 800GB, so adjust the configs on the mounts you're caching. Don\u2019t just delete the existing cached files. You\u2019ll need to stop the mounts first before you adjust the cache sizes.","title":"Why is my disk full?"},{"location":"reference/guides/chazguides/disk-full/#why-is-my-disk-full","text":"First, a quick refresher on how the system works: Your downloader puts files in /mnt/local/downloads . Sonarr/Radarr move [usenet] or copy [default torrent] these files to /mnt/local/Media . [They\u2019re actually moving files to /mnt/unionfs/Media , but the mergerfs config routes them in /mnt/local/Media ] Once /mnt/local/Media hits 200GB, cloudplow uploads the contents to your cloud drive. Once that\u2019s complete they will show up in /mnt/remote/Media as well as /mnt/unionfs/Media . Chances are, if your disk is full, the cause is one of two things: Sonarr/Radarr are not importing downloaded media Cloudplow isn't uploading things to the cloud. If you are using rclone\u2019s --vfs-cache=full, then there\u2019s a third likely cause: Your rclone vfs cache is filling your disk This is written assuming Usenet downloads, so filling your disks with seeding torrents isn't covered. You can use these tools to find out if that's the issue, though.","title":"Why is my disk full?"},{"location":"reference/guides/chazguides/disk-full/#where-is-the-space-going","text":"The first step is to find out where the space is going on your disk; which directories contain all the files. At a command prompt, type: sudo ncdu -x --exclude /opt/plex / What\u2019s that command? sudo run with root privileges ncdu show graphic display of disk usage -x don\u2019t cross filesystem boundaries [this will show only local space used and won't cross over to remote file systems like your google drive] --exclude /opt/plex ignore this directory; it\u2019s full of thousands of tiny files that take forever to scan and MOST LIKELY you\u2019re not going to want to delete anything from here. / starting point of scan You'll probably see something like this: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- / ------------------------------------------------------ 558.0 GiB [##########] /mnt 20.9 GiB [ ] /var 3.5 GiB [ ] /usr Drill into /mnt/local: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- /mnt/local --------------------------------------------- /.. 472.9 GiB [##########] /downloads 43.9 GiB [ ] /Media 37.5 GiB [ ] /Backups 3.7 GiB [ ] /transcodes Here, I have 473 GB of unimported downloads and 44 GB waiting to be uploaded by Cloudplow. Rclone vfs cache is more install-dependent. I\u2019m going to assume that if you\u2019re reading this you didn\u2019t change things from the defaults, and chances are you\u2019ll see something like this: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help ------------------------------------------------------------ 252.3 GiB [##########] /home 119.6 GiB [#### ] /mnt 29.5 GiB [# ] /var 3.4 GiB [ ] /usr Drill into /home/YOUR_USERNAME/: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- /home/seed --------------------------------------------- /.. 203.0 GiB [##########] /.cache 37.9 MiB [ ] /.pkg-cache 34.5 MiB [ ] /.npm And further into .cache/rclone: ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- /home/seed/.cache/rclone ------------------------------- /.. 202.9 GiB [##########] /vfs 4.8 MiB [ ] /vfsMeta 16.0 KiB [ ] /webgui That\u2019s your VFS cache.","title":"Where is the space going?"},{"location":"reference/guides/chazguides/disk-full/#radarrsonarr-didnt-import-stuff","text":"Drill into downloads to examine what's there in more detail. Chances are you\u2019ll find /mnt/local/nzbs/nzbget/downloads/completed is where all the files are. Those are downloads that Radarr/Sonarr didn\u2019t import. Use Wanted -> Manual Import to find out why particular things weren't imported. Perhaps Radarr couldn\u2019t work out what movie a thing was: Maybe it doesn\u2019t look like an upgrade for one reason or another: That same information is also available in the logs. You can import things from here after telling Radarr what movie it is or the like, or you can delete them from within ncdu or via whatever other means.","title":"Radarr/Sonarr didn\u2019t import stuff!"},{"location":"reference/guides/chazguides/disk-full/#cloudplow-isnt-uploading-stuff","text":"If the bulk of the space is in staged-for-upload files sitting in /mnt/local/Media , then cloudplow hasn\u2019t uploaded those files yet. This is typically due to one of the following: Upload threshold hasn\u2019t been reached. You\u2019ve reached the Google Drive upload cap of 750GB/day The default threshold to start a Google upload is 200GB, so in my case above cloudplow wouldn\u2019t do anything until 150GB more gets put into /mnt/local/Media . At a command prompt, type: tail /opt/cloudplow/cloudplow.log You should see something like: Uploader: google. Local folder size is currently 44 GB. Still have 156 GB remaining before its eligible to begin uploading... If you do, cloudplow is working as expected. If you want cloudplow to start uploading stuff sooner, you can adjust those thresholds in your cloudplow config file. At the bottom of /opt/cloudplow/config.json , you\u2019ll find something like this: \"google\": { \"check_interval\": 30, \"exclude_open_files\": true, \"max_size_gb\": 200, \"opened_excludes\": [ \"/downloads/\" ], \"service_account_path\": \"\", \"size_excludes\": [ \"downloads/*\" ] } That\u2019s going to check every 30 minutes, and start uploading when the folder reaches 200GB. Adjust those values to suit your use case. Restart the cloudplow service if you make changes here. In the default setup, you can upload 750GB per day. To see if you\u2019ve hit that quota, run a cloudplow upload manually. At a command prompt, type: cloudplow upload This will kick off an upload without regard for the threshold. You can run this anytime you want to upload whatever\u2019s pending right this very minute. PAY ATTENTION TO WHAT THE LOG SAYS. The errors should let you know what\u2019s going on. If you want more detail: cloudplow upload --loglevel=DEBUG You'll get a great deal of information about what cloudplow is doing and why. If you find yourself hitting that 750GB cap regularly, you may want to set up service-account uploading .","title":"Cloudplow isn\u2019t uploading stuff!"},{"location":"reference/guides/chazguides/disk-full/#rclone-cache-is-out-of-control","text":"If the bulk of the space is in your rclone VFS cache, you\u2019ll want to check the vfs_cache configuration for all your mounts to control this. Perhaps you used a copy-pasted config that is setting the max cache to 200G or so, and applied that to four mounts. That means your rclone cache might grow to 800GB, so adjust the configs on the mounts you're caching. Don\u2019t just delete the existing cached files. You\u2019ll need to stop the mounts first before you adjust the cache sizes.","title":"Rclone cache is out of control!"},{"location":"reference/guides/chazguides/home-server/","text":"Installing Saltbox on a home server \u00b6 This article discusses details to consider when running Saltbox on a home server behind a residential router. It's not meant to replace the existing install documentation. Things here may not be discussed in sequence, as it's not intended as an install guide. For that, refer to the install guide on the menu bar above. Prerequisites: Domain Static IP OR Dynamic DNS configured ISP supports you running servers on ports 80 and 443. Some ISPs don\u2019t allow or actively block this. Router supports port forwarding and hairpin NAT (or NAT loopback) Saltbox assumes that you are accessing apps via subdomains like \u201cradarr.mydomain.com\u201d rather than ip and port like 192.168.1.25:7878. Without \u201chairpin NAT\u201d, a request to \u201cradarr.mydomain.com\u201d from inside the network will not find its way to the proxy which does that routing. NOTE: None of this initial setup is Saltbox-specific. If you want to run a server on a machine behind your router and connect to it using a domain name, whether Saltbox sets it up or something else, you\u2019ll need to do these very same things. Domain: \u00b6 You need a domain. They\u2019re cheap or even free. You can find cheap ones here . There are a variety of places that provide free domains. Here\u2019s one offered with no endorsement; the first Google result for \u201cfree domain\u201d . Configure the DNS at your registrar to point your domain at your home external IP address. You can find your home external IP address using something like: https://whatismyipaddress.com/ Dynamic DNS: \u00b6 You will need to configure \u201cdynamic DNS\u201d to make sure that domain keeps pointing to your home IP, which is subject to change, most likely. When you set up a server in a data center, typically that server has a fixed unchanging IP address, so you set up DNS one time. Most residential internet connections do not get a fixed address; your home IP will change periodically. \"Dynamic DNS\" updates your DNS setup whenever your IP address changes, ensuring that \"myhomeaddress.com\" always points at the correct IP address. Probably your router has this available. If not, there\u2019s a Dynamic DNS Client role available in saltbox you can install. If you use Cloudflare for DNS, the ddns client configuration will be automatically done for you when you run the role. The saltbox role is ddclient , and you run it like any other saltbox role: sb install ddclient You\u2019ll do this AFTER you\u2019ve installed saltbox. Router: \u00b6 Port Forwarding: \u00b6 You need some ports forwarded to that machine on your router. Explaining how to do that for any arbitrary router is out of scope, but I\u2019ll show you where it is on my Netgear. Port forwarding is rather like ordering a pizza at a fancy hotel rather than at home. When I order a pizza at home, the delivery comes right to my door; when I order a pizza at a fancy hotel, the delivery arrives at the front door of the hotel, and the front desk clerk has to make sure it gets routed to the correct room. A remote server like one at Hetzner is just exposed to the open internet, so when you connect to that server on port 123, you\u2019re connecting directly to that specific machine. This is the \"pizza at home\" scenario. Your home network doesn\u2019t work like that. Your ISP gives you a single IP address, and your router translates all traffic in and out of your network to make sure it gets to the correct place. This is the \"pizza at a fancy hotel\" scenario. This means that when a connection from the outside comes in, it is connecting to the router, not any individual machine. You need to set up port forwarding so that when you try to connect to Radarr, for example, your router knows to send this request to the machine where you\u2019ve installed Radarr. There are two parts to what you need to do: Give your server an unchanging local IP address Forward requests from the outside on relevant ports to that IP address. The first is required because typically your router will be able to configure port forwarding to an IP address, so you don\u2019t want the IP of your server changing. Typically, on your router, everything gets an IP assigned automatically by the router\u2019s DHCP server, so the IP address of a specific thing might change. Depending on how your network is set up, it may be unlikely, but it\u2019s a possibility nonetheless, so we\u2019re going to make sure it doesn\u2019t happen by telling the router \u201cAlways give this machine the IP address 1.2.3.4\u201d. On my Netgear, they call this \u201cAddress Reservation\u201d and it\u2019s found under \u201cLAN Setup\u201d: I scroll to the end of that list, click \u201cAdd\u201d, then choose a device and type in the address I want that thing to have. The server I\u2019m installing Saltbox on is \u201crandom\u201d, and I\u2019ve assigned it 192.168.1.11. Next, port forwarding: You can see here that I\u2019ve set it such that outside requests to port 80, 443, 3526, and 3468 get forwarded on to the IP we just assigned to the saltbox server. Note this example assumes you have not modified either the SSH listening port or the plex-autoscan listening port on the Saltbox machine. If you have done, then you should forward to the relevant ports instead of to 22 and 3468. Depending on the applications you end up installing, you may need to forward other ports. That example covers the reverse proxy (80 $ 443), ssh (3526), and Plex-Autoscan (3468). Ports used by the stock saltbox apps can be found here . Warning If your ISP does not allow you to do this, STOP NOW. You won\u2019t be able to run saltbox at home. Port Forward Testing: \u00b6 At this point, you should be able to SSH to that machine using your domain. ssh YOU@YOUR_DOMAIN -p 2207 That should work just like: ssh YOU@192.168.X.Y If it doesn\u2019t, verify all the port-forwarding details. You should also be able to connect to a web server running on that machine. Let's test that. Verify this part is working by installing apache on your server: sudo apt install apache2 Then open a web browser and go to your domain [http://yourdomain.tld] . Maybe use your phone with wifi off to make sure the request is coming from outside your house. If you see the default apache page, you\u2019re set to go. Once verified, remove apache: sudo apt remove apache2 Warning You MUST remove apache before installing saltbox With that done, we can move on to the install. Warning IF THAT DOESN\u2019T WORK, DON\u2019T CONTINUE UNTIL IT DOES. Verify your port forwarding setup and try again. Verify that your ISP allows this. Narrated example install \u00b6 From this point on there is nothing special about the install process on this home server as opposed to a remote server. I\u2019m just following the docs. This is just an example of the install. You should refer to the actual install docs . I installed Ubuntu server 20.04 on the machine, accepting all defaults except: I enabled OpenSSH and imported my SSH keys from github That\u2019s all. Since I installed Ubuntu on my own hardware, the first user I created is a member of the sudoers group. I\u2019ll be running the install as that user from the start rather than starting as root like you would on a remote server. First, I set up the post forwards and the like as detailed above. I ran the first dependency script on this page . That ran for a while and finished without errors. In my accounts.yml , I\u2019m entering an existing account on the ubuntu machine [this is the account I created when I installed Ubuntu]: - user: name: chaz pass: REDACTED domain: domain.tld email: chaz@chazlarson.com plex: user: REDACTED pass: REDACTED tfa: no cloudflare: email: REDACTED api: REDACTED pushover: app_token: user_key: priority: apprise: dockerhub: user: token: I entered my cloudflare credentials because DNS for the domain I\u2019m using is set up there, so the saltbox install is going to create the subdomains for me. I made no changes to settings.yml . Run the preinstall: sb install preinstall In my case there were no kernel updates required, so the preinstall didn\u2019t reboot. I am already logged in as the user I specified in accounts.yml , so I didn\u2019t have to log out of the root account and log back in as chaz . If you specified a new account that the preinstall created, you need to log out and log in as that account. I then set up the rclone remote as usual. Next, I ran saltbox setup: sb install saltbox In my case the setup ran through without problems the first time: PLAY RECAP ******************************************************************************************************** localhost : ok=787 changed=197 unreachable=0 failed=0 skipped=329 rescued=0 ignored=0 Friday 18 February 2022 15:15:15 -0600 (0:00:02.386) 0:33:08.898 ******* =============================================================================== user : User Account | Reset ownership of '/opt/' path ----------------------------------------------------- 651.36s system : APT | APT full-upgrade --------------------------------------------------------------------------- 226.68s docker : Binary | Get 'Docker CE CLI' version ------------------------------------------------------------- 121.57s unionfs : Docker | Daemon | Restart docker service -------------------------------------------------------- 121.49s unionfs : Docker | Containers Stop | Stop all running Docker containers ----------------------------------- 109.26s docker : Wait for 60 seconds before commencing ------------------------------------------------------------ 60.49s unionfs : Docker | Daemon | Wait for 30 seconds before commencing ----------------------------------------- 30.33s iperf3 : Build and install iperf3 ------------------------------------------------------------------------- 19.05s plex_extra_tasks : Stop Docker Container ------------------------------------------------------------------ 16.10s docker : Re-start all previously running Docker containers ------------------------------------------------ 15.95s system : APT | Remove dependencies that are no longer required -------------------------------------------- 15.61s unionfs : Docker | Containers Start | Start all previously running Docker containers ---------------------- 15.58s docker : Stop docker service ------------------------------------------------------------------------------ 14.77s plex_extra_tasks : Post-Install Checks | Wait for Plex executable to be created --------------------------- 11.76s remote : Rclone VFS | Start 'rclone_vfs.service' ---------------------------------------------------------- 11.41s traefik : Resources | Tasks | Docker | Remove Docker Container | Remove Docker Container ------------------ 11.28s nzbget : Post-Install | Wait for 10 seconds --------------------------------------------------------------- 10.25s plex : Resources | Tasks | Docker | Remove Docker Container | Remove Docker Container --------------------- 10.05s system : Populate Service Facts --------------------------------------------------------------------------- 9.70s rutorrent : Resources | Tasks | Docker | Remove Docker Container | Remove Docker Container ---------------- 7.45s Now I did one last log out and back in so I could access the docker command. At this point, everything is running and I\u2019m ready to go through the application setup.","title":"Installing Saltbox on a home server"},{"location":"reference/guides/chazguides/home-server/#installing-saltbox-on-a-home-server","text":"This article discusses details to consider when running Saltbox on a home server behind a residential router. It's not meant to replace the existing install documentation. Things here may not be discussed in sequence, as it's not intended as an install guide. For that, refer to the install guide on the menu bar above. Prerequisites: Domain Static IP OR Dynamic DNS configured ISP supports you running servers on ports 80 and 443. Some ISPs don\u2019t allow or actively block this. Router supports port forwarding and hairpin NAT (or NAT loopback) Saltbox assumes that you are accessing apps via subdomains like \u201cradarr.mydomain.com\u201d rather than ip and port like 192.168.1.25:7878. Without \u201chairpin NAT\u201d, a request to \u201cradarr.mydomain.com\u201d from inside the network will not find its way to the proxy which does that routing. NOTE: None of this initial setup is Saltbox-specific. If you want to run a server on a machine behind your router and connect to it using a domain name, whether Saltbox sets it up or something else, you\u2019ll need to do these very same things.","title":"Installing Saltbox on a home server"},{"location":"reference/guides/chazguides/home-server/#domain","text":"You need a domain. They\u2019re cheap or even free. You can find cheap ones here . There are a variety of places that provide free domains. Here\u2019s one offered with no endorsement; the first Google result for \u201cfree domain\u201d . Configure the DNS at your registrar to point your domain at your home external IP address. You can find your home external IP address using something like: https://whatismyipaddress.com/","title":"Domain:"},{"location":"reference/guides/chazguides/home-server/#dynamic-dns","text":"You will need to configure \u201cdynamic DNS\u201d to make sure that domain keeps pointing to your home IP, which is subject to change, most likely. When you set up a server in a data center, typically that server has a fixed unchanging IP address, so you set up DNS one time. Most residential internet connections do not get a fixed address; your home IP will change periodically. \"Dynamic DNS\" updates your DNS setup whenever your IP address changes, ensuring that \"myhomeaddress.com\" always points at the correct IP address. Probably your router has this available. If not, there\u2019s a Dynamic DNS Client role available in saltbox you can install. If you use Cloudflare for DNS, the ddns client configuration will be automatically done for you when you run the role. The saltbox role is ddclient , and you run it like any other saltbox role: sb install ddclient You\u2019ll do this AFTER you\u2019ve installed saltbox.","title":"Dynamic DNS:"},{"location":"reference/guides/chazguides/home-server/#router","text":"","title":"Router:"},{"location":"reference/guides/chazguides/home-server/#port-forwarding","text":"You need some ports forwarded to that machine on your router. Explaining how to do that for any arbitrary router is out of scope, but I\u2019ll show you where it is on my Netgear. Port forwarding is rather like ordering a pizza at a fancy hotel rather than at home. When I order a pizza at home, the delivery comes right to my door; when I order a pizza at a fancy hotel, the delivery arrives at the front door of the hotel, and the front desk clerk has to make sure it gets routed to the correct room. A remote server like one at Hetzner is just exposed to the open internet, so when you connect to that server on port 123, you\u2019re connecting directly to that specific machine. This is the \"pizza at home\" scenario. Your home network doesn\u2019t work like that. Your ISP gives you a single IP address, and your router translates all traffic in and out of your network to make sure it gets to the correct place. This is the \"pizza at a fancy hotel\" scenario. This means that when a connection from the outside comes in, it is connecting to the router, not any individual machine. You need to set up port forwarding so that when you try to connect to Radarr, for example, your router knows to send this request to the machine where you\u2019ve installed Radarr. There are two parts to what you need to do: Give your server an unchanging local IP address Forward requests from the outside on relevant ports to that IP address. The first is required because typically your router will be able to configure port forwarding to an IP address, so you don\u2019t want the IP of your server changing. Typically, on your router, everything gets an IP assigned automatically by the router\u2019s DHCP server, so the IP address of a specific thing might change. Depending on how your network is set up, it may be unlikely, but it\u2019s a possibility nonetheless, so we\u2019re going to make sure it doesn\u2019t happen by telling the router \u201cAlways give this machine the IP address 1.2.3.4\u201d. On my Netgear, they call this \u201cAddress Reservation\u201d and it\u2019s found under \u201cLAN Setup\u201d: I scroll to the end of that list, click \u201cAdd\u201d, then choose a device and type in the address I want that thing to have. The server I\u2019m installing Saltbox on is \u201crandom\u201d, and I\u2019ve assigned it 192.168.1.11. Next, port forwarding: You can see here that I\u2019ve set it such that outside requests to port 80, 443, 3526, and 3468 get forwarded on to the IP we just assigned to the saltbox server. Note this example assumes you have not modified either the SSH listening port or the plex-autoscan listening port on the Saltbox machine. If you have done, then you should forward to the relevant ports instead of to 22 and 3468. Depending on the applications you end up installing, you may need to forward other ports. That example covers the reverse proxy (80 $ 443), ssh (3526), and Plex-Autoscan (3468). Ports used by the stock saltbox apps can be found here . Warning If your ISP does not allow you to do this, STOP NOW. You won\u2019t be able to run saltbox at home.","title":"Port Forwarding:"},{"location":"reference/guides/chazguides/home-server/#port-forward-testing","text":"At this point, you should be able to SSH to that machine using your domain. ssh YOU@YOUR_DOMAIN -p 2207 That should work just like: ssh YOU@192.168.X.Y If it doesn\u2019t, verify all the port-forwarding details. You should also be able to connect to a web server running on that machine. Let's test that. Verify this part is working by installing apache on your server: sudo apt install apache2 Then open a web browser and go to your domain [http://yourdomain.tld] . Maybe use your phone with wifi off to make sure the request is coming from outside your house. If you see the default apache page, you\u2019re set to go. Once verified, remove apache: sudo apt remove apache2 Warning You MUST remove apache before installing saltbox With that done, we can move on to the install. Warning IF THAT DOESN\u2019T WORK, DON\u2019T CONTINUE UNTIL IT DOES. Verify your port forwarding setup and try again. Verify that your ISP allows this.","title":"Port Forward Testing:"},{"location":"reference/guides/chazguides/home-server/#narrated-example-install","text":"From this point on there is nothing special about the install process on this home server as opposed to a remote server. I\u2019m just following the docs. This is just an example of the install. You should refer to the actual install docs . I installed Ubuntu server 20.04 on the machine, accepting all defaults except: I enabled OpenSSH and imported my SSH keys from github That\u2019s all. Since I installed Ubuntu on my own hardware, the first user I created is a member of the sudoers group. I\u2019ll be running the install as that user from the start rather than starting as root like you would on a remote server. First, I set up the post forwards and the like as detailed above. I ran the first dependency script on this page . That ran for a while and finished without errors. In my accounts.yml , I\u2019m entering an existing account on the ubuntu machine [this is the account I created when I installed Ubuntu]: - user: name: chaz pass: REDACTED domain: domain.tld email: chaz@chazlarson.com plex: user: REDACTED pass: REDACTED tfa: no cloudflare: email: REDACTED api: REDACTED pushover: app_token: user_key: priority: apprise: dockerhub: user: token: I entered my cloudflare credentials because DNS for the domain I\u2019m using is set up there, so the saltbox install is going to create the subdomains for me. I made no changes to settings.yml . Run the preinstall: sb install preinstall In my case there were no kernel updates required, so the preinstall didn\u2019t reboot. I am already logged in as the user I specified in accounts.yml , so I didn\u2019t have to log out of the root account and log back in as chaz . If you specified a new account that the preinstall created, you need to log out and log in as that account. I then set up the rclone remote as usual. Next, I ran saltbox setup: sb install saltbox In my case the setup ran through without problems the first time: PLAY RECAP ******************************************************************************************************** localhost : ok=787 changed=197 unreachable=0 failed=0 skipped=329 rescued=0 ignored=0 Friday 18 February 2022 15:15:15 -0600 (0:00:02.386) 0:33:08.898 ******* =============================================================================== user : User Account | Reset ownership of '/opt/' path ----------------------------------------------------- 651.36s system : APT | APT full-upgrade --------------------------------------------------------------------------- 226.68s docker : Binary | Get 'Docker CE CLI' version ------------------------------------------------------------- 121.57s unionfs : Docker | Daemon | Restart docker service -------------------------------------------------------- 121.49s unionfs : Docker | Containers Stop | Stop all running Docker containers ----------------------------------- 109.26s docker : Wait for 60 seconds before commencing ------------------------------------------------------------ 60.49s unionfs : Docker | Daemon | Wait for 30 seconds before commencing ----------------------------------------- 30.33s iperf3 : Build and install iperf3 ------------------------------------------------------------------------- 19.05s plex_extra_tasks : Stop Docker Container ------------------------------------------------------------------ 16.10s docker : Re-start all previously running Docker containers ------------------------------------------------ 15.95s system : APT | Remove dependencies that are no longer required -------------------------------------------- 15.61s unionfs : Docker | Containers Start | Start all previously running Docker containers ---------------------- 15.58s docker : Stop docker service ------------------------------------------------------------------------------ 14.77s plex_extra_tasks : Post-Install Checks | Wait for Plex executable to be created --------------------------- 11.76s remote : Rclone VFS | Start 'rclone_vfs.service' ---------------------------------------------------------- 11.41s traefik : Resources | Tasks | Docker | Remove Docker Container | Remove Docker Container ------------------ 11.28s nzbget : Post-Install | Wait for 10 seconds --------------------------------------------------------------- 10.25s plex : Resources | Tasks | Docker | Remove Docker Container | Remove Docker Container --------------------- 10.05s system : Populate Service Facts --------------------------------------------------------------------------- 9.70s rutorrent : Resources | Tasks | Docker | Remove Docker Container | Remove Docker Container ---------------- 7.45s Now I did one last log out and back in so I could access the docker command. At this point, everything is running and I\u2019m ready to go through the application setup.","title":"Narrated example install"},{"location":"reference/guides/chazguides/no-media/","text":"I can\u2019t see my media! \u00b6 [in Plex, Emby, Radarr, Sonarr, etc] Usually this is a simple problem, but there are several places where it could be. There are several layers between your Google Drive and Plex [or other app]. rclone remote, which provides the link to your Google Drive. This is where you sign into your Google account. rclone_vfs service, which makes that rclone remote visible at /mnt/remote mergerfs service which combines that mount point with a local \u201cstaging\u201d directory at /mnt/unionfs . mapping of the mergerfs into the various docker containers. If any layer is having problems, Plex isn\u2019t going to see your media. For purposes of these notes, I\u2019m assuming your setup is based on the current standard Saltbox configuration: rclone remote is mounted via rclone_vfs /mnt/unionfs directory is created using merger_fs I\u2019m further assuming that you are using the default file structure as suggested in the Saltbox wiki. See the end of this doc for some notes on how to tell if 1 and 2 are true. MY FOLDERS AND FILES IN THESE SCREENSHOTS WILL NOT MATCH YOURS. THAT\u2019S FINE AND EXPECTED. When I refer to a shell command throughout, you\u2019re typing the part highlighted in blue and looking for the part highlighted in orange. In most cases, running the mounts tag will clear up any problems you may be having with the various auto-generated service files. sb install mounts A quick look \u00b6 The df command can give you a quick look at things: \u279c ~ df -h Filesystem Size Used Avail Use% Mounted on ... local:remote 6.1P 107T 224G 100% /mnt/unionfs google: 1.0P 107T 1.0P 10% /mnt/remote \u279c ~ That shows a device called \u201cgoogle\u201d [created by rclone config] mounted at /mnt/remote [done by rclone_vfs.service], and then two directories [local and remote, which are both inside the /mnt directory] combined into /mnt/unionfs [that\u2019s done by mergerfs.service] If this looks good, your problem is most likely in the bind mounts within the containers. Now we\u2019ll step through the various layers involved in this and check them one at a time. rclone remote \u00b6 The rclone config command should show you the google remote you defined during setup: \u279c ~ rclone config Current remotes: Name Type ==== ==== google drive e) Edit existing remote ... e/n/d/r/c/s/q> q You should be able to get a file listing from that remote: \u279c ~ rclone lsd google:/Media -1 2018-12-01 20:16:06 -1 Music -1 2019-03-15 19:26:14 -1 Movies -1 2018-12-01 20:14:35 -1 TV \u279c ~ That file listing should match what\u2019s displayed on the Google Drive website. If you've used the Saltbox scripted setup, those directories witll be spread across the three shared drives that get created. Yours will probably contain \u201cMovies\u201d and \u201cTV\u201d. If it doesn\u2019t, step one is to fix that. Recreate or edit that google: rclone remote until the file listings match. If you've used the Saltbox scripted setup, examine the three shared drive remotes; the google remote is just a union of those. Do not continue until those two file listings match. They won\u2019t match mine; they should both show the same files from YOUR gdrive. Now that the rclone remote is known good, let\u2019s move to the next layer, the rclone_vfs mount. rclone_vfs mount \u00b6 First, let\u2019s check that the service is running: \u279c ~ sudo systemctl status rclone_vfs.service \u25cf rclone_vfs.service - Rclone VFS Mount Loaded: loaded (/etc/systemd/system/rclone_vfs.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2019-11-02 06:45:34 EET; 10h ago Process: 1053 ExecStartPre=/bin/sleep 10 (code=exited, status=0/SUCCESS) Main PID: 1247 (rclone) Tasks: 23 (limit: 4915) CGroup: /system.slice/rclone_vfs.service \u2514\u25001247 /usr/bin/rclone mount --config=/home/seed/.config/rclone/rclone.conf --user-agent . . . Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting Rclone VFS Mount... Nov 02 06:45:34 Ubuntu-1804-bionic-64-minimal rclone[1247]: Serving remote control on http://127.0.0.1:5572/ Nov 02 06:45:34 Ubuntu-1804-bionic-64-minimal systemd[1]: Started Rclone VFS Mount. You want to see \u201c active (running) \u201d there. You can look at the log to find out what\u2019s wrong if it\u2019s not \u201c active (running) \u201d \u279c ~ sudo journalctl -fu rclone_vfs.service -- Logs begin at Mon 2019-08-05 16:56:44 EEST. -- Nov 02 06:42:44 Ubuntu-1804-bionic-64-minimal rclone[9625]: Serving remote control on http://127.0.0.1:5572/ Nov 02 06:42:44 Ubuntu-1804-bionic-64-minimal systemd[1]: Started Rclone VFS Mount. Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopping Rclone VFS Mount... Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal rclone[9625]: Fatal error: failed to umount FUSE fs: exit status 1: fusermount: entry for /mnt/remote not found in /etc/mtab Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: rclone_vfs.service: Main process exited, code=exited, status=1/FAILURE Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: rclone_vfs.service: Failed with result 'exit-code'. Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopped Rclone VFS Mount. -- Reboot -- Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting Rclone VFS Mount... Nov 02 06:45:34 Ubuntu-1804-bionic-64-minimal rclone[1247]: Serving remote control on http://127.0.0.1:5572/ Nov 02 06:45:34 Ubuntu-1804-bionic-64-minimal systemd[1]: Started Rclone VFS Mount. In that log you can see an error from last night when my server ran out of disk space, the rclone_vfs service died, then a reboot [after clearing space] and it came back up. If there are errors there, first try restarting the service: sudo systemctl restart rclone_vfs If that doesn\u2019t get you to an \u201c active (running) \u201d state, try a reboot of the machine. If that doesn\u2019t work, the problem is deeper; maybe a config problem or a failed install? Read the log. Chances are the specific problem is called out [missing directory, perhaps]. You\u2019re running a server. Learn to read logs. If all fails, take the log information to the Discord, but be prepared to describe what you\u2019ve done and provide details. Don\u2019t come in with \u201cShit\u2019s busted, my dudes! What\u2019s wrong?\u201d Now that the service is running, let\u2019s make sure the files are showing up where they are supposed to be. You can extract the location where the rclone_vfs service is mounting your google storage with a quick egrep command: \u279c ~ egrep -i -e \"/mnt/\" /etc/systemd/system/rclone_vfs.service google: /mnt/remote ExecStop=/bin/fusermount -uz /mnt/remote You can see in that output that rclone_vfs is mounting your google: remote at /mnt/remote. That means that the content of your google drive should also appear at that location. Let\u2019s check that: \u279c ~ ls -al /mnt/remote/Media total 0 drwxrwxr-x 1 seed seed 0 Dec 1 2018 Music drwxrwxr-x 1 seed seed 0 Mar 15 2019 Movies drwxrwxr-x 1 seed seed 0 Dec 1 2018 TV \u279c ~ Note that that matches the file listing from the Google Drive web UI above. If it doesn\u2019t, there\u2019s a problem running the rclone_vfs.service. Perhaps try running the mounts tag. Do not continue until those two file listings match. They won\u2019t match mine; they should both show the same files from YOUR gdrive. We\u2019ve established that the rclone remote is good, and the rclone_vfs service is mounting it as a file system at the expected location. The next step is the mergerfs mount where all the apps look for your files. Mergerfs service \u00b6 Just like we did with the rclone_vfs service, check the mergerfs status: \u279c ~ sudo systemctl status mergerfs.service \u25cf mergerfs.service - MergerFS Mount Loaded: loaded (/etc/systemd/system/mergerfs.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2019-11-02 06:45:24 EET; 11h ago Process: 1034 ExecStart=/usr/bin/mergerfs -o category.create=ff,minfreespace=0,allow_other -o dropcacheonclose=true,security_capability=false,xattr=nosys -o statfs_ignore=ro,use_ino,auto_ Tasks: 9 (limit: 4915) CGroup: /system.slice/mergerfs.service \u2514\u25001074 /usr/bin/mergerfs -o category.create=ff,minfreespace=0,allow_other -o dropcacheonclose=true,security_capability=false,xattr=nosys -o statfs_ignore=ro,use_ino,auto_cache,um Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount... Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount. As before, if not \u201c active (running) \u201d, you can check the mergerfs log for some clue: \u279c ~ sudo journalctl -fu mergerfs.service -- Logs begin at Mon 2019-08-05 16:56:44 EEST. -- Oct 13 17:00:11 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount... Oct 13 17:00:11 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount. -- Reboot -- Nov 02 06:42:54 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopping MergerFS Mount... Nov 02 06:42:56 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopped MergerFS Mount. Nov 02 06:43:06 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount... Nov 02 06:43:06 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount. Nov 02 06:44:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopping MergerFS Mount... Nov 02 06:44:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopped MergerFS Mount. -- Reboot -- Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount... Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount. If everything looks good, you can check the contents of the filesystem: \u279c ~ ls -al /mnt/unionfs/Media total 0 drwxrwxr-x 1 seed seed 120 Sep 28 18:32 . drwxrwxr-x 1 seed seed 62 Sep 28 18:31 .. drwxrwxr-x 1 seed seed 338 Oct 18 20:21 Music drwxrwxr-x 1 seed seed 78 May 3 2019 Movies drwxrwxr-x 1 seed seed 28196 Nov 2 01:42 TV \u279c ~ Again, this should match all the file listings you\u2019ve looked at so far, at least. There may be some extra folders here depending on a variety of things; other mounts that are included in the mergerfs and so forth. Probably not, given my assumption that you are using the default configuration. Do not continue until those two file listings match. They won\u2019t match mine; they should both show the same files from YOUR gdrive. So at this point we know that all the layers on the host are working, so the last step is to check the views inside the containers. Docker volume maps \u00b6 All the docker containers that need to access your media files have the relevant directories mapped inside them. You can have a look at specifically how with the docker inspect command: \u279c ~ docker inspect plex | head -n 90 [ { \"Id\": \"070d5fc16d4372156c39a6cf2923e6edb2e8576817cbcf9b6432f88f2237a2e8\", \"Created\": \"2019-10-16T19:45:29.93111423Z\", \"Path\": \"/init\", \"Args\": [], \"State\": { \"Status\": \"running\", ... \"HostConfig\": { \"Binds\": [ \"/tmp:/tmp:rw\", \"/mnt/local/transcodes/plex:/transcode:rw\", \"/opt/plex:/config:rw\", \"/mnt:/mnt:rw\", \"/opt/scripts:/scripts:rw\", \"/dev/shm:/dev/shm:rw\" ], ... \u279c ~ I\u2019ve trimmed some stuff out there particularly on the top]. If the \u201cBinds\u201d section isn\u2019t visible, try scrolling up, or increase the \u201c90\u201d to display more lines. It should be right around the same place as mine, though. Take a look at the \u201c Binds \u201d section. Each entry there shows a path on the host [on the left] and the location where those files appear inside the container. Media-related defaults: \u00b6 Container/Application INSIDE CONTAINER ON HOST sonarr /mnt /mnt radarr /mnt /mnt lidarr /mnt /mnt plex /mnt /mnt Let\u2019s check that in Plex: \u279c ~ docker exec plex ls -al /mnt/unionfs/Media total 4 drwxrwxr-x 1 plex plex 120 Sep 28 18:32 . drwxr-xr-x 1 root root 4096 Oct 16 22:45 .. drwxrwxr-x 1 plex plex 338 Oct 18 20:21 Music drwxrwxr-x 1 plex plex 78 May 3 2019 Movies drwxrwxr-x 1 plex plex 28196 Nov 2 01:42 TV Again, all the same files as always. If that doesn\u2019t show your files as expected, chances are something happened to the mounts while the container was running and the map has broken. First restart the container and if that doesn\u2019t work restart the server. \u279c ~ docker restart plex plex \u279c ~ Then try the \u201c docker exec plex ls -al /mnt/unionfs/Media \u201d command again. Some common problems are: /mnt/unionfs not empty when the mergerfs service starts. The log in that case will look something like this: ubuntu systemd[1]: Starting MergerFS Mount... Ubuntu mergerfs[10803]: fuse: mountpoint is not empty ubuntu mergerfs[10803]: fuse: if you are sure this is safe, use the 'nonempty' mount option ubuntu systemd[1]: mergerfs.service: Control process exited, code=exited status=1 ubuntu systemd[1]: mergerfs.service: Failed with result 'exit-code'. ubuntu systemd[1]: Failed to start MergerFS Mount. If you see this, rerunning the mounts tag, with or without rebuild, actually checks for non empty paths left there as part of a previous failure, and moves the folder to /mnt/unionfs_<date> before mounting again. sb install mounts If this is the result of something writing into that directory while the mergerfs service was down, the mounts tag won\u2019t address it. You\u2019ll have to clean out /mnt/unionfs yourself first. HOW DO I KNOW IF I AM USING RCLONE_VFS AND MERGERFS? \u00b6 There are a few things you can look at: In the following examples, you\u2019re typing the part in blue and looking for the part highlighted in orange. Look at the settings file: \u279c saltbox git:(master) head adv_settings.yml --- System: timezone: auto Mounts: unionfs: mergerfs <<<< RIGHT remote: rclone_vfs <<<< HERE Plex: open_port: no force_auto_adjust_quality: no force_high_output_bitrates: no \u279c saltbox git:(master) Check the status of the services \u279c ~ service rclone_vfs status \u25cf rclone_vfs.service - Rclone VFS Mount Loaded: loaded (/etc/systemd/system/rclone_vfs.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2019-06-16 22:41:58 EEST; 1 day 18h ago \u2026 \u279c ~ service mergerfs status \u25cf mergerfs.service - MergerFS Mount Loaded: loaded (/etc/systemd/system/mergerfs.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2019-06-16 22:41:48 EEST; 1 day 18h ago \u2026 If you\u2019re not using either rclone_vfs or mergerfs you\u2019ll see errors there instead. Check the filesystem behind the mounts: \u279c ~ sudo mount | egrep \"remote\" local:remote on /mnt/unionfs type fuse.mergerfs \u2026 <<<< Mergerfs google: on /mnt/remote type fuse.rclone \u2026 <<<< RClone","title":"I can't see my media!"},{"location":"reference/guides/chazguides/no-media/#i-cant-see-my-media","text":"[in Plex, Emby, Radarr, Sonarr, etc] Usually this is a simple problem, but there are several places where it could be. There are several layers between your Google Drive and Plex [or other app]. rclone remote, which provides the link to your Google Drive. This is where you sign into your Google account. rclone_vfs service, which makes that rclone remote visible at /mnt/remote mergerfs service which combines that mount point with a local \u201cstaging\u201d directory at /mnt/unionfs . mapping of the mergerfs into the various docker containers. If any layer is having problems, Plex isn\u2019t going to see your media. For purposes of these notes, I\u2019m assuming your setup is based on the current standard Saltbox configuration: rclone remote is mounted via rclone_vfs /mnt/unionfs directory is created using merger_fs I\u2019m further assuming that you are using the default file structure as suggested in the Saltbox wiki. See the end of this doc for some notes on how to tell if 1 and 2 are true. MY FOLDERS AND FILES IN THESE SCREENSHOTS WILL NOT MATCH YOURS. THAT\u2019S FINE AND EXPECTED. When I refer to a shell command throughout, you\u2019re typing the part highlighted in blue and looking for the part highlighted in orange. In most cases, running the mounts tag will clear up any problems you may be having with the various auto-generated service files. sb install mounts","title":"I can\u2019t see my media!"},{"location":"reference/guides/chazguides/no-media/#a-quick-look","text":"The df command can give you a quick look at things: \u279c ~ df -h Filesystem Size Used Avail Use% Mounted on ... local:remote 6.1P 107T 224G 100% /mnt/unionfs google: 1.0P 107T 1.0P 10% /mnt/remote \u279c ~ That shows a device called \u201cgoogle\u201d [created by rclone config] mounted at /mnt/remote [done by rclone_vfs.service], and then two directories [local and remote, which are both inside the /mnt directory] combined into /mnt/unionfs [that\u2019s done by mergerfs.service] If this looks good, your problem is most likely in the bind mounts within the containers. Now we\u2019ll step through the various layers involved in this and check them one at a time.","title":"A quick look"},{"location":"reference/guides/chazguides/no-media/#rclone-remote","text":"The rclone config command should show you the google remote you defined during setup: \u279c ~ rclone config Current remotes: Name Type ==== ==== google drive e) Edit existing remote ... e/n/d/r/c/s/q> q You should be able to get a file listing from that remote: \u279c ~ rclone lsd google:/Media -1 2018-12-01 20:16:06 -1 Music -1 2019-03-15 19:26:14 -1 Movies -1 2018-12-01 20:14:35 -1 TV \u279c ~ That file listing should match what\u2019s displayed on the Google Drive website. If you've used the Saltbox scripted setup, those directories witll be spread across the three shared drives that get created. Yours will probably contain \u201cMovies\u201d and \u201cTV\u201d. If it doesn\u2019t, step one is to fix that. Recreate or edit that google: rclone remote until the file listings match. If you've used the Saltbox scripted setup, examine the three shared drive remotes; the google remote is just a union of those. Do not continue until those two file listings match. They won\u2019t match mine; they should both show the same files from YOUR gdrive. Now that the rclone remote is known good, let\u2019s move to the next layer, the rclone_vfs mount.","title":"rclone remote"},{"location":"reference/guides/chazguides/no-media/#rclone_vfs-mount","text":"First, let\u2019s check that the service is running: \u279c ~ sudo systemctl status rclone_vfs.service \u25cf rclone_vfs.service - Rclone VFS Mount Loaded: loaded (/etc/systemd/system/rclone_vfs.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2019-11-02 06:45:34 EET; 10h ago Process: 1053 ExecStartPre=/bin/sleep 10 (code=exited, status=0/SUCCESS) Main PID: 1247 (rclone) Tasks: 23 (limit: 4915) CGroup: /system.slice/rclone_vfs.service \u2514\u25001247 /usr/bin/rclone mount --config=/home/seed/.config/rclone/rclone.conf --user-agent . . . Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting Rclone VFS Mount... Nov 02 06:45:34 Ubuntu-1804-bionic-64-minimal rclone[1247]: Serving remote control on http://127.0.0.1:5572/ Nov 02 06:45:34 Ubuntu-1804-bionic-64-minimal systemd[1]: Started Rclone VFS Mount. You want to see \u201c active (running) \u201d there. You can look at the log to find out what\u2019s wrong if it\u2019s not \u201c active (running) \u201d \u279c ~ sudo journalctl -fu rclone_vfs.service -- Logs begin at Mon 2019-08-05 16:56:44 EEST. -- Nov 02 06:42:44 Ubuntu-1804-bionic-64-minimal rclone[9625]: Serving remote control on http://127.0.0.1:5572/ Nov 02 06:42:44 Ubuntu-1804-bionic-64-minimal systemd[1]: Started Rclone VFS Mount. Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopping Rclone VFS Mount... Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal rclone[9625]: Fatal error: failed to umount FUSE fs: exit status 1: fusermount: entry for /mnt/remote not found in /etc/mtab Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: rclone_vfs.service: Main process exited, code=exited, status=1/FAILURE Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: rclone_vfs.service: Failed with result 'exit-code'. Nov 02 06:44:09 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopped Rclone VFS Mount. -- Reboot -- Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting Rclone VFS Mount... Nov 02 06:45:34 Ubuntu-1804-bionic-64-minimal rclone[1247]: Serving remote control on http://127.0.0.1:5572/ Nov 02 06:45:34 Ubuntu-1804-bionic-64-minimal systemd[1]: Started Rclone VFS Mount. In that log you can see an error from last night when my server ran out of disk space, the rclone_vfs service died, then a reboot [after clearing space] and it came back up. If there are errors there, first try restarting the service: sudo systemctl restart rclone_vfs If that doesn\u2019t get you to an \u201c active (running) \u201d state, try a reboot of the machine. If that doesn\u2019t work, the problem is deeper; maybe a config problem or a failed install? Read the log. Chances are the specific problem is called out [missing directory, perhaps]. You\u2019re running a server. Learn to read logs. If all fails, take the log information to the Discord, but be prepared to describe what you\u2019ve done and provide details. Don\u2019t come in with \u201cShit\u2019s busted, my dudes! What\u2019s wrong?\u201d Now that the service is running, let\u2019s make sure the files are showing up where they are supposed to be. You can extract the location where the rclone_vfs service is mounting your google storage with a quick egrep command: \u279c ~ egrep -i -e \"/mnt/\" /etc/systemd/system/rclone_vfs.service google: /mnt/remote ExecStop=/bin/fusermount -uz /mnt/remote You can see in that output that rclone_vfs is mounting your google: remote at /mnt/remote. That means that the content of your google drive should also appear at that location. Let\u2019s check that: \u279c ~ ls -al /mnt/remote/Media total 0 drwxrwxr-x 1 seed seed 0 Dec 1 2018 Music drwxrwxr-x 1 seed seed 0 Mar 15 2019 Movies drwxrwxr-x 1 seed seed 0 Dec 1 2018 TV \u279c ~ Note that that matches the file listing from the Google Drive web UI above. If it doesn\u2019t, there\u2019s a problem running the rclone_vfs.service. Perhaps try running the mounts tag. Do not continue until those two file listings match. They won\u2019t match mine; they should both show the same files from YOUR gdrive. We\u2019ve established that the rclone remote is good, and the rclone_vfs service is mounting it as a file system at the expected location. The next step is the mergerfs mount where all the apps look for your files.","title":"rclone_vfs mount"},{"location":"reference/guides/chazguides/no-media/#mergerfs-service","text":"Just like we did with the rclone_vfs service, check the mergerfs status: \u279c ~ sudo systemctl status mergerfs.service \u25cf mergerfs.service - MergerFS Mount Loaded: loaded (/etc/systemd/system/mergerfs.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2019-11-02 06:45:24 EET; 11h ago Process: 1034 ExecStart=/usr/bin/mergerfs -o category.create=ff,minfreespace=0,allow_other -o dropcacheonclose=true,security_capability=false,xattr=nosys -o statfs_ignore=ro,use_ino,auto_ Tasks: 9 (limit: 4915) CGroup: /system.slice/mergerfs.service \u2514\u25001074 /usr/bin/mergerfs -o category.create=ff,minfreespace=0,allow_other -o dropcacheonclose=true,security_capability=false,xattr=nosys -o statfs_ignore=ro,use_ino,auto_cache,um Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount... Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount. As before, if not \u201c active (running) \u201d, you can check the mergerfs log for some clue: \u279c ~ sudo journalctl -fu mergerfs.service -- Logs begin at Mon 2019-08-05 16:56:44 EEST. -- Oct 13 17:00:11 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount... Oct 13 17:00:11 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount. -- Reboot -- Nov 02 06:42:54 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopping MergerFS Mount... Nov 02 06:42:56 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopped MergerFS Mount. Nov 02 06:43:06 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount... Nov 02 06:43:06 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount. Nov 02 06:44:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopping MergerFS Mount... Nov 02 06:44:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Stopped MergerFS Mount. -- Reboot -- Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Starting MergerFS Mount... Nov 02 06:45:24 Ubuntu-1804-bionic-64-minimal systemd[1]: Started MergerFS Mount. If everything looks good, you can check the contents of the filesystem: \u279c ~ ls -al /mnt/unionfs/Media total 0 drwxrwxr-x 1 seed seed 120 Sep 28 18:32 . drwxrwxr-x 1 seed seed 62 Sep 28 18:31 .. drwxrwxr-x 1 seed seed 338 Oct 18 20:21 Music drwxrwxr-x 1 seed seed 78 May 3 2019 Movies drwxrwxr-x 1 seed seed 28196 Nov 2 01:42 TV \u279c ~ Again, this should match all the file listings you\u2019ve looked at so far, at least. There may be some extra folders here depending on a variety of things; other mounts that are included in the mergerfs and so forth. Probably not, given my assumption that you are using the default configuration. Do not continue until those two file listings match. They won\u2019t match mine; they should both show the same files from YOUR gdrive. So at this point we know that all the layers on the host are working, so the last step is to check the views inside the containers.","title":"Mergerfs service"},{"location":"reference/guides/chazguides/no-media/#docker-volume-maps","text":"All the docker containers that need to access your media files have the relevant directories mapped inside them. You can have a look at specifically how with the docker inspect command: \u279c ~ docker inspect plex | head -n 90 [ { \"Id\": \"070d5fc16d4372156c39a6cf2923e6edb2e8576817cbcf9b6432f88f2237a2e8\", \"Created\": \"2019-10-16T19:45:29.93111423Z\", \"Path\": \"/init\", \"Args\": [], \"State\": { \"Status\": \"running\", ... \"HostConfig\": { \"Binds\": [ \"/tmp:/tmp:rw\", \"/mnt/local/transcodes/plex:/transcode:rw\", \"/opt/plex:/config:rw\", \"/mnt:/mnt:rw\", \"/opt/scripts:/scripts:rw\", \"/dev/shm:/dev/shm:rw\" ], ... \u279c ~ I\u2019ve trimmed some stuff out there particularly on the top]. If the \u201cBinds\u201d section isn\u2019t visible, try scrolling up, or increase the \u201c90\u201d to display more lines. It should be right around the same place as mine, though. Take a look at the \u201c Binds \u201d section. Each entry there shows a path on the host [on the left] and the location where those files appear inside the container.","title":"Docker volume maps"},{"location":"reference/guides/chazguides/no-media/#media-related-defaults","text":"Container/Application INSIDE CONTAINER ON HOST sonarr /mnt /mnt radarr /mnt /mnt lidarr /mnt /mnt plex /mnt /mnt Let\u2019s check that in Plex: \u279c ~ docker exec plex ls -al /mnt/unionfs/Media total 4 drwxrwxr-x 1 plex plex 120 Sep 28 18:32 . drwxr-xr-x 1 root root 4096 Oct 16 22:45 .. drwxrwxr-x 1 plex plex 338 Oct 18 20:21 Music drwxrwxr-x 1 plex plex 78 May 3 2019 Movies drwxrwxr-x 1 plex plex 28196 Nov 2 01:42 TV Again, all the same files as always. If that doesn\u2019t show your files as expected, chances are something happened to the mounts while the container was running and the map has broken. First restart the container and if that doesn\u2019t work restart the server. \u279c ~ docker restart plex plex \u279c ~ Then try the \u201c docker exec plex ls -al /mnt/unionfs/Media \u201d command again. Some common problems are: /mnt/unionfs not empty when the mergerfs service starts. The log in that case will look something like this: ubuntu systemd[1]: Starting MergerFS Mount... Ubuntu mergerfs[10803]: fuse: mountpoint is not empty ubuntu mergerfs[10803]: fuse: if you are sure this is safe, use the 'nonempty' mount option ubuntu systemd[1]: mergerfs.service: Control process exited, code=exited status=1 ubuntu systemd[1]: mergerfs.service: Failed with result 'exit-code'. ubuntu systemd[1]: Failed to start MergerFS Mount. If you see this, rerunning the mounts tag, with or without rebuild, actually checks for non empty paths left there as part of a previous failure, and moves the folder to /mnt/unionfs_<date> before mounting again. sb install mounts If this is the result of something writing into that directory while the mergerfs service was down, the mounts tag won\u2019t address it. You\u2019ll have to clean out /mnt/unionfs yourself first.","title":"Media-related defaults:"},{"location":"reference/guides/chazguides/no-media/#how-do-i-know-if-i-am-using-rclone_vfs-and-mergerfs","text":"There are a few things you can look at: In the following examples, you\u2019re typing the part in blue and looking for the part highlighted in orange. Look at the settings file: \u279c saltbox git:(master) head adv_settings.yml --- System: timezone: auto Mounts: unionfs: mergerfs <<<< RIGHT remote: rclone_vfs <<<< HERE Plex: open_port: no force_auto_adjust_quality: no force_high_output_bitrates: no \u279c saltbox git:(master) Check the status of the services \u279c ~ service rclone_vfs status \u25cf rclone_vfs.service - Rclone VFS Mount Loaded: loaded (/etc/systemd/system/rclone_vfs.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2019-06-16 22:41:58 EEST; 1 day 18h ago \u2026 \u279c ~ service mergerfs status \u25cf mergerfs.service - MergerFS Mount Loaded: loaded (/etc/systemd/system/mergerfs.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2019-06-16 22:41:48 EEST; 1 day 18h ago \u2026 If you\u2019re not using either rclone_vfs or mergerfs you\u2019ll see errors there instead. Check the filesystem behind the mounts: \u279c ~ sudo mount | egrep \"remote\" local:remote on /mnt/unionfs type fuse.mergerfs \u2026 <<<< Mergerfs google: on /mnt/remote type fuse.rclone \u2026 <<<< RClone","title":"HOW DO I KNOW IF I AM USING RCLONE_VFS AND MERGERFS?"},{"location":"reference/guides/chazguides/pas-map/","text":"Plex Autoscan Mappings; how do they work? \u00b6 There are these things in the Plex Autoscan config, and they seem to cause a great deal of consternation. SERVER_PATH_MAPPINGS : \u00b6 Here is one of mine, for example: \"SERVER_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/Movies/\" : [ \"/movies/\" , \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" ] }, Plex Autoscan is going to use these \u201cmaps\u201d to decide what path to tell Plex to scan. Each one should be filled out like this: \"Plex sees files at this path\" : [ \"App #1 sees those same files at this path\" , \"App #2 sees those same files at this path\" , \"Google Drive #1 path to those files\" , ...e t c ], Case is significant. \u201cMovies\u201d does not match \u201cmovies\u201d, for example. The JSON formatting is significant. Those brackets and such matter. The various paths are only required if you're using them. For example, if you aren't using Google Drive Monitoring you don't have to include the Google Drive path. What does Plex Autoscan do with them? \u00b6 Here's a generic setup just for this example: \"SERVER_PATH_MAPPINGS\" : { \"/plex/Movie/path/\" : [ \"/radarr/movie/path/\" , \"/google/drive/movie/path/\" ], \"/plex/TV/path/\" : [ \"/sonarr/tv/path/\" , \"/google/drive/tv/path/\" ] }, Plex Autoscan gets a request for a path like this: /radarr/movie/path/Big Space Movie (2022)/Big Space Movie (2022).mkv It looks at the table above to find which one matches the path. In this case it's: \"/plex/Movie/path/\" : [ \"/radarr/movie/path/\" , <<<< THIS ONE RIGHT HERE \"/google/drive/movie/path/\" ], PAS then changes \" /radarr/movie/path/ \" to \" /plex/Movie/path/ \" to make it into /plex/Movie/path/Big Space Movie (2022)/Big Space Movie (2022).mkv Then tells Plex to scan that location. Part of \u201ctells Plex to scan\u201d is finding out which library contains the thing. To do this PAS gets a list of libraries from Plex, then loops through all of them comparing the root paths in the libraries to the path it's about to send. If there\u2019s a match, PAS then issues the scan request to Plex. If there is no Plex Library that matches the path, PAS will display an error in its log [\u201cunable to map to a section ID\u201d]. This can also happen if the Plex path is incorrectly entered [It\u2019s not actually the folder configured in a library] or if one of the source paths is incorrect [Radarr isn\u2019t set to save files in the path listed] or some combination of that sort of thing. Actual example from a working setup: \u00b6 Let\u2019s look at one of my sections. \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" ], Plex: \u00b6 One Plex Movie library is pointed at \"/mnt/unionfs/Media/Movies/Movies\": So that\u2019s the \u201cheading\u201d on this map: \"/mnt/unionfs/Media/Movies/\" : [ <<< PLEX PATH RIGHT HERE \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" ], Radarr: \u00b6 Radarr is configured to send updates to Plex Autoscan, so let\u2019s go take a look at it: My root dir for movies in Radarr is \"/mnt/unionfs/Media/Movies/\": For example: So that\u2019s an element of this map: \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , <<< RADARR PATH RIGHT HERE \"Movies/Media/Movies/\" ], Google Drive: \u00b6 Lastly, I have Google Drive monitoring enabled, and all my movies get uploaded to a Teamdrive: So that\u2019s the last element of this map: \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" <<< GOOGLE DRIVE PATH RIGHT HERE ], Note: the first \u201cMovies\u201d is the name of the drive as it appears in the Google Drive web UI, not the name of your rclone remote. If you had other teamdrives you were monitoring that were also merged into your unionfs, those could come next: \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" , \"TEAMDRIVE_01/OLD_MOVIES/\" ], Multiple applications or sources \u00b6 You need a mapping for each unique library path; for example: \"SERVER_PATH_MAPPINGS\" : { \"plex/Movie/path/\" : [ \"/radarr/movie/path/\" , \"/google/drive/movie/path/\" ], \"plex/TV/path/\" : [ \"/sonarr/tv/path/\" , \"/google/drive/tv/path/\" ] }, If there are common roots, they can be consolidated. For example, this: \"SERVER_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/Movies/\" : [ \"/incoming/Movies/\" , \"/google_drive/Stuff/Movies/\" ], \"/mnt/unionfs/Media/TV/\" : [ \"/incoming/TV/\" , \"/google_drive/Stuff/TV/\" ] }, Could be reduced to: \"SERVER_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/\" : [ \"/incoming/\" , \"/google_drive/Stuff/\" ] }, That\u2019s possible since the TV and Movie folders are all the same until that bottom level. This is just a string replacement. You don\u2019t need a map for every media type, necessarily. You need a map for each unique set of answers to the question: \u201cWhen some app sees a file at location /what/ever/it/is, where does Plex sees it?\u201d Generalized Process Flow \u00b6 Now, what Plex Autoscan is going to do with that, in generic form: Given this SERVER_PATH_MAPPING: \"PATH_WHERE_PLEX_LOOKS\" :[ \"PATH_WHERE_RADARR_LOOKS\" , \"PATH_WHERE_APP_TWO_LOOKS\" , \"PATH_ON_GOOGLE_DRIVE\" ], Example 1 \u00b6 Plex Autoscan processes PATH_WHERE_RADARR_LOOKS/bing/bang/boing based on a request from Radarr. Plex Autoscan finds PATH_WHERE_RADARR_LOOKS in the list, so it does a substitution based on the map and tells Plex to scan: PATH_WHERE_PLEX_LOOKS/bing/bang/boing Example 2 \u00b6 Plex Autoscan processes PATH_WHERE_APP_TWO_LOOKS/bing/bang/boing based on a request from a second application; maybe it's a second Radarr, or Couch Potato, or a custom script. Whatever the source, this source sees those same files at PATH_WHERE_APP_TWO_LOOKS , so that\u2019s what it sends to Plex Autoscan. Plex Autoscan finds PATH_WHERE_APP_TWO_LOOKS in the list, so it does a substitution based on the map and tells Plex to scan PATH_WHERE_PLEX_LOOKS/bing/bang/boing Example 3 \u00b6 Plex Autoscan processes PATH_ON_GOOGLE_DRIVE/bing/bang/boing based on Google Drive Monitoring. Plex Autoscan finds PATH_ON_GOOGLE_DRIVE in the list, so it does a substitution based on the map and tells Plex to scan PATH_WHERE_PLEX_LOOKS/bing/bang/boing Example 4 [error case] \u00b6 Plex Autoscan processes SOME_RANDOM_PATH/bing/bang/boing based on some trigger, maybe a manual scan. Plex Autoscan DOES NOT find SOME_RANDOM_PATH in the list, so no substitution is done and PAS tells Plex to scan SOME_RANDOM_PATH/bing/bang/boing Plex Autoscan then logs: \u201cunable to map to a section ID\u201d since that path doesn't correspond to any library in Plex. SERVER_FILE_EXIST_PATH_MAPPINGS : \u00b6 PAS uses this map to alter path mappings before checking that the file exists. \"SERVER_FILE_EXIST_PATH_MAPPINGS\" : { \"Files are on host at this path\" : [ \"Plex sees files at this path\" ] }, Following the example above, my mappings here is: \"SERVER_FILE_EXIST_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , ] }, In the default case, it looks like this: \"SERVER_FILE_EXIST_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/\" : [ \"/data/\" , ] }, Files are visible on the host at \u2018/mnt/unionfs/Media/Movies/\u2026\u2019 and inside Plex at \u2018/data/Movies/\u2026\u2019. Same string substitution concepts as above apply here.","title":"Plex Autoscan Mappings; how do they work?"},{"location":"reference/guides/chazguides/pas-map/#plex-autoscan-mappings-how-do-they-work","text":"There are these things in the Plex Autoscan config, and they seem to cause a great deal of consternation.","title":"Plex Autoscan Mappings; how do they work?"},{"location":"reference/guides/chazguides/pas-map/#server_path_mappings","text":"Here is one of mine, for example: \"SERVER_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/Movies/\" : [ \"/movies/\" , \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" ] }, Plex Autoscan is going to use these \u201cmaps\u201d to decide what path to tell Plex to scan. Each one should be filled out like this: \"Plex sees files at this path\" : [ \"App #1 sees those same files at this path\" , \"App #2 sees those same files at this path\" , \"Google Drive #1 path to those files\" , ...e t c ], Case is significant. \u201cMovies\u201d does not match \u201cmovies\u201d, for example. The JSON formatting is significant. Those brackets and such matter. The various paths are only required if you're using them. For example, if you aren't using Google Drive Monitoring you don't have to include the Google Drive path.","title":"SERVER_PATH_MAPPINGS:"},{"location":"reference/guides/chazguides/pas-map/#what-does-plex-autoscan-do-with-them","text":"Here's a generic setup just for this example: \"SERVER_PATH_MAPPINGS\" : { \"/plex/Movie/path/\" : [ \"/radarr/movie/path/\" , \"/google/drive/movie/path/\" ], \"/plex/TV/path/\" : [ \"/sonarr/tv/path/\" , \"/google/drive/tv/path/\" ] }, Plex Autoscan gets a request for a path like this: /radarr/movie/path/Big Space Movie (2022)/Big Space Movie (2022).mkv It looks at the table above to find which one matches the path. In this case it's: \"/plex/Movie/path/\" : [ \"/radarr/movie/path/\" , <<<< THIS ONE RIGHT HERE \"/google/drive/movie/path/\" ], PAS then changes \" /radarr/movie/path/ \" to \" /plex/Movie/path/ \" to make it into /plex/Movie/path/Big Space Movie (2022)/Big Space Movie (2022).mkv Then tells Plex to scan that location. Part of \u201ctells Plex to scan\u201d is finding out which library contains the thing. To do this PAS gets a list of libraries from Plex, then loops through all of them comparing the root paths in the libraries to the path it's about to send. If there\u2019s a match, PAS then issues the scan request to Plex. If there is no Plex Library that matches the path, PAS will display an error in its log [\u201cunable to map to a section ID\u201d]. This can also happen if the Plex path is incorrectly entered [It\u2019s not actually the folder configured in a library] or if one of the source paths is incorrect [Radarr isn\u2019t set to save files in the path listed] or some combination of that sort of thing.","title":"What does Plex Autoscan do with them?"},{"location":"reference/guides/chazguides/pas-map/#actual-example-from-a-working-setup","text":"Let\u2019s look at one of my sections. \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" ],","title":"Actual example from a working setup:"},{"location":"reference/guides/chazguides/pas-map/#plex","text":"One Plex Movie library is pointed at \"/mnt/unionfs/Media/Movies/Movies\": So that\u2019s the \u201cheading\u201d on this map: \"/mnt/unionfs/Media/Movies/\" : [ <<< PLEX PATH RIGHT HERE \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" ],","title":"Plex:"},{"location":"reference/guides/chazguides/pas-map/#radarr","text":"Radarr is configured to send updates to Plex Autoscan, so let\u2019s go take a look at it: My root dir for movies in Radarr is \"/mnt/unionfs/Media/Movies/\": For example: So that\u2019s an element of this map: \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , <<< RADARR PATH RIGHT HERE \"Movies/Media/Movies/\" ],","title":"Radarr:"},{"location":"reference/guides/chazguides/pas-map/#google-drive","text":"Lastly, I have Google Drive monitoring enabled, and all my movies get uploaded to a Teamdrive: So that\u2019s the last element of this map: \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" <<< GOOGLE DRIVE PATH RIGHT HERE ], Note: the first \u201cMovies\u201d is the name of the drive as it appears in the Google Drive web UI, not the name of your rclone remote. If you had other teamdrives you were monitoring that were also merged into your unionfs, those could come next: \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , \"Movies/Media/Movies/\" , \"TEAMDRIVE_01/OLD_MOVIES/\" ],","title":"Google Drive:"},{"location":"reference/guides/chazguides/pas-map/#multiple-applications-or-sources","text":"You need a mapping for each unique library path; for example: \"SERVER_PATH_MAPPINGS\" : { \"plex/Movie/path/\" : [ \"/radarr/movie/path/\" , \"/google/drive/movie/path/\" ], \"plex/TV/path/\" : [ \"/sonarr/tv/path/\" , \"/google/drive/tv/path/\" ] }, If there are common roots, they can be consolidated. For example, this: \"SERVER_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/Movies/\" : [ \"/incoming/Movies/\" , \"/google_drive/Stuff/Movies/\" ], \"/mnt/unionfs/Media/TV/\" : [ \"/incoming/TV/\" , \"/google_drive/Stuff/TV/\" ] }, Could be reduced to: \"SERVER_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/\" : [ \"/incoming/\" , \"/google_drive/Stuff/\" ] }, That\u2019s possible since the TV and Movie folders are all the same until that bottom level. This is just a string replacement. You don\u2019t need a map for every media type, necessarily. You need a map for each unique set of answers to the question: \u201cWhen some app sees a file at location /what/ever/it/is, where does Plex sees it?\u201d","title":"Multiple applications or sources"},{"location":"reference/guides/chazguides/pas-map/#generalized-process-flow","text":"Now, what Plex Autoscan is going to do with that, in generic form: Given this SERVER_PATH_MAPPING: \"PATH_WHERE_PLEX_LOOKS\" :[ \"PATH_WHERE_RADARR_LOOKS\" , \"PATH_WHERE_APP_TWO_LOOKS\" , \"PATH_ON_GOOGLE_DRIVE\" ],","title":"Generalized Process Flow"},{"location":"reference/guides/chazguides/pas-map/#example-1","text":"Plex Autoscan processes PATH_WHERE_RADARR_LOOKS/bing/bang/boing based on a request from Radarr. Plex Autoscan finds PATH_WHERE_RADARR_LOOKS in the list, so it does a substitution based on the map and tells Plex to scan: PATH_WHERE_PLEX_LOOKS/bing/bang/boing","title":"Example 1"},{"location":"reference/guides/chazguides/pas-map/#example-2","text":"Plex Autoscan processes PATH_WHERE_APP_TWO_LOOKS/bing/bang/boing based on a request from a second application; maybe it's a second Radarr, or Couch Potato, or a custom script. Whatever the source, this source sees those same files at PATH_WHERE_APP_TWO_LOOKS , so that\u2019s what it sends to Plex Autoscan. Plex Autoscan finds PATH_WHERE_APP_TWO_LOOKS in the list, so it does a substitution based on the map and tells Plex to scan PATH_WHERE_PLEX_LOOKS/bing/bang/boing","title":"Example 2"},{"location":"reference/guides/chazguides/pas-map/#example-3","text":"Plex Autoscan processes PATH_ON_GOOGLE_DRIVE/bing/bang/boing based on Google Drive Monitoring. Plex Autoscan finds PATH_ON_GOOGLE_DRIVE in the list, so it does a substitution based on the map and tells Plex to scan PATH_WHERE_PLEX_LOOKS/bing/bang/boing","title":"Example 3"},{"location":"reference/guides/chazguides/pas-map/#example-4-error-case","text":"Plex Autoscan processes SOME_RANDOM_PATH/bing/bang/boing based on some trigger, maybe a manual scan. Plex Autoscan DOES NOT find SOME_RANDOM_PATH in the list, so no substitution is done and PAS tells Plex to scan SOME_RANDOM_PATH/bing/bang/boing Plex Autoscan then logs: \u201cunable to map to a section ID\u201d since that path doesn't correspond to any library in Plex.","title":"Example 4 [error case]"},{"location":"reference/guides/chazguides/pas-map/#server_file_exist_path_mappings","text":"PAS uses this map to alter path mappings before checking that the file exists. \"SERVER_FILE_EXIST_PATH_MAPPINGS\" : { \"Files are on host at this path\" : [ \"Plex sees files at this path\" ] }, Following the example above, my mappings here is: \"SERVER_FILE_EXIST_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/Movies/\" : [ \"/mnt/unionfs/Media/Movies/\" , ] }, In the default case, it looks like this: \"SERVER_FILE_EXIST_PATH_MAPPINGS\" : { \"/mnt/unionfs/Media/\" : [ \"/data/\" , ] }, Files are visible on the host at \u2018/mnt/unionfs/Media/Movies/\u2026\u2019 and inside Plex at \u2018/data/Movies/\u2026\u2019. Same string substitution concepts as above apply here.","title":"SERVER_FILE_EXIST_PATH_MAPPINGS:"},{"location":"reference/guides/chazguides/server/","text":"Can I run Saltbox on this server? \u00b6 Yes. Wait, no. Um, maybe. Try it and see. The answer to this question depends on a whole bunch of things, including but not limited to: CPU Memory Storage type Format of media Location of server Location of clients Type of clients Number of simultaneous streams Transcoding or not Expectations of clients Random nonsense Server Hardware \u00b6 For example, at time of writing the author had a Hetzner EX42-NVME in Helsinki. Nearly all users were in the Minneapolis area on Comcast cable. One user in Utah, one in Brisbane, Australia. No 4K media. The box was an AIO; usenet downloading happened on that box as well as streaming and no throttles were in place to slow NZBget or Cloudplow while Plex was streaming. For the most part, this box met requirements during its tenure. All author's streaming happened over a 1G fiber line to an AppleTV. Most other active streamers used Plex Web, Roku, or a Smart TV Plex app. The guy in Brisbane had trouble streaming due to his local ISP [Telstra], but streaming worked great from a Gold Coast hotel. However, another fellow, who lives blocks away from the author, got one of these same servers and found it unusable for his target usage. Maybe that was a config issue [didn't seem to be], but it illustrates that there is no \"one-size-fits-all\" answer. Ultimately, there\u2019s not really a sure way to answer this question. Plex\u2019 article on the topic is here . Plex Metadata: \u00b6 Plex saves metadata [posters, etc] for all your media; that gets stored in /opt/plex and as your library grows so does that directory. Required disk space therefore grows over time. This directory can be quite large. For example: Here Plex has 9640 movies and 137140 TV episodes. Radarr is tracking 11608 movies and Sonarr 3070 series. [These displays are produced by ncdu a command-line tool that shows disk usage; they're showing the content of the /opt directory] ncdu 1.14.1 ~ Use the arrow keys to navigate, press ? for help --- /opt ------------------------------------------------------- 78.3 GiB [##########] /plex 10.0 GiB [# ] /radarr 4.2 GiB [ ] /sonarr Here Plex contains has a lot more than that. ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- /opt ------------------------------------------------------- 274.5 GiB [##########] /plex 7.4 GiB [ ] /tautulli Plex transcoding: \u00b6 Ideally, all your clients would Direct Play everything; in that case the server is just shoveling bits out as fast as it can and you don\u2019t need any CPU power. In practice, some transcoding will be happening. There are two types of transcoding; hardware or software. Software transcoding is CPU intensive, but higher-quality. Hardware transcoding doesn\u2019t burden your CPU [so it\u2019s free to continue extracting rar files or something], but it\u2019s typically lower quality. Depending on the specific CPU, dramatically lower quality. Some Intel CPUs support hardware transcoding, a smaller subset of AMD processors support hardware transcoding, so if you want hardware transcoding you probably want Intel [assuming you\u2019re not using a separate GPU on a video card to do it]. But that\u2019s just Plex. Context Acquisition: \u00b6 You\u2019re looking to run Saltbox, so chances are you\u2019re downloading via Usenet or torrents, so there are other concerns. Usenet: \u00b6 Usenet is all about speed of disk access as things are unrar\u2019ed. An SSD should be considered required, and NVME highly recommended. In practical terms, you should have at least 300GB of space available for downloading and extracting. That\u2019s a general idea; sure you can make do with less, but it may be tight. The author's first cloud server had a 160GB disk, and it was very tight. Torrents: \u00b6 If you\u2019re downloading torrents from private servers, you probably need to seed things for some minimal amount of time; so multiple TBs of disk space are a plus. Client Peering to the Server: \u00b6 Depending on where you are in the world, peering to cloud servers will be different. If you\u2019re in the US, Hetzner\u2019s German data centers are typically pretty good, but YMMV. If you want a server in the US for that reason, it will probably be more expensive. And so on. So, the only way to answer this question is: Maybe; try it and see. The other way this question is posed is: What is the cheapest VPS or dedi on which I can run saltbox? \u00b6 That question cannot be answered in any meaningful sense other than the requirements laid out in the docs. Saltbox itself and the apps it installs do not have particularly great hardware requirements to run . Some docker containers, a couple services. You can install Saltbox on a tiny little Digital Ocean instance or the like. The apps obviously have higher requirements if you want them to actually do anything, so whether a given box will work for you is entirely down to what you\u2019re going to do with it. Refer to the previous section. Again, the only way to answer this question is: Maybe; try it and see.","title":"Can I run Saltbox on this server?"},{"location":"reference/guides/chazguides/server/#can-i-run-saltbox-on-this-server","text":"Yes. Wait, no. Um, maybe. Try it and see. The answer to this question depends on a whole bunch of things, including but not limited to: CPU Memory Storage type Format of media Location of server Location of clients Type of clients Number of simultaneous streams Transcoding or not Expectations of clients Random nonsense","title":"Can I run Saltbox on this server?"},{"location":"reference/guides/chazguides/server/#server-hardware","text":"For example, at time of writing the author had a Hetzner EX42-NVME in Helsinki. Nearly all users were in the Minneapolis area on Comcast cable. One user in Utah, one in Brisbane, Australia. No 4K media. The box was an AIO; usenet downloading happened on that box as well as streaming and no throttles were in place to slow NZBget or Cloudplow while Plex was streaming. For the most part, this box met requirements during its tenure. All author's streaming happened over a 1G fiber line to an AppleTV. Most other active streamers used Plex Web, Roku, or a Smart TV Plex app. The guy in Brisbane had trouble streaming due to his local ISP [Telstra], but streaming worked great from a Gold Coast hotel. However, another fellow, who lives blocks away from the author, got one of these same servers and found it unusable for his target usage. Maybe that was a config issue [didn't seem to be], but it illustrates that there is no \"one-size-fits-all\" answer. Ultimately, there\u2019s not really a sure way to answer this question. Plex\u2019 article on the topic is here .","title":"Server Hardware"},{"location":"reference/guides/chazguides/server/#plex-metadata","text":"Plex saves metadata [posters, etc] for all your media; that gets stored in /opt/plex and as your library grows so does that directory. Required disk space therefore grows over time. This directory can be quite large. For example: Here Plex has 9640 movies and 137140 TV episodes. Radarr is tracking 11608 movies and Sonarr 3070 series. [These displays are produced by ncdu a command-line tool that shows disk usage; they're showing the content of the /opt directory] ncdu 1.14.1 ~ Use the arrow keys to navigate, press ? for help --- /opt ------------------------------------------------------- 78.3 GiB [##########] /plex 10.0 GiB [# ] /radarr 4.2 GiB [ ] /sonarr Here Plex contains has a lot more than that. ncdu 1.12 ~ Use the arrow keys to navigate, press ? for help --- /opt ------------------------------------------------------- 274.5 GiB [##########] /plex 7.4 GiB [ ] /tautulli","title":"Plex Metadata:"},{"location":"reference/guides/chazguides/server/#plex-transcoding","text":"Ideally, all your clients would Direct Play everything; in that case the server is just shoveling bits out as fast as it can and you don\u2019t need any CPU power. In practice, some transcoding will be happening. There are two types of transcoding; hardware or software. Software transcoding is CPU intensive, but higher-quality. Hardware transcoding doesn\u2019t burden your CPU [so it\u2019s free to continue extracting rar files or something], but it\u2019s typically lower quality. Depending on the specific CPU, dramatically lower quality. Some Intel CPUs support hardware transcoding, a smaller subset of AMD processors support hardware transcoding, so if you want hardware transcoding you probably want Intel [assuming you\u2019re not using a separate GPU on a video card to do it]. But that\u2019s just Plex.","title":"Plex transcoding:"},{"location":"reference/guides/chazguides/server/#context-acquisition","text":"You\u2019re looking to run Saltbox, so chances are you\u2019re downloading via Usenet or torrents, so there are other concerns.","title":"Context Acquisition:"},{"location":"reference/guides/chazguides/server/#usenet","text":"Usenet is all about speed of disk access as things are unrar\u2019ed. An SSD should be considered required, and NVME highly recommended. In practical terms, you should have at least 300GB of space available for downloading and extracting. That\u2019s a general idea; sure you can make do with less, but it may be tight. The author's first cloud server had a 160GB disk, and it was very tight.","title":"Usenet:"},{"location":"reference/guides/chazguides/server/#torrents","text":"If you\u2019re downloading torrents from private servers, you probably need to seed things for some minimal amount of time; so multiple TBs of disk space are a plus.","title":"Torrents:"},{"location":"reference/guides/chazguides/server/#client-peering-to-the-server","text":"Depending on where you are in the world, peering to cloud servers will be different. If you\u2019re in the US, Hetzner\u2019s German data centers are typically pretty good, but YMMV. If you want a server in the US for that reason, it will probably be more expensive. And so on. So, the only way to answer this question is: Maybe; try it and see. The other way this question is posed is:","title":"Client Peering to the Server:"},{"location":"reference/guides/chazguides/server/#what-is-the-cheapest-vps-or-dedi-on-which-i-can-run-saltbox","text":"That question cannot be answered in any meaningful sense other than the requirements laid out in the docs. Saltbox itself and the apps it installs do not have particularly great hardware requirements to run . Some docker containers, a couple services. You can install Saltbox on a tiny little Digital Ocean instance or the like. The apps obviously have higher requirements if you want them to actually do anything, so whether a given box will work for you is entirely down to what you\u2019re going to do with it. Refer to the previous section. Again, the only way to answer this question is: Maybe; try it and see.","title":"What is the cheapest VPS or dedi on which I can run saltbox?"},{"location":"reference/guides/chazguides/success/","text":"Did my Saltbox install succeed? If you started with the first install step And went through the first five steps, completely and without seeing any errors, it should be. Perhaps you skipped some of those 5 required steps. If so, why? Go back to the beginning and start again. Perhaps you ignored some errors. If so, why? Go back to the beginning and start again. The install is complete when you get to the end of this step with no errors. It\u2019s not complete until then. What does success look like? After running the Saltbox install command: ~$ sb install saltbox A lot of logging information will scroll by. Eventually, it will stop, and if successful, will display something like this: TODO: REPLACE WITH SALTBOX VERSION PLAY RECAP ************************************************************************************ localhost : ok=713 changed=180 unreachable=0 failed=0 Tuesday 14 April 2020 11:31:47 -0500 (0:00:00.040) 0:13:22.200 ********* =============================================================================== docker : Start docker service -----------------------------------------------------...- 121.63s docker : Wait for 30 seconds before commencing ------------------------------------...- 30.65s iperf3 : Build and install iperf3 -------------------------------------------------...- 17.04s system : APT | APT upgrade --------------------------------------------------------...- 16.82s plex : Extra | Stop Plex Container ------------------------------------------------...- 11.39s plex : Create and start container -------------------------------------------------...- 11.30s remote : Rclone VFS | Start 'rclone_vfs.service' ----------------------------------...- 11.03s rutorrent : Settings | Wait for 10 seconds before stopping rutorrent container ----...- 10.43s ombi : Create and start container -------------------------------------------------...- 9.39s docker : Stop docker service ------------------------------------------------------...- 8.48s system : sysctl | Tuning ----------------------------------------------------------...- 7.49s nodejs : Install nodejs -----------------------------------------------------------...- 7.37s plexpy : Create and start container -----------------------------------------------...- 7.03s jackett : Create and start container ----------------------------------------------...- 6.78s nzbhydra2 : Create and start container --------------------------------------------...- 6.22s nodejs : Update npm ---------------------------------------------------------------...- 6.12s remote : Rclone VFS | \"Wait for 5 seconds\" ----------------------------------------...- 5.42s sanity_check : Get all available TAGS ---------------------------------------------...- 5.08s sonarr : Create and start container -----------------------------------------------...- 4.96s lidarr : Create and start container -----------------------------------------------...- 4.88s chaz@oberon:~/saltbox$ Note this part: it\u2019s even color-coded: PLAY RECAP ************************************************************************************ localhost : ok=713 changed=180 unreachable=0 failed=0 No red there. Emphasizing what you want to see: ok=713 changed=180 unreachable=0 failed=0 Zero failures. If you are not left at a prompt like this after running the saltbox install, chances are an error occurred during the install, and typically that error is shown at the end here. If you come to the discord asking for help, this log will be the first thing we ask you for. Once more for emphasis: If you come to the discord asking for help, this log will be the first thing we ask you for. What does an error look like? For example, if I enter a bad domain in my accounts.yml: --- user: name: REDACTED pass: REDACTED domain: bing.bang.boing email: REDACTED ... It runs for a bit and stops here: TASK [pre_tasks : Add Subdomain | Cloudflare: Add 'saltbox' subdomain to 'bing.bang.boing'] ********************************************************************************* Tuesday 14 April 2020 11:53:29 -0500 (0:00:00.142) 0:00:52.680 ********* fatal: [localhost]: FAILED! => {\"changed\": false, \"msg\": \"No zone found with name bing.bang.boing\"} PLAY RECAP ********************************************************************** localhost : ok=131 changed=3 unreachable=0 failed=1 Tuesday 14 April 2020 11:53:30 -0500 (0:00:00.779) 0:00:53.460 ********* =============================================================================== sanity_check : Get all available TAGS ---------------------------------------------------------------------------------...- 5.02s Gathering Facts ---------------------------------------------------------------------------------...- 1.51s ... TRIMMED FOR SPACE ... settings : Copy | Check if 'ansible.cfg' exists ---------------------------------------------------------------------------------...- 0.35s chaz@oberon:~/saltbox$ Lots of red there, showing exactly what went wrong. Or, If I set the cloudflare email in the config to a bad value: ... cloudflare: email: bing@bang.boing api: REDACTED ... TASK [pre_tasks : Add Subdomain | Cloudflare: Add 'saltbox' subdomain to 'DOMAIN.TLD'] ******************************************************************************************** Tuesday 14 April 2020 11:56:54 -0500 (0:00:00.224) 0:00:52.892 ********* fatal: [localhost]: FAILED! => {\"changed\": false, \"msg\": \"API request not authenticated; Status: 403; Method: GET: Call: /zones?name=DOMAIN.TLD; Error details: code: 9103, error: Unknown X-Auth-Key or X-Auth-Email; \"} PLAY RECAP ********************************************************************************* localhost : ok=131 changed=2 unreachable=0 failed=1 Tuesday 14 April 2020 11:56:55 -0500 (0:00:00.686) 0:00:53.579 ********* =============================================================================== sanity_check : Get all available TAGS ---------------------------------------------------------------------------------...- 5.06s Gathering Facts ---------------------------------------------------------------------------------...- 1.52s ... TRIMMED FOR SPACE ... settings : Start | Check to see if yyq is installed ---------------------------------------------------------------------------------...- 0.35s chaz@oberon:~/saltbox$ Again, lots of red there, showing exactly what went wrong. Typically, all errors will be displayed in that manner. Maybe docker didn\u2019t get installed, maybe your Plex credentials are bad, maybe some network issue prevented the install from grabbing a thing from github, etc. Whatever it is will be displayed in that install log, and no one can say anything more than \u201cI\u2019m sorry it didn\u2019t work\u201d if this output is not provided. If you come to the discord asking for help, this log will be the first thing we ask you for. Once more for emphasis: If you come to the discord asking for help, this log will be the first thing we ask you for. What now? Is DNS configured? If you entered your cloudflare credentials into the settings, the install should have created subdomains at cloudflare for you. You can verify this with the ping utility: (nothing special about my choice of ombi here) You should see something like: chaz@oberon:~/saltbox$ ping ombi.YOURDOMAIN.TLD PING ombi.YOURDOMAIN.TLD (111.222.333.444): 56 data bytes 64 bytes from 111.222.333.444: icmp_seq=0 ttl=48 time=114.425 ms That IP address should be the IP address of the server. If this is a home server, it should be your external IP. If instead you should see something like: chaz@oberon:~/saltbox$ ping ombi.YOURDOMAIN.TLD ping: cannot resolve ombi.YOURDOMAIN.TLD: Unknown host ...then you need to fix your DNS setup. Either enter valid Cloudflare credentials in the settings, OR, if you are not using Cloudflare, go set up the required subdomains manually at your DNS provider. Are the containers running? The install should leave you with all the docker containers set up and running. Verify this with docker ps (The display here has been edited for readability and space) chaz@oberon:~/saltbox$ docker ps CONTAINER ID IMAGE CREATED STATUS 99c552628534 hotio/lidarr 27 minutes ago Up 27 minutes fae88a0e46d1 hotio/radarr 27 minutes ago Up 27 minutes a5858358c3f8 hotio/sonarr:phantom 27 minutes ago Up 27 minutes 84e39d15fbdd hotio/nzbhydra2 27 minutes ago Up 27 minutes a579ca009eb2 hotio/jackett 27 minutes ago Up 27 minutes 0d879c79a547 horjulf/rutorrent-autodl 28 minutes ago Up 28 minutes a1d387692b30 hotio/nzbget 28 minutes ago Up 28 minutes c4b5b3a73aeb organizrtools/organizr-v2:plex 29 minutes ago Up 29 minutes 974f5bc87364 portainer/portainer 29 minutes ago Up 29 minutes 7ac30109104c hotio/ombi 29 minutes ago Up 29 minutes 0cb9c230f5f1 tautulli/tautulli:nightly 30 minutes ago Up 30 minutes bed4af6dc439 cloudb0x/plex:latest 31 minutes ago Up 30 minutes 18b10e11029a jrcs/letsencrypt-nginx-proxy-companion 31 minutes ago Up 31 minutes 51b214fdf273 jwilder/nginx-proxy 31 minutes ago Up 31 minutes That\u2019s the list of containers installed by the default setup at the time of writing. There should be no way for the install to complete without errors, but leave no containers running. Is the proxy running? You can verify the proxy with curl: (nothing special about my choice of ombi here) chaz@oberon:~/saltbox$ curl http://ombi.DOMAIN.TLD | head -n 20 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 169 100 169 0 0 12071 0 --:--:-- --:--:-- --:--:-- 12071 <html> <head><title>301 Moved Permanently</title></head> <body> <center><h1>301 Moved Permanently</h1></center> <hr><center>nginx/1.17.6</center> </body> </html> That\u2019s expected, it\u2019s the standard saltbox behavior where the non-secure URL forwards to the secure URL. Tell curl to follow the redirect by adding -L: You're ready to start the application setup in the wiki.","title":"Did my Saltbox install succeed?"},{"location":"reference/guides/chazguides/teamdrive/","text":"How do I mount a teamdrive? \u00b6 You have a teamdrive you want to add to your Saltbox server so Plex can see it. In this article I\u2019m assuming that\u2019s ALL you want to do. If you want to set up a teamdrive and upload to it, see the \u201cTip #44\u201d document Here, I\u2019m assuming you have access to a teamdrive, and you want to set it up so you can point Plex or Emby at it. No more than that. Overview: \u00b6 There are three steps: Create an rclone remote [this tells rclone about the teamdrive] Create the rclone_vfs service files [this makes rclone mount the teamdrive at /mnt/WHATEVER ] Modify your mergerfs service file [this will include the contents of the new teamdrive in /mnt/unionfs for use in your apps] This step is actually optional, but it makes app configuration a little more straightforward since all your media files are in the same directory rather then some in /mnt/unionfs and some in /mnt/bing-bang-boing Not \u201cTeamdrive\u201d specific \u00b6 The concepts here are not specific to teamdrives. It\u2019s described in terms of Teamdrives since this is aimed at Saltbox users who use Google Drive almost exclusively. You can go through this exercise with any rclone backend that supports the relevant setup, of course modifying the rclone setup described to suit your OneDrive or Box or whatever other backend. Prerequisites \u00b6 Access to a teamdrive Either one of these for an account with access to the teamdrive ClientID/Secret Service Account JSON file[s] Put this/these in some fixed location like /opt/sa Basic linux knowledge Like all of these docs and guides, we are assuming basic familiarity with Linux systems and concepts. You are going to be copying files, editing files, etc. This guide is not here to explain how to do those things. Everything in this doc that appears in ALL_CAPS is a placeholder that needs to be replaced with something that applies to your situation. For example, if I were to say \u201cEnter YOUR_PASSWORD\u201d, I don\u2019t mean for you to enter \u201cYOUR_PASSWORD\u201d; I mean you should enter your password, whatever it is. I think that should be obvious on its face, but here we are. Let\u2019s go! Create the rclone remote After saving the remote and exiting rclone, and before you continue, verify that the remote is working correctly. Type rclone lsd NAME_OF_THE_REMOTE_YOU_JUST_CREATED:/ $ rclone lsd teamdrive-movies:/ -1 2019-03-21 10:59:48 -1 Media It should show you the directories on the root level of the teamdrive you are adding. Verify this with the Google Drive Web UI if necessary. If the teamdrive is empty, create a folder and verify that rclone shows that folder. Nothing after this will work if this connection is not set up correctly. If it doesn\u2019t show you what you\u2019re expecting, go back over the rclone remote setup. Take your time. Something isn\u2019t right. Perhaps you chose the wrong teamdrive. DO NOT PROCEED UNTIL YOU HAVE VERIFIED THAT THIS RCLONE COMMAND SHOWS YOU THE EXPECTED THING. Get that remote mounted in the filesystem Now you have an rclone remote. You can use this with rclone commands like rclone copy or rclone move or what have you. To use it with Plex/Emby/whatever other application, you need to create service files to \u201cmount\u201d the teamdrive in your filesystem. Saltbox does this with your Google Drive at /mnt/remote . You\u2019re going to create an analogous setup that does the same thing for that teamdrive remote you just created. First, you need to create the folder where you want the teamdrive contents to appear. Generally, I recommend using the same name as the remote for clarity: Create a mount point for the teamdrive Create a directory where you want to mount this teamdrive under the /mnt directory: for example: /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED You may have to use sudo to create the directory: sudo mkdir /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED It should be on the root level of /mnt ; not within any other remote mount directory. NOT, for example, /mnt/remote/NAME_OF_THE_REMOTE_YOU_JUST_CREATED OR /mnt/unionfs/NAME_OF_THE_REMOTE_YOU_JUST_CREATED OR /mnt/local/NAME_OF_THE_REMOTE_YOU_JUST_CREATED etc. Make sure it has the same ownership and permissions as the existing /mnt/remote : \u279c ~ ls -al /mnt total 16 drwxr-xr-x 1 root root 168 May 8 18:35 . drwxr-xr-x 1 root root 334 May 18 18:53 .. drwxrwxr-x 1 seed seed 48 May 8 19:08 local drwxrwxr-x 1 seed seed 0 May 20 23:16 remote drwxrwxr-x 1 seed seed 48 May 8 19:08 unionfs To do this: sudo chown -R seed:seed /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED sudo chmod -R g+w /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED Of course, seed:seed is YOUR USER AND GROUP if it differs from seed:seed You will use this mountpoint when you configure the rclone_vfs service. Create service files which will accomplish the mounting: Make copies of the rclone_vfs service file: /etc/systemd/system/rclone_vfs.service sudo cp /etc/systemd/system/rclone_vfs.service /etc/systemd/system/NAME_OF_THE_REMOTE_YOU_JUST_CREATED_vfs.service Edit /etc/systemd/system/NAME_OF_THE_REMOTE_YOU_JUST_CREATED_vfs.service: Change the port [5572] in two lines [lines 27 and 42 at this writing]: --rc-addr=localhost:5572 \\ ... ExecStartPost=/usr/bin/rclone rc vfs/refresh recursive=true --rc-addr localhost:5572 _async=true The specific port you use doesn\u2019t matter, but maybe just use 5573. --rc-addr=localhost:5573 \\ ... ExecStartPost=/usr/bin/rclone rc vfs/refresh recursive=true --rc-addr localhost:5573 _async=true Change the remote name and mount directory in this line [line 41 at this writing]: NAME_OF_THE_REMOTE_YOU_JUST_CREATED: /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED The first bit before the colon is the name of the rclone remote from step 1. The path is the mount point directory you created a moment ago. For example, you might end up with something like this: teamdrive-movies: /mnt/teamdrive-movies What you will enter specifically depneds entirely on how you just configured the remote and moutn directory above. This example is almost certainly not what you should enter. Change the next line to match the path you just entered: ExecStop=/bin/fusermount -uz /mnt/remote For example: ExecStop=/bin/fusermount -uz /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED Lastly enable and start that new service: Reload all the services sudo systemctl daemon-reload Start/restart the service sudo systemctl restart NAME_OF_THE_REMOTE_YOU_JUST_CREATED_vfs.service Enable the new service you created sudo systemctl enable NAME_OF_THE_REMOTE_YOU_JUST_CREATED_vfs.service Now, before you continue, verify that the mount is working correctly. Type ls -haltr /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED . It should show you the same thing that you saw in the rclone lsd , and the same stuff you see in the Google Drive Web UI: \u279c ~ ls -haltr /mnt/teamdrive-movies total 14M drwxrwxr-x 1 seed seed 0 Mar 21 2019 Media -rw-rw-r-- 1 seed seed 0 Dec 3 16:14 mounted-movies.bin \u279c ~ As before, DO NOT PROCEED UNTIL YOU HAVE VERIFIED THAT THIS LS COMMAND SHOWS YOU THE EXPECTED THING. Add that teamdrive to the mergerfs Last step; you\u2019re going to add the teamdrive to the mergerfs configuration so that the files from it show up under /mnt/unionfs with the rest of your files. Edit the mergerfs service file to include the new teamdrive in the mergerfs. Edit this file: /etc/systemd/system/mergerfs.service Edit this line to include your new teamdrive: /mnt/local=RW:/mnt/remote=NC /mnt/unionfs For example: /mnt/local=RW:/mnt/remote=NC:/mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED=NC /mnt/unionfs Note: that MUST BE all one line, just as it is in the original unedited file. Just like the rclone_vfs service, reload and restart: Reload all the services sudo systemctl daemon-reload Start/restart the mergerfs sudo systemctl restart mergerfs.service Enable the mergerfs just for good measure sudo systemctl enable mergerfs.service Now, verify that the mergerfs is working correctly. Type ls -haltr /mnt/unionfs . The files from your teamdrive should now be included in the listing. Depending on how busy the root of your drive[s] are, this listing may be pretty long, but look through it to verify that the files you expect as shown in the previous two steps are there [I\u2019ve edited my listing for space]: \u279c ~ ls -haltr /mnt/unionfs/ total 1.4G ... -rwxrwxr-x 1 seed seed 0 Dec 3 16:14 mounted-movies.bin ... \u279c ~ If they don\u2019t show up, go back over the mergerfs config. Assuming they do, you\u2019re done. Now Plex and Emby and any other application that already sees /mnt/unionfs will be able to see those files. You may have to restart the server, or the containers, before they can see the newly-merged files. OMG I have so many teamdrives, this will take forever \u00b6 There\u2019s a set of scripts for that: https://github.com/maximuskowalski/smount Those scripts will automate creating all the rclone entries [which you then copy and paste into your rclone config file], automate creating all the service files, and leave you with all the drives mounted, ready for the mergerfs step. The develop branch ALSO generates the mergerfs config for you. The other day, using those scripts, I had 21 teamdrives set up and mounted in a few minutes. Personally, I think the wiki over there is very clear, but you will need to know some linux. OMG this is so complicated, isn\u2019t there an easier way? \u00b6 No. I\u2019m afraid there isn\u2019t. With the smount scripts, you need to rename a file or two [perhaps], make simple edits to maybe 2 files, run a script, copy and paste some output to another file, then run another script. Honestly, if that\u2019s too much this really isn\u2019t for you.","title":"How do I mount a teamdrive?"},{"location":"reference/guides/chazguides/teamdrive/#how-do-i-mount-a-teamdrive","text":"You have a teamdrive you want to add to your Saltbox server so Plex can see it. In this article I\u2019m assuming that\u2019s ALL you want to do. If you want to set up a teamdrive and upload to it, see the \u201cTip #44\u201d document Here, I\u2019m assuming you have access to a teamdrive, and you want to set it up so you can point Plex or Emby at it. No more than that.","title":"How do I mount a teamdrive?"},{"location":"reference/guides/chazguides/teamdrive/#overview","text":"There are three steps: Create an rclone remote [this tells rclone about the teamdrive] Create the rclone_vfs service files [this makes rclone mount the teamdrive at /mnt/WHATEVER ] Modify your mergerfs service file [this will include the contents of the new teamdrive in /mnt/unionfs for use in your apps] This step is actually optional, but it makes app configuration a little more straightforward since all your media files are in the same directory rather then some in /mnt/unionfs and some in /mnt/bing-bang-boing","title":"Overview:"},{"location":"reference/guides/chazguides/teamdrive/#not-teamdrive-specific","text":"The concepts here are not specific to teamdrives. It\u2019s described in terms of Teamdrives since this is aimed at Saltbox users who use Google Drive almost exclusively. You can go through this exercise with any rclone backend that supports the relevant setup, of course modifying the rclone setup described to suit your OneDrive or Box or whatever other backend.","title":"Not \u201cTeamdrive\u201d specific"},{"location":"reference/guides/chazguides/teamdrive/#prerequisites","text":"Access to a teamdrive Either one of these for an account with access to the teamdrive ClientID/Secret Service Account JSON file[s] Put this/these in some fixed location like /opt/sa Basic linux knowledge Like all of these docs and guides, we are assuming basic familiarity with Linux systems and concepts. You are going to be copying files, editing files, etc. This guide is not here to explain how to do those things. Everything in this doc that appears in ALL_CAPS is a placeholder that needs to be replaced with something that applies to your situation. For example, if I were to say \u201cEnter YOUR_PASSWORD\u201d, I don\u2019t mean for you to enter \u201cYOUR_PASSWORD\u201d; I mean you should enter your password, whatever it is. I think that should be obvious on its face, but here we are. Let\u2019s go! Create the rclone remote After saving the remote and exiting rclone, and before you continue, verify that the remote is working correctly. Type rclone lsd NAME_OF_THE_REMOTE_YOU_JUST_CREATED:/ $ rclone lsd teamdrive-movies:/ -1 2019-03-21 10:59:48 -1 Media It should show you the directories on the root level of the teamdrive you are adding. Verify this with the Google Drive Web UI if necessary. If the teamdrive is empty, create a folder and verify that rclone shows that folder. Nothing after this will work if this connection is not set up correctly. If it doesn\u2019t show you what you\u2019re expecting, go back over the rclone remote setup. Take your time. Something isn\u2019t right. Perhaps you chose the wrong teamdrive. DO NOT PROCEED UNTIL YOU HAVE VERIFIED THAT THIS RCLONE COMMAND SHOWS YOU THE EXPECTED THING. Get that remote mounted in the filesystem Now you have an rclone remote. You can use this with rclone commands like rclone copy or rclone move or what have you. To use it with Plex/Emby/whatever other application, you need to create service files to \u201cmount\u201d the teamdrive in your filesystem. Saltbox does this with your Google Drive at /mnt/remote . You\u2019re going to create an analogous setup that does the same thing for that teamdrive remote you just created. First, you need to create the folder where you want the teamdrive contents to appear. Generally, I recommend using the same name as the remote for clarity: Create a mount point for the teamdrive Create a directory where you want to mount this teamdrive under the /mnt directory: for example: /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED You may have to use sudo to create the directory: sudo mkdir /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED It should be on the root level of /mnt ; not within any other remote mount directory. NOT, for example, /mnt/remote/NAME_OF_THE_REMOTE_YOU_JUST_CREATED OR /mnt/unionfs/NAME_OF_THE_REMOTE_YOU_JUST_CREATED OR /mnt/local/NAME_OF_THE_REMOTE_YOU_JUST_CREATED etc. Make sure it has the same ownership and permissions as the existing /mnt/remote : \u279c ~ ls -al /mnt total 16 drwxr-xr-x 1 root root 168 May 8 18:35 . drwxr-xr-x 1 root root 334 May 18 18:53 .. drwxrwxr-x 1 seed seed 48 May 8 19:08 local drwxrwxr-x 1 seed seed 0 May 20 23:16 remote drwxrwxr-x 1 seed seed 48 May 8 19:08 unionfs To do this: sudo chown -R seed:seed /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED sudo chmod -R g+w /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED Of course, seed:seed is YOUR USER AND GROUP if it differs from seed:seed You will use this mountpoint when you configure the rclone_vfs service. Create service files which will accomplish the mounting: Make copies of the rclone_vfs service file: /etc/systemd/system/rclone_vfs.service sudo cp /etc/systemd/system/rclone_vfs.service /etc/systemd/system/NAME_OF_THE_REMOTE_YOU_JUST_CREATED_vfs.service Edit /etc/systemd/system/NAME_OF_THE_REMOTE_YOU_JUST_CREATED_vfs.service: Change the port [5572] in two lines [lines 27 and 42 at this writing]: --rc-addr=localhost:5572 \\ ... ExecStartPost=/usr/bin/rclone rc vfs/refresh recursive=true --rc-addr localhost:5572 _async=true The specific port you use doesn\u2019t matter, but maybe just use 5573. --rc-addr=localhost:5573 \\ ... ExecStartPost=/usr/bin/rclone rc vfs/refresh recursive=true --rc-addr localhost:5573 _async=true Change the remote name and mount directory in this line [line 41 at this writing]: NAME_OF_THE_REMOTE_YOU_JUST_CREATED: /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED The first bit before the colon is the name of the rclone remote from step 1. The path is the mount point directory you created a moment ago. For example, you might end up with something like this: teamdrive-movies: /mnt/teamdrive-movies What you will enter specifically depneds entirely on how you just configured the remote and moutn directory above. This example is almost certainly not what you should enter. Change the next line to match the path you just entered: ExecStop=/bin/fusermount -uz /mnt/remote For example: ExecStop=/bin/fusermount -uz /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED Lastly enable and start that new service: Reload all the services sudo systemctl daemon-reload Start/restart the service sudo systemctl restart NAME_OF_THE_REMOTE_YOU_JUST_CREATED_vfs.service Enable the new service you created sudo systemctl enable NAME_OF_THE_REMOTE_YOU_JUST_CREATED_vfs.service Now, before you continue, verify that the mount is working correctly. Type ls -haltr /mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED . It should show you the same thing that you saw in the rclone lsd , and the same stuff you see in the Google Drive Web UI: \u279c ~ ls -haltr /mnt/teamdrive-movies total 14M drwxrwxr-x 1 seed seed 0 Mar 21 2019 Media -rw-rw-r-- 1 seed seed 0 Dec 3 16:14 mounted-movies.bin \u279c ~ As before, DO NOT PROCEED UNTIL YOU HAVE VERIFIED THAT THIS LS COMMAND SHOWS YOU THE EXPECTED THING. Add that teamdrive to the mergerfs Last step; you\u2019re going to add the teamdrive to the mergerfs configuration so that the files from it show up under /mnt/unionfs with the rest of your files. Edit the mergerfs service file to include the new teamdrive in the mergerfs. Edit this file: /etc/systemd/system/mergerfs.service Edit this line to include your new teamdrive: /mnt/local=RW:/mnt/remote=NC /mnt/unionfs For example: /mnt/local=RW:/mnt/remote=NC:/mnt/NAME_OF_THE_REMOTE_YOU_JUST_CREATED=NC /mnt/unionfs Note: that MUST BE all one line, just as it is in the original unedited file. Just like the rclone_vfs service, reload and restart: Reload all the services sudo systemctl daemon-reload Start/restart the mergerfs sudo systemctl restart mergerfs.service Enable the mergerfs just for good measure sudo systemctl enable mergerfs.service Now, verify that the mergerfs is working correctly. Type ls -haltr /mnt/unionfs . The files from your teamdrive should now be included in the listing. Depending on how busy the root of your drive[s] are, this listing may be pretty long, but look through it to verify that the files you expect as shown in the previous two steps are there [I\u2019ve edited my listing for space]: \u279c ~ ls -haltr /mnt/unionfs/ total 1.4G ... -rwxrwxr-x 1 seed seed 0 Dec 3 16:14 mounted-movies.bin ... \u279c ~ If they don\u2019t show up, go back over the mergerfs config. Assuming they do, you\u2019re done. Now Plex and Emby and any other application that already sees /mnt/unionfs will be able to see those files. You may have to restart the server, or the containers, before they can see the newly-merged files.","title":"Prerequisites"},{"location":"reference/guides/chazguides/teamdrive/#omg-i-have-so-many-teamdrives-this-will-take-forever","text":"There\u2019s a set of scripts for that: https://github.com/maximuskowalski/smount Those scripts will automate creating all the rclone entries [which you then copy and paste into your rclone config file], automate creating all the service files, and leave you with all the drives mounted, ready for the mergerfs step. The develop branch ALSO generates the mergerfs config for you. The other day, using those scripts, I had 21 teamdrives set up and mounted in a few minutes. Personally, I think the wiki over there is very clear, but you will need to know some linux.","title":"OMG I have so many teamdrives, this will take forever"},{"location":"reference/guides/chazguides/teamdrive/#omg-this-is-so-complicated-isnt-there-an-easier-way","text":"No. I\u2019m afraid there isn\u2019t. With the smount scripts, you need to rename a file or two [perhaps], make simple edits to maybe 2 files, run a script, copy and paste some output to another file, then run another script. Honestly, if that\u2019s too much this really isn\u2019t for you.","title":"OMG this is so complicated, isn\u2019t there an easier way?"},{"location":"reference/guides/chazguides/tip44/","text":"This is a Cloudbox article that has not yet been updated for saltbox. The information therein may not apply to Saltbox. Tip 44: UNSUPPORTED Shared Drive/Service Account setup for Cloudbox The scripted rclone setup is the saltbox equivalent to that setup. The longer article discusses the concepts behind it, but the tasks are taken care of by the scripted rclone setup . If you had that set up in Cloudbox, you can and should reuse your existing setup. There is no reason to set it up again from scratch.","title":"Tip 44 Guide to Shared Drive/Service Account setup for Saltbox"},{"location":"saltbox/backup/backup/","text":"Backup \u00b6 With Saltbox you can either run a backup task manually or schedule it to run automatically. Manual Backup \u00b6 Info This step assumes you have completed the configuration of the backup_config.yml in the configuration step . Without Screen With Screen sb install backup screen -dmS saltbox-backup sb install backup screen -r CTRL A + D Scheduled Backup \u00b6 Info This step assumes you have completed the configuration of the backup_config.yml in the configuration step . Have Saltbox configure cron Configure cron manually sb install set-backup crontab -e 0 4 * * * sudo PATH = '/usr/bin:/bin:/usr/local/bin' env ANSIBLE_CONFIG = '/srv/git/saltbox/ansible.cfg' '/usr/local/bin/ansible-playbook' '/srv/git/saltbox/backup.yml' >> '/home/seed/logs/saltbox_backup.log' 2 > & 1 Remember to edit the seed username if you changed the Saltbox user in the accounts.yml . Visit crontab.guru for help with the scheduling format.","title":"Backup"},{"location":"saltbox/backup/backup/#backup","text":"With Saltbox you can either run a backup task manually or schedule it to run automatically.","title":"Backup"},{"location":"saltbox/backup/backup/#manual-backup","text":"Info This step assumes you have completed the configuration of the backup_config.yml in the configuration step . Without Screen With Screen sb install backup screen -dmS saltbox-backup sb install backup screen -r CTRL A + D","title":"Manual Backup"},{"location":"saltbox/backup/backup/#scheduled-backup","text":"Info This step assumes you have completed the configuration of the backup_config.yml in the configuration step . Have Saltbox configure cron Configure cron manually sb install set-backup crontab -e 0 4 * * * sudo PATH = '/usr/bin:/bin:/usr/local/bin' env ANSIBLE_CONFIG = '/srv/git/saltbox/ansible.cfg' '/usr/local/bin/ansible-playbook' '/srv/git/saltbox/backup.yml' >> '/home/seed/logs/saltbox_backup.log' 2 > & 1 Remember to edit the seed username if you changed the Saltbox user in the accounts.yml . Visit crontab.guru for help with the scheduling format.","title":"Scheduled Backup"},{"location":"saltbox/backup/migrate/","text":"This guide will outline some basic steps to copy/move your Saltbox setup to another server and/or another domain name. Listed below are some common scenarios and their migration instructions. Move Saltbox to Another Server and Keep the Same Domain Name \u00b6 Current Server \u00b6 Back up your current Saltbox server. New Server \u00b6 Restore Saltbox to the new server. If you are not using Cloudflare: Point your domain's DNS to the new server. Install the relevant Saltbox type: Saltbox, Mediabox, or Feederbox . Install any extra, not-default containers you had installed previously from Sandbox or on your own. Check to see if your Plex Autoscan URL has changed and update Sonarr , Radarr , and Lidarr accordingly, if you are using Plex Autoscan. Move Saltbox to Another Server and Change the Domain Name \u00b6 Current Server \u00b6 Back up your current Saltbox server. New Server \u00b6 Restore Saltbox to the new server. Add your new domain name into Accounts . If you are using Cloudflare: Register your domain with Cloudflare . Add the Cloudflare API into Accounts . If you are not using Cloudflare: Point your domain's DNS to the new server. Replace the domain name in app specific config files: /opt/cloudplow/config.json /opt/motd/config.json /opt/traktarr/config.json (only if installed) /opt/plex_dupefinder/config.json (only if installed) /opt/plex_patrol/settings.ini (only if installed) Install the relevant Saltbox type: Saltbox, Mediabox, or Feederbox . Install any extra, not-default containers you had installed previously from Sandbox or on your own. Check to see if your Plex Autoscan URL has changed and update Sonarr , Radarr , and Lidarr accordingly, if you are using Plex Autoscan. 6. Keep Saltbox on the Same Server but Change the Domain Name \u00b6 Back up your current Saltbox server. Add your new domain name into Accounts . If you are using Cloudflare: Register your domain with Cloudflare . Add the Cloudflare API into Accounts . If you are not using Cloudflare: Point your domain's DNS to the new server. Replace the domain name in app specific config files: /opt/cloudplow/config.json /opt/motd/config.json /opt/traktarr/config.json (only if installed) /opt/plex_dupefinder/config.json (only if installed) /opt/plex_patrol/settings.ini (only if installed) Install the relevant Saltbox type: Saltbox, Mediabox, or Feederbox . Install any extra, not-default containers you had installed previously from Sandbox or on your own. Check to see if your Plex Autoscan URL has changed and update Sonarr , Radarr , and Lidarr accordingly, if you are using Plex Autoscan.","title":"Migrate"},{"location":"saltbox/backup/migrate/#move-saltbox-to-another-server-and-keep-the-same-domain-name","text":"","title":"Move Saltbox to Another Server and Keep the Same Domain Name"},{"location":"saltbox/backup/migrate/#current-server","text":"Back up your current Saltbox server.","title":"Current Server"},{"location":"saltbox/backup/migrate/#new-server","text":"Restore Saltbox to the new server. If you are not using Cloudflare: Point your domain's DNS to the new server. Install the relevant Saltbox type: Saltbox, Mediabox, or Feederbox . Install any extra, not-default containers you had installed previously from Sandbox or on your own. Check to see if your Plex Autoscan URL has changed and update Sonarr , Radarr , and Lidarr accordingly, if you are using Plex Autoscan.","title":"New Server"},{"location":"saltbox/backup/migrate/#move-saltbox-to-another-server-and-change-the-domain-name","text":"","title":"Move Saltbox to Another Server and Change the Domain Name"},{"location":"saltbox/backup/migrate/#current-server_1","text":"Back up your current Saltbox server.","title":"Current Server"},{"location":"saltbox/backup/migrate/#new-server_1","text":"Restore Saltbox to the new server. Add your new domain name into Accounts . If you are using Cloudflare: Register your domain with Cloudflare . Add the Cloudflare API into Accounts . If you are not using Cloudflare: Point your domain's DNS to the new server. Replace the domain name in app specific config files: /opt/cloudplow/config.json /opt/motd/config.json /opt/traktarr/config.json (only if installed) /opt/plex_dupefinder/config.json (only if installed) /opt/plex_patrol/settings.ini (only if installed) Install the relevant Saltbox type: Saltbox, Mediabox, or Feederbox . Install any extra, not-default containers you had installed previously from Sandbox or on your own. Check to see if your Plex Autoscan URL has changed and update Sonarr , Radarr , and Lidarr accordingly, if you are using Plex Autoscan. 6.","title":"New Server"},{"location":"saltbox/backup/migrate/#keep-saltbox-on-the-same-server-but-change-the-domain-name","text":"Back up your current Saltbox server. Add your new domain name into Accounts . If you are using Cloudflare: Register your domain with Cloudflare . Add the Cloudflare API into Accounts . If you are not using Cloudflare: Point your domain's DNS to the new server. Replace the domain name in app specific config files: /opt/cloudplow/config.json /opt/motd/config.json /opt/traktarr/config.json (only if installed) /opt/plex_dupefinder/config.json (only if installed) /opt/plex_patrol/settings.ini (only if installed) Install the relevant Saltbox type: Saltbox, Mediabox, or Feederbox . Install any extra, not-default containers you had installed previously from Sandbox or on your own. Check to see if your Plex Autoscan URL has changed and update Sonarr , Radarr , and Lidarr accordingly, if you are using Plex Autoscan.","title":"Keep Saltbox on the Same Server but Change the Domain Name"},{"location":"saltbox/backup/restore/","text":"Restore \u00b6 Info Just like the initial install, these instructions are assuming you are running as root until told otherwise below. Dependencies \u00b6 Start by installing dependencies. curl wget curl (verbose) wget (verbose) curl -sL https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox wget -qO- https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox curl -sL https://install.saltbox.dev | sudo -H bash -s -- -v ; cd /srv/git/saltbox wget -qO- https://install.saltbox.dev | sudo -H bash -s -- -v ; cd /srv/git/saltbox Then retrieve the configuration files from a backup. Using Restore Service \u00b6 curl wget curl -sL https://restore.saltbox.dev | bash -s 'USERNAME' 'PASSWORD' # (1)! Use the username and password defined for the service when last backup was executed. Must wrap the username and password in quotes. wget -qO- https://restore.saltbox.dev | bash -s 'USERNAME' 'PASSWORD' # (1)! Use the username and password defined for the service when last backup was executed. Must wrap the username and password in quotes. Then run preinstall which will setup the user account and a few other dependencies for the restore. sb install preinstall Info From this point you'll want to make sure you run commands as the user specified in the accounts.yml Info If you are using a service account to authenticate the rclone remote that holds the backup, you will need to put that SA JSON file in place manually so that the restore process can authenticate the remote to download the rest of the backup. Start the restore process. sb install restore Once succesfully completed you can now follow the installation guide from this step . Without Restore Service \u00b6 Retrieve the following configuration files from your backup manually and place them in /srv/git/saltbox : accounts.yml settings.yml adv_settings.yml backup_config.yml providers.yml hetzner_nfs.yml rclone.conf localhost.yml Then run preinstall which will setup the user account and a few other dependencies for the restore. sb install preinstall Info From this point you'll want to make sure you run commands as the user specified in the accounts.yml Info If you are using a service account to authenticate the rclone remote that holds the backup, you will need to put that SA JSON file in place manually so that the restore process can authenticate the remote to download the rest of the backup. Start the restore process. sb install restore Once successfully completed you can now continue: If you are migrating from one server to another, return to the migration guide If you are restoring to the same server, you can now follow the installation guide from this step .","title":"Restore"},{"location":"saltbox/backup/restore/#restore","text":"Info Just like the initial install, these instructions are assuming you are running as root until told otherwise below.","title":"Restore"},{"location":"saltbox/backup/restore/#dependencies","text":"Start by installing dependencies. curl wget curl (verbose) wget (verbose) curl -sL https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox wget -qO- https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox curl -sL https://install.saltbox.dev | sudo -H bash -s -- -v ; cd /srv/git/saltbox wget -qO- https://install.saltbox.dev | sudo -H bash -s -- -v ; cd /srv/git/saltbox Then retrieve the configuration files from a backup.","title":"Dependencies"},{"location":"saltbox/backup/restore/#using-restore-service","text":"curl wget curl -sL https://restore.saltbox.dev | bash -s 'USERNAME' 'PASSWORD' # (1)! Use the username and password defined for the service when last backup was executed. Must wrap the username and password in quotes. wget -qO- https://restore.saltbox.dev | bash -s 'USERNAME' 'PASSWORD' # (1)! Use the username and password defined for the service when last backup was executed. Must wrap the username and password in quotes. Then run preinstall which will setup the user account and a few other dependencies for the restore. sb install preinstall Info From this point you'll want to make sure you run commands as the user specified in the accounts.yml Info If you are using a service account to authenticate the rclone remote that holds the backup, you will need to put that SA JSON file in place manually so that the restore process can authenticate the remote to download the rest of the backup. Start the restore process. sb install restore Once succesfully completed you can now follow the installation guide from this step .","title":"Using Restore Service"},{"location":"saltbox/backup/restore/#without-restore-service","text":"Retrieve the following configuration files from your backup manually and place them in /srv/git/saltbox : accounts.yml settings.yml adv_settings.yml backup_config.yml providers.yml hetzner_nfs.yml rclone.conf localhost.yml Then run preinstall which will setup the user account and a few other dependencies for the restore. sb install preinstall Info From this point you'll want to make sure you run commands as the user specified in the accounts.yml Info If you are using a service account to authenticate the rclone remote that holds the backup, you will need to put that SA JSON file in place manually so that the restore process can authenticate the remote to download the rest of the backup. Start the restore process. sb install restore Once successfully completed you can now continue: If you are migrating from one server to another, return to the migration guide If you are restoring to the same server, you can now follow the installation guide from this step .","title":"Without Restore Service"},{"location":"saltbox/backup/settings/","text":"Configuration \u00b6 The configuration file for backup/restore is called backup_config.yml and is located in /srv/git/saltbox --- backup : local : enable : true # (1)! destination : /mnt/local/Backups/Saltbox # (2)! rclone : enable : true # (3)! destination : google:/Backups/Saltbox # (4)! rsync : enable : false # (5)! destination : rsync://somehost.com/Backups/Saltbox # (6)! port : 22 # (7)! cron : cron_time : weekly # (8)! enable : no # (9)! restore_service : user : # (10)! pass : # (11)! misc : snapshot : true # (12)! Toggle for keeping a local copy of the backup. Options are: true or false Path used for the local backups. Toggle for using Rclone remote backup storage. Options are: true or false Path used for the Rclone remote. Backups outside of the most recent one will be located in the archived folder. Make sure that this path is unique if you run multiple instances of Saltbox. Toggle for using Rsync backups. Options are: true or false Path used for the Rsync backups. Port used by rsync on the target server. Schedule for when the backup task will be executed. Options are: reboot , yearly , annually , monthly , weekly , daily , hourly . Should you desire more granular control over the schedule you can edit the crontab for the Saltbox user once setup. Toggle for enabling automatic backups. Options are: no or yes Depending on the option set here the cron entry created by Saltbox will be added, removed or modified. Username used for the OPTIONAL restore service. Has to be unique across all users of the service. Try sticking with a url for the server box.domain.tld unique to each server for something easily remembered. Usernames are hashed before requests are sent to the restore service. Password used to encrypt/decrypt the configuration files in the OPTIONAL restore service. Only used on the client side in scripts. Toggle for BTRFS snaphots. Options are: true or false Requires BTRFS on / or /opt Use of the restore service is optional. Using it means that [client-side] encrypted copies of your config files are stored on saltbox servers for later use with the sb restore command. If you are uncomfortable with this, leave the username and password blank and the restore server will not be used. Visit crontab.guru for help with the scheduling format. Important These values: restore_service : user : # (1)! pass : # (2)! Username used for the OPTIONAL restore service. Has to be unique across all users of the service. Try sticking with a url for the server box.domain.tld unique to each server for something easily remembered. Usernames are hashed before requests are sent to the restore service. Password used encrypt/decrypt the configuration files for the OPTIONAL restore service. Only used on the client side in scripts. SHOULD NOT BE YOUR SERVER ACCOUNT CREDENTIALS. These are an arbitrary username/password that you make up which are used ONLY with this backup/restore service. They are used to encrypt your config files before they are placed on the saltbox restore server, and then in the restore command that retrieves the backup for decryption. They are not sent or stored anywhere else. If they are not filled in, then your config files will not be sent to the saltbox restore service.","title":"Settings"},{"location":"saltbox/backup/settings/#configuration","text":"The configuration file for backup/restore is called backup_config.yml and is located in /srv/git/saltbox --- backup : local : enable : true # (1)! destination : /mnt/local/Backups/Saltbox # (2)! rclone : enable : true # (3)! destination : google:/Backups/Saltbox # (4)! rsync : enable : false # (5)! destination : rsync://somehost.com/Backups/Saltbox # (6)! port : 22 # (7)! cron : cron_time : weekly # (8)! enable : no # (9)! restore_service : user : # (10)! pass : # (11)! misc : snapshot : true # (12)! Toggle for keeping a local copy of the backup. Options are: true or false Path used for the local backups. Toggle for using Rclone remote backup storage. Options are: true or false Path used for the Rclone remote. Backups outside of the most recent one will be located in the archived folder. Make sure that this path is unique if you run multiple instances of Saltbox. Toggle for using Rsync backups. Options are: true or false Path used for the Rsync backups. Port used by rsync on the target server. Schedule for when the backup task will be executed. Options are: reboot , yearly , annually , monthly , weekly , daily , hourly . Should you desire more granular control over the schedule you can edit the crontab for the Saltbox user once setup. Toggle for enabling automatic backups. Options are: no or yes Depending on the option set here the cron entry created by Saltbox will be added, removed or modified. Username used for the OPTIONAL restore service. Has to be unique across all users of the service. Try sticking with a url for the server box.domain.tld unique to each server for something easily remembered. Usernames are hashed before requests are sent to the restore service. Password used to encrypt/decrypt the configuration files in the OPTIONAL restore service. Only used on the client side in scripts. Toggle for BTRFS snaphots. Options are: true or false Requires BTRFS on / or /opt Use of the restore service is optional. Using it means that [client-side] encrypted copies of your config files are stored on saltbox servers for later use with the sb restore command. If you are uncomfortable with this, leave the username and password blank and the restore server will not be used. Visit crontab.guru for help with the scheduling format. Important These values: restore_service : user : # (1)! pass : # (2)! Username used for the OPTIONAL restore service. Has to be unique across all users of the service. Try sticking with a url for the server box.domain.tld unique to each server for something easily remembered. Usernames are hashed before requests are sent to the restore service. Password used encrypt/decrypt the configuration files for the OPTIONAL restore service. Only used on the client side in scripts. SHOULD NOT BE YOUR SERVER ACCOUNT CREDENTIALS. These are an arbitrary username/password that you make up which are used ONLY with this backup/restore service. They are used to encrypt your config files before they are placed on the saltbox restore server, and then in the restore command that retrieves the backup for decryption. They are not sent or stored anywhere else. If they are not filled in, then your config files will not be sent to the saltbox restore service.","title":"Configuration"},{"location":"saltbox/basics/accessing_apps/","text":"Accessing Saltbox Apps \u00b6 Note 1: After the initial setup, it will take a a while for the SSL certificates to propagate. A side effect of this will be that certain domains were redirect to other apps (e.g. sonarr.yourdomain.com -> nzbget.yourdomain.com). Just give it a bit of time and this will correct itself. Note 2: If pages don't load at all, make sure you've set up your domain properly and also checkout the FAQ . Default Apps \u00b6 Saltbox apps will be accessed via appname. yourdomain.com (see table below). App Name with domain without domain Jackett https://jackett. yourdomain.com http:// server_ip :9117 Lidarr https://lidarr. yourdomain.com http:// server_ip :8686 NZBGet https://nzbget. yourdomain.com http:// server_ip :6789 NZBHydra2 https://nzbhydra2. yourdomain.com http:// server_ip :5076 Organizr https://organizr. yourdomain.com http:// server_ip :port Overseerr https://overseerr. yourdomain.com http:// server_ip :5055 Plex https://plex. yourdomain.com http:// server_ip :32400 WebTools for Plex https://plex-webtools. yourdomain.com http:// server_ip :33400 Portainer https://portainer. yourdomain.com http:// server_ip :9000 Radarr https://radarr. yourdomain.com http:// server_ip :7878 ruTorrent https://rutorrent. yourdomain.com http:// server_ip :port Sonarr https://sonarr. yourdomain.com http:// server_ip :8989 Tautulli https://tautulli. yourdomain.com http:// server_ip :8181 Additional Apps \u00b6 Coming soon. Next, let's discuss Saltbox' default paths .","title":"Accessing Apps"},{"location":"saltbox/basics/accessing_apps/#accessing-saltbox-apps","text":"Note 1: After the initial setup, it will take a a while for the SSL certificates to propagate. A side effect of this will be that certain domains were redirect to other apps (e.g. sonarr.yourdomain.com -> nzbget.yourdomain.com). Just give it a bit of time and this will correct itself. Note 2: If pages don't load at all, make sure you've set up your domain properly and also checkout the FAQ .","title":"Accessing Saltbox Apps"},{"location":"saltbox/basics/accessing_apps/#default-apps","text":"Saltbox apps will be accessed via appname. yourdomain.com (see table below). App Name with domain without domain Jackett https://jackett. yourdomain.com http:// server_ip :9117 Lidarr https://lidarr. yourdomain.com http:// server_ip :8686 NZBGet https://nzbget. yourdomain.com http:// server_ip :6789 NZBHydra2 https://nzbhydra2. yourdomain.com http:// server_ip :5076 Organizr https://organizr. yourdomain.com http:// server_ip :port Overseerr https://overseerr. yourdomain.com http:// server_ip :5055 Plex https://plex. yourdomain.com http:// server_ip :32400 WebTools for Plex https://plex-webtools. yourdomain.com http:// server_ip :33400 Portainer https://portainer. yourdomain.com http:// server_ip :9000 Radarr https://radarr. yourdomain.com http:// server_ip :7878 ruTorrent https://rutorrent. yourdomain.com http:// server_ip :port Sonarr https://sonarr. yourdomain.com http:// server_ip :8989 Tautulli https://tautulli. yourdomain.com http:// server_ip :8181","title":"Default Apps"},{"location":"saltbox/basics/accessing_apps/#additional-apps","text":"Coming soon. Next, let's discuss Saltbox' default paths .","title":"Additional Apps"},{"location":"saltbox/basics/basics/","text":"Basics \u00b6 What is Saltbox? \u00b6 Saltbox is an Ansible and Docker based solution for rapidly deploying a cloud media server using Ubuntu Server 20.04 or Ubuntu Server 22.04 LTS running on AMD64. ARM processors, Raspberry Pi notably, are not supported. Primary functions are: the automatic acquisition of media, storing that media on the cloud, and being able to play it back from anywhere and from any device. NOTE: Saltbox does not have a dashboard or GUI of its own. All Saltbox-specific setup and commands are done on the linux command-line. Why use Saltbox? \u00b6 Custom Domains \u00b6 Have your server setup behind your own domain, securely (e.g. https://apps.yourdomain.com). Fast Deployment \u00b6 Have a system running in minutes with minimal input. Docker-Based Applications \u00b6 Docker containers keep your apps isolated from each other - no more conflicts between apps. Docker containers keep your system tidy since none of the apps' files (executables and dependencies) are stored outside of the container. Quickly install and uninstall apps. Cloud Storage \u00b6 Store media on cloud storage to save on local drive space. Can Choose Your Preferred Media Server Application \u00b6 You can decide whether to use Plex, Emby or Jellyfin. Custom Server Deployment \u00b6 You can deploy Saltbox on an all-in-one server, for downloading and streaming. or You can deploy Saltbox between two servers: a Mediabox, as streaming server, and a Feederbox, as a downloading server. Secure \u00b6 Saltbox uses secure HTTPS backed by Let's Encrypt or ZeroSSL certificates. Easy Backup and Restore \u00b6 Configuration and data files for all key applications are conveniently stored in /opt, which makes backup so easy. Easily pack up your server and move to another one with Saltbox's built-in Backup. How does Saltbox function ? \u00b6 Sonarr manages downloading your favorite TV Shows and Radarr manages downloading your favorite movies. Both use either Usenet (via NZBGet ) and/or Torrents (via ruTorrent ) to do this. [1] [2] Once the downloads are complete, Sonarr & Radarr will move [or copy in the case of torrents] these downloads to your server's /mnt/local/Media/ folder [3] and send a notification to Autoscan . AutoScan will, in turn, tell Plex to scan for the newly downloaded TV Show or Movie, by only scanning the specific season or movie folder. This will make the media appear in Plex sooner than what a full library scan would have been able to do, and reduce the chances of Cloud Storage API bans for excessive activity. Cloudplow will eventually [4] move everything [5] from /mnt/local/Media/ to a folder named Media on the remote cloud storage, thereby reducing the storage used on the (local) server. During this migration, the media files will continue to be accessible to Media Servers (e.g. Plex) because the remote cloud storage (e.g. Google Drive) will be mounted on to the server as if it were a local drive. This is accomplished with an Rclone VFS mount pointing to the cloud storage, and a union of that mount with the server\u2019s own local storage (accomplished via mergerfs ). 1 Some of the applications above can be replaced with similar apps. 2 If you want to use Torrents, it is recommended to be a member of a private tracker vs using public ones. If you want to to use Usenet, you will need to purchase Usenet provider service (or multiple services) and also be a member of one or more Usenet indexers. 3 The move to /mnt/local/Media is indirect; Radarr/Sonarr are using /mnt/unionfs/Media , and they move the file there , however, /mnt/local is the only writeable part of the mergerfs [for the purpose of creating new files], so the newly-written files will be placed in /mnt/local . 4 By default, Cloudplow will check every half hour to see if there is 200GB of data staged in /mnt/local and if there is, all that data is pushed to your Google Drive. This threshold can be adjusted as needed in the Cloudplow config. 5 There is presently a 750GB/day upload limitation on Google accounts. The standard Saltbox setup will create a set of shared drives and service accounts. The service accounts can be enabled in cloudplow to exceeed this limit on uploads [750 GB/day/service account]. Next, let's discuss the Prerequisites for Saltbox installation.","title":"Basics"},{"location":"saltbox/basics/basics/#basics","text":"","title":"Basics"},{"location":"saltbox/basics/basics/#what-is-saltbox","text":"Saltbox is an Ansible and Docker based solution for rapidly deploying a cloud media server using Ubuntu Server 20.04 or Ubuntu Server 22.04 LTS running on AMD64. ARM processors, Raspberry Pi notably, are not supported. Primary functions are: the automatic acquisition of media, storing that media on the cloud, and being able to play it back from anywhere and from any device. NOTE: Saltbox does not have a dashboard or GUI of its own. All Saltbox-specific setup and commands are done on the linux command-line.","title":"What is Saltbox?"},{"location":"saltbox/basics/basics/#why-use-saltbox","text":"","title":"Why use Saltbox?"},{"location":"saltbox/basics/basics/#custom-domains","text":"Have your server setup behind your own domain, securely (e.g. https://apps.yourdomain.com).","title":"Custom Domains"},{"location":"saltbox/basics/basics/#fast-deployment","text":"Have a system running in minutes with minimal input.","title":"Fast Deployment"},{"location":"saltbox/basics/basics/#docker-based-applications","text":"Docker containers keep your apps isolated from each other - no more conflicts between apps. Docker containers keep your system tidy since none of the apps' files (executables and dependencies) are stored outside of the container. Quickly install and uninstall apps.","title":"Docker-Based Applications"},{"location":"saltbox/basics/basics/#cloud-storage","text":"Store media on cloud storage to save on local drive space.","title":"Cloud Storage"},{"location":"saltbox/basics/basics/#can-choose-your-preferred-media-server-application","text":"You can decide whether to use Plex, Emby or Jellyfin.","title":"Can Choose Your Preferred Media Server Application"},{"location":"saltbox/basics/basics/#custom-server-deployment","text":"You can deploy Saltbox on an all-in-one server, for downloading and streaming. or You can deploy Saltbox between two servers: a Mediabox, as streaming server, and a Feederbox, as a downloading server.","title":"Custom Server Deployment"},{"location":"saltbox/basics/basics/#secure","text":"Saltbox uses secure HTTPS backed by Let's Encrypt or ZeroSSL certificates.","title":"Secure"},{"location":"saltbox/basics/basics/#easy-backup-and-restore","text":"Configuration and data files for all key applications are conveniently stored in /opt, which makes backup so easy. Easily pack up your server and move to another one with Saltbox's built-in Backup.","title":"Easy Backup and Restore"},{"location":"saltbox/basics/basics/#how-does-saltbox-function","text":"Sonarr manages downloading your favorite TV Shows and Radarr manages downloading your favorite movies. Both use either Usenet (via NZBGet ) and/or Torrents (via ruTorrent ) to do this. [1] [2] Once the downloads are complete, Sonarr & Radarr will move [or copy in the case of torrents] these downloads to your server's /mnt/local/Media/ folder [3] and send a notification to Autoscan . AutoScan will, in turn, tell Plex to scan for the newly downloaded TV Show or Movie, by only scanning the specific season or movie folder. This will make the media appear in Plex sooner than what a full library scan would have been able to do, and reduce the chances of Cloud Storage API bans for excessive activity. Cloudplow will eventually [4] move everything [5] from /mnt/local/Media/ to a folder named Media on the remote cloud storage, thereby reducing the storage used on the (local) server. During this migration, the media files will continue to be accessible to Media Servers (e.g. Plex) because the remote cloud storage (e.g. Google Drive) will be mounted on to the server as if it were a local drive. This is accomplished with an Rclone VFS mount pointing to the cloud storage, and a union of that mount with the server\u2019s own local storage (accomplished via mergerfs ). 1 Some of the applications above can be replaced with similar apps. 2 If you want to use Torrents, it is recommended to be a member of a private tracker vs using public ones. If you want to to use Usenet, you will need to purchase Usenet provider service (or multiple services) and also be a member of one or more Usenet indexers. 3 The move to /mnt/local/Media is indirect; Radarr/Sonarr are using /mnt/unionfs/Media , and they move the file there , however, /mnt/local is the only writeable part of the mergerfs [for the purpose of creating new files], so the newly-written files will be placed in /mnt/local . 4 By default, Cloudplow will check every half hour to see if there is 200GB of data staged in /mnt/local and if there is, all that data is pushed to your Google Drive. This threshold can be adjusted as needed in the Cloudplow config. 5 There is presently a 750GB/day upload limitation on Google accounts. The standard Saltbox setup will create a set of shared drives and service accounts. The service accounts can be enabled in cloudplow to exceeed this limit on uploads [750 GB/day/service account]. Next, let's discuss the Prerequisites for Saltbox installation.","title":"How does Saltbox function ?"},{"location":"saltbox/basics/install_types/","text":"Saltbox Install Types \u00b6 Saltbox consists of a \"Core\" with various extra components added onto that core. At a minimum, you need to install \"core\" to do anything further with the Saltbox infrastructure. core saltbox mediabox feederbox System Tweaks Saltbox MOTD Common Tools and Tasks Docker Rclone Mounts: MergerFS Mounts: Rclone VFS Scripts Traefik ( Docker ) Authelia ( Docker ) Plex ( Docker ) Tautulli ( Docker ) Overseerr ( Docker ) Autoscan (Media Scanner Helper Script) Portainer ( Docker ) Organizr ( Docker ) Cloudplow (Media Uploader) NZBGet ( Docker ) rTorrent / ruTorrent ( Docker ) Jackett ( Docker ) NZBHydra 2 ( Docker ) Sonarr ( Docker ) Radarr ( Docker ) Lidarr ( Docker ) Next, let's move on to Installing Saltbox .","title":"Install Types"},{"location":"saltbox/basics/install_types/#saltbox-install-types","text":"Saltbox consists of a \"Core\" with various extra components added onto that core. At a minimum, you need to install \"core\" to do anything further with the Saltbox infrastructure. core saltbox mediabox feederbox System Tweaks Saltbox MOTD Common Tools and Tasks Docker Rclone Mounts: MergerFS Mounts: Rclone VFS Scripts Traefik ( Docker ) Authelia ( Docker ) Plex ( Docker ) Tautulli ( Docker ) Overseerr ( Docker ) Autoscan (Media Scanner Helper Script) Portainer ( Docker ) Organizr ( Docker ) Cloudplow (Media Uploader) NZBGet ( Docker ) rTorrent / ruTorrent ( Docker ) Jackett ( Docker ) NZBHydra 2 ( Docker ) Sonarr ( Docker ) Radarr ( Docker ) Lidarr ( Docker ) Next, let's move on to Installing Saltbox .","title":"Saltbox Install Types"},{"location":"saltbox/basics/paths/","text":"Saltbox Paths \u00b6 General Info \u00b6 It is recommended to assign all your disk space to / , as all of your imported media and app data will be saved to /mnt/local/ and /opt/ , respectively. This allows your application metadata and your staged media to make the most use of your available disk space without worrying about partitioning. Note 1: ALL folders/paths mentioned below, and elsewhere on the wiki, are CASE SENSITIVE (e.g. Google Drive: Media not media , Movies not movies , TV not tv ; Plex Requests: /logs not /Logs , etc). This is important, or else apps like Plex, Sonarr, and Radarr will not be able find your media. Note 2: This wiki uses ~/ interchangeably with /home/<username>/ , which is defined as /home/{{user}}/ in Ansible syntax (as used in settings.yml ). So if your user name was seed , your ~/ path would be /home/seed/ . For this reason it is important that you run commands as the appropriate user as you go through the wiki. Google Drive Paths \u00b6 Media \u251c\u2500\u2500 Movies \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV Path Description /Media/ Location of all your media folders. /Media/Movies/ Location of all your movies (folder format: /Media/Movies/Movie Name (year)/movie file.ext ). /Media/Music/ Location of all your music. /Media/TV/ Location of all your TV shows (folder format: /Media/TV/TV Show Name/Season 00/episode file.ext ). Note: If you would like to customize your Plex libraries differently, see Customizing Plex Libraries . Local Paths \u00b6 mnt \u251c\u2500\u2500local | \u2514\u2500\u2500 Media \u251c\u2500\u2500remote | \u2514\u2500\u2500 Media \u2514\u2500\u2500unionfs \u2514\u2500\u2500 Media Media \u00b6 Path Description /mnt/local/Media/ Location of media stored on the server. This is the local part of /mnt/unionfs/Media/ . /mnt/remote/Media/ Location of media stored on Google Drive (mounted by rclone). /mnt/unionfs/Media/ Combined folder of local media ( /mnt/local/Media/ ) and online media ( /mnt/remote/Media/ ). This is the folder that Plex, Sonarr, and Radarr read when scanning for media. Note: Make sure /mnt/local/ has enough space to store the imported media (before cloudplow is able to move it to Google Drive). Cloudplow \u00b6 Path Description /mnt/local/Media/ Location of media stored on the server. Size of this path is checked periodically (default 30 min). When the folder size reaches its target (default 200GB), media files are moved off/uploaded to the cloud, freeing up local disk space. Note: For more info, see the Cloudplow page. Docker Paths \u00b6 The Dockerized app (e.g. Plex) will \"see\" the Docker Path , but that path will actually be the Host Path on the server. By default, NZB and Torrent downloads are stored in /mnt/local/downloads/nzbs/ and /mnt/local/downloads/torrents/ , respectively. However, this can be changed to point elsewhere (e.g. a second hard drive) by editing the settings.yml file. But regardless of the download location chosen, the Docker Path will always be the same. Note: It is advised to leave at least 100GB free on /opt for the storage of Docker data . Any container that requires disk access \u00b6 Docker Path Host Path Description /mnt /mnt Provides access to all standard mounted storage. Every container sees any path inside /mnt the same as the host and same as any other container. That means that no path translation is required from context to context. If nzbget reports a download at /mnt/unionfs/downloads/... then Radarr will see it in the same place; when Radarr tells Plex-Autoscan [PAS] about it, PAS sees it in that same place; when PAS tells Plex about it, Plex sees it in that same place. Plex \u00b6 Docker Path Host Path Description /mnt/unionfs/Media/Movies/ /mnt/unionfs/Media/Movies/ Plex reads this for Movies. /mnt/unionfs/Media/TV/ /mnt/unionfs/Media/TV/ Plex reads this for TV Shows. /mnt/unionfs/Media/Music/ /mnt/unionfs/Media/Music/ Plex reads this for Music. Sonarr \u00b6 Docker Path Host Path Description /mnt/unionfs/Media/TV/ /mnt/unionfs/Media/TV/ Sonarr will import to /tv/ , which is actually /mnt/unionfs/Media/TV/ on host system. /mnt/unionfs/downloads/nzbs/ /mnt/local/downloads/nzbs/ (default) NZB downloads folder as set in settings.yml ). For example, when using NZBGet, Sonarr will import from /mnt/unionfs/downloads/nzbs/nzbget/ , which is essentially /mnt/local/downloads/nzbs/nzbget/ on host system. /mnt/unionfs/downloads/torrents/ /mnt/local/downloads/torrents/ (default) Torrent downloads folder as set in settings.yml ). For example, when using ruTorrent, Sonarr will import from /mnt/unionfs/downloads/torrents/rutorrent/ , which is essentially /mnt/local/downloads/torrents/rutorrent/ on host system. Radarr \u00b6 Docker Path Host Path Description /mnt/unionfs/Media/movies/ /mnt/unionfs/Media/Movies/ Radarr will import to /movies/ , which is actually /mnt/unionfs/Media/Movies/ on host system. /mnt/unionfs/downloads/nzbs/ /mnt/local/downloads/nzbs/ (default) NZB downloads folder as set in settings.yml ). For example, when using NZBGet, Radarr will import from /mnt/unionfs/downloads/nzbs/nzbget/ , which is essentially /mnt/local/downloads/nzbs/nzbget/ on host system. /mnt/unionfs/downloads/torrents/ /mnt/local/downloads/torrents/ (default) Torrent downloads folder as set in settings.yml ). For example, when using ruTorrent, Radarr will import from /mnt/unionfs/downloads/torrents/rutorrent/ , which is essentially /mnt/local/downloads/torrents/rutorrent/ on host system. Lidarr \u00b6 Docker Path Host Path Description /mnt/unionfs/Media/Music/ /mnt/unionfs/Media/Music/ Lidarr will import to /music/ , which is actually /mnt/unionfs/Media/Music/ on host system. /mnt/unionfs/downloads/nzbs/ /mnt/local/downloads/nzbs/ (default) NZB downloads folder as set in settings.yml ). For example, when using NZBGet, Lidarr will import from /mnt/unionfs/downloads/nzbs/nzbget/ , which is essentially /mnt/local/downloads/nzbs/nzbget/ on host system. /mnt/unionfs/downloads/torrents/ /mnt/local/downloads/torrents/ (default) Torrent downloads folder as set in settings.yml ). For example, when using ruTorrent, Lidarr will import from /mnt/unionfs/downloads/torrents/rutorrent/ , which is essentially /mnt/local/downloads/torrents/rutorrent/ on host system. Tautulli \u00b6 Docker Path Host Path Description /logs/ /opt/plex/Library/Application Support/Plex Media Server/Logs/ Location of the Plex logs used by Tautulli. Next, let's discuss the inventory system for customization.","title":"Paths"},{"location":"saltbox/basics/paths/#saltbox-paths","text":"","title":"Saltbox Paths"},{"location":"saltbox/basics/paths/#general-info","text":"It is recommended to assign all your disk space to / , as all of your imported media and app data will be saved to /mnt/local/ and /opt/ , respectively. This allows your application metadata and your staged media to make the most use of your available disk space without worrying about partitioning. Note 1: ALL folders/paths mentioned below, and elsewhere on the wiki, are CASE SENSITIVE (e.g. Google Drive: Media not media , Movies not movies , TV not tv ; Plex Requests: /logs not /Logs , etc). This is important, or else apps like Plex, Sonarr, and Radarr will not be able find your media. Note 2: This wiki uses ~/ interchangeably with /home/<username>/ , which is defined as /home/{{user}}/ in Ansible syntax (as used in settings.yml ). So if your user name was seed , your ~/ path would be /home/seed/ . For this reason it is important that you run commands as the appropriate user as you go through the wiki.","title":"General Info"},{"location":"saltbox/basics/paths/#google-drive-paths","text":"Media \u251c\u2500\u2500 Movies \u251c\u2500\u2500 Music \u2514\u2500\u2500 TV Path Description /Media/ Location of all your media folders. /Media/Movies/ Location of all your movies (folder format: /Media/Movies/Movie Name (year)/movie file.ext ). /Media/Music/ Location of all your music. /Media/TV/ Location of all your TV shows (folder format: /Media/TV/TV Show Name/Season 00/episode file.ext ). Note: If you would like to customize your Plex libraries differently, see Customizing Plex Libraries .","title":"Google Drive Paths"},{"location":"saltbox/basics/paths/#local-paths","text":"mnt \u251c\u2500\u2500local | \u2514\u2500\u2500 Media \u251c\u2500\u2500remote | \u2514\u2500\u2500 Media \u2514\u2500\u2500unionfs \u2514\u2500\u2500 Media","title":"Local Paths"},{"location":"saltbox/basics/paths/#media","text":"Path Description /mnt/local/Media/ Location of media stored on the server. This is the local part of /mnt/unionfs/Media/ . /mnt/remote/Media/ Location of media stored on Google Drive (mounted by rclone). /mnt/unionfs/Media/ Combined folder of local media ( /mnt/local/Media/ ) and online media ( /mnt/remote/Media/ ). This is the folder that Plex, Sonarr, and Radarr read when scanning for media. Note: Make sure /mnt/local/ has enough space to store the imported media (before cloudplow is able to move it to Google Drive).","title":"Media"},{"location":"saltbox/basics/paths/#cloudplow","text":"Path Description /mnt/local/Media/ Location of media stored on the server. Size of this path is checked periodically (default 30 min). When the folder size reaches its target (default 200GB), media files are moved off/uploaded to the cloud, freeing up local disk space. Note: For more info, see the Cloudplow page.","title":"Cloudplow"},{"location":"saltbox/basics/paths/#docker-paths","text":"The Dockerized app (e.g. Plex) will \"see\" the Docker Path , but that path will actually be the Host Path on the server. By default, NZB and Torrent downloads are stored in /mnt/local/downloads/nzbs/ and /mnt/local/downloads/torrents/ , respectively. However, this can be changed to point elsewhere (e.g. a second hard drive) by editing the settings.yml file. But regardless of the download location chosen, the Docker Path will always be the same. Note: It is advised to leave at least 100GB free on /opt for the storage of Docker data .","title":"Docker Paths"},{"location":"saltbox/basics/paths/#any-container-that-requires-disk-access","text":"Docker Path Host Path Description /mnt /mnt Provides access to all standard mounted storage. Every container sees any path inside /mnt the same as the host and same as any other container. That means that no path translation is required from context to context. If nzbget reports a download at /mnt/unionfs/downloads/... then Radarr will see it in the same place; when Radarr tells Plex-Autoscan [PAS] about it, PAS sees it in that same place; when PAS tells Plex about it, Plex sees it in that same place.","title":"Any container that requires disk access"},{"location":"saltbox/basics/paths/#plex","text":"Docker Path Host Path Description /mnt/unionfs/Media/Movies/ /mnt/unionfs/Media/Movies/ Plex reads this for Movies. /mnt/unionfs/Media/TV/ /mnt/unionfs/Media/TV/ Plex reads this for TV Shows. /mnt/unionfs/Media/Music/ /mnt/unionfs/Media/Music/ Plex reads this for Music.","title":"Plex"},{"location":"saltbox/basics/paths/#sonarr","text":"Docker Path Host Path Description /mnt/unionfs/Media/TV/ /mnt/unionfs/Media/TV/ Sonarr will import to /tv/ , which is actually /mnt/unionfs/Media/TV/ on host system. /mnt/unionfs/downloads/nzbs/ /mnt/local/downloads/nzbs/ (default) NZB downloads folder as set in settings.yml ). For example, when using NZBGet, Sonarr will import from /mnt/unionfs/downloads/nzbs/nzbget/ , which is essentially /mnt/local/downloads/nzbs/nzbget/ on host system. /mnt/unionfs/downloads/torrents/ /mnt/local/downloads/torrents/ (default) Torrent downloads folder as set in settings.yml ). For example, when using ruTorrent, Sonarr will import from /mnt/unionfs/downloads/torrents/rutorrent/ , which is essentially /mnt/local/downloads/torrents/rutorrent/ on host system.","title":"Sonarr"},{"location":"saltbox/basics/paths/#radarr","text":"Docker Path Host Path Description /mnt/unionfs/Media/movies/ /mnt/unionfs/Media/Movies/ Radarr will import to /movies/ , which is actually /mnt/unionfs/Media/Movies/ on host system. /mnt/unionfs/downloads/nzbs/ /mnt/local/downloads/nzbs/ (default) NZB downloads folder as set in settings.yml ). For example, when using NZBGet, Radarr will import from /mnt/unionfs/downloads/nzbs/nzbget/ , which is essentially /mnt/local/downloads/nzbs/nzbget/ on host system. /mnt/unionfs/downloads/torrents/ /mnt/local/downloads/torrents/ (default) Torrent downloads folder as set in settings.yml ). For example, when using ruTorrent, Radarr will import from /mnt/unionfs/downloads/torrents/rutorrent/ , which is essentially /mnt/local/downloads/torrents/rutorrent/ on host system.","title":"Radarr"},{"location":"saltbox/basics/paths/#lidarr","text":"Docker Path Host Path Description /mnt/unionfs/Media/Music/ /mnt/unionfs/Media/Music/ Lidarr will import to /music/ , which is actually /mnt/unionfs/Media/Music/ on host system. /mnt/unionfs/downloads/nzbs/ /mnt/local/downloads/nzbs/ (default) NZB downloads folder as set in settings.yml ). For example, when using NZBGet, Lidarr will import from /mnt/unionfs/downloads/nzbs/nzbget/ , which is essentially /mnt/local/downloads/nzbs/nzbget/ on host system. /mnt/unionfs/downloads/torrents/ /mnt/local/downloads/torrents/ (default) Torrent downloads folder as set in settings.yml ). For example, when using ruTorrent, Lidarr will import from /mnt/unionfs/downloads/torrents/rutorrent/ , which is essentially /mnt/local/downloads/torrents/rutorrent/ on host system.","title":"Lidarr"},{"location":"saltbox/basics/paths/#tautulli","text":"Docker Path Host Path Description /logs/ /opt/plex/Library/Application Support/Plex Media Server/Logs/ Location of the Plex logs used by Tautulli. Next, let's discuss the inventory system for customization.","title":"Tautulli"},{"location":"saltbox/basics/update/","text":"Update \u00b6 Updating Saltbox \u00b6 To update Saltbox run: sb update This will also upgrade Ansible as needed and migrate the configuration files as additional options are added over time. This updates the saltbox files only ; It does not update your containers. For example, if a new feature is added to saltbox, sb update will get that new feature. If a new version of Radarr is available, sb update will not update your Radarr to that new version. Updating apps \u00b6 Generally, to update individual applications, run the tag for that application. For example, sb install radarr This will retrieve the current version of the radarr image and recreate the container, which will update the application version. The same thing happens if you run one of the top-level tags: sb install saltbox This will do as above for all the containers installed by the saltbox tag. Next, let's discuss how you will access the applications .","title":"Update"},{"location":"saltbox/basics/update/#update","text":"","title":"Update"},{"location":"saltbox/basics/update/#updating-saltbox","text":"To update Saltbox run: sb update This will also upgrade Ansible as needed and migrate the configuration files as additional options are added over time. This updates the saltbox files only ; It does not update your containers. For example, if a new feature is added to saltbox, sb update will get that new feature. If a new version of Radarr is available, sb update will not update your Radarr to that new version.","title":"Updating Saltbox"},{"location":"saltbox/basics/update/#updating-apps","text":"Generally, to update individual applications, run the tag for that application. For example, sb install radarr This will retrieve the current version of the radarr image and recreate the container, which will update the application version. The same thing happens if you run one of the top-level tags: sb install saltbox This will do as above for all the containers installed by the saltbox tag. Next, let's discuss how you will access the applications .","title":"Updating apps"},{"location":"saltbox/install/after/","text":"All the apps are installed and configured, but here are some things you want to set up or do that aren't done automatically: Harden your SSH server. There are some tips here , but three simple actions to take are: Change the default SSH port from 22 to something else. Disable password login and use only SSH keys to authenticate. Disable root login. Set up scheduled backups . There is no backup enabled automatically , so unless you explicitly set them up, you will be disappointed to find that you don't have a backup when something goes wrong. Take some time to verify disk space usage for the apps. You need local disk space for stuff between download completion and cloudplow moving things into the cloud. If you don't, for example, set cloudplow's upload thresholds and Nzbget's \"stop downloading\" disk space threshold to meaningful values for your situation, you can get into a situation where cloudplow's not uploading because that threshold hasn't been met and nzbget has stopped because its threshold has been met and everything grinds to a halt. Alternatively, nzbget just keeps going and runs your disk out of space. You also need a bunch of disk space for the scheduled backups that you just set up to succeed, so be sure to take that into account. Another common \"hidden\" disk space consumer is unfinished or unimported downloads. If NZBGet downloads something and Radarr can't tell what movie it is, it will just sit consuming disk space. There is a script you can set up to keep this stuff cleaned up in the user crontab examples . Spend some time working with the system before you start customizing. A lot of problems are seen when new users rush ahead to install All The Things and customize the system without understanding how things work. Slow down. Learn how the thing works, and then make changes in a controlled manner. None of these apps or scripts are sentient, so if they are not doing what you expect, it's almost certainly a configuration problem. Take time to go through some Youtube or other tutorials about: JSON Many config files are written in JSON, so you need to have a grounding in how JSON works before editing them. You should know how to edit within the structure of a JSON file, and how to validate a JSON file to figure out how you've broken it. first \"json tutorial\" result; no endorsement online JSON validator YAML Many config files are written in YAML, so you need to have a grounding in how YAML works before editing them. first \"yaml tutorial\" result; no endorsement online YAML validator Docker Nearly everything is running as a Docker container, so it's helpful to have at least a nodding familiarity with how that works. first \"docker tutorial\" result; no endorsement Next, let's discuss how updates are done.","title":"After-Install"},{"location":"saltbox/install/install/","text":"If you're migrating from Cloudbox you probably want the Cloudbox migration instructions If you're migrating from PlexGuide there are some rudimentary notes provided by a user here . Expansions to those notes would be welcome. Please read through these steps prior to executing any of them, just to get a grounding in what is going to happen through out the process. It could be that things in later steps inform your decisions in earlier steps. Broadly, the base install consists of six steps: Installing dependencies Preparing your configuration file(s) Running a pre-install script Configuring your cloud storage Running the install script Configuring installed applications Step 1: Dependencies \u00b6 curl wget curl (verbose) wget (verbose) curl -sL https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox wget -qO- https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox curl -sL https://install.saltbox.dev | sudo -H bash -s -- -v ; cd /srv/git/saltbox wget -qO- https://install.saltbox.dev | sudo -H bash -s -- -v ; cd /srv/git/saltbox Info See here for more information about the dependencies. Step 2: Configuration \u00b6 Make sure you fill out the following configuration files before proceeding. Each file will be located in /srv/git/saltbox accounts.yml To edit [assuming you are still logged in as root ]: nano /srv/git/saltbox/accounts.yml Contents: --- user : name : seed # (1)! pass : password123 # (2)! domain : testsaltbox.ml # (3)! email : your@email.com # (4)! ssh_key : # (13)! cloudflare : email : # (5)! api : # (6)! plex : user : # (7)! pass : # (8)! tfa : no # (9)! dockerhub : user : # (10)! token : # (11)! apprise : # (12)! Username that will be created (if it doesn't exist) during the installation and apps that have automatic user configuration. Do not use root. Required. Password used for username account during the installation and apps that have automatic user configuration. Required. Domain that you want to use for the server. Email address used for Let's Encrypt SSL certificates. Required. Email used for the Cloudflare account. Cloudflare Global API Key. Plex.tv username or email address on the account. Plex.tv password for the account. Enable if you want to use the Two Factor Authentication [TFA] compatible Plex account login. Docker Hub account name. Entering these credentials will at least double your image pull capacity from 100 every 6 hours to 200. https://www.docker.com/blog/checking-your-current-docker-pull-rate-limits-and-status/ Docker Hub account token apprise url. See https://github.com/caronc/apprise#popular-notification-services for more information. SSH Public Key. The key will be added to your configured user's authorized_keys file. This parameter accepts either the public key or a GitHub url (i.e. https://github.com/charlie.keys ) which will pull the keys you have added to your GitHub account. settings.yml To edit [assuming you are still logged in as root ]: nano /srv/git/saltbox/settings.yml Contents: --- downloads : /mnt/unionfs/downloads # (1)!! rclone : version : latest # (3)! remote : google # (4)! shell : bash # (5)! authelia : master : yes # (6)! subdomain : login # (7)! Folder used for downloads. Folder used for temporary transcode files. Rclone version that Saltbox will install. Valid options are latest , beta or a specific version ( 1.55 ). Name of the rclone remote that Saltbox will mount by default and use in any automated configuration. Optional - Leave empty to avoid remote mount setup. Shell used by the system. Valid options are bash or zsh. If the current server should have Authelia installed or use one installed elsewhere. Subdomain used for Authelia. Use different values here when using a Mediabox + Feederbox setup if deploying multiple Authelia instances. On a Feederbox where you want to use Authelia on the Mediabox just put in the same subdomain the Mediabox uses for Authelia (master having been set to no on the Feederbox). Info See here for more information about these settings. Step 3: Preinstall \u00b6 Warning Make sure that you have set up the configuration correctly before proceeding. This step will create the user account specified in accounts.yml , add it to sudoers, update the kernel, edit GRUB configuration, install Rclone, and reboot the server if needed. sb install preinstall Warning From this point you'll want to make sure you run commands as the user specified in the accounts.yml If your server did not need to reboot you can run su username to switch user or reconnect to SSH as the newly created user. Everything after this point will assume you are running as the user entered in accounts.yml Info See here for more information about the preinstall. Step 4: Rclone \u00b6 Warning As noted in the previous step, from this point you'll want to make sure you are logged into the server as the user specified in the accounts.yml . Info THIS IS AN OPTIONAL STEP, required only if you plan to use cloud storage [Google Drive, for instance] If you do not plan to use cloud storage, leave the rclone -> remote: setting blank in your settings.yml , and skip this step. Saltbox defaults to an rclone remote pointed at your Google Drive named google [as shown in the settings.yml above]. There is nothing special about Saltbox's implementation of this setup, aside from its opinions about the media paths. If you already know how to set that up, do so with your usual methods. If not: Cloudbox users PlexGuide users I'm totally new to this Minimal setup, please You already have the required setup complete. You should use your existing Google setup at least to start with. Cloudbox migration instructions You already have the required setup complete. You should use your existing Google setup at least to start with. The issues you will have to deal with will largely be around: Encrypted drives File system differences Service account files [PlexGuide removed the .json extension from what it calls \"BlitzKeys\", Saltbox expects them to be there] Plexguide migration notes If you have a brand new Google Drive account and want to be walked through all the steps you need to perform, start here That's an eight-step process that is mostly copy-paste commands. When you have completed it, come back here. That eight-step process will create three shared drives, 300 service accounts, and will configure rclone for you. This should be enough capacity for quite a while for most users. The simplest possible case is: Set up a Google Project and OAuth Credential file if you don't already have one. This process is described here You will need the ID and Secret from that process in step 3 below. Create a Shared Drive in the Google Web UI. This process is described here Create an rclone remote pointing at that shared drive. This process is described here Warning Do not proceed until you have configured your rclone remote[s] or disabled cloud storage in the settings. Step 5: Saltbox \u00b6 If you are installing a Feederbox/Mediabox setup [if your reaction to this question is \"huh?\" then you are not, and should use the saltbox install], set up the Feederbox first, then add the feeder mount to the mediabox prior to install. Saltbox Mediabox Feederbox Core sb install saltbox sb install mediabox sb install feederbox sb install core Info See here for more information about the install. Reboot \u00b6 After rebooting, you're now ready to go through the basic setup for the apps! Step 6: App Setup \u00b6 If you would like to configure cloudplow to use service accounts to exceed the 750G daily upload limit, and you went through the scripted rclone setup above, you can do this now. Instructions are here . Go through these one at a time in order; some of the setups depend on previous setups. NZBGet ruTorrent NZBHydra2 Jackett Plex Media Server Autoscan Sonarr Radarr Lidarr Tautulli Overseerr Portainer Organizr Info These are not all the available applications, just the core set that are installed by the saltbox tag. Click on the \"Apps\" header at the top for a full listing of applications available in Saltbox. Click the \"Sandbox\" heading for a listing of commmunity-supplied applications. Next, some tasks to perform after installation is complete .","title":"Install"},{"location":"saltbox/install/install/#step-1-dependencies","text":"curl wget curl (verbose) wget (verbose) curl -sL https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox wget -qO- https://install.saltbox.dev | sudo -H bash ; cd /srv/git/saltbox curl -sL https://install.saltbox.dev | sudo -H bash -s -- -v ; cd /srv/git/saltbox wget -qO- https://install.saltbox.dev | sudo -H bash -s -- -v ; cd /srv/git/saltbox Info See here for more information about the dependencies.","title":"Step 1: Dependencies"},{"location":"saltbox/install/install/#step-2-configuration","text":"Make sure you fill out the following configuration files before proceeding. Each file will be located in /srv/git/saltbox accounts.yml To edit [assuming you are still logged in as root ]: nano /srv/git/saltbox/accounts.yml Contents: --- user : name : seed # (1)! pass : password123 # (2)! domain : testsaltbox.ml # (3)! email : your@email.com # (4)! ssh_key : # (13)! cloudflare : email : # (5)! api : # (6)! plex : user : # (7)! pass : # (8)! tfa : no # (9)! dockerhub : user : # (10)! token : # (11)! apprise : # (12)! Username that will be created (if it doesn't exist) during the installation and apps that have automatic user configuration. Do not use root. Required. Password used for username account during the installation and apps that have automatic user configuration. Required. Domain that you want to use for the server. Email address used for Let's Encrypt SSL certificates. Required. Email used for the Cloudflare account. Cloudflare Global API Key. Plex.tv username or email address on the account. Plex.tv password for the account. Enable if you want to use the Two Factor Authentication [TFA] compatible Plex account login. Docker Hub account name. Entering these credentials will at least double your image pull capacity from 100 every 6 hours to 200. https://www.docker.com/blog/checking-your-current-docker-pull-rate-limits-and-status/ Docker Hub account token apprise url. See https://github.com/caronc/apprise#popular-notification-services for more information. SSH Public Key. The key will be added to your configured user's authorized_keys file. This parameter accepts either the public key or a GitHub url (i.e. https://github.com/charlie.keys ) which will pull the keys you have added to your GitHub account. settings.yml To edit [assuming you are still logged in as root ]: nano /srv/git/saltbox/settings.yml Contents: --- downloads : /mnt/unionfs/downloads # (1)!! rclone : version : latest # (3)! remote : google # (4)! shell : bash # (5)! authelia : master : yes # (6)! subdomain : login # (7)! Folder used for downloads. Folder used for temporary transcode files. Rclone version that Saltbox will install. Valid options are latest , beta or a specific version ( 1.55 ). Name of the rclone remote that Saltbox will mount by default and use in any automated configuration. Optional - Leave empty to avoid remote mount setup. Shell used by the system. Valid options are bash or zsh. If the current server should have Authelia installed or use one installed elsewhere. Subdomain used for Authelia. Use different values here when using a Mediabox + Feederbox setup if deploying multiple Authelia instances. On a Feederbox where you want to use Authelia on the Mediabox just put in the same subdomain the Mediabox uses for Authelia (master having been set to no on the Feederbox). Info See here for more information about these settings.","title":"Step 2: Configuration"},{"location":"saltbox/install/install/#step-3-preinstall","text":"Warning Make sure that you have set up the configuration correctly before proceeding. This step will create the user account specified in accounts.yml , add it to sudoers, update the kernel, edit GRUB configuration, install Rclone, and reboot the server if needed. sb install preinstall Warning From this point you'll want to make sure you run commands as the user specified in the accounts.yml If your server did not need to reboot you can run su username to switch user or reconnect to SSH as the newly created user. Everything after this point will assume you are running as the user entered in accounts.yml Info See here for more information about the preinstall.","title":"Step 3: Preinstall"},{"location":"saltbox/install/install/#step-4-rclone","text":"Warning As noted in the previous step, from this point you'll want to make sure you are logged into the server as the user specified in the accounts.yml . Info THIS IS AN OPTIONAL STEP, required only if you plan to use cloud storage [Google Drive, for instance] If you do not plan to use cloud storage, leave the rclone -> remote: setting blank in your settings.yml , and skip this step. Saltbox defaults to an rclone remote pointed at your Google Drive named google [as shown in the settings.yml above]. There is nothing special about Saltbox's implementation of this setup, aside from its opinions about the media paths. If you already know how to set that up, do so with your usual methods. If not: Cloudbox users PlexGuide users I'm totally new to this Minimal setup, please You already have the required setup complete. You should use your existing Google setup at least to start with. Cloudbox migration instructions You already have the required setup complete. You should use your existing Google setup at least to start with. The issues you will have to deal with will largely be around: Encrypted drives File system differences Service account files [PlexGuide removed the .json extension from what it calls \"BlitzKeys\", Saltbox expects them to be there] Plexguide migration notes If you have a brand new Google Drive account and want to be walked through all the steps you need to perform, start here That's an eight-step process that is mostly copy-paste commands. When you have completed it, come back here. That eight-step process will create three shared drives, 300 service accounts, and will configure rclone for you. This should be enough capacity for quite a while for most users. The simplest possible case is: Set up a Google Project and OAuth Credential file if you don't already have one. This process is described here You will need the ID and Secret from that process in step 3 below. Create a Shared Drive in the Google Web UI. This process is described here Create an rclone remote pointing at that shared drive. This process is described here Warning Do not proceed until you have configured your rclone remote[s] or disabled cloud storage in the settings.","title":"Step 4: Rclone"},{"location":"saltbox/install/install/#step-5-saltbox","text":"If you are installing a Feederbox/Mediabox setup [if your reaction to this question is \"huh?\" then you are not, and should use the saltbox install], set up the Feederbox first, then add the feeder mount to the mediabox prior to install. Saltbox Mediabox Feederbox Core sb install saltbox sb install mediabox sb install feederbox sb install core Info See here for more information about the install.","title":"Step 5: Saltbox"},{"location":"saltbox/install/install/#reboot","text":"After rebooting, you're now ready to go through the basic setup for the apps!","title":"Reboot"},{"location":"saltbox/install/install/#step-6-app-setup","text":"If you would like to configure cloudplow to use service accounts to exceed the 750G daily upload limit, and you went through the scripted rclone setup above, you can do this now. Instructions are here . Go through these one at a time in order; some of the setups depend on previous setups. NZBGet ruTorrent NZBHydra2 Jackett Plex Media Server Autoscan Sonarr Radarr Lidarr Tautulli Overseerr Portainer Organizr Info These are not all the available applications, just the core set that are installed by the saltbox tag. Click on the \"Apps\" header at the top for a full listing of applications available in Saltbox. Click the \"Sandbox\" heading for a listing of commmunity-supplied applications. Next, some tasks to perform after installation is complete .","title":"Step 6: App Setup"},{"location":"saltbox/inventory/","text":"Inventory \u00b6 Advanced use cases that would normally require editing roles can now be handled through the inventory system instead. Any variables defined in /srv/git/saltbox/roles/<role_name>/defaults/main.yml or /opt/sandbox/roles/<role_name>/defaults/main.yml are available to be overridden by the user in: /srv/git/saltbox/inventories/host_vars/localhost.yml This implementation avoids git merge conflicts when updating Saltbox. Should you require additional functionality then by all means create an issue on the main repository and we'll look at accommodating it. A common use for these overrides will be specifying the version of the docker image to be used, so let's see how that's done by looking into /srv/git/saltbox/roles/sonarr/defaults/main.yml around line 85: ################################ # Docker ################################ # Container sonarr_docker_container : \"{{ sonarr_name }}\" # Image sonarr_docker_image_pull : true sonarr_docker_image_repo : \"cr.hotio.dev/hotio/sonarr\" sonarr_docker_image_tag : \"release\" sonarr_docker_image : \"{{ lookup('vars', sonarr_name + '_docker_image_repo', default=sonarr_docker_image_repo) + ':' + lookup('vars', sonarr_name + '_docker_image_tag', default=sonarr_docker_image_tag) }}\" Note: sonarr_docker_image_tag: \"release\" For Sonarr, Saltbox will use the docker image cr.hotio.dev/hotio/sonarr:release by default. If you wanted to change that to \"nightly\", you'd add this line to /srv/git/saltbox/inventories/host_vars/localhost.yml : sonarr_docker_image_tag : \"nightly\" Which would override the default [ release ] and result in Saltbox using the cr.hotio.dev/hotio/sonarr:nightly docker image instead, wihtout you modifying this file. If you update Saltbox and this file is replaced, your tag change to nightly remains in effect. Previously undefined variables may be added as well. Typical use would be to pass new Docker parameters under variables with the name ending in custom : jackett_docker_labels_custom : com.centurylinklabs.watchtower.enable : \"true\" Additional Examples \u00b6 Various \u00b6 ##### Plex Ports for local access##### plex_open_main_ports : true plex_open_local_ports : true ##### Plex Container Variables #### plex_docker_image_tag : beta plex_open_main_ports : true plex_db_cache_size : 30000000 #### Examples of specified container images: #### radarr_docker_image_tag : nightly sonarr_docker_image_tag : nightly petio_docker_image_tag : nightly #### BW Limiting speeds #### transfer_docker_envs_custom : MAX_UPLOAD_SIZE : \"104857546\" #### Specify Overseerr DNS server - can fix name resolution issue with TMDb #### overseerr_docker_dns_servers : - 8.8.8.8 - 8.8.4.4 #### Add custom aliases to bash shell #### #### Note the syntax - a pipe and two space indentation for the contents #### shell_bash_bashrc_block_custom : | alias sbu='sb update' alias sbi='sb install' #### Add custom aliases to zsh shell ### #### Note the syntax - a pipe and two space indentation for the contents #### shell_zsh_zshrc_block_custom : | alias sbu='sb update' alias sbi='sb install' Authelia App Bypass \u00b6 Some may not want the additional layer of security that Authelia supplies, good news is that it can be disabled with a simple override. To determine which apps by default are included in Authelia, one can run this command or similar: grep -Ril \"_traefik_sso_middleware:\" /srv/git/saltbox/roles /opt/sandbox/roles | awk 'BEGIN{RS=\"roles/\"; FS=\"/defaults\"}NF>1{print $1}' | sort -u Override example: \u00b6 ### Authelia App Bypass ### sonarr_traefik_sso_middleware : \"\" tautulli_traefik_sso_middleware : \"\" radarr_traefik_sso_middleware : \"\" nzbget_traefik_sso_middleware : \"\" prowlarr_traefik_sso_middleware : \"\" ` After making this change in the inventory file, simply run the appropriate role command in order to disable Authelia on that specific app. Reminder you can run multiple tags at once. Authorize with App Credentials \u00b6 Inject an Authorization header - Traefik performs basic auth with the backend app \u00b6 This allows you to keep basic auth enabled within apps but not have the hassle of entering the credentials manually. The authorization header is only inserted if the request is authorized through the SSO middleware (Authelia) and is not applied to the API endpoint(s). Use this tool to generate the header contents based on your credentials. sonarr_docker_labels_custom : traefik.http.middlewares.appAuth.headers.customrequestheaders.Authorization : \"Basic <base64 header>\" sonarr_traefik_middleware_custom : \"appAuth\" Subdomain Customization \u00b6 Overrides: \u00b6 #### Make Organizr available only at the base domain #### organizr_web_subdomain : \"\" #### Make Tautulli available only at `stats.domain.tld` #### tautulli_web_subdomain : \"stats\" Additions: \u00b6 #### Make Organizr available at both `organizr.domain.tld` and `domain.tld` #### organizr_docker_labels_custom : traefik.http.routers.organizr-http.rule : \"Host(`{{ organizr_web_subdomain + '.' + organizr_web_domain }}`) || Host(`{{ organizr_web_domain }}`)\" traefik.http.routers.organizr.rule : \"Host(`{{ organizr_web_subdomain + '.' + organizr_web_domain }}`) || Host(`{{ organizr_web_domain }}`)\" #### Make Overseerr available at both `overseerr.domain.tld` and `requests.domain.tld` #### overseerr_docker_labels_custom : traefik.http.routers.overseerr-http.rule : \"Host(`{{ overseerr_web_subdomain + '.' + overseerr_web_domain }}`) || Host(`{{ 'requests.' + overseerr_web_domain }}`)\" traefik.http.routers.overseerr.rule : \"Host(`{{ overseerr_web_subdomain + '.' + overseerr_web_domain }}`) || Host(`{{ 'requests.' + overseerr_web_domain }}`)\" Note that this last set of examples requires you to add DNS records manually.","title":"Inventory"},{"location":"saltbox/inventory/#inventory","text":"Advanced use cases that would normally require editing roles can now be handled through the inventory system instead. Any variables defined in /srv/git/saltbox/roles/<role_name>/defaults/main.yml or /opt/sandbox/roles/<role_name>/defaults/main.yml are available to be overridden by the user in: /srv/git/saltbox/inventories/host_vars/localhost.yml This implementation avoids git merge conflicts when updating Saltbox. Should you require additional functionality then by all means create an issue on the main repository and we'll look at accommodating it. A common use for these overrides will be specifying the version of the docker image to be used, so let's see how that's done by looking into /srv/git/saltbox/roles/sonarr/defaults/main.yml around line 85: ################################ # Docker ################################ # Container sonarr_docker_container : \"{{ sonarr_name }}\" # Image sonarr_docker_image_pull : true sonarr_docker_image_repo : \"cr.hotio.dev/hotio/sonarr\" sonarr_docker_image_tag : \"release\" sonarr_docker_image : \"{{ lookup('vars', sonarr_name + '_docker_image_repo', default=sonarr_docker_image_repo) + ':' + lookup('vars', sonarr_name + '_docker_image_tag', default=sonarr_docker_image_tag) }}\" Note: sonarr_docker_image_tag: \"release\" For Sonarr, Saltbox will use the docker image cr.hotio.dev/hotio/sonarr:release by default. If you wanted to change that to \"nightly\", you'd add this line to /srv/git/saltbox/inventories/host_vars/localhost.yml : sonarr_docker_image_tag : \"nightly\" Which would override the default [ release ] and result in Saltbox using the cr.hotio.dev/hotio/sonarr:nightly docker image instead, wihtout you modifying this file. If you update Saltbox and this file is replaced, your tag change to nightly remains in effect. Previously undefined variables may be added as well. Typical use would be to pass new Docker parameters under variables with the name ending in custom : jackett_docker_labels_custom : com.centurylinklabs.watchtower.enable : \"true\"","title":"Inventory"},{"location":"saltbox/inventory/#additional-examples","text":"","title":"Additional Examples"},{"location":"saltbox/inventory/#various","text":"##### Plex Ports for local access##### plex_open_main_ports : true plex_open_local_ports : true ##### Plex Container Variables #### plex_docker_image_tag : beta plex_open_main_ports : true plex_db_cache_size : 30000000 #### Examples of specified container images: #### radarr_docker_image_tag : nightly sonarr_docker_image_tag : nightly petio_docker_image_tag : nightly #### BW Limiting speeds #### transfer_docker_envs_custom : MAX_UPLOAD_SIZE : \"104857546\" #### Specify Overseerr DNS server - can fix name resolution issue with TMDb #### overseerr_docker_dns_servers : - 8.8.8.8 - 8.8.4.4 #### Add custom aliases to bash shell #### #### Note the syntax - a pipe and two space indentation for the contents #### shell_bash_bashrc_block_custom : | alias sbu='sb update' alias sbi='sb install' #### Add custom aliases to zsh shell ### #### Note the syntax - a pipe and two space indentation for the contents #### shell_zsh_zshrc_block_custom : | alias sbu='sb update' alias sbi='sb install'","title":"Various"},{"location":"saltbox/inventory/#authelia-app-bypass","text":"Some may not want the additional layer of security that Authelia supplies, good news is that it can be disabled with a simple override. To determine which apps by default are included in Authelia, one can run this command or similar: grep -Ril \"_traefik_sso_middleware:\" /srv/git/saltbox/roles /opt/sandbox/roles | awk 'BEGIN{RS=\"roles/\"; FS=\"/defaults\"}NF>1{print $1}' | sort -u","title":"Authelia App Bypass"},{"location":"saltbox/inventory/#override-example","text":"### Authelia App Bypass ### sonarr_traefik_sso_middleware : \"\" tautulli_traefik_sso_middleware : \"\" radarr_traefik_sso_middleware : \"\" nzbget_traefik_sso_middleware : \"\" prowlarr_traefik_sso_middleware : \"\" ` After making this change in the inventory file, simply run the appropriate role command in order to disable Authelia on that specific app. Reminder you can run multiple tags at once.","title":"Override example:"},{"location":"saltbox/inventory/#authorize-with-app-credentials","text":"","title":"Authorize with App Credentials"},{"location":"saltbox/inventory/#inject-an-authorization-header-traefik-performs-basic-auth-with-the-backend-app","text":"This allows you to keep basic auth enabled within apps but not have the hassle of entering the credentials manually. The authorization header is only inserted if the request is authorized through the SSO middleware (Authelia) and is not applied to the API endpoint(s). Use this tool to generate the header contents based on your credentials. sonarr_docker_labels_custom : traefik.http.middlewares.appAuth.headers.customrequestheaders.Authorization : \"Basic <base64 header>\" sonarr_traefik_middleware_custom : \"appAuth\"","title":"Inject an Authorization header - Traefik performs basic auth with the backend app"},{"location":"saltbox/inventory/#subdomain-customization","text":"","title":"Subdomain Customization"},{"location":"saltbox/inventory/#overrides","text":"#### Make Organizr available only at the base domain #### organizr_web_subdomain : \"\" #### Make Tautulli available only at `stats.domain.tld` #### tautulli_web_subdomain : \"stats\"","title":"Overrides:"},{"location":"saltbox/inventory/#additions","text":"#### Make Organizr available at both `organizr.domain.tld` and `domain.tld` #### organizr_docker_labels_custom : traefik.http.routers.organizr-http.rule : \"Host(`{{ organizr_web_subdomain + '.' + organizr_web_domain }}`) || Host(`{{ organizr_web_domain }}`)\" traefik.http.routers.organizr.rule : \"Host(`{{ organizr_web_subdomain + '.' + organizr_web_domain }}`) || Host(`{{ organizr_web_domain }}`)\" #### Make Overseerr available at both `overseerr.domain.tld` and `requests.domain.tld` #### overseerr_docker_labels_custom : traefik.http.routers.overseerr-http.rule : \"Host(`{{ overseerr_web_subdomain + '.' + overseerr_web_domain }}`) || Host(`{{ 'requests.' + overseerr_web_domain }}`)\" traefik.http.routers.overseerr.rule : \"Host(`{{ overseerr_web_subdomain + '.' + overseerr_web_domain }}`) || Host(`{{ 'requests.' + overseerr_web_domain }}`)\" Note that this last set of examples requires you to add DNS records manually.","title":"Additions:"},{"location":"saltbox/prerequisites/prerequisites/","text":"Presumptions \u00b6 Saltbox presumes you have a basic understanding of Linux, Docker containers, BitTorrent, and Usenet, and are also familiar with Sonarr, Radarr, NZBGet, rTorrent/ruTorrent, and Plex/Emby. The Saltbox setup is all done on the command line in the linux shell. There is no GUI and there are no plans to add one. If you want to run Saltbox, you will need to be familiar with Linux. The guides in this wiki are only meant to setup Saltbox specific settings into the various apps that are installed with Saltbox (e.g. Sonarr, Radarr, Plex, etc) and are not meant to be a full setup for, or an introduction to, the workings of these apps. However, you may pick up a few things as you go thru the guides. If you wish to learn more about them in detail, you can easily find a ton of guides for them online (e.g. HTPC Guides , YouTube , etc). There are, broadly, 4 prerequisites to installing Saltbox: A Server A Domain Name Cloud Storage A Plex Account Usenet or Bittorrent sources System Requirements \u00b6 Operating Systems \u00b6 At this time, we only support LTS releases of Ubuntu Server 20.04 and 22.04 , freshly installed. Warning Desktop editions are excluded. While Saltbox may technically run alongside a desktop environment, we will decline all forms of support around this use case. Server \u00b6 For best results, the assumed server environment for Saltbox is: a dedicated remote server [not a VPS], a processor compliant with the x86_64 / amd64 [ arm NOT SUPPORTED] architecture, from a server provider like Hetzner, OVH, kimsufi, etc., nothing else [docker, for example] preinstalled, with at least 500GB of disk space, and allowing root access. See here for more information about server requirements. Domain \u00b6 You will need a domain name as Saltbox apps are only accessed via https://appname. yourdomain.com (see Accessing Apps ). Ports are [for the most part] bound only to the internal saltbox docker network, which means they are not visible on the host; you won't be able to connect externally to the apps using IP:PORT . See here for more information about setting up a domain and DNS settings for use with Saltbox. Cloud Storage \u00b6 A base assumption in Saltbox is that you are storing your media on cloud storage. Saltbox can be set up to use any cloud storage provider that Rclone supports. However, Google Drive via G-Suite Business is the preferred choice among users. Some of the components are designed expressly for Google Drive, like the Google Drive monitoring in plex-autoscan and the service-account rotation in cloudplow. See here for more information about Cloud Storage requirements and running Saltbox without it. Plex Account \u00b6 You'll need a Plex account , if you don't already have one, for purposes of the install, even if you're not planning to use Plex . This may change in the future, but for now it's a requirement for the simplest Happy Path install described here. See here for more information about Plex account requirements. Usenet or Bittorrent sources \u00b6 If you are planning to set up a standard Saltbox or a feederbox, you will need a source of media; Usenet, Torrents, or both You won't need these particular [media source] details for the initial install, but you will need them for application setup. See here for more information about media source requirements. Next, let's discuss Saltbox Install types .","title":"Prerequisites"},{"location":"saltbox/prerequisites/prerequisites/#presumptions","text":"Saltbox presumes you have a basic understanding of Linux, Docker containers, BitTorrent, and Usenet, and are also familiar with Sonarr, Radarr, NZBGet, rTorrent/ruTorrent, and Plex/Emby. The Saltbox setup is all done on the command line in the linux shell. There is no GUI and there are no plans to add one. If you want to run Saltbox, you will need to be familiar with Linux. The guides in this wiki are only meant to setup Saltbox specific settings into the various apps that are installed with Saltbox (e.g. Sonarr, Radarr, Plex, etc) and are not meant to be a full setup for, or an introduction to, the workings of these apps. However, you may pick up a few things as you go thru the guides. If you wish to learn more about them in detail, you can easily find a ton of guides for them online (e.g. HTPC Guides , YouTube , etc). There are, broadly, 4 prerequisites to installing Saltbox: A Server A Domain Name Cloud Storage A Plex Account Usenet or Bittorrent sources","title":"Presumptions"},{"location":"saltbox/prerequisites/prerequisites/#system-requirements","text":"","title":"System Requirements"},{"location":"saltbox/prerequisites/prerequisites/#operating-systems","text":"At this time, we only support LTS releases of Ubuntu Server 20.04 and 22.04 , freshly installed. Warning Desktop editions are excluded. While Saltbox may technically run alongside a desktop environment, we will decline all forms of support around this use case.","title":"Operating Systems"},{"location":"saltbox/prerequisites/prerequisites/#server","text":"For best results, the assumed server environment for Saltbox is: a dedicated remote server [not a VPS], a processor compliant with the x86_64 / amd64 [ arm NOT SUPPORTED] architecture, from a server provider like Hetzner, OVH, kimsufi, etc., nothing else [docker, for example] preinstalled, with at least 500GB of disk space, and allowing root access. See here for more information about server requirements.","title":"Server"},{"location":"saltbox/prerequisites/prerequisites/#domain","text":"You will need a domain name as Saltbox apps are only accessed via https://appname. yourdomain.com (see Accessing Apps ). Ports are [for the most part] bound only to the internal saltbox docker network, which means they are not visible on the host; you won't be able to connect externally to the apps using IP:PORT . See here for more information about setting up a domain and DNS settings for use with Saltbox.","title":"Domain"},{"location":"saltbox/prerequisites/prerequisites/#cloud-storage","text":"A base assumption in Saltbox is that you are storing your media on cloud storage. Saltbox can be set up to use any cloud storage provider that Rclone supports. However, Google Drive via G-Suite Business is the preferred choice among users. Some of the components are designed expressly for Google Drive, like the Google Drive monitoring in plex-autoscan and the service-account rotation in cloudplow. See here for more information about Cloud Storage requirements and running Saltbox without it.","title":"Cloud Storage"},{"location":"saltbox/prerequisites/prerequisites/#plex-account","text":"You'll need a Plex account , if you don't already have one, for purposes of the install, even if you're not planning to use Plex . This may change in the future, but for now it's a requirement for the simplest Happy Path install described here. See here for more information about Plex account requirements.","title":"Plex Account"},{"location":"saltbox/prerequisites/prerequisites/#usenet-or-bittorrent-sources","text":"If you are planning to set up a standard Saltbox or a feederbox, you will need a source of media; Usenet, Torrents, or both You won't need these particular [media source] details for the initial install, but you will need them for application setup. See here for more information about media source requirements. Next, let's discuss Saltbox Install types .","title":"Usenet or Bittorrent sources"},{"location":"sandbox/","text":"Sandbox - All Apps Index \u00b6 adguardhome - tag - sandbox-adguardhome adminer - tag - sandbox-adminer airdcpp - tag - sandbox-airdcpp airsonic - tag - sandbox-airsonic alltube - tag - sandbox-alltube alternatrr - tag - sandbox-alternatrr alternatrrx - tag - sandbox-alternatrrx apprise - tag - sandbox-apprise archivebox - tag - sandbox-archivebox a_train - tag - sandbox-a_train audiobookshelf - tag - sandbox-audiobookshelf autobrr - tag - sandbox-autobrr beets - tag - sandbox-beets booksonic - tag - sandbox-booksonic bookstack - tag - sandbox-bookstack calibre - tag - sandbox-calibre calibre_web - tag - sandbox-calibre-web changedetection - tag - sandbox-changedetection cherry - tag - sandbox-cherry coder - tag - sandbox-coder comicstreamer - tag - sandbox-comicstreamer comixed - tag - sandbox-comixed deemix - tag - sandbox-deemix delugevpn - tag - sandbox-delugevpn doplarr - tag - sandbox-doplarr dozzle - tag - sandbox-dozzle duplicati - tag - sandbox-duplicati embystat - tag - sandbox-embystat epms - tag - sandbox-epms filebot - tag - sandbox-filebot filebrowser - tag - sandbox-filebrowser filezilla - tag - sandbox-filezilla flaresolverr - tag - sandbox-flaresolverr freshrss - tag - sandbox-freshrss funkwhale - tag - sandbox-funkwhale gaps - tag - sandbox-gaps gitea - tag - sandbox-gitea glances_web - tag - sandbox-glances-web goaccess - tag - sandbox-goaccess goplaxt - tag - sandbox-goplaxt gotenberg - tag - sandbox-gotenberg gotify - tag - sandbox-gotify guacamole - tag - sandbox-guacamole handbrake - tag - sandbox-handbrake healthchecks - tag - sandbox-healthchecks heimdall - tag - sandbox-heimdall Homarr - tag - sandbox-homarr homebox - tag - sandbox-homebox influxdb - tag - sandbox-influxdb invoiceninja - tag - sandbox-invoiceninja jdownloader2 - tag - sandbox-jdownloader2 jirafeau - tag - sandbox-jirafeau joplin - tag - sandbox-joplin kavita - tag - sandbox-kavita kcptun_client - tag - sandbox-kcptun-client kcptun_server - tag - sandbox-kcptun-server kitana - tag - sandbox-kitana komga - tag - sandbox-komga lazylibrarian - tag - sandbox-lazylibrarian linkding - tag - sandbox-linkding logarr - tag - sandbox-logarr makemkv - tag - sandbox-makemkv mcrouter - tag - sandbox-mcrouter medusa - tag - sandbox-medusa minecraft - tag - sandbox-minecraft minecraft-bedrock - tag - sandbox-minecraft-bedrock mkvtoolnix - tag - sandbox-mkvtoolnix monitorr - tag - sandbox-monitorr moviematch - tag - sandbox-moviematch mylar3 - tag - sandbox-mylar3 nabarr - tag - sandbox-nabarr navidrome - tag - sandbox-navidrome nextcloud - tag - sandbox-nextcloud notifiarr - tag - sandbox-notifiarr olivetin - tag - sandbox-olivetin ombi - tag - sandbox-ombi ombix - tag - sandbox-ombix omegabrr - tag - sandbox-omegabrr ouroboros - tag - sandbox-ouroboros paperless-ngx - tag - sandbox-paperless-ngx pgadmin - tag - sandbox-pgadmin photoprism - tag - sandbox-photoprism plex_auto_languages - tag - sandbox-plex_auto_languages plex_autoscan - tag - sandbox-plex_autoscan plex_credits_detect - tag - sandbox-plex_credits_detect plex_dupefinder - tag - sandbox-plex_dupefinder plex-meta-manager - tag - sandbox-plex-meta-manager plex_patrol - tag - sandbox-plex_patrol plextraktsync - tag - sandbox-plextraktsync plex_utills - tag - sandbox-plex_utills privatebin - tag - sandbox-privatebin Puddletag - tag - sandbox-puddletag pyload - tag - pyload python-plexlibrary - tag - python-plexlibrary qbit_manage - tag - sandbox-qbit_manage qbittorrentvpn - tag - sandbox-qbittorrentvpn rdtclient - tag - sandbox-rdtclient recyclarr - tag - sandbox-recyclarr reposilite - tag - sandbox-reposilite requestrr - tag - sandbox-requestrr requestrrx - tag - sandbox-requestrrx resiliosync - tag - sandbox-resiliosync rflood - tag - rflood rfloodx - tag - rfloodx rocketchat - tag - rocketchat sabthrottle - tag - sandbox-sabthrottle sarotate - tag - sandbox-sarotate speedtest - tag - sandbox-speedtest sqlitebrowser - tag - sandbox-sqlitebrowser sshwifty - tag - sandbox-sshwifty stash - tag - sandbox-stash syncthing - tag - sandbox-syncthing tandoor - tag - sandbox-tandoor tdarr - tag - sandbox-tdarr tdarr_node - tag - sandbox-tdarr_node teamspeak - tag - sandbox-teamspeak telegraf - tag - sandbox-telegraf thelounge - tag - sandbox-thelounge tika - tag - sandbox-tika tqm - tag - sandbox-tqm traefik_robotstxt - tag - sandbox-traefik_robotstxt transmission - tag - sandbox-transmission transmissionvpn - tag - sandbox-transmissionvpn transmissionx - tag - sandbox-transmissionx trilium - tag - sandbox-trilium tubearchivist - tag - sandbox-tubearchivist unifi - tag - sandbox-unifi unmanic - tag - sandbox-unmanic unpackerr - tag - sandbox-unpackerr uptime-kuma - tag - sandbox-uptime-kuma varken - tag - sandbox-varken vaultwarden - tag - sandbox-vaultwarden vnstat - tag - sandbox-vnstat watchtower - tag - sandbox-watchtower whisparr - tag - sandbox-whisparr wireguard - tag - sandbox-wireguard wizarr - tag - sandbox-wizarr wordpress - tag - sandbox-wordpress wrapperr - tag - sandbox-wrapperr xbackbone - tag - sandbox-xbackbone xteve - tag - sandbox-xteve yacht - tag - sandbox-yacht znc - tag - sandbox-znc","title":"Index"},{"location":"sandbox/#sandbox-all-apps-index","text":"adguardhome - tag - sandbox-adguardhome adminer - tag - sandbox-adminer airdcpp - tag - sandbox-airdcpp airsonic - tag - sandbox-airsonic alltube - tag - sandbox-alltube alternatrr - tag - sandbox-alternatrr alternatrrx - tag - sandbox-alternatrrx apprise - tag - sandbox-apprise archivebox - tag - sandbox-archivebox a_train - tag - sandbox-a_train audiobookshelf - tag - sandbox-audiobookshelf autobrr - tag - sandbox-autobrr beets - tag - sandbox-beets booksonic - tag - sandbox-booksonic bookstack - tag - sandbox-bookstack calibre - tag - sandbox-calibre calibre_web - tag - sandbox-calibre-web changedetection - tag - sandbox-changedetection cherry - tag - sandbox-cherry coder - tag - sandbox-coder comicstreamer - tag - sandbox-comicstreamer comixed - tag - sandbox-comixed deemix - tag - sandbox-deemix delugevpn - tag - sandbox-delugevpn doplarr - tag - sandbox-doplarr dozzle - tag - sandbox-dozzle duplicati - tag - sandbox-duplicati embystat - tag - sandbox-embystat epms - tag - sandbox-epms filebot - tag - sandbox-filebot filebrowser - tag - sandbox-filebrowser filezilla - tag - sandbox-filezilla flaresolverr - tag - sandbox-flaresolverr freshrss - tag - sandbox-freshrss funkwhale - tag - sandbox-funkwhale gaps - tag - sandbox-gaps gitea - tag - sandbox-gitea glances_web - tag - sandbox-glances-web goaccess - tag - sandbox-goaccess goplaxt - tag - sandbox-goplaxt gotenberg - tag - sandbox-gotenberg gotify - tag - sandbox-gotify guacamole - tag - sandbox-guacamole handbrake - tag - sandbox-handbrake healthchecks - tag - sandbox-healthchecks heimdall - tag - sandbox-heimdall Homarr - tag - sandbox-homarr homebox - tag - sandbox-homebox influxdb - tag - sandbox-influxdb invoiceninja - tag - sandbox-invoiceninja jdownloader2 - tag - sandbox-jdownloader2 jirafeau - tag - sandbox-jirafeau joplin - tag - sandbox-joplin kavita - tag - sandbox-kavita kcptun_client - tag - sandbox-kcptun-client kcptun_server - tag - sandbox-kcptun-server kitana - tag - sandbox-kitana komga - tag - sandbox-komga lazylibrarian - tag - sandbox-lazylibrarian linkding - tag - sandbox-linkding logarr - tag - sandbox-logarr makemkv - tag - sandbox-makemkv mcrouter - tag - sandbox-mcrouter medusa - tag - sandbox-medusa minecraft - tag - sandbox-minecraft minecraft-bedrock - tag - sandbox-minecraft-bedrock mkvtoolnix - tag - sandbox-mkvtoolnix monitorr - tag - sandbox-monitorr moviematch - tag - sandbox-moviematch mylar3 - tag - sandbox-mylar3 nabarr - tag - sandbox-nabarr navidrome - tag - sandbox-navidrome nextcloud - tag - sandbox-nextcloud notifiarr - tag - sandbox-notifiarr olivetin - tag - sandbox-olivetin ombi - tag - sandbox-ombi ombix - tag - sandbox-ombix omegabrr - tag - sandbox-omegabrr ouroboros - tag - sandbox-ouroboros paperless-ngx - tag - sandbox-paperless-ngx pgadmin - tag - sandbox-pgadmin photoprism - tag - sandbox-photoprism plex_auto_languages - tag - sandbox-plex_auto_languages plex_autoscan - tag - sandbox-plex_autoscan plex_credits_detect - tag - sandbox-plex_credits_detect plex_dupefinder - tag - sandbox-plex_dupefinder plex-meta-manager - tag - sandbox-plex-meta-manager plex_patrol - tag - sandbox-plex_patrol plextraktsync - tag - sandbox-plextraktsync plex_utills - tag - sandbox-plex_utills privatebin - tag - sandbox-privatebin Puddletag - tag - sandbox-puddletag pyload - tag - pyload python-plexlibrary - tag - python-plexlibrary qbit_manage - tag - sandbox-qbit_manage qbittorrentvpn - tag - sandbox-qbittorrentvpn rdtclient - tag - sandbox-rdtclient recyclarr - tag - sandbox-recyclarr reposilite - tag - sandbox-reposilite requestrr - tag - sandbox-requestrr requestrrx - tag - sandbox-requestrrx resiliosync - tag - sandbox-resiliosync rflood - tag - rflood rfloodx - tag - rfloodx rocketchat - tag - rocketchat sabthrottle - tag - sandbox-sabthrottle sarotate - tag - sandbox-sarotate speedtest - tag - sandbox-speedtest sqlitebrowser - tag - sandbox-sqlitebrowser sshwifty - tag - sandbox-sshwifty stash - tag - sandbox-stash syncthing - tag - sandbox-syncthing tandoor - tag - sandbox-tandoor tdarr - tag - sandbox-tdarr tdarr_node - tag - sandbox-tdarr_node teamspeak - tag - sandbox-teamspeak telegraf - tag - sandbox-telegraf thelounge - tag - sandbox-thelounge tika - tag - sandbox-tika tqm - tag - sandbox-tqm traefik_robotstxt - tag - sandbox-traefik_robotstxt transmission - tag - sandbox-transmission transmissionvpn - tag - sandbox-transmissionvpn transmissionx - tag - sandbox-transmissionx trilium - tag - sandbox-trilium tubearchivist - tag - sandbox-tubearchivist unifi - tag - sandbox-unifi unmanic - tag - sandbox-unmanic unpackerr - tag - sandbox-unpackerr uptime-kuma - tag - sandbox-uptime-kuma varken - tag - sandbox-varken vaultwarden - tag - sandbox-vaultwarden vnstat - tag - sandbox-vnstat watchtower - tag - sandbox-watchtower whisparr - tag - sandbox-whisparr wireguard - tag - sandbox-wireguard wizarr - tag - sandbox-wizarr wordpress - tag - sandbox-wordpress wrapperr - tag - sandbox-wrapperr xbackbone - tag - sandbox-xbackbone xteve - tag - sandbox-xteve yacht - tag - sandbox-yacht znc - tag - sandbox-znc","title":"Sandbox - All Apps Index"},{"location":"sandbox/basics/","text":"Basics \u00b6 The Saltbox Sandbox repository is installed with Saltbox as part of a standard install. The Saltbox Sandbox application installers are provided and maintained by the community but are subject to approval. The applications are not part of a standard Saltbox install, but they should all be compatible with the Saltbox ecosystem. Sandbox is not a free-for-all no-rules repository but what will be accepted is a much broader range of applications which may not necessarily have anything to do with running a media server. Applications that are newly submitted or need testing will primarily land in the Sandbox repo and if relevant, stable, and maintained may end up in the Saltbox repo. Saltbox documentation is written by community members to help others make the most of their systems. Providing documentation for Sandbox applications is encouraged but not required. All Saltbox applications must have documentation Install \u00b6 sb install sandbox Update \u00b6 To update Saltbox Sandbox run a standard saltbox update; Sandbox and Saltbox will both be updated sb update Info Note that sb update updates only the saltbox files themselves; it does not update any applications. You will need to follow this with an sb install <tags here> command to update applications or installed components. How to Install Sandbox Apps \u00b6 For most apps it is as simple as running the sb install command in a shell with a sandbox- prefix followed by the name of the role. sb install sandbox-rolename For example, to install mkvtoolnix you would run the mkvtoolnix role:- sb install sandbox-mkvtoolnix Before running any role you should first carefully read through any docs to see if there are any additional steps or pre configuration settings required. A list of all roles available to Saltbox including Sandbox can be called from the terminal via:- sb list Tip Where possible the configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml and used to create a default user an password for logging in. Contributing to Sandbox Apps \u00b6 Note: If you just want to install a container into the Saltbox system without creating a role, see this article . That work will also help you determine what you will need to do in a role, so starting there would not be wasted effort. If you want to create a role to allow others to install your role, keep reading. Editing an existing role: \u00b6 If you want to make a change to an existing role [for example, changing the docker image it uses], you don't have [or want to] to create a new role. You make changes like this for either core or sandbox roles using the inventory system Preparatory work: \u00b6 Start by making your own fork of the Sandbox repo by clicking on the \"Fork\" button up and to the right. This will take you to your own copy of the Sandbox repo. On your development machine [which should probably be a machine running saltbox, as it makes things easier with regard to testing]: clone your Sandbox fork: git clone https://github.com/YOURNAMEHERE/Sandbox.git sandbox go into that local sandbox dir: cd sandbox make sure your local repo is up-to-date: git pull create your feature branch: git checkout -b my-cool-role Creating a role: \u00b6 Now you're ready to start work on your new role. A good starting point is to find a role that is similar to the one you want to add and use it as a starting point. For example, if your container requires mariadb and you want to create a database during setup, bookstack does that. copy the \"starting point\" role to your role: cp -R roles/bookstack roles/my-cool-role [of course, substitute whatever role you're using as your prototype for \"bookstack\"] Next step is to create the role. At a minimum, you will need to modify: roles \u2514\u2500\u2500 my-cool-role \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 tasks \u2514\u2500\u2500 main.yml sandbox.yml There may be other things required; there may be templates or sub-tasks or what have you. Those three files are the absolute bare minimum that would need to be created to add a new role. What are those things? roles/my-cool-role/defaults/main.yml This file contains various details for your role; the docker image, the name, subdomain, that sort of thing. The stuff in there should be self-explanatory or understandable with comparisons to existing roles; if it's not, then with all respect you probably shouldn't be creating a role right now. roles/my-cool-role/tasks/main.yml This file drives the install of your role. The stuff in there should be self-explanatory or understandable with comparisons to existing roles; if it's not, then again, with all respect you probably shouldn't be creating a role right now. There is a wiki article on adding new containers here ; this may be of some use. Don't forget the header in both these files: ######################################################################### # Title: Sandbox: my-cool-role # # Author(s): some-guy, salty # # URL: https://github.com/saltyorg/Sandbox # # -- # ######################################################################### # GNU General Public License v3.0 # ######################################################################### --- Be sure you edit this to reflect your role, name, and such depending on what's there in your prototype sandbox.yml This file drives the ansible install system by providing the valid tags that you can use with: sb install sandbox-TAG Again, it's a simple file, and it should be quite apparent what needs to be added for a new role. Other files you may need to edit: \u00b6 defaults \u2514\u2500\u2500 settings.yml.default This file provides the prototype settings file; if your role requires some new settings, add them to this file. When the sandbox repo is updated, your new settings will be added to the user's current settings file and they will be prompted to review it. templates \u2514\u2500\u2500 my-cool-role.j2 Perhaps you need to create a config file, or a service file, or the like. Create templates for them here and fill them in at install time. THere are lots of examples in the existing roles. Testing: \u00b6 Warning BE SURE TO TEST YOUR ROLE. You want to make sure that your role works, so be sure you run it several times. Run it on fresh installs, reinstalls, enlist someone else to run it for you. The point of doing this is to add something to sandbox for others to use; if you don't verify that it works, why are you doing it? Creating the Pull Request: \u00b6 Now it's complete, and tested, and you want it to be added to sandbox for other users to enjoy. First, commit your changes to your fork. Warning BE SURE YOU DO NOT COMMIT FILES CONTAINING SECRETS LIKE API KEYS OR TOKENS. This will involve adding the files you changed or added and doing a git commit and git push. This is standard git stuff, and again, with all respect, if you don't know these git basics you probably shouldn't be creating a role right now. Back at github.com, create a pull request against the \"master\" branch of the sandbox repo. You do this by switching to your feature branch in your repo and clicking \"Pull request\" at the top where it says something like: \"This branch is 2 commits ahead of sandbox:master.\" This is a request for the Saltbox team to \"pull\" your changes into their repo. If there are special instructions or details that your role needs, add them to the pull request comments. If needed, create a doc page [which will be its own pull request] for the role. Warning BE SURE YOU DO NOT COMMIT FILES CONTAINING SECRETS LIKE API KEYS OR TOKENS. Your pull request will be reviewed eventually, and may generate comments or change requests. You can address those change requests by making further commits to your feature branch; they will automatically be added to this pull request. Eventually, if deemed a good or just reasonable fit, your pull request will be accepted and it will appear in the source sandbox repo.","title":"Basics"},{"location":"sandbox/basics/#basics","text":"The Saltbox Sandbox repository is installed with Saltbox as part of a standard install. The Saltbox Sandbox application installers are provided and maintained by the community but are subject to approval. The applications are not part of a standard Saltbox install, but they should all be compatible with the Saltbox ecosystem. Sandbox is not a free-for-all no-rules repository but what will be accepted is a much broader range of applications which may not necessarily have anything to do with running a media server. Applications that are newly submitted or need testing will primarily land in the Sandbox repo and if relevant, stable, and maintained may end up in the Saltbox repo. Saltbox documentation is written by community members to help others make the most of their systems. Providing documentation for Sandbox applications is encouraged but not required. All Saltbox applications must have documentation","title":"Basics"},{"location":"sandbox/basics/#install","text":"sb install sandbox","title":"Install"},{"location":"sandbox/basics/#update","text":"To update Saltbox Sandbox run a standard saltbox update; Sandbox and Saltbox will both be updated sb update Info Note that sb update updates only the saltbox files themselves; it does not update any applications. You will need to follow this with an sb install <tags here> command to update applications or installed components.","title":"Update"},{"location":"sandbox/basics/#how-to-install-sandbox-apps","text":"For most apps it is as simple as running the sb install command in a shell with a sandbox- prefix followed by the name of the role. sb install sandbox-rolename For example, to install mkvtoolnix you would run the mkvtoolnix role:- sb install sandbox-mkvtoolnix Before running any role you should first carefully read through any docs to see if there are any additional steps or pre configuration settings required. A list of all roles available to Saltbox including Sandbox can be called from the terminal via:- sb list Tip Where possible the configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml and used to create a default user an password for logging in.","title":"How to Install Sandbox Apps"},{"location":"sandbox/basics/#contributing-to-sandbox-apps","text":"Note: If you just want to install a container into the Saltbox system without creating a role, see this article . That work will also help you determine what you will need to do in a role, so starting there would not be wasted effort. If you want to create a role to allow others to install your role, keep reading.","title":"Contributing to Sandbox Apps"},{"location":"sandbox/basics/#editing-an-existing-role","text":"If you want to make a change to an existing role [for example, changing the docker image it uses], you don't have [or want to] to create a new role. You make changes like this for either core or sandbox roles using the inventory system","title":"Editing an existing role:"},{"location":"sandbox/basics/#preparatory-work","text":"Start by making your own fork of the Sandbox repo by clicking on the \"Fork\" button up and to the right. This will take you to your own copy of the Sandbox repo. On your development machine [which should probably be a machine running saltbox, as it makes things easier with regard to testing]: clone your Sandbox fork: git clone https://github.com/YOURNAMEHERE/Sandbox.git sandbox go into that local sandbox dir: cd sandbox make sure your local repo is up-to-date: git pull create your feature branch: git checkout -b my-cool-role","title":"Preparatory work:"},{"location":"sandbox/basics/#creating-a-role","text":"Now you're ready to start work on your new role. A good starting point is to find a role that is similar to the one you want to add and use it as a starting point. For example, if your container requires mariadb and you want to create a database during setup, bookstack does that. copy the \"starting point\" role to your role: cp -R roles/bookstack roles/my-cool-role [of course, substitute whatever role you're using as your prototype for \"bookstack\"] Next step is to create the role. At a minimum, you will need to modify: roles \u2514\u2500\u2500 my-cool-role \u251c\u2500\u2500 defaults \u2502 \u2514\u2500\u2500 main.yml \u2514\u2500\u2500 tasks \u2514\u2500\u2500 main.yml sandbox.yml There may be other things required; there may be templates or sub-tasks or what have you. Those three files are the absolute bare minimum that would need to be created to add a new role. What are those things? roles/my-cool-role/defaults/main.yml This file contains various details for your role; the docker image, the name, subdomain, that sort of thing. The stuff in there should be self-explanatory or understandable with comparisons to existing roles; if it's not, then with all respect you probably shouldn't be creating a role right now. roles/my-cool-role/tasks/main.yml This file drives the install of your role. The stuff in there should be self-explanatory or understandable with comparisons to existing roles; if it's not, then again, with all respect you probably shouldn't be creating a role right now. There is a wiki article on adding new containers here ; this may be of some use. Don't forget the header in both these files: ######################################################################### # Title: Sandbox: my-cool-role # # Author(s): some-guy, salty # # URL: https://github.com/saltyorg/Sandbox # # -- # ######################################################################### # GNU General Public License v3.0 # ######################################################################### --- Be sure you edit this to reflect your role, name, and such depending on what's there in your prototype sandbox.yml This file drives the ansible install system by providing the valid tags that you can use with: sb install sandbox-TAG Again, it's a simple file, and it should be quite apparent what needs to be added for a new role.","title":"Creating a role:"},{"location":"sandbox/basics/#other-files-you-may-need-to-edit","text":"defaults \u2514\u2500\u2500 settings.yml.default This file provides the prototype settings file; if your role requires some new settings, add them to this file. When the sandbox repo is updated, your new settings will be added to the user's current settings file and they will be prompted to review it. templates \u2514\u2500\u2500 my-cool-role.j2 Perhaps you need to create a config file, or a service file, or the like. Create templates for them here and fill them in at install time. THere are lots of examples in the existing roles.","title":"Other files you may need to edit:"},{"location":"sandbox/basics/#testing","text":"Warning BE SURE TO TEST YOUR ROLE. You want to make sure that your role works, so be sure you run it several times. Run it on fresh installs, reinstalls, enlist someone else to run it for you. The point of doing this is to add something to sandbox for others to use; if you don't verify that it works, why are you doing it?","title":"Testing:"},{"location":"sandbox/basics/#creating-the-pull-request","text":"Now it's complete, and tested, and you want it to be added to sandbox for other users to enjoy. First, commit your changes to your fork. Warning BE SURE YOU DO NOT COMMIT FILES CONTAINING SECRETS LIKE API KEYS OR TOKENS. This will involve adding the files you changed or added and doing a git commit and git push. This is standard git stuff, and again, with all respect, if you don't know these git basics you probably shouldn't be creating a role right now. Back at github.com, create a pull request against the \"master\" branch of the sandbox repo. You do this by switching to your feature branch in your repo and clicking \"Pull request\" at the top where it says something like: \"This branch is 2 commits ahead of sandbox:master.\" This is a request for the Saltbox team to \"pull\" your changes into their repo. If there are special instructions or details that your role needs, add them to the pull request comments. If needed, create a doc page [which will be its own pull request] for the role. Warning BE SURE YOU DO NOT COMMIT FILES CONTAINING SECRETS LIKE API KEYS OR TOKENS. Your pull request will be reviewed eventually, and may generate comments or change requests. You can address those change requests by making further commits to your feature branch; they will automatically be added to this pull request. Eventually, if deemed a good or just reasonable fit, your pull request will be accepted and it will appear in the source sandbox repo.","title":"Creating the Pull Request:"},{"location":"sandbox/settings/","text":"The Settings File \u00b6 The configuration file for Saltbox Sandbox settings is called settings.yml and is located at /opt/sandbox/settings.yml settings.yml --- alternatrrx : roles : [ \"1080webdl\" , \"1080remux\" ] a_train : remotes : [ \"\" ] delugevpn : vpn_endpoint : netherlands.ovpn vpn_pass : your_vpn_password vpn_prov : pia vpn_user : your_vpn_username vpn_client : wireguard # 'wireguard' or 'openvpn' doplarr : discord_token : your_discord_bot_token # MUST BE SET #you must define below overseer credential OR (Radarr AND Sonarr) credentials #Overseer: overseerr_url : \"http://overseerr:5055\" #set to empty and define radarr and sonarr parameters if you want to use radarr/sonarr rather than overserr. overseerr_api : #to be defined if you want to use overseer #Radarr AND Sonarr: radarr_api : #not defined by default. set it if you want to use sonarr and radarr. radarr_url : #not defined by default. set it if you want to use sonarr and radarr. sonarr_api : #not defined by default. set it if you want to use sonarr and radarr. sonarr_url : #not defined by default. set it if you want to use sonarr and radarr. #Optional settings: discord_max_results : 25 discord_role_id : #optional: role id of users allowed to talk to the bot. Empty=all discord_requested_msg_style : \":plain\" #optional: Sets the style of the request alert message. One of :plain :embed :none sonarr_quality_profile : #optional radarr_quality_profile : #optional sonarr_language_profile : #optional overseer_default_id : #optional - The Overseerr user id to use by default if there is no associated discord account for the requester partial_seasons : \"true\" #optional - Sets whether users can request partial seasons. log_level : \":info\" #optional - One of :trace :debug :info :warn :error :fatal :report goplaxt : trakt_id : ~ trakt_secret : ~ handbrake : handbrake_pass : saltbox # must be less than eight characters invoiceninja : app_key : 'base64:O1S3kAJEDgo92gPkXtxfdCJpoGShgKloUSdcaHMXmoY=' # Generate your own with: docker run --rm -it invoiceninja/invoiceninja php artisan key:generate --show moviematch : libraries : Movies plex_url : http://plex:32400 notifiarr : api_key : \"api-key-from-notifiarr.com\" ui_password : \"username:password\" # Password needs to be at least 16 characters long. ombix : roles : [ \"4k\" ] plex_meta_manager : time : \"03:00\" qbit_manage : qbt_run : \"false\" # Default is \"false\" qbt_schedule : \"30\" # Default is \"30\" qbt_config : \"config.yml\" # Default is \"config.yml\" qbt_logfile : \"activity.log\" # Default is \"activity.log\" qbt_cross_seed : \"false\" # Default is \"false\" qbt_recheck : \"false\" # Default is \"false\" qbt_cat_update : \"false\" # Default is \"false\" qbt_tag_update : \"false\" # Default is \"false\" qbt_rem_unregistered : \"false\" # Default is \"false\" qbt_rem_orphaned : \"false\" # Default is \"false\" qbt_tag_nohardlinks : \"false\" # Default is \"false\" qbt_skip_recycle : \"false\" # Default is \"false\" qbt_dry_run : \"true\" # Default is \"false\" qbt_log_level : \"INFO\" # Default is \"INFO\" qbt_divider : \"=\" # Default is \"=\" qbt_width : \"100\" # Default is \"100\" qbt_debug : \"false\" qbt_trace : \"false\" recyclarr : cron_schedule : \"@daily\" # Standard cron syntax for how often you want Recyclarr to run requestrrx : roles : [ \"1080p\" , \"4k\" ] rfloodx : roles : [ \"\" ] sarotate : remotes : [ \"\" ] sa_path : \"your_sa_folder_path\" sleeptime : #optional: Delay between service account rotation (Default is 300) rc_port : #optional: The port used by rc (Default is saltbox default of 5572) rc_user : #optional: The user used by rc if authentication is enabled (Default is no authentication) rc_pass : #optional: The password used by rc if autentication is enabled (Default is no authentication) apprise : #optional: apprise notifications (Default is blank) tandoor : secret_key : #Required: You can generate one with 'base64 /dev/urandom | head -c50' transmissionvpn : vpn_user : vpn_pass : vpn_prov : transmissionx : roles : [ \"\" ]","title":"Settings"},{"location":"sandbox/settings/#the-settings-file","text":"The configuration file for Saltbox Sandbox settings is called settings.yml and is located at /opt/sandbox/settings.yml settings.yml --- alternatrrx : roles : [ \"1080webdl\" , \"1080remux\" ] a_train : remotes : [ \"\" ] delugevpn : vpn_endpoint : netherlands.ovpn vpn_pass : your_vpn_password vpn_prov : pia vpn_user : your_vpn_username vpn_client : wireguard # 'wireguard' or 'openvpn' doplarr : discord_token : your_discord_bot_token # MUST BE SET #you must define below overseer credential OR (Radarr AND Sonarr) credentials #Overseer: overseerr_url : \"http://overseerr:5055\" #set to empty and define radarr and sonarr parameters if you want to use radarr/sonarr rather than overserr. overseerr_api : #to be defined if you want to use overseer #Radarr AND Sonarr: radarr_api : #not defined by default. set it if you want to use sonarr and radarr. radarr_url : #not defined by default. set it if you want to use sonarr and radarr. sonarr_api : #not defined by default. set it if you want to use sonarr and radarr. sonarr_url : #not defined by default. set it if you want to use sonarr and radarr. #Optional settings: discord_max_results : 25 discord_role_id : #optional: role id of users allowed to talk to the bot. Empty=all discord_requested_msg_style : \":plain\" #optional: Sets the style of the request alert message. One of :plain :embed :none sonarr_quality_profile : #optional radarr_quality_profile : #optional sonarr_language_profile : #optional overseer_default_id : #optional - The Overseerr user id to use by default if there is no associated discord account for the requester partial_seasons : \"true\" #optional - Sets whether users can request partial seasons. log_level : \":info\" #optional - One of :trace :debug :info :warn :error :fatal :report goplaxt : trakt_id : ~ trakt_secret : ~ handbrake : handbrake_pass : saltbox # must be less than eight characters invoiceninja : app_key : 'base64:O1S3kAJEDgo92gPkXtxfdCJpoGShgKloUSdcaHMXmoY=' # Generate your own with: docker run --rm -it invoiceninja/invoiceninja php artisan key:generate --show moviematch : libraries : Movies plex_url : http://plex:32400 notifiarr : api_key : \"api-key-from-notifiarr.com\" ui_password : \"username:password\" # Password needs to be at least 16 characters long. ombix : roles : [ \"4k\" ] plex_meta_manager : time : \"03:00\" qbit_manage : qbt_run : \"false\" # Default is \"false\" qbt_schedule : \"30\" # Default is \"30\" qbt_config : \"config.yml\" # Default is \"config.yml\" qbt_logfile : \"activity.log\" # Default is \"activity.log\" qbt_cross_seed : \"false\" # Default is \"false\" qbt_recheck : \"false\" # Default is \"false\" qbt_cat_update : \"false\" # Default is \"false\" qbt_tag_update : \"false\" # Default is \"false\" qbt_rem_unregistered : \"false\" # Default is \"false\" qbt_rem_orphaned : \"false\" # Default is \"false\" qbt_tag_nohardlinks : \"false\" # Default is \"false\" qbt_skip_recycle : \"false\" # Default is \"false\" qbt_dry_run : \"true\" # Default is \"false\" qbt_log_level : \"INFO\" # Default is \"INFO\" qbt_divider : \"=\" # Default is \"=\" qbt_width : \"100\" # Default is \"100\" qbt_debug : \"false\" qbt_trace : \"false\" recyclarr : cron_schedule : \"@daily\" # Standard cron syntax for how often you want Recyclarr to run requestrrx : roles : [ \"1080p\" , \"4k\" ] rfloodx : roles : [ \"\" ] sarotate : remotes : [ \"\" ] sa_path : \"your_sa_folder_path\" sleeptime : #optional: Delay between service account rotation (Default is 300) rc_port : #optional: The port used by rc (Default is saltbox default of 5572) rc_user : #optional: The user used by rc if authentication is enabled (Default is no authentication) rc_pass : #optional: The password used by rc if autentication is enabled (Default is no authentication) apprise : #optional: apprise notifications (Default is blank) tandoor : secret_key : #Required: You can generate one with 'base64 /dev/urandom | head -c50' transmissionvpn : vpn_user : vpn_pass : vpn_prov : transmissionx : roles : [ \"\" ]","title":"The Settings File"},{"location":"sandbox/apps/a_train/","text":"A-Train \u00b6 What is it? \u00b6 A-Train is the official Autoscan trigger that listens for changes within Google Drive. It is the successor of Autoscan's Bernard trigger, which unfortunately contains enough logic errors to prompt a rewrite. Supports Shared Drives Service Account-based authentication Does not support My Drive Does not support encrypted files Does not support alternative authentication methods","title":"A-Train"},{"location":"sandbox/apps/a_train/#a-train","text":"","title":"A-Train"},{"location":"sandbox/apps/a_train/#what-is-it","text":"A-Train is the official Autoscan trigger that listens for changes within Google Drive. It is the successor of Autoscan's Bernard trigger, which unfortunately contains enough logic errors to prompt a rewrite. Supports Shared Drives Service Account-based authentication Does not support My Drive Does not support encrypted files Does not support alternative authentication methods","title":"What is it?"},{"location":"sandbox/apps/adguardhome/","text":"AdGuard Home \u00b6 What is it? \u00b6 AdGuard Home is a network-wide, open source software for blocking ads & tracking and for gaining control over all traffic in your home network. After you set it up, it'll cover ALL devices in your home Wi-Fi network, and you won't need any client-side software for that. At the same time, it provides a user-friendly web interface that allows you to easily manage the traffic, even from a mobile device. There are some concerns with the security of running a DNS server remotely so just be aware of this if you choose to run it on a public network. Details Project home Docs Github Docker Info AdGuard Home is a latency sensitive DNS server, so it's discouraged to use it when your server is far away from you. 1. Installation \u00b6 sb install sandbox-adguardhome 2. URL \u00b6 To access AdGuard Home dashboard, visit https://adguardhome._yourdomain.com_ 3. Usage \u00b6 Make sure you have an application that supports DNS over HTTPS, e.g. Intra for Android or DNSCloak for iOS Connect to AdGuard Home with one of the above applications using https://adguardhome._yourdomain.com/dns-query","title":"AdGuard Home"},{"location":"sandbox/apps/adguardhome/#adguard-home","text":"","title":"AdGuard Home"},{"location":"sandbox/apps/adguardhome/#what-is-it","text":"AdGuard Home is a network-wide, open source software for blocking ads & tracking and for gaining control over all traffic in your home network. After you set it up, it'll cover ALL devices in your home Wi-Fi network, and you won't need any client-side software for that. At the same time, it provides a user-friendly web interface that allows you to easily manage the traffic, even from a mobile device. There are some concerns with the security of running a DNS server remotely so just be aware of this if you choose to run it on a public network. Details Project home Docs Github Docker Info AdGuard Home is a latency sensitive DNS server, so it's discouraged to use it when your server is far away from you.","title":"What is it?"},{"location":"sandbox/apps/adguardhome/#1-installation","text":"sb install sandbox-adguardhome","title":"1. Installation"},{"location":"sandbox/apps/adguardhome/#2-url","text":"To access AdGuard Home dashboard, visit https://adguardhome._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/adguardhome/#3-usage","text":"Make sure you have an application that supports DNS over HTTPS, e.g. Intra for Android or DNSCloak for iOS Connect to AdGuard Home with one of the above applications using https://adguardhome._yourdomain.com/dns-query","title":"3. Usage"},{"location":"sandbox/apps/adminer/","text":"Adminer \u00b6 What is it? \u00b6 Adminer Adminer (formerly phpMinAdmin) is a full-featured database management tool written in PHP. Adminer is available for MySQL, MariaDB, PostgreSQL, SQLite, MS SQL, Oracle, Elasticsearch, MongoDB and others via plugin. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-Adminer 2. URL \u00b6 To access Adminer, visit https://adminer._yourdomain.com_ 3. Setup \u00b6 Default login for mariadb yaml System: Mysql Server: mariadb:3306 Username: root Password: password321 Default login for postgres { .yaml} System: PostgreSQL Server: postgres:5432 Username: your_saltbox_user Password: password4321 Documentation: Adminer Docs","title":"adminer"},{"location":"sandbox/apps/adminer/#adminer","text":"","title":"Adminer"},{"location":"sandbox/apps/adminer/#what-is-it","text":"Adminer Adminer (formerly phpMinAdmin) is a full-featured database management tool written in PHP. Adminer is available for MySQL, MariaDB, PostgreSQL, SQLite, MS SQL, Oracle, Elasticsearch, MongoDB and others via plugin. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/adminer/#1-installation","text":"sb install sandbox-Adminer","title":"1. Installation"},{"location":"sandbox/apps/adminer/#2-url","text":"To access Adminer, visit https://adminer._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/adminer/#3-setup","text":"Default login for mariadb yaml System: Mysql Server: mariadb:3306 Username: root Password: password321 Default login for postgres { .yaml} System: PostgreSQL Server: postgres:5432 Username: your_saltbox_user Password: password4321 Documentation: Adminer Docs","title":"3. Setup"},{"location":"sandbox/apps/airdcpp/","text":"AirDC++ \u00b6 What is it? \u00b6 AirDC++ is an easy to use client for Advanced Direct Connect and Direct Connect networks. You are able to join \"hubs\" with other users, and chat, perform searches and browse the share of each user. It allows you to share files with friends and other people. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-airdcpp 2. URL \u00b6 To access AirDC++, visit https://airdcpp._yourdomain.com_ 3. Setup \u00b6 Documentation: AirDC++ Client Docs","title":"AirDC++"},{"location":"sandbox/apps/airdcpp/#airdc","text":"","title":"AirDC++"},{"location":"sandbox/apps/airdcpp/#what-is-it","text":"AirDC++ is an easy to use client for Advanced Direct Connect and Direct Connect networks. You are able to join \"hubs\" with other users, and chat, perform searches and browse the share of each user. It allows you to share files with friends and other people. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/airdcpp/#1-installation","text":"sb install sandbox-airdcpp","title":"1. Installation"},{"location":"sandbox/apps/airdcpp/#2-url","text":"To access AirDC++, visit https://airdcpp._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/airdcpp/#3-setup","text":"Documentation: AirDC++ Client Docs","title":"3. Setup"},{"location":"sandbox/apps/airsonic/","text":"Airsonic \u00b6 What is it? \u00b6 Airsonic is a free, web-based media streamer, providing ubiquitious access to your music. Use it to share your music with friends, or to listen to your own music while at work. You can stream to multiple players simultaneously, for instance to one player in your kitchen and another in your living room. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-airsonic 2. URL \u00b6 To access Airsonic, visit https://airsonic._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"airsonic"},{"location":"sandbox/apps/airsonic/#airsonic","text":"","title":"Airsonic"},{"location":"sandbox/apps/airsonic/#what-is-it","text":"Airsonic is a free, web-based media streamer, providing ubiquitious access to your music. Use it to share your music with friends, or to listen to your own music while at work. You can stream to multiple players simultaneously, for instance to one player in your kitchen and another in your living room. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/airsonic/#1-installation","text":"sb install sandbox-airsonic","title":"1. Installation"},{"location":"sandbox/apps/airsonic/#2-url","text":"To access Airsonic, visit https://airsonic._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/airsonic/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/alltube/","text":"AllTube \u00b6 What is it? \u00b6 AllTube is an HTML GUI for youtube-dl supporting a wide range of websites . Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-alltube 2. URL \u00b6 To access AllTube, visit https://alltube._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Alltube"},{"location":"sandbox/apps/alltube/#alltube","text":"","title":"AllTube"},{"location":"sandbox/apps/alltube/#what-is-it","text":"AllTube is an HTML GUI for youtube-dl supporting a wide range of websites . Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/alltube/#1-installation","text":"sb install sandbox-alltube","title":"1. Installation"},{"location":"sandbox/apps/alltube/#2-url","text":"To access AllTube, visit https://alltube._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/alltube/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/alternatrr/","text":"alternatrr \u00b6 What is it? \u00b6 alternatrr lets you add alternative titles to your sonarr instance by editing the sonarr.db file directly via a simple UI. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-alternatrr 2. URL \u00b6 To access alternatrr, visit https://alternatrr._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"alternatrr"},{"location":"sandbox/apps/alternatrr/#alternatrr","text":"","title":"alternatrr"},{"location":"sandbox/apps/alternatrr/#what-is-it","text":"alternatrr lets you add alternative titles to your sonarr instance by editing the sonarr.db file directly via a simple UI. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/alternatrr/#1-installation","text":"sb install sandbox-alternatrr","title":"1. Installation"},{"location":"sandbox/apps/alternatrr/#2-url","text":"To access alternatrr, visit https://alternatrr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/alternatrr/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/alternatrrx/","text":"alternatrr X \u00b6 What is it? \u00b6 alternatrr X is an arrX role for alternatrr . Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-alternatrrx 2. URL \u00b6 To access alternatrr X , visit https://alternatrrX._yourdomain.com_ 3. Setup \u00b6 Read through the general arr X role instructions . Add your X instance names to the alternatrr X section in sandbox settings.yml : using a list format as below. alternatrrx : roles : - 1080webdl - 1080remux For app specific instructions refer to the parent role, alternatrr and the upstream documentation Documentation","title":"alternatrrx"},{"location":"sandbox/apps/alternatrrx/#alternatrrx","text":"","title":"alternatrrX"},{"location":"sandbox/apps/alternatrrx/#what-is-it","text":"alternatrr X is an arrX role for alternatrr . Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/alternatrrx/#1-installation","text":"sb install sandbox-alternatrrx","title":"1. Installation"},{"location":"sandbox/apps/alternatrrx/#2-url","text":"To access alternatrr X , visit https://alternatrrX._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/alternatrrx/#3-setup","text":"Read through the general arr X role instructions . Add your X instance names to the alternatrr X section in sandbox settings.yml : using a list format as below. alternatrrx : roles : - 1080webdl - 1080remux For app specific instructions refer to the parent role, alternatrr and the upstream documentation Documentation","title":"3. Setup"},{"location":"sandbox/apps/apprise/","text":"Apprise \u00b6 What is it? \u00b6 Apprise allows you to send a notification to almost all of the most popular notification services available to us today such as: Telegram, Discord, Slack, Amazon SNS, Gotify, etc. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-apprise 2. Setup \u00b6 As configured, the instance runs on the Docker network accessible to other saltbox network containers at http://apprise:8000 as well as via the reverse proxy at https://apprise.domain.tld . The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation: Apprise Client Docs","title":"apprise"},{"location":"sandbox/apps/apprise/#apprise","text":"","title":"Apprise"},{"location":"sandbox/apps/apprise/#what-is-it","text":"Apprise allows you to send a notification to almost all of the most popular notification services available to us today such as: Telegram, Discord, Slack, Amazon SNS, Gotify, etc. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/apprise/#1-installation","text":"sb install sandbox-apprise","title":"1. Installation"},{"location":"sandbox/apps/apprise/#2-setup","text":"As configured, the instance runs on the Docker network accessible to other saltbox network containers at http://apprise:8000 as well as via the reverse proxy at https://apprise.domain.tld . The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation: Apprise Client Docs","title":"2. Setup"},{"location":"sandbox/apps/archivebox/","text":"ArchiveBox \u00b6 What is it? \u00b6 ArchiveBox is a powerful, self-hosted internet archiving solution to collect, save, and view sites you want to preserve offline. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-archivebox 2. URL \u00b6 To access ArchiveBox, visit https://archivebox._yourdomain.com_ 3. Setup \u00b6 Initial setup guide thanks to erisheaded on CB discord. Run tag: sb install sandbox-archivebox Connect to container: docker exec -it archivebox /bin/bash NOTE: (This drops you in the /data folder. DO NOT switch to /data/archive directory) Switch to archivebox user for config: su archivebox Initialize with setup to create a web admin: archivebox init -\u2014setup Enter username, email, and password Load URL and test login By default, your new installation has a publicly accessible web index, snapshots, and archive addition access. You may not want this for a host of security reasons, so it's recommended to review the ArchiveBox Security Overview and tailoring these settings to your preference when setting up.","title":"Archivebox"},{"location":"sandbox/apps/archivebox/#archivebox","text":"","title":"ArchiveBox"},{"location":"sandbox/apps/archivebox/#what-is-it","text":"ArchiveBox is a powerful, self-hosted internet archiving solution to collect, save, and view sites you want to preserve offline. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/archivebox/#1-installation","text":"sb install sandbox-archivebox","title":"1. Installation"},{"location":"sandbox/apps/archivebox/#2-url","text":"To access ArchiveBox, visit https://archivebox._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/archivebox/#3-setup","text":"Initial setup guide thanks to erisheaded on CB discord. Run tag: sb install sandbox-archivebox Connect to container: docker exec -it archivebox /bin/bash NOTE: (This drops you in the /data folder. DO NOT switch to /data/archive directory) Switch to archivebox user for config: su archivebox Initialize with setup to create a web admin: archivebox init -\u2014setup Enter username, email, and password Load URL and test login By default, your new installation has a publicly accessible web index, snapshots, and archive addition access. You may not want this for a host of security reasons, so it's recommended to review the ArchiveBox Security Overview and tailoring these settings to your preference when setting up.","title":"3. Setup"},{"location":"sandbox/apps/arrx/","text":"arr X \u00b6 Create multiple container instances \u00b6 Read through this entire page, even if you are only installing one of the apps. NOTE: This functionality is being moved to a more generalized and customizable multiple instances system. As roles are transitioned, they will be removed from the table below. Background \u00b6 There are a number of roles in the saltbox community repo which can be used to create multiple instances of an application. Some of these include: Role Description alternatarrx Alternate Name Management ombix Request management requestrrx Discord request bot rfloodx Torrent client transmissionx Torrent client They're all named something X because they allow creation of X number of something . They are all configured in the same way. In general terms, you'll enter the instances you want into the sandbox settings.yml : appnamex : roles : - \"\" - bing - bang - boing That will create: appname appnamebing appnamebang appnameboing as docker containers, subdomain, and data directories in /opt . For example, with this configuration: ombix : roles : - \"\" - bing - bang - boing Running the saltbox community sonarrx tag would produce: entry Container Config dir Subdomain Note \"\" ombi /opt/ombi ombi.YOURDOMAIN.TLD Replaces the stock container bing ombibing /opt/ombibing ombibing.YOURDOMAIN.TLD bang ombibang /opt/ombibang ombibang.YOURDOMAIN.TLD boing ombiboing /opt/ombiboing ombiboing.YOURDOMAIN.TLD NOTE: the names have to be compliant with both domain names and docker names, so no funny business. Do not use anything but a-z and 0-9, no spaces, no commas, no colons, no dash, no exclamation marks, no nothing! The names, within the constraints above, are completely arbitrary. There is nothing magic about the example configs [1080webdl, 1080remux] given below. They represent some common use cases, but you can use whatever names you wish, as in the \"bing, bang, boing\" examples above. You will need to configure these new containers just as you did the stock containers. One change; if applicable, be sure each one gets a unique download category , so that each instance imports only those downloads meant for it. Also, you probably want to put some thought into the directory and library structure you want to use. See \"Customizing Plex Libraries\" . Overwriting the stock container \u00b6 The example above shows a \"\" config entry. For those apps which are also found in the stock saltbox install, this will overwrite the existing container. Then, when you rerun the saltbox tag, this container will get overwritten by the stock one again. You probably don't want that. For one thing, these \"arrX\" roles may be based on different images than the stock images. You probably want to overwrite your existing role with this one; that will ensure that all your instances of Bazarr are based on the same image and get updated in the same way. It's up to you, though, how you want to manage them. If you want to use this to overwrite your existing Bazarr/etc container: \u00b6 Include a \"\" entry in the config: bazarrx : roles : - \"\" - bing - bang - boing Run the role as described below. bash sb install cm-bazarrx Add the stock tag to the [skip] section in \"/srv/git/saltbox/ansible.cfg\" : [tags] skip = bazarr,whatever,whatever That will ensure that the stock bazarr tag doesn't overwrite the container you are creating here. When you want to update Bazarr, you'll run the Saltbox Community bazarrx tag instead. The same thing holds for every arrX variant discussed here. If you DO NOT want to overwrite your existing Bazarr/etc container: \u00b6 Make sure there IS NOT a \"\" entry in the config: bazarrx : roles : - bing - bang - boing That's all. Your existing bazarr container will not be touched. Again, the same thing holds for every arrX variant discussed here. Examples: multiple Bazarr containers \u00b6 Edit settings.yml and change the bazarrx roles to what you want: I want to add a BING [4K, kids, German, whatever] version and leave my existing container untouched. bazarrx : roles : - BING I want to add BING and BANG versions and leave my existing container untouched. bazarrx : roles : - BING - BANG I want to replace my existing version and add BANG and BOING versions. bazarrx : roles : - \"\" - BANG - BOING **Refer to the notes above about overwriting the default container.** Run the bazarrx role as a normal saltbox community role. sb install cm-bazarrx Remember that all those names are arbitrary and purely cosmetic for your own use. There is nothing that ties readarr-romance.YOURDOMAIN.TLD to romance literature aside from the configuration that you are going to give it.","title":"ArrX"},{"location":"sandbox/apps/arrx/#arrx","text":"","title":"arrX"},{"location":"sandbox/apps/arrx/#create-multiple-container-instances","text":"Read through this entire page, even if you are only installing one of the apps. NOTE: This functionality is being moved to a more generalized and customizable multiple instances system. As roles are transitioned, they will be removed from the table below.","title":"Create multiple container instances"},{"location":"sandbox/apps/arrx/#background","text":"There are a number of roles in the saltbox community repo which can be used to create multiple instances of an application. Some of these include: Role Description alternatarrx Alternate Name Management ombix Request management requestrrx Discord request bot rfloodx Torrent client transmissionx Torrent client They're all named something X because they allow creation of X number of something . They are all configured in the same way. In general terms, you'll enter the instances you want into the sandbox settings.yml : appnamex : roles : - \"\" - bing - bang - boing That will create: appname appnamebing appnamebang appnameboing as docker containers, subdomain, and data directories in /opt . For example, with this configuration: ombix : roles : - \"\" - bing - bang - boing Running the saltbox community sonarrx tag would produce: entry Container Config dir Subdomain Note \"\" ombi /opt/ombi ombi.YOURDOMAIN.TLD Replaces the stock container bing ombibing /opt/ombibing ombibing.YOURDOMAIN.TLD bang ombibang /opt/ombibang ombibang.YOURDOMAIN.TLD boing ombiboing /opt/ombiboing ombiboing.YOURDOMAIN.TLD NOTE: the names have to be compliant with both domain names and docker names, so no funny business. Do not use anything but a-z and 0-9, no spaces, no commas, no colons, no dash, no exclamation marks, no nothing! The names, within the constraints above, are completely arbitrary. There is nothing magic about the example configs [1080webdl, 1080remux] given below. They represent some common use cases, but you can use whatever names you wish, as in the \"bing, bang, boing\" examples above. You will need to configure these new containers just as you did the stock containers. One change; if applicable, be sure each one gets a unique download category , so that each instance imports only those downloads meant for it. Also, you probably want to put some thought into the directory and library structure you want to use. See \"Customizing Plex Libraries\" .","title":"Background"},{"location":"sandbox/apps/arrx/#overwriting-the-stock-container","text":"The example above shows a \"\" config entry. For those apps which are also found in the stock saltbox install, this will overwrite the existing container. Then, when you rerun the saltbox tag, this container will get overwritten by the stock one again. You probably don't want that. For one thing, these \"arrX\" roles may be based on different images than the stock images. You probably want to overwrite your existing role with this one; that will ensure that all your instances of Bazarr are based on the same image and get updated in the same way. It's up to you, though, how you want to manage them.","title":"Overwriting the stock container"},{"location":"sandbox/apps/arrx/#if-you-want-to-use-this-to-overwrite-your-existing-bazarretc-container","text":"Include a \"\" entry in the config: bazarrx : roles : - \"\" - bing - bang - boing Run the role as described below. bash sb install cm-bazarrx Add the stock tag to the [skip] section in \"/srv/git/saltbox/ansible.cfg\" : [tags] skip = bazarr,whatever,whatever That will ensure that the stock bazarr tag doesn't overwrite the container you are creating here. When you want to update Bazarr, you'll run the Saltbox Community bazarrx tag instead. The same thing holds for every arrX variant discussed here.","title":"If you want to use this to overwrite your existing Bazarr/etc container:"},{"location":"sandbox/apps/arrx/#if-you-do-not-want-to-overwrite-your-existing-bazarretc-container","text":"Make sure there IS NOT a \"\" entry in the config: bazarrx : roles : - bing - bang - boing That's all. Your existing bazarr container will not be touched. Again, the same thing holds for every arrX variant discussed here.","title":"If you DO NOT want to overwrite your existing Bazarr/etc container:"},{"location":"sandbox/apps/arrx/#examples-multiple-bazarr-containers","text":"Edit settings.yml and change the bazarrx roles to what you want: I want to add a BING [4K, kids, German, whatever] version and leave my existing container untouched. bazarrx : roles : - BING I want to add BING and BANG versions and leave my existing container untouched. bazarrx : roles : - BING - BANG I want to replace my existing version and add BANG and BOING versions. bazarrx : roles : - \"\" - BANG - BOING **Refer to the notes above about overwriting the default container.** Run the bazarrx role as a normal saltbox community role. sb install cm-bazarrx Remember that all those names are arbitrary and purely cosmetic for your own use. There is nothing that ties readarr-romance.YOURDOMAIN.TLD to romance literature aside from the configuration that you are going to give it.","title":"Examples: multiple Bazarr containers"},{"location":"sandbox/apps/audiobookshelf/","text":"Audiobookshelf \u00b6 What is it? \u00b6 audiobookshelf is a self-hosted audio book and podcast server. Info By default, the role is NOT protected behind your Authelia/SSO middleware. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-audiobookshelf 2. URL \u00b6 To access Audiobookshelf, visit https://audiobookshelf._yourdomain.com_ Documentation: Audiobookshelf Docs","title":"audiobookshelf"},{"location":"sandbox/apps/audiobookshelf/#audiobookshelf","text":"","title":"Audiobookshelf"},{"location":"sandbox/apps/audiobookshelf/#what-is-it","text":"audiobookshelf is a self-hosted audio book and podcast server. Info By default, the role is NOT protected behind your Authelia/SSO middleware. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/audiobookshelf/#1-installation","text":"sb install sandbox-audiobookshelf","title":"1. Installation"},{"location":"sandbox/apps/audiobookshelf/#2-url","text":"To access Audiobookshelf, visit https://audiobookshelf._yourdomain.com_ Documentation: Audiobookshelf Docs","title":"2. URL"},{"location":"sandbox/apps/autobrr/","text":"Autobrr \u00b6 What is it? \u00b6 Autobrr is a modern single binary replacement for the autodl-irssi+rutorrent plugin. autobrr monitors IRC announce channels and torznab RSS feeds to get releases as soon as they are available, with good filtering, and regex support. Go brr. Note \ud83d\udce2 Work in progress. Expect bugs and breaking changes. Features may be broken or incomplete. Details Project home Docs Github 1. Installation \u00b6 sb install sandbox-autobrr 2. URL \u00b6 To access the Autobrr dashboard, visit https://autobrr._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Autobrr"},{"location":"sandbox/apps/autobrr/#autobrr","text":"","title":"Autobrr"},{"location":"sandbox/apps/autobrr/#what-is-it","text":"Autobrr is a modern single binary replacement for the autodl-irssi+rutorrent plugin. autobrr monitors IRC announce channels and torznab RSS feeds to get releases as soon as they are available, with good filtering, and regex support. Go brr. Note \ud83d\udce2 Work in progress. Expect bugs and breaking changes. Features may be broken or incomplete. Details Project home Docs Github","title":"What is it?"},{"location":"sandbox/apps/autobrr/#1-installation","text":"sb install sandbox-autobrr","title":"1. Installation"},{"location":"sandbox/apps/autobrr/#2-url","text":"To access the Autobrr dashboard, visit https://autobrr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/autobrr/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/beets/","text":"Beets \u00b6 What is it? \u00b6 Beets catalogs your collection, automatically improving its metadata as it goes using the MusicBrainz database. Then it provides a bouquet of tools for manipulating and accessing your music. Beets is a music library manager and not, for the most part, a music player. It does include a simple player plugin and an experimental Web-based player, but it generally leaves actual sound-reproduction to specialized tools. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-beets 2. URL \u00b6 To access Beets, visit https://beets._yourdomain.com_ 3. Setup \u00b6 The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml When the role is run, a cron job is set to automatically import any music found at /mnt/local/downloads/music every hour. If a match is under 95% beets will skip the file and it will need manual importing. To run a manual import (which will help correct any matches under 95%) run the following command: rm /opt/beets/state.pickle && docker exec -it beets /bin/bash -c 'beet import /downloads' If you want to change the folder structure you should do so in the config file located at /opt/beets/config.yaml This link details the allowed options If you already have imported music you will need to run an import using the following command: docker exec -it beets /bin/bash -c 'beet import /music' Documentation","title":"beets"},{"location":"sandbox/apps/beets/#beets","text":"","title":"Beets"},{"location":"sandbox/apps/beets/#what-is-it","text":"Beets catalogs your collection, automatically improving its metadata as it goes using the MusicBrainz database. Then it provides a bouquet of tools for manipulating and accessing your music. Beets is a music library manager and not, for the most part, a music player. It does include a simple player plugin and an experimental Web-based player, but it generally leaves actual sound-reproduction to specialized tools. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/beets/#1-installation","text":"sb install sandbox-beets","title":"1. Installation"},{"location":"sandbox/apps/beets/#2-url","text":"To access Beets, visit https://beets._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/beets/#3-setup","text":"The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml When the role is run, a cron job is set to automatically import any music found at /mnt/local/downloads/music every hour. If a match is under 95% beets will skip the file and it will need manual importing. To run a manual import (which will help correct any matches under 95%) run the following command: rm /opt/beets/state.pickle && docker exec -it beets /bin/bash -c 'beet import /downloads' If you want to change the folder structure you should do so in the config file located at /opt/beets/config.yaml This link details the allowed options If you already have imported music you will need to run an import using the following command: docker exec -it beets /bin/bash -c 'beet import /music' Documentation","title":"3. Setup"},{"location":"sandbox/apps/booksonic/","text":"Booksonic Air \u00b6 What is it? \u00b6 Booksonic Air is a platform for accessing the audibooks you own wherever you are. At the moment the platform consists of Booksonic Air - A server for streaming your audiobooks, successor to the original Booksonic server and based on Airsonic. Booksonic App - An DSub based Android app for connection to Booksonic-Air servers. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-booksonic 2. URL \u00b6 To access Booksonic Air, visit https://booksonic._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"booksonic"},{"location":"sandbox/apps/booksonic/#booksonic-air","text":"","title":"Booksonic Air"},{"location":"sandbox/apps/booksonic/#what-is-it","text":"Booksonic Air is a platform for accessing the audibooks you own wherever you are. At the moment the platform consists of Booksonic Air - A server for streaming your audiobooks, successor to the original Booksonic server and based on Airsonic. Booksonic App - An DSub based Android app for connection to Booksonic-Air servers. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/booksonic/#1-installation","text":"sb install sandbox-booksonic","title":"1. Installation"},{"location":"sandbox/apps/booksonic/#2-url","text":"To access Booksonic Air, visit https://booksonic._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/booksonic/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/bookstack/","text":"BookStack \u00b6 What is it? \u00b6 BookStack is a simple, self-hosted, easy-to-use platform for organising and storing information. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-bookstack 2. URL \u00b6 To access BookStack, visit https://bookstack._yourdomain.com_ 3. Setup \u00b6 Log in using the default admin details admin@admin.com with a password of password . You should change these details immediately after logging in for the first time. Documentation","title":"bookstack"},{"location":"sandbox/apps/bookstack/#bookstack","text":"","title":"BookStack"},{"location":"sandbox/apps/bookstack/#what-is-it","text":"BookStack is a simple, self-hosted, easy-to-use platform for organising and storing information. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/bookstack/#1-installation","text":"sb install sandbox-bookstack","title":"1. Installation"},{"location":"sandbox/apps/bookstack/#2-url","text":"To access BookStack, visit https://bookstack._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/bookstack/#3-setup","text":"Log in using the default admin details admin@admin.com with a password of password . You should change these details immediately after logging in for the first time. Documentation","title":"3. Setup"},{"location":"sandbox/apps/calibre/","text":"Calibre \u00b6 What is it? \u00b6 Calibre is a powerful and easy to use e-book manager. Users say it\u2019s outstanding and a must-have. It\u2019ll allow you to do nearly everything and it takes things a step beyond normal e-book software. It\u2019s also completely free and open source and great for both casual users and computer experts. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-calibre 2. URL \u00b6 To access Calibre, visit https://calibre._yourdomain.com_ 3. Setup \u00b6 The username is abc . The configured password is taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Calibre is ready for use. If you added your pre-existing Calibre library to /mnt/local/Media/Books then you should see your library is ready to go. If not, then you have a blank library ready for you to fill. Info Running Calibre on a headless server is not very fun. If at all possible, run Calibre on your local, home computer. Use rclone to sync the files from home to google drive, and then another sync from google drive to your server so that Calibre-Web can use it. A local database file is required. This means you cannot run either Calibre or Calibre-Web from a mounted teamdrive, and this is the biggest pain for many of us. The easiest solution is to simply have your database and book files all located in /mnt/local/Media/Books. Both Calibre and Calibre-Web expect to find your library in /mnt/unionfs/Media/Books . Note that per standard Saltbox setup, /mnt/local is included inside /mnt/unionfs . However, both dockers also include access to anything in your /mnt directory. 4. Handy commands for managing your calibre docker: \u00b6 You can access advanced features of the Guacamole remote desktop using ctrl+alt+shift enabling you to use remote copy/paste and different languages. Shell access whilst the container is running: docker exec -it calibre /bin/bash To monitor the logs of the container in realtime: docker logs -f calibre Container version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' calibre Image version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' linuxserver/calibre Documentation","title":"calibre"},{"location":"sandbox/apps/calibre/#calibre","text":"","title":"Calibre"},{"location":"sandbox/apps/calibre/#what-is-it","text":"Calibre is a powerful and easy to use e-book manager. Users say it\u2019s outstanding and a must-have. It\u2019ll allow you to do nearly everything and it takes things a step beyond normal e-book software. It\u2019s also completely free and open source and great for both casual users and computer experts. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/calibre/#1-installation","text":"sb install sandbox-calibre","title":"1. Installation"},{"location":"sandbox/apps/calibre/#2-url","text":"To access Calibre, visit https://calibre._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/calibre/#3-setup","text":"The username is abc . The configured password is taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Calibre is ready for use. If you added your pre-existing Calibre library to /mnt/local/Media/Books then you should see your library is ready to go. If not, then you have a blank library ready for you to fill. Info Running Calibre on a headless server is not very fun. If at all possible, run Calibre on your local, home computer. Use rclone to sync the files from home to google drive, and then another sync from google drive to your server so that Calibre-Web can use it. A local database file is required. This means you cannot run either Calibre or Calibre-Web from a mounted teamdrive, and this is the biggest pain for many of us. The easiest solution is to simply have your database and book files all located in /mnt/local/Media/Books. Both Calibre and Calibre-Web expect to find your library in /mnt/unionfs/Media/Books . Note that per standard Saltbox setup, /mnt/local is included inside /mnt/unionfs . However, both dockers also include access to anything in your /mnt directory.","title":"3. Setup"},{"location":"sandbox/apps/calibre/#4-handy-commands-for-managing-your-calibre-docker","text":"You can access advanced features of the Guacamole remote desktop using ctrl+alt+shift enabling you to use remote copy/paste and different languages. Shell access whilst the container is running: docker exec -it calibre /bin/bash To monitor the logs of the container in realtime: docker logs -f calibre Container version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' calibre Image version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' linuxserver/calibre Documentation","title":"4. Handy commands for managing your calibre docker:"},{"location":"sandbox/apps/calibre_web/","text":"Calibre-Web \u00b6 What is it? \u00b6 Calibre-Web is a web app providing a clean interface for browsing, reading and downloading eBooks using an existing Calibre database. Calibre-Web allows you to add users, and each user can set up a Kindle email address to have ebooks automatically sent to their Kindle reader or Kindle app. Users can also simply download epub, pdf, or whatever files you have. Requires an existing Calibre library database. Info Calibre and Calibre-web do NOT need to be on the same server. But you do need to have a local copy of the Calibre metadata.db and a path to the books for calibre-web to operate. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-calibre-web 2. URL \u00b6 To access Calibre-Web, visit https://calibre-web._yourdomain.com_ 3. Setup \u00b6 Default admin login: Username : admin Password : admin123 Change the default log in details immediately. Unrar is included by default and needs to be set in the Calibre-Web admin page (Basic Configuration:External Binaries) with a path of /usr/bin/unrar . Automatic ebook conversion via Calibre converter is included. Enable it in the Calibre-Web admin page (Basic Configuration:External Binaries) by setting the Path to Calibre E-Book Converter to /usr/bin/ebook-convert . The kepubify ebook conversion tool (MIT License) to convert epub to kepub is included. In the Calibre-Web admin page (Basic Configuration:External Binaries) set the Path to Kepubify E-Book Converter to /usr/bin/kepubify . Book cover thumbnails will improve browsing speed but they aren't generated by default. Enable them on the Calibre-Web admin page by either schedule a task (Edit Scheduled Task Settings) or running it manually (Refresh Thumbnail Cover Cache). Useful docker commands Shell access whilst the container is running: docker exec -it calibre-web /bin/bash To monitor the logs of the container in realtime: docker logs -f calibre-web Container version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' calibre-web Image version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' linuxserver/calibre-web 4. SK's Calibre-Web Usage Tips \u00b6 SMTP Email Server Setup \u00b6 A useful function of Calibre-Web is sending ebooks by email. Therefore, you need to set up SMTP e-mail server settings. I am using Google to host the email for mydomain.com. In my case, after trial and error, I found it most reliable to go into my Google control panel, go to the SMTP settings, and whitelist my server\u2019s IP address without authentication. Now, I can send email from any Saltbox app that supports it (Ombi, Tautelli, Organizr, and Calibre-Web) with no troubles. Hostname: smtp-relay.gmail.com, Port: 25, SSL: No Kindle Setup \u00b6 There is a nice benefit to using a Kindle. When you send a \u201cpersonal document\u201d (book) to your Kindle account, it will automatically download to the specific device tied to the email address you use. Even though it\u2019s called a document, it goes into your regular library and looks just like any book you may have purchased, including the cover. In addition, that book is available on any other device or app tied to your account, so you can read the same book on your phone, a Kindle Paperwhite, and an iPad. Amazon\u2019s WhisperSync feature will bookmark your most recent page in the background, so if you switch devices it will ask if you want to update to the most recent page read. If you (or your users) want to have books sent directly to a Kindle from Calibre-Web email, then there are additional one-time setup steps for each user. Tell Amazon to accept books sent from your website Go to www.amazon.com On the top navigation bar, go to Account & Lists . In the dropdown, click on Your Content and Devices . Towards the top of the white section, in the middle, click on Preferences Scroll down to Personal Document Settings. Click the title to open up that section of the page. Under Approved Personal Document E-mail List , click the link for \"Add a new approved e-mail address\" In the popup, add @yourdomain.com and save. Done! Before closing the website, you might want to grab your device email address for the next step. Under the Send-to-Kindle E-Mail Settings, copy the email address where you want the books sent by default. Add your Kindle email address to your profile on books.yourdomain.com Once logged in, on the top ride side, click your name to open your profile Add your kindle email address and save Your Kindle email address will be something like name_79@kindle.com. Every Kindle device and mobile app has its own unique address, however, you can send to any of your devices and it will still be available on all of them. You can find this email address either in the Settings of the device/app, or copy it from the Devices page Info Kindle has started sending verification emails on every document sent if your Kindle's email is the one they generated for you. While you are on your settings page, go ahead and make up a new Kindle email address. Enjoy! 5. Advanced Method of Library Storage \u00b6 Since only the metadata.db file has to be local, you can keep the metadata.db file in /mnt/local/Media/Books as RW and the actual book files in teamdrive:Books as RO and mergerfs them together. Use the latest rclone --vfs-cache-mode=full and related cloud-seeding settings for your teamdrive mount so that it does not get laggy. Have a script that copies the metadata.db file regularly to the local disk, and leave the books in the cloud. If this paragraph does not make sense to you, then please do not try it.","title":"calibre_web"},{"location":"sandbox/apps/calibre_web/#calibre-web","text":"","title":"Calibre-Web"},{"location":"sandbox/apps/calibre_web/#what-is-it","text":"Calibre-Web is a web app providing a clean interface for browsing, reading and downloading eBooks using an existing Calibre database. Calibre-Web allows you to add users, and each user can set up a Kindle email address to have ebooks automatically sent to their Kindle reader or Kindle app. Users can also simply download epub, pdf, or whatever files you have. Requires an existing Calibre library database. Info Calibre and Calibre-web do NOT need to be on the same server. But you do need to have a local copy of the Calibre metadata.db and a path to the books for calibre-web to operate. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/calibre_web/#1-installation","text":"sb install sandbox-calibre-web","title":"1. Installation"},{"location":"sandbox/apps/calibre_web/#2-url","text":"To access Calibre-Web, visit https://calibre-web._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/calibre_web/#3-setup","text":"Default admin login: Username : admin Password : admin123 Change the default log in details immediately. Unrar is included by default and needs to be set in the Calibre-Web admin page (Basic Configuration:External Binaries) with a path of /usr/bin/unrar . Automatic ebook conversion via Calibre converter is included. Enable it in the Calibre-Web admin page (Basic Configuration:External Binaries) by setting the Path to Calibre E-Book Converter to /usr/bin/ebook-convert . The kepubify ebook conversion tool (MIT License) to convert epub to kepub is included. In the Calibre-Web admin page (Basic Configuration:External Binaries) set the Path to Kepubify E-Book Converter to /usr/bin/kepubify . Book cover thumbnails will improve browsing speed but they aren't generated by default. Enable them on the Calibre-Web admin page by either schedule a task (Edit Scheduled Task Settings) or running it manually (Refresh Thumbnail Cover Cache). Useful docker commands Shell access whilst the container is running: docker exec -it calibre-web /bin/bash To monitor the logs of the container in realtime: docker logs -f calibre-web Container version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' calibre-web Image version number: docker inspect -f '{{ index .Config.Labels \"build_version\" }}' linuxserver/calibre-web","title":"3. Setup"},{"location":"sandbox/apps/calibre_web/#4-sks-calibre-web-usage-tips","text":"","title":"4. SK's Calibre-Web Usage Tips"},{"location":"sandbox/apps/calibre_web/#smtp-email-server-setup","text":"A useful function of Calibre-Web is sending ebooks by email. Therefore, you need to set up SMTP e-mail server settings. I am using Google to host the email for mydomain.com. In my case, after trial and error, I found it most reliable to go into my Google control panel, go to the SMTP settings, and whitelist my server\u2019s IP address without authentication. Now, I can send email from any Saltbox app that supports it (Ombi, Tautelli, Organizr, and Calibre-Web) with no troubles. Hostname: smtp-relay.gmail.com, Port: 25, SSL: No","title":"SMTP Email Server Setup"},{"location":"sandbox/apps/calibre_web/#kindle-setup","text":"There is a nice benefit to using a Kindle. When you send a \u201cpersonal document\u201d (book) to your Kindle account, it will automatically download to the specific device tied to the email address you use. Even though it\u2019s called a document, it goes into your regular library and looks just like any book you may have purchased, including the cover. In addition, that book is available on any other device or app tied to your account, so you can read the same book on your phone, a Kindle Paperwhite, and an iPad. Amazon\u2019s WhisperSync feature will bookmark your most recent page in the background, so if you switch devices it will ask if you want to update to the most recent page read. If you (or your users) want to have books sent directly to a Kindle from Calibre-Web email, then there are additional one-time setup steps for each user. Tell Amazon to accept books sent from your website Go to www.amazon.com On the top navigation bar, go to Account & Lists . In the dropdown, click on Your Content and Devices . Towards the top of the white section, in the middle, click on Preferences Scroll down to Personal Document Settings. Click the title to open up that section of the page. Under Approved Personal Document E-mail List , click the link for \"Add a new approved e-mail address\" In the popup, add @yourdomain.com and save. Done! Before closing the website, you might want to grab your device email address for the next step. Under the Send-to-Kindle E-Mail Settings, copy the email address where you want the books sent by default. Add your Kindle email address to your profile on books.yourdomain.com Once logged in, on the top ride side, click your name to open your profile Add your kindle email address and save Your Kindle email address will be something like name_79@kindle.com. Every Kindle device and mobile app has its own unique address, however, you can send to any of your devices and it will still be available on all of them. You can find this email address either in the Settings of the device/app, or copy it from the Devices page Info Kindle has started sending verification emails on every document sent if your Kindle's email is the one they generated for you. While you are on your settings page, go ahead and make up a new Kindle email address. Enjoy!","title":"Kindle Setup"},{"location":"sandbox/apps/calibre_web/#5-advanced-method-of-library-storage","text":"Since only the metadata.db file has to be local, you can keep the metadata.db file in /mnt/local/Media/Books as RW and the actual book files in teamdrive:Books as RO and mergerfs them together. Use the latest rclone --vfs-cache-mode=full and related cloud-seeding settings for your teamdrive mount so that it does not get laggy. Have a script that copies the metadata.db file regularly to the local disk, and leave the books in the cloud. If this paragraph does not make sense to you, then please do not try it.","title":"5. Advanced Method of Library Storage"},{"location":"sandbox/apps/changedetection/","text":"changedetection \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 changedetection is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-changedetection 2. URL \u00b6 To access changedetection, visit https://changedetection._yourdomain.com_ 3. Usage \u00b6 Instructions for changedetection","title":"changedetection"},{"location":"sandbox/apps/changedetection/#changedetection","text":"","title":"changedetection"},{"location":"sandbox/apps/changedetection/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/changedetection/#what-is-it","text":"changedetection is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/changedetection/#1-installation","text":"sb install sandbox-changedetection","title":"1. Installation"},{"location":"sandbox/apps/changedetection/#2-url","text":"To access changedetection, visit https://changedetection._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/changedetection/#3-usage","text":"Instructions for changedetection","title":"3. Usage"},{"location":"sandbox/apps/cherry/","text":"Cherry \u00b6 What is it? \u00b6 Cherry is a bookmark service that is open source. The code of Cherry service and the browser extension are all available on GitHub. It's self-hostable. Your data in in your own hands. Using SQLite, management and backup is a breeze. It has a simple UI. But you got all the features you want for a bookmark service. Tags, groups, full text search and browser extensions. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github 1. Installation \u00b6 sb install sandbox-cherry 2. URL \u00b6 To access Cherry, visit https://cherry._yourdomain.com_ 3. Setup \u00b6 Default login: Username : \"your user from accounts.yml\" Password : your_normal_password Note To create an additional user, use Cherry cli: docker exec cherry cherry create-user <email> <password> Documentation: Cherry Docs","title":"Cherry"},{"location":"sandbox/apps/cherry/#cherry","text":"","title":"Cherry"},{"location":"sandbox/apps/cherry/#what-is-it","text":"Cherry is a bookmark service that is open source. The code of Cherry service and the browser extension are all available on GitHub. It's self-hostable. Your data in in your own hands. Using SQLite, management and backup is a breeze. It has a simple UI. But you got all the features you want for a bookmark service. Tags, groups, full text search and browser extensions. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github","title":"What is it?"},{"location":"sandbox/apps/cherry/#1-installation","text":"sb install sandbox-cherry","title":"1. Installation"},{"location":"sandbox/apps/cherry/#2-url","text":"To access Cherry, visit https://cherry._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/cherry/#3-setup","text":"Default login: Username : \"your user from accounts.yml\" Password : your_normal_password Note To create an additional user, use Cherry cli: docker exec cherry cherry create-user <email> <password> Documentation: Cherry Docs","title":"3. Setup"},{"location":"sandbox/apps/coder/","text":"code-server \u00b6 What is it? \u00b6 code-server . Run VS Code on any machine anywhere and access it in the browser. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-coder 2. URL \u00b6 To access code-server, visit https://coder._yourdomain.com_ 3. Setup \u00b6 VS Code Documentation","title":"Coder"},{"location":"sandbox/apps/coder/#code-server","text":"","title":"code-server"},{"location":"sandbox/apps/coder/#what-is-it","text":"code-server . Run VS Code on any machine anywhere and access it in the browser. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/coder/#1-installation","text":"sb install sandbox-coder","title":"1. Installation"},{"location":"sandbox/apps/coder/#2-url","text":"To access code-server, visit https://coder._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/coder/#3-setup","text":"VS Code Documentation","title":"3. Setup"},{"location":"sandbox/apps/comicstreamer/","text":"ComicStreamer \u00b6 What is it? \u00b6 ComicStreamer is a media server app for sharing a library of comic files with client applications. It allows for searching for comics based on a rich set of metadata including fields like series name, title, publisher, story arcs, characters, and creator credits. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-comicstreamer 2. URL \u00b6 To access ComicStreamer, visit https://comicstreamer._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"comicstreamer"},{"location":"sandbox/apps/comicstreamer/#comicstreamer","text":"","title":"ComicStreamer"},{"location":"sandbox/apps/comicstreamer/#what-is-it","text":"ComicStreamer is a media server app for sharing a library of comic files with client applications. It allows for searching for comics based on a rich set of metadata including fields like series name, title, publisher, story arcs, characters, and creator credits. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/comicstreamer/#1-installation","text":"sb install sandbox-comicstreamer","title":"1. Installation"},{"location":"sandbox/apps/comicstreamer/#2-url","text":"To access ComicStreamer, visit https://comicstreamer._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/comicstreamer/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/comixed/","text":"ComiXed \u00b6 What is it? \u00b6 ComiXed is anapplication for managing digital comics. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-comixed 2. URL \u00b6 To access ComiXed, visit https://comixed._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"comixed"},{"location":"sandbox/apps/comixed/#comixed","text":"","title":"ComiXed"},{"location":"sandbox/apps/comixed/#what-is-it","text":"ComiXed is anapplication for managing digital comics. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/comixed/#1-installation","text":"sb install sandbox-comixed","title":"1. Installation"},{"location":"sandbox/apps/comixed/#2-url","text":"To access ComiXed, visit https://comixed._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/comixed/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/deemix/","text":"deemix \u00b6 What is it? \u00b6 deemix is a barebone deezer downloader library built from the ashes of Deezloader Remix. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-deemix 2. URL \u00b6 To access deemix, visit https://deemix._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"deemix"},{"location":"sandbox/apps/deemix/#deemix","text":"","title":"deemix"},{"location":"sandbox/apps/deemix/#what-is-it","text":"deemix is a barebone deezer downloader library built from the ashes of Deezloader Remix. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/deemix/#1-installation","text":"sb install sandbox-deemix","title":"1. Installation"},{"location":"sandbox/apps/deemix/#2-url","text":"To access deemix, visit https://deemix._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/deemix/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/delugevpn/","text":"DelugeVPN \u00b6 What is it? \u00b6 DelugeVPN is a VPN version of Deluge with OpenVPN to ensure a secure and private connection to the Internet, including use of iptables to prevent IP leakage when the tunnel is down. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-delugevpn 2. URL \u00b6 To access DelugeVPN, visit https://delugevpn._yourdomain.com_ 3. Setup \u00b6 See the parent Deluge role for app setup. Edit the DelugeVPN settings in the delugevpn section in saltbox settings.yml : as shown below. delugevpn : vpn_endpoint : netherlands.ovpn vpn_pass : your_vpn_password vpn_prov : pia vpn_user : your_vpn_username vpn_client : wireguard # 'wireguard' or 'openvpn' For Private Internet Access Add your user name and password Change the vpn_endpoint to your chosen server. Note that PIA occasionally changes which servers have port forwarding. The Netherlands server no longer offers port forwarding. See configuration section for more details. For other VPN providers Add your user name and password Change vpn_prov to custom Leave vpn_endpoint as netherlands.ovpn Follow step 2 below then immediately follow step 3 Run the DelugeVPN Role \u00b6 sb install sandbox-delugevpn Configuring Server for Custom VPN providers (only for non-pia)** \u00b6 Why you need to do this For custom VPN providers, delugevpn needs an ovpn file to complete the install properly. It can check for a custom file in the /opt/delugevpn/openvpn folder, but this folder does not yet exist. Therefore, we will first use PIA's netherlands.ovpn file, which we will modify later to have our own VPN provider details. The steps above have created some files in /opt/delugevpn/openvpn . ca.rsa.2048.crt - Leave this crl.rsa.2048.pem - Leave this credentials.conf - Leave this. Your VPN username and password are stored here. netherlands.ovpn - Your server details are stored here. We will change this. docker stop delugevpn cd /opt/delugevpn/openvpn rm netherlands.ovpn Now you can upload your own .ovpn file from your VPN provider, renamed as netherlands.ovpn . If your VPN provider has also included a ca.crt file, upload that file as well. Upload one or both files into /opt/delugevpn/openvpn . Note \u00b6 Do not rename the original netherlands.ovpn file if you're using Filezilla. delugevpn will automatically use the renamed file instead of netherlands.ovpn and your newly uploaded .ovpn file will still be ignored. Now you can restart the docker docker start delugevpn Configuration \u00b6 FOR PIA vpn_user: Your PIA user name vpn_pass: Your PIA password vpn_prov: pia vpn_endpoint: netherlands.ovpn Included PIA OpenVPN end point options are. Endpoint Endpoint Endpoint Endpoint albania.ovpn egypt.ovpn monaco.ovpn uk_london.ovp algeria.ovpn finland.ovpn mongolia.ovpn uk_manchester.ovpn andorra.ovpn france.ovpn montenegro.ovpn uk_southampton.ovpn argentina.ovpn georgia.ovpn morocco.ovpn ukraine.ovpn armenia.ovpn greece.ovpn netherlands.ovpn united_arab_emirates.ovpn au_melbourne.ovpn greenland.ovpn new_zealand.ovpn us_atlanta.ovpn au_perth.ovpn hong_kong.ovpn nigeria.ovpn us_california.ovpn au_sydney.ovpn hungary.ovpn norway.ovpn us_chicago.ovpn austria.ovpn iceland.ovpn panama.ovpn us_denver.ovpn bahamas.ovpn india.ovpn philippines.ovpn us_east.ovpn bangladesh.ovpn ireland.ovpn poland.ovpn us_florida.ovpn belgium.ovpn isle_of_man.ovpn portugal.ovpn us_houston.ovpn brazil.ovpn israel.ovpn qatar.ovpn us_las_vegas.ovpn bulgaria.ovpn italy.ovpn romania.ovpn us_new_york.ovpn ca_montreal.ovpn japan.ovpn saudi_arabia.ovpn us_seattle.ovpn ca_ontario.ovpn kazakhstan.ovpn serbia.ovpn us_silicon_valley.ovpn ca_toronto.ovpn latvia.ovpn singapore.ovpn us_texas.ovpn ca_vancouver.ovpn liechtenstein.ovpn slovakia.ovpn us_washington_dc.ovpn cambodia.ovpn lithuania.ovpn south_africa.ovpn us_west.ovpn china.ovpn luxembourg.ovpn spain.ovpn venezuela.ovpn cyprus.ovpn macao.ovpn sri_lanka.ovpn vietnam.ovpn czech_republic.ovpn macedonia.ovpn sweden.ovpn de_berlin.ovpn malta.ovpn switzerland.ovpn de_frankfurt.ovpn mexico.ovpn taiwan.ovpn denmark.ovpn moldova.ovpn turkey.ovpn As of July 4, 2020, the PIA servers that allow port forwarding, and DelugeVPN to work properly, are: CA Toronto, CA Montreal, CA Vancouver, Czech Republic, DE Berlin, DE Frankfurt, France, Israel, Romania, Spain, Switzerland, Sweden. Check the PIA website for changes if these servers do not work. Tips \u00b6 If you run into issues check settings.yml modified during pre install setup. If your endpoint has spaces you can use single quotes in the settings.yml ex.) vpn_endpoint: 'CA Toronto.ovpn' After checking/fixing settings.yml execute sudo rm -rf /opt/delugevpn WARNING: this will delete all files and folder in /opt/delugevpn, backup first if you need anything) Follow installation steps above again For app specific instructions refer to the parent role \u00b6 Deluge and the upstream documentation Documentation","title":"Delugevpn"},{"location":"sandbox/apps/delugevpn/#delugevpn","text":"","title":"DelugeVPN"},{"location":"sandbox/apps/delugevpn/#what-is-it","text":"DelugeVPN is a VPN version of Deluge with OpenVPN to ensure a secure and private connection to the Internet, including use of iptables to prevent IP leakage when the tunnel is down. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/delugevpn/#1-installation","text":"sb install sandbox-delugevpn","title":"1. Installation"},{"location":"sandbox/apps/delugevpn/#2-url","text":"To access DelugeVPN, visit https://delugevpn._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/delugevpn/#3-setup","text":"See the parent Deluge role for app setup. Edit the DelugeVPN settings in the delugevpn section in saltbox settings.yml : as shown below. delugevpn : vpn_endpoint : netherlands.ovpn vpn_pass : your_vpn_password vpn_prov : pia vpn_user : your_vpn_username vpn_client : wireguard # 'wireguard' or 'openvpn' For Private Internet Access Add your user name and password Change the vpn_endpoint to your chosen server. Note that PIA occasionally changes which servers have port forwarding. The Netherlands server no longer offers port forwarding. See configuration section for more details. For other VPN providers Add your user name and password Change vpn_prov to custom Leave vpn_endpoint as netherlands.ovpn Follow step 2 below then immediately follow step 3","title":"3. Setup"},{"location":"sandbox/apps/delugevpn/#run-the-delugevpn-role","text":"sb install sandbox-delugevpn","title":"Run the DelugeVPN Role"},{"location":"sandbox/apps/delugevpn/#configuring-server-for-custom-vpn-providers-only-for-non-pia","text":"Why you need to do this For custom VPN providers, delugevpn needs an ovpn file to complete the install properly. It can check for a custom file in the /opt/delugevpn/openvpn folder, but this folder does not yet exist. Therefore, we will first use PIA's netherlands.ovpn file, which we will modify later to have our own VPN provider details. The steps above have created some files in /opt/delugevpn/openvpn . ca.rsa.2048.crt - Leave this crl.rsa.2048.pem - Leave this credentials.conf - Leave this. Your VPN username and password are stored here. netherlands.ovpn - Your server details are stored here. We will change this. docker stop delugevpn cd /opt/delugevpn/openvpn rm netherlands.ovpn Now you can upload your own .ovpn file from your VPN provider, renamed as netherlands.ovpn . If your VPN provider has also included a ca.crt file, upload that file as well. Upload one or both files into /opt/delugevpn/openvpn .","title":"Configuring Server for Custom VPN providers (only for non-pia)**"},{"location":"sandbox/apps/delugevpn/#note","text":"Do not rename the original netherlands.ovpn file if you're using Filezilla. delugevpn will automatically use the renamed file instead of netherlands.ovpn and your newly uploaded .ovpn file will still be ignored. Now you can restart the docker docker start delugevpn","title":"Note"},{"location":"sandbox/apps/delugevpn/#configuration","text":"FOR PIA vpn_user: Your PIA user name vpn_pass: Your PIA password vpn_prov: pia vpn_endpoint: netherlands.ovpn Included PIA OpenVPN end point options are. Endpoint Endpoint Endpoint Endpoint albania.ovpn egypt.ovpn monaco.ovpn uk_london.ovp algeria.ovpn finland.ovpn mongolia.ovpn uk_manchester.ovpn andorra.ovpn france.ovpn montenegro.ovpn uk_southampton.ovpn argentina.ovpn georgia.ovpn morocco.ovpn ukraine.ovpn armenia.ovpn greece.ovpn netherlands.ovpn united_arab_emirates.ovpn au_melbourne.ovpn greenland.ovpn new_zealand.ovpn us_atlanta.ovpn au_perth.ovpn hong_kong.ovpn nigeria.ovpn us_california.ovpn au_sydney.ovpn hungary.ovpn norway.ovpn us_chicago.ovpn austria.ovpn iceland.ovpn panama.ovpn us_denver.ovpn bahamas.ovpn india.ovpn philippines.ovpn us_east.ovpn bangladesh.ovpn ireland.ovpn poland.ovpn us_florida.ovpn belgium.ovpn isle_of_man.ovpn portugal.ovpn us_houston.ovpn brazil.ovpn israel.ovpn qatar.ovpn us_las_vegas.ovpn bulgaria.ovpn italy.ovpn romania.ovpn us_new_york.ovpn ca_montreal.ovpn japan.ovpn saudi_arabia.ovpn us_seattle.ovpn ca_ontario.ovpn kazakhstan.ovpn serbia.ovpn us_silicon_valley.ovpn ca_toronto.ovpn latvia.ovpn singapore.ovpn us_texas.ovpn ca_vancouver.ovpn liechtenstein.ovpn slovakia.ovpn us_washington_dc.ovpn cambodia.ovpn lithuania.ovpn south_africa.ovpn us_west.ovpn china.ovpn luxembourg.ovpn spain.ovpn venezuela.ovpn cyprus.ovpn macao.ovpn sri_lanka.ovpn vietnam.ovpn czech_republic.ovpn macedonia.ovpn sweden.ovpn de_berlin.ovpn malta.ovpn switzerland.ovpn de_frankfurt.ovpn mexico.ovpn taiwan.ovpn denmark.ovpn moldova.ovpn turkey.ovpn As of July 4, 2020, the PIA servers that allow port forwarding, and DelugeVPN to work properly, are: CA Toronto, CA Montreal, CA Vancouver, Czech Republic, DE Berlin, DE Frankfurt, France, Israel, Romania, Spain, Switzerland, Sweden. Check the PIA website for changes if these servers do not work.","title":"Configuration"},{"location":"sandbox/apps/delugevpn/#tips","text":"If you run into issues check settings.yml modified during pre install setup. If your endpoint has spaces you can use single quotes in the settings.yml ex.) vpn_endpoint: 'CA Toronto.ovpn' After checking/fixing settings.yml execute sudo rm -rf /opt/delugevpn WARNING: this will delete all files and folder in /opt/delugevpn, backup first if you need anything) Follow installation steps above again","title":"Tips"},{"location":"sandbox/apps/delugevpn/#for-app-specific-instructions-refer-to-the-parent-role","text":"Deluge and the upstream documentation Documentation","title":"For app specific instructions refer to the parent role"},{"location":"sandbox/apps/doplarr/","text":"Doplarr \u00b6 What is it? \u00b6 Doplarr is a chatbot used to simplify using services like Sonarr/Radarr/Overseer via the use of chat. Current platform is Discord only. Details Project home Docs Github Docker Setup Doplarr \u00b6 1. Create Discord bot \u00b6 Create a new Application in Discord Go to the Bot tab and add a new bot Copy out the token and paste it in /opt/sandbox/settings.yaml in the doplarr.discord_token field. Go to OAuth2 and under \"OAuth2 URL Generator\", enable applications.commands and bot Copy the resulting URL and open it in your browser in order to invite your bot to your discord channel. 2. Set up overseer parameters \u00b6 In /opt/sandbox/settings.yaml : set up the overseer url in the corresponding field doplarr.overseerr_url according to your setings. If you have not customize saltbox settings, the default url http://overseerr:5055 should be correct. In /opt/sandbox/settings.yaml : set up the overseer API key in the corresponding field doplarr.overseerr_api according to your overseer settings. You can get your api keys in your main setting page in overseer: https://overseerr._yourdomain.com_/settings 3. Installation \u00b6 sb install sandbox-doplarr Note \ud83d\udce2 You may also override the default setting of Doplarr working with overseer, to work with Sonarr and Radarr. Additional informations here Documentation . The recommended way to customize these parameters is to use the inventory : You should edit /srv/git/saltbox/inventories/host_vars/localhost.yml and add the following section: yaml ### Custom settings for Doplarr ### doplarr_docker_envs_defaults: SONARR__URL: \"http://sonarr:8989\" RADARR__URL: \"http://radarr:7878\" SONARR__API: sonarr_api RADARR__API: radarr_api DISCORD__TOKEN: your_discord_bot_token","title":"Doplarr"},{"location":"sandbox/apps/doplarr/#doplarr","text":"","title":"Doplarr"},{"location":"sandbox/apps/doplarr/#what-is-it","text":"Doplarr is a chatbot used to simplify using services like Sonarr/Radarr/Overseer via the use of chat. Current platform is Discord only. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/doplarr/#setup-doplarr","text":"","title":"Setup Doplarr"},{"location":"sandbox/apps/doplarr/#1-create-discord-bot","text":"Create a new Application in Discord Go to the Bot tab and add a new bot Copy out the token and paste it in /opt/sandbox/settings.yaml in the doplarr.discord_token field. Go to OAuth2 and under \"OAuth2 URL Generator\", enable applications.commands and bot Copy the resulting URL and open it in your browser in order to invite your bot to your discord channel.","title":"1. Create Discord bot"},{"location":"sandbox/apps/doplarr/#2-set-up-overseer-parameters","text":"In /opt/sandbox/settings.yaml : set up the overseer url in the corresponding field doplarr.overseerr_url according to your setings. If you have not customize saltbox settings, the default url http://overseerr:5055 should be correct. In /opt/sandbox/settings.yaml : set up the overseer API key in the corresponding field doplarr.overseerr_api according to your overseer settings. You can get your api keys in your main setting page in overseer: https://overseerr._yourdomain.com_/settings","title":"2. Set up overseer parameters"},{"location":"sandbox/apps/doplarr/#3-installation","text":"sb install sandbox-doplarr Note \ud83d\udce2 You may also override the default setting of Doplarr working with overseer, to work with Sonarr and Radarr. Additional informations here Documentation . The recommended way to customize these parameters is to use the inventory : You should edit /srv/git/saltbox/inventories/host_vars/localhost.yml and add the following section: yaml ### Custom settings for Doplarr ### doplarr_docker_envs_defaults: SONARR__URL: \"http://sonarr:8989\" RADARR__URL: \"http://radarr:7878\" SONARR__API: sonarr_api RADARR__API: radarr_api DISCORD__TOKEN: your_discord_bot_token","title":"3. Installation"},{"location":"sandbox/apps/dozzle/","text":"Dozzle \u00b6 What is it? \u00b6 Dozzle is a small lightweight application with a web based interface to monitor Docker logs. It doesn\u2019t store any log files. It is for live monitoring of your container logs only. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-dozzle 2. URL \u00b6 To access Dozzle, visit https://dozzle._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Dozzle"},{"location":"sandbox/apps/dozzle/#dozzle","text":"","title":"Dozzle"},{"location":"sandbox/apps/dozzle/#what-is-it","text":"Dozzle is a small lightweight application with a web based interface to monitor Docker logs. It doesn\u2019t store any log files. It is for live monitoring of your container logs only. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/dozzle/#1-installation","text":"sb install sandbox-dozzle","title":"1. Installation"},{"location":"sandbox/apps/dozzle/#2-url","text":"To access Dozzle, visit https://dozzle._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/dozzle/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/duplicati/","text":"duplicati \u00b6 What is it? \u00b6 duplicati is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-duplicati 2. URL \u00b6 To access duplicati, visit https://duplicati._yourdomain.com_ 3. Usage \u00b6 Consult the doc","title":"Duplicati"},{"location":"sandbox/apps/duplicati/#duplicati","text":"","title":"duplicati"},{"location":"sandbox/apps/duplicati/#what-is-it","text":"duplicati is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/duplicati/#1-installation","text":"sb install sandbox-duplicati","title":"1. Installation"},{"location":"sandbox/apps/duplicati/#2-url","text":"To access duplicati, visit https://duplicati._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/duplicati/#3-usage","text":"Consult the doc","title":"3. Usage"},{"location":"sandbox/apps/embystat/","text":"EmbyStat \u00b6 What is it? \u00b6 EmbyStat is a personal web server that can calculate all kinds of statistics from your (local) Emby or Jellyfin server. Just install this on your server and let him calculate all kinds of fun stuff. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-embystat 2. URL \u00b6 To access EmbyStat, visit https://embystat._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"embystat"},{"location":"sandbox/apps/embystat/#embystat","text":"","title":"EmbyStat"},{"location":"sandbox/apps/embystat/#what-is-it","text":"EmbyStat is a personal web server that can calculate all kinds of statistics from your (local) Emby or Jellyfin server. Just install this on your server and let him calculate all kinds of fun stuff. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/embystat/#1-installation","text":"sb install sandbox-embystat","title":"1. Installation"},{"location":"sandbox/apps/embystat/#2-url","text":"To access EmbyStat, visit https://embystat._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/embystat/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/epms/","text":"Extended Personal Media Shows Agent and Scanner \u00b6 What is it? \u00b6 EPMS is very useful for sports or things that do not have a DB to scrape against, creates episode numbers for date-based media and sorts correctly in Plex interface. The Extended Personal Media Shows Agent is a Metadata Agent for personal media files. It works in conjunction with the Extended Personal Media Scanner to scan personal media shows. The meta data agent sets the summary details on the episode. The agent expects the files to follow the naming conventions for personal media that are outlined in the Plex documentation. This scanner is not meant to be full replacement of the Plex Media Scanner. Requests for functionality will be considered but may be limited by what Plex currently allows in the TV Show sections. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-epms 2. Setup \u00b6 Documentation","title":"Extended Personal Media Scanner"},{"location":"sandbox/apps/epms/#extended-personal-media-shows-agent-and-scanner","text":"","title":"Extended Personal Media Shows Agent and Scanner"},{"location":"sandbox/apps/epms/#what-is-it","text":"EPMS is very useful for sports or things that do not have a DB to scrape against, creates episode numbers for date-based media and sorts correctly in Plex interface. The Extended Personal Media Shows Agent is a Metadata Agent for personal media files. It works in conjunction with the Extended Personal Media Scanner to scan personal media shows. The meta data agent sets the summary details on the episode. The agent expects the files to follow the naming conventions for personal media that are outlined in the Plex documentation. This scanner is not meant to be full replacement of the Plex Media Scanner. Requests for functionality will be considered but may be limited by what Plex currently allows in the TV Show sections. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/epms/#1-installation","text":"sb install sandbox-epms","title":"1. Installation"},{"location":"sandbox/apps/epms/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"sandbox/apps/filebot/","text":"FileBot \u00b6 What is it? \u00b6 FileBot is the ultimate tool for organizing and renaming your movies, tv shows or anime, and music well as downloading subtitles and artwork. It's smart and just works. This is a Docker container for FileBot. The GUI of the application is accessed through a modern web browser (no installation or configuration needed on the client side) or via any VNC client. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-filebot 2. URL \u00b6 To access FileBot, visit https://filebot._yourdomain.com_ 3. Setup \u00b6 The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"Filebot"},{"location":"sandbox/apps/filebot/#filebot","text":"","title":"FileBot"},{"location":"sandbox/apps/filebot/#what-is-it","text":"FileBot is the ultimate tool for organizing and renaming your movies, tv shows or anime, and music well as downloading subtitles and artwork. It's smart and just works. This is a Docker container for FileBot. The GUI of the application is accessed through a modern web browser (no installation or configuration needed on the client side) or via any VNC client. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/filebot/#1-installation","text":"sb install sandbox-filebot","title":"1. Installation"},{"location":"sandbox/apps/filebot/#2-url","text":"To access FileBot, visit https://filebot._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/filebot/#3-setup","text":"The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"3. Setup"},{"location":"sandbox/apps/filebrowser/","text":"File Browser \u00b6 What is it? \u00b6 File Browser is is a create-your-own-cloud-kind of software where you can install it on a server, direct it to a path and then access your files through a nice web interface. You have many available features! Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-filebrowser 2. URL \u00b6 To access File Browser, visit https://filebrowser._yourdomain.com_ Info default login { .yaml } user: admin password: admin Change the default user and password immediately. 3. Setup \u00b6 Documentation","title":"Filebrowser"},{"location":"sandbox/apps/filebrowser/#file-browser","text":"","title":"File Browser"},{"location":"sandbox/apps/filebrowser/#what-is-it","text":"File Browser is is a create-your-own-cloud-kind of software where you can install it on a server, direct it to a path and then access your files through a nice web interface. You have many available features! Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/filebrowser/#1-installation","text":"sb install sandbox-filebrowser","title":"1. Installation"},{"location":"sandbox/apps/filebrowser/#2-url","text":"To access File Browser, visit https://filebrowser._yourdomain.com_ Info default login { .yaml } user: admin password: admin Change the default user and password immediately.","title":"2. URL"},{"location":"sandbox/apps/filebrowser/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/filezilla/","text":"FileZilla \u00b6 What is it? \u00b6 FileZilla is a cross-platform graphical FTP, SFTP, and FTPS file management tool with a vast list of features. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-filezilla 2. URL \u00b6 To access FileZilla, visit https://filezilla._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Filezilla"},{"location":"sandbox/apps/filezilla/#filezilla","text":"","title":"FileZilla"},{"location":"sandbox/apps/filezilla/#what-is-it","text":"FileZilla is a cross-platform graphical FTP, SFTP, and FTPS file management tool with a vast list of features. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/filezilla/#1-installation","text":"sb install sandbox-filezilla","title":"1. Installation"},{"location":"sandbox/apps/filezilla/#2-url","text":"To access FileZilla, visit https://filezilla._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/filezilla/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/flaresolverr/","text":"FlareSolverr \u00b6 What is it? \u00b6 FlareSolverr is a proxy server to bypass Cloudflare protection. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-flaresolverr 2. Setup \u00b6 Jackett \u00b6 Locate the FlareSolverr API URL field in the main page. Input http://flaresolverr:8191 and apply the settings. Prowlarr \u00b6 In the settings, add an Indexer Proxy and select FlareSolverr. Host should be http://flaresolverr:8191 . Documentation","title":"flaresolverr"},{"location":"sandbox/apps/flaresolverr/#flaresolverr","text":"","title":"FlareSolverr"},{"location":"sandbox/apps/flaresolverr/#what-is-it","text":"FlareSolverr is a proxy server to bypass Cloudflare protection. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/flaresolverr/#1-installation","text":"sb install sandbox-flaresolverr","title":"1. Installation"},{"location":"sandbox/apps/flaresolverr/#2-setup","text":"","title":"2. Setup"},{"location":"sandbox/apps/flaresolverr/#jackett","text":"Locate the FlareSolverr API URL field in the main page. Input http://flaresolverr:8191 and apply the settings.","title":"Jackett"},{"location":"sandbox/apps/flaresolverr/#prowlarr","text":"In the settings, add an Indexer Proxy and select FlareSolverr. Host should be http://flaresolverr:8191 . Documentation","title":"Prowlarr"},{"location":"sandbox/apps/freshrss/","text":"freshrss \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 freshrss is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-freshrss 2. URL \u00b6 To access freshrss, visit https://freshrss._yourdomain.com_ 3. Usage \u00b6 Instructions for freshrss","title":"freshrss"},{"location":"sandbox/apps/freshrss/#freshrss","text":"","title":"freshrss"},{"location":"sandbox/apps/freshrss/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/freshrss/#what-is-it","text":"freshrss is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/freshrss/#1-installation","text":"sb install sandbox-freshrss","title":"1. Installation"},{"location":"sandbox/apps/freshrss/#2-url","text":"To access freshrss, visit https://freshrss._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/freshrss/#3-usage","text":"Instructions for freshrss","title":"3. Usage"},{"location":"sandbox/apps/funkwhale/","text":"Funkwhale \u00b6 What is it? \u00b6 Funkwhale is a modern, self-hosted, free and open-source music server. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-funkwhale 2. URL \u00b6 To access Funkwhale, visit https://funkwhale._yourdomain.com_ 3. Setup \u00b6 First create the superuser docker exec -it funkwhale manage createsuperuser (for ease of access, set it as your Saltbox user and password.) enter the exit command when finished to return to your server's shell. Now configure these settings via the web GUI Access Funkwhale, visit https://funkwhale._yourdomain.com_ and log in with the user and password you just created. Enter Music->Add Content->Create a new Library and fill out the information. Enter your new Library and Details. There will be a sharing link such as: https://funkwhale.domain.com/federation/music/libraries/da8bd97b-3c3f-4e7b-92cb-6ba45721837b Copy out the last portion: da8bd97b-3c3f-4e7b-92cb-6ba45721837b Return to the shell session to import music library docker exec -it funkwhale /usr/bin/python3 /app/api/manage.py import_files da8bd97b-3c3f-4e7b-92cb-6ba45721837b \"/music/Media/Audio/Music/**/**/*.flac\" --in-place --async --recursive The above line explained: docker exec -it funkwhale /usr/bin/python3 /app/api/manage.py import_files tells funkwhale to import music. da8bd97b-3c3f-4e7b-92cb-6ba45721837b is your library id \"/music/Media/Audio/Music/**/**/*.flac\" is the path to your media. --in-place means do not copy the media into Funkwhale and leave it where it is. --async means it will import the music first and then pull the metadata` --recursive will recursively scan the folders If everything goes as planned you'll get prompted like this: > Checking imported paths against settings.MUSIC_DIRECTORY_PATH > Import summary: > - 149828 files found matching this pattern: [ '/music/Media/Audio/Music/**/**/*.flac' ] > - 0 files already found in database > - 149828 new files > Selected options: in place > Are you sure you want to do this? > Type 'yes' to continue , or 'no' to cancel: Answer yes at the prompt and the import will begin. Info Useful URLs Libraries URL: https://funkwhale.domain.com/content/libraries/ Admin Account Edit Page: https://funkwhale.domain.com/api/admin/users/user/1/change/ Info If you want to use subsonic clients then you'll need to set a password here: https://funkwhale.domain.com/settings (subsonic protocol requires storing password in cleartext, so to avoid compromising your Funkwhale account, we use a different password). Additional Information: Documentation","title":"funkwhale"},{"location":"sandbox/apps/funkwhale/#funkwhale","text":"","title":"Funkwhale"},{"location":"sandbox/apps/funkwhale/#what-is-it","text":"Funkwhale is a modern, self-hosted, free and open-source music server. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/funkwhale/#1-installation","text":"sb install sandbox-funkwhale","title":"1. Installation"},{"location":"sandbox/apps/funkwhale/#2-url","text":"To access Funkwhale, visit https://funkwhale._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/funkwhale/#3-setup","text":"First create the superuser docker exec -it funkwhale manage createsuperuser (for ease of access, set it as your Saltbox user and password.) enter the exit command when finished to return to your server's shell. Now configure these settings via the web GUI Access Funkwhale, visit https://funkwhale._yourdomain.com_ and log in with the user and password you just created. Enter Music->Add Content->Create a new Library and fill out the information. Enter your new Library and Details. There will be a sharing link such as: https://funkwhale.domain.com/federation/music/libraries/da8bd97b-3c3f-4e7b-92cb-6ba45721837b Copy out the last portion: da8bd97b-3c3f-4e7b-92cb-6ba45721837b Return to the shell session to import music library docker exec -it funkwhale /usr/bin/python3 /app/api/manage.py import_files da8bd97b-3c3f-4e7b-92cb-6ba45721837b \"/music/Media/Audio/Music/**/**/*.flac\" --in-place --async --recursive The above line explained: docker exec -it funkwhale /usr/bin/python3 /app/api/manage.py import_files tells funkwhale to import music. da8bd97b-3c3f-4e7b-92cb-6ba45721837b is your library id \"/music/Media/Audio/Music/**/**/*.flac\" is the path to your media. --in-place means do not copy the media into Funkwhale and leave it where it is. --async means it will import the music first and then pull the metadata` --recursive will recursively scan the folders If everything goes as planned you'll get prompted like this: > Checking imported paths against settings.MUSIC_DIRECTORY_PATH > Import summary: > - 149828 files found matching this pattern: [ '/music/Media/Audio/Music/**/**/*.flac' ] > - 0 files already found in database > - 149828 new files > Selected options: in place > Are you sure you want to do this? > Type 'yes' to continue , or 'no' to cancel: Answer yes at the prompt and the import will begin. Info Useful URLs Libraries URL: https://funkwhale.domain.com/content/libraries/ Admin Account Edit Page: https://funkwhale.domain.com/api/admin/users/user/1/change/ Info If you want to use subsonic clients then you'll need to set a password here: https://funkwhale.domain.com/settings (subsonic protocol requires storing password in cleartext, so to avoid compromising your Funkwhale account, we use a different password). Additional Information: Documentation","title":"3. Setup"},{"location":"sandbox/apps/gaps/","text":"Gaps \u00b6 What is it? \u00b6 Gaps searches through your Plex Server for all movies, then queries for known movies in the same collection. If those movies don't exist in your library, Gaps will recommend getting those movies, legally of course. Info By default, the role is protected behind your Authelia/SSO middleware. You will NOT have to log into the app itself, as basic Auth is disabled by default. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-gaps 2. URL \u00b6 To access gaps, visit https://gaps._yourdomain.com_ 3. Setup \u00b6 All you need to get started is a Plex Auth Token , and a TMDB api key. Documentation: gaps Docs","title":"Gaps"},{"location":"sandbox/apps/gaps/#gaps","text":"","title":"Gaps"},{"location":"sandbox/apps/gaps/#what-is-it","text":"Gaps searches through your Plex Server for all movies, then queries for known movies in the same collection. If those movies don't exist in your library, Gaps will recommend getting those movies, legally of course. Info By default, the role is protected behind your Authelia/SSO middleware. You will NOT have to log into the app itself, as basic Auth is disabled by default. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/gaps/#1-installation","text":"sb install sandbox-gaps","title":"1. Installation"},{"location":"sandbox/apps/gaps/#2-url","text":"To access gaps, visit https://gaps._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/gaps/#3-setup","text":"All you need to get started is a Plex Auth Token , and a TMDB api key. Documentation: gaps Docs","title":"3. Setup"},{"location":"sandbox/apps/gitea/","text":"Gitea \u00b6 What is it? \u00b6 Gitea is a community managed lightweight code hosting solution written in Go. Gitea is a painless self-hosted Git service. It is similar to GitHub, Bitbucket, and GitLab. Gitea is a fork of Gogs. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-gitea 2. URL \u00b6 To access Gitea, visit https://gitea._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Gitea"},{"location":"sandbox/apps/gitea/#gitea","text":"","title":"Gitea"},{"location":"sandbox/apps/gitea/#what-is-it","text":"Gitea is a community managed lightweight code hosting solution written in Go. Gitea is a painless self-hosted Git service. It is similar to GitHub, Bitbucket, and GitLab. Gitea is a fork of Gogs. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/gitea/#1-installation","text":"sb install sandbox-gitea","title":"1. Installation"},{"location":"sandbox/apps/gitea/#2-url","text":"To access Gitea, visit https://gitea._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/gitea/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/glances_web/","text":"Glances \u00b6 What is it? \u00b6 Glances is a cross-platform monitoring tool which aims to present a large amount of monitoring information through a curses or Web based interface. The information dynamically adapts depending on the size of the user interface. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-glances-web 2. URL \u00b6 To access Glances, visit https://glances._yourdomain.com_ 3. Setup \u00b6 The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"glances_web"},{"location":"sandbox/apps/glances_web/#glances","text":"","title":"Glances"},{"location":"sandbox/apps/glances_web/#what-is-it","text":"Glances is a cross-platform monitoring tool which aims to present a large amount of monitoring information through a curses or Web based interface. The information dynamically adapts depending on the size of the user interface. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/glances_web/#1-installation","text":"sb install sandbox-glances-web","title":"1. Installation"},{"location":"sandbox/apps/glances_web/#2-url","text":"To access Glances, visit https://glances._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/glances_web/#3-setup","text":"The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"3. Setup"},{"location":"sandbox/apps/goaccess/","text":"GoAccess \u00b6 What is it? \u00b6 GoAccess is an open source real-time web log analyzer and interactive viewer that runs in a terminal in *nix systems or through your browser. It provides fast and valuable HTTP statistics for system administrators that require a visual server report on the fly. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-goaccess 2. URL \u00b6 To access GoAccess, visit https://goaccess._yourdomain.com_ 3. Setup \u00b6 The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"GoAccess"},{"location":"sandbox/apps/goaccess/#goaccess","text":"","title":"GoAccess"},{"location":"sandbox/apps/goaccess/#what-is-it","text":"GoAccess is an open source real-time web log analyzer and interactive viewer that runs in a terminal in *nix systems or through your browser. It provides fast and valuable HTTP statistics for system administrators that require a visual server report on the fly. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/goaccess/#1-installation","text":"sb install sandbox-goaccess","title":"1. Installation"},{"location":"sandbox/apps/goaccess/#2-url","text":"To access GoAccess, visit https://goaccess._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/goaccess/#3-setup","text":"The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"3. Setup"},{"location":"sandbox/apps/goplaxt/","text":"Goplaxt \u00b6 What is it? \u00b6 Goplaxt scrobbles Plex plays to Trakt with ease! Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-goplaxt 2. URL \u00b6 To access Goplaxt, visit https://goplaxt._yourdomain.com_ 3. Setup \u00b6 Create an API application through Trakt here . The Redirect URI should be your goplaxt.domain + /authorize , so it reads as: https://goplaxt.domain.com/authorize . Edit the Goplaxt section in saltbox settings.yml : substituting your own ID and secret . goplaxt : trakt_id : IDHERE trakt_secret : SECRETHERE Run the role install command sb install sandbox-goplaxt Visit the goplaxt site at https://goplaxt.domain.com . Enter your Plex Username then Authorize , and add the Webhook in Plex Settings . Make sure under your server Settings > Network that Webhooks is enabled . Documentation","title":"goplaxt"},{"location":"sandbox/apps/goplaxt/#goplaxt","text":"","title":"Goplaxt"},{"location":"sandbox/apps/goplaxt/#what-is-it","text":"Goplaxt scrobbles Plex plays to Trakt with ease! Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/goplaxt/#1-installation","text":"sb install sandbox-goplaxt","title":"1. Installation"},{"location":"sandbox/apps/goplaxt/#2-url","text":"To access Goplaxt, visit https://goplaxt._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/goplaxt/#3-setup","text":"Create an API application through Trakt here . The Redirect URI should be your goplaxt.domain + /authorize , so it reads as: https://goplaxt.domain.com/authorize . Edit the Goplaxt section in saltbox settings.yml : substituting your own ID and secret . goplaxt : trakt_id : IDHERE trakt_secret : SECRETHERE Run the role install command sb install sandbox-goplaxt Visit the goplaxt site at https://goplaxt.domain.com . Enter your Plex Username then Authorize , and add the Webhook in Plex Settings . Make sure under your server Settings > Network that Webhooks is enabled . Documentation","title":"3. Setup"},{"location":"sandbox/apps/gotenberg/","text":"gotenberg \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 gotenberg is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-gotenberg 2. URL \u00b6 To access gotenberg, visit https://gotenberg._yourdomain.com_ 3. Usage \u00b6 Instructions for gotenberg","title":"gotenberg"},{"location":"sandbox/apps/gotenberg/#gotenberg","text":"","title":"gotenberg"},{"location":"sandbox/apps/gotenberg/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/gotenberg/#what-is-it","text":"gotenberg is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/gotenberg/#1-installation","text":"sb install sandbox-gotenberg","title":"1. Installation"},{"location":"sandbox/apps/gotenberg/#2-url","text":"To access gotenberg, visit https://gotenberg._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/gotenberg/#3-usage","text":"Instructions for gotenberg","title":"3. Usage"},{"location":"sandbox/apps/gotify/","text":"Gotify \u00b6 What is it? \u00b6 Gotify a simple server for sending and receiving messages. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-gotify 2. URL \u00b6 To access Gotify, visit https://gotify._yourdomain.com_ 3. Setup \u00b6 The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation Info Android App https://github.com/gotify/android https://f-droid.org/de/packages/com.github.gotify/","title":"gotify"},{"location":"sandbox/apps/gotify/#gotify","text":"","title":"Gotify"},{"location":"sandbox/apps/gotify/#what-is-it","text":"Gotify a simple server for sending and receiving messages. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/gotify/#1-installation","text":"sb install sandbox-gotify","title":"1. Installation"},{"location":"sandbox/apps/gotify/#2-url","text":"To access Gotify, visit https://gotify._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/gotify/#3-setup","text":"The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation Info Android App https://github.com/gotify/android https://f-droid.org/de/packages/com.github.gotify/","title":"3. Setup"},{"location":"sandbox/apps/grafana/","text":"Grafana \u00b6 What is it? \u00b6 Grafana allows you to query, visualize, alert on, and understand your data no matter where it\u2019s stored. With Grafana you can create, explore and share all of your data through beautiful, flexible dashboards. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-grafana 2. URL \u00b6 To access Grafana, visit https://grafana._yourdomain.com_ 3. Setup \u00b6 The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"Grafana"},{"location":"sandbox/apps/grafana/#grafana","text":"","title":"Grafana"},{"location":"sandbox/apps/grafana/#what-is-it","text":"Grafana allows you to query, visualize, alert on, and understand your data no matter where it\u2019s stored. With Grafana you can create, explore and share all of your data through beautiful, flexible dashboards. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/grafana/#1-installation","text":"sb install sandbox-grafana","title":"1. Installation"},{"location":"sandbox/apps/grafana/#2-url","text":"To access Grafana, visit https://grafana._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/grafana/#3-setup","text":"The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"3. Setup"},{"location":"sandbox/apps/guacamole/","text":"Guacamole \u00b6 What is it? \u00b6 Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH. We call it clientless because no plugins or client software are required. Thanks to HTML5, once Guacamole is installed on a server, all you need to access your desktops is a web browser. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-guacamole 2. URL \u00b6 To access Guacamole, visit https://guacamole._yourdomain.com_ 3. Setup \u00b6 Log in with user and password guacadmin . Change the default user and password immediately. Documentation","title":"guacamole"},{"location":"sandbox/apps/guacamole/#guacamole","text":"","title":"Guacamole"},{"location":"sandbox/apps/guacamole/#what-is-it","text":"Guacamole is a clientless remote desktop gateway. It supports standard protocols like VNC, RDP, and SSH. We call it clientless because no plugins or client software are required. Thanks to HTML5, once Guacamole is installed on a server, all you need to access your desktops is a web browser. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/guacamole/#1-installation","text":"sb install sandbox-guacamole","title":"1. Installation"},{"location":"sandbox/apps/guacamole/#2-url","text":"To access Guacamole, visit https://guacamole._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/guacamole/#3-setup","text":"Log in with user and password guacadmin . Change the default user and password immediately. Documentation","title":"3. Setup"},{"location":"sandbox/apps/handbrake/","text":"HandBrake \u00b6 What is it? \u00b6 HandBrake is a tool for converting video from nearly any format to a selection of modern, widely supported codecs. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-handbrake 2. URL \u00b6 To access HandBrake, visit https://handbrake._yourdomain.com_ 3. Setup \u00b6 Edit the HandBrake section in saltbox settings.yml : and enter your desired password. Please note that it MUST be less than eight characters. handbrake : handbrake_pass : saltbox Run the role install command sb install sandbox-handbrake Access HandBrake https://handbrake._yourdomain.com_ See the HandBrake documentation for usage: Documentation Tip This container has an automatic video converter built in, see the container documentation here .","title":"handbrake"},{"location":"sandbox/apps/handbrake/#handbrake","text":"","title":"HandBrake"},{"location":"sandbox/apps/handbrake/#what-is-it","text":"HandBrake is a tool for converting video from nearly any format to a selection of modern, widely supported codecs. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/handbrake/#1-installation","text":"sb install sandbox-handbrake","title":"1. Installation"},{"location":"sandbox/apps/handbrake/#2-url","text":"To access HandBrake, visit https://handbrake._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/handbrake/#3-setup","text":"Edit the HandBrake section in saltbox settings.yml : and enter your desired password. Please note that it MUST be less than eight characters. handbrake : handbrake_pass : saltbox Run the role install command sb install sandbox-handbrake Access HandBrake https://handbrake._yourdomain.com_ See the HandBrake documentation for usage: Documentation Tip This container has an automatic video converter built in, see the container documentation here .","title":"3. Setup"},{"location":"sandbox/apps/healthchecks/","text":"Healthchecks \u00b6 What is it? \u00b6 Healthchecks is a watchdog for your cron jobs. It's a web server that listens for pings from your cron jobs, plus a web interface. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-healthchecks 2. URL \u00b6 To access Healthchecks, visit https://healthchecks._yourdomain.com_ 3. Setup \u00b6 The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"Healthchecks"},{"location":"sandbox/apps/healthchecks/#healthchecks","text":"","title":"Healthchecks"},{"location":"sandbox/apps/healthchecks/#what-is-it","text":"Healthchecks is a watchdog for your cron jobs. It's a web server that listens for pings from your cron jobs, plus a web interface. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/healthchecks/#1-installation","text":"sb install sandbox-healthchecks","title":"1. Installation"},{"location":"sandbox/apps/healthchecks/#2-url","text":"To access Healthchecks, visit https://healthchecks._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/healthchecks/#3-setup","text":"The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"3. Setup"},{"location":"sandbox/apps/heimdall/","text":"Heimdall \u00b6 What is it? \u00b6 Heimdall is a way to organise all those links to your most used web sites and web applications in a simple way. Simplicity is the key to Heimdall. Why not use it as your browser start page? It even has the ability to include a search bar using either Google, Bing or DuckDuckGo. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-heimdall 2. URL \u00b6 To access Heimdall, visit https://heimdall._yourdomain.com_ 3. Setup \u00b6 The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"heimdall"},{"location":"sandbox/apps/heimdall/#heimdall","text":"","title":"Heimdall"},{"location":"sandbox/apps/heimdall/#what-is-it","text":"Heimdall is a way to organise all those links to your most used web sites and web applications in a simple way. Simplicity is the key to Heimdall. Why not use it as your browser start page? It even has the ability to include a search bar using either Google, Bing or DuckDuckGo. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/heimdall/#1-installation","text":"sb install sandbox-heimdall","title":"1. Installation"},{"location":"sandbox/apps/heimdall/#2-url","text":"To access Heimdall, visit https://heimdall._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/heimdall/#3-setup","text":"The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"3. Setup"},{"location":"sandbox/apps/homarr/","text":"Homarr \u00b6 What is it? \u00b6 Homarr is a simple and modern homepage for your server that helps you access all of your services in one place. It integrates with the services you use to display useful information or control them. It's easy to install and supports many different devices. Integrates with services you use. Search the web directly from your homepage. Search overseerr directly from your homepage. Real-time status indicator for every service. Automatically finds icons while you type the name of a service. Widgets that can display all types of information. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker Recommended install types: Saltbox, Core 1. Installation \u00b6 sb install sandbox-homarr 2. URL \u00b6 To access homarr, visit https://homarr._yourdomain.com_ 3. Setup \u00b6 Default login: Password : your_normal_password Documentation: Homarr Docs","title":"Homarr"},{"location":"sandbox/apps/homarr/#homarr","text":"","title":"Homarr"},{"location":"sandbox/apps/homarr/#what-is-it","text":"Homarr is a simple and modern homepage for your server that helps you access all of your services in one place. It integrates with the services you use to display useful information or control them. It's easy to install and supports many different devices. Integrates with services you use. Search the web directly from your homepage. Search overseerr directly from your homepage. Real-time status indicator for every service. Automatically finds icons while you type the name of a service. Widgets that can display all types of information. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker Recommended install types: Saltbox, Core","title":"What is it?"},{"location":"sandbox/apps/homarr/#1-installation","text":"sb install sandbox-homarr","title":"1. Installation"},{"location":"sandbox/apps/homarr/#2-url","text":"To access homarr, visit https://homarr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/homarr/#3-setup","text":"Default login: Password : your_normal_password Documentation: Homarr Docs","title":"3. Setup"},{"location":"sandbox/apps/homebox/","text":"Homebox \u00b6 What is it? \u00b6 Homebox is the inventory and organization system built for the Home User! With a focus on simplicity and ease of use, Homebox is the perfect solution for your home inventory, organization, and management needs. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github 1. Installation \u00b6 sb install sandbox-homebox 2. URL \u00b6 To access Homebox, visit https://homebox._yourdomain.com_ 3. Setup \u00b6 Create a user in the web ui, add your email and password, then log in. Documentation: Homebox Docs","title":"Homebox"},{"location":"sandbox/apps/homebox/#homebox","text":"","title":"Homebox"},{"location":"sandbox/apps/homebox/#what-is-it","text":"Homebox is the inventory and organization system built for the Home User! With a focus on simplicity and ease of use, Homebox is the perfect solution for your home inventory, organization, and management needs. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github","title":"What is it?"},{"location":"sandbox/apps/homebox/#1-installation","text":"sb install sandbox-homebox","title":"1. Installation"},{"location":"sandbox/apps/homebox/#2-url","text":"To access Homebox, visit https://homebox._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/homebox/#3-setup","text":"Create a user in the web ui, add your email and password, then log in. Documentation: Homebox Docs","title":"3. Setup"},{"location":"sandbox/apps/influxdb/","text":"InfluxDB \u00b6 What is it? \u00b6 InfluxDB is an open source time series database for recording metrics, events, and analytics. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-influxdb 2. Setup \u00b6 Documentation","title":"Influxdb"},{"location":"sandbox/apps/influxdb/#influxdb","text":"","title":"InfluxDB"},{"location":"sandbox/apps/influxdb/#what-is-it","text":"InfluxDB is an open source time series database for recording metrics, events, and analytics. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/influxdb/#1-installation","text":"sb install sandbox-influxdb","title":"1. Installation"},{"location":"sandbox/apps/influxdb/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"sandbox/apps/invoiceninja/","text":"Invoice Ninja v5 \u00b6 What is it? \u00b6 InvoiceNinja is a self-hosted accounting system with ability to Quote & Invoice Clients, Time Billable-Tasks, Track Expenses, Get Paid. Details Project home Docs Github Docker 1. Installation \u00b6 Ideally you should set a unique app key in settings.yml. Generate the key using: docker run --rm -it invoiceninja/invoiceninja php artisan key:generate --show insert this in the invoiceninja.app_key setting in /opt/sandbox/settings.yml sb install sandbox-invoiceninja 2. URL \u00b6 To access Invoice Ninja, visit https://invoiceninja._yourdomain.com_ 3. Log in \u00b6 Enter email, and password from accounts.yml setting. Documentation","title":"Invoice Ninja"},{"location":"sandbox/apps/invoiceninja/#invoice-ninja-v5","text":"","title":"Invoice Ninja v5"},{"location":"sandbox/apps/invoiceninja/#what-is-it","text":"InvoiceNinja is a self-hosted accounting system with ability to Quote & Invoice Clients, Time Billable-Tasks, Track Expenses, Get Paid. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/invoiceninja/#1-installation","text":"Ideally you should set a unique app key in settings.yml. Generate the key using: docker run --rm -it invoiceninja/invoiceninja php artisan key:generate --show insert this in the invoiceninja.app_key setting in /opt/sandbox/settings.yml sb install sandbox-invoiceninja","title":"1. Installation"},{"location":"sandbox/apps/invoiceninja/#2-url","text":"To access Invoice Ninja, visit https://invoiceninja._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/invoiceninja/#3-log-in","text":"Enter email, and password from accounts.yml setting. Documentation","title":"3. Log in"},{"location":"sandbox/apps/jdownloader2/","text":"JDownloader \u00b6 What is it? \u00b6 JDownloader is a free download-manager that makes downloading as easy, fast and automated as it should be. It's like your personal internet robot that does all the work for you. He will download whole photo albums, playlists or just about anything else with just one click. Go ahead and try it! Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-jdownloader2 2. URL \u00b6 To access JDownloader, visit https://jdownloader2._yourdomain.com_ 3. Setup \u00b6 The configured password is taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Configure your myjdownloader account (Create at https://my.jdownloader.org/ if needed) and name your instance so you can connect via web or browser extensions. Use clipboard for two step copy and paste if needed. Note that some settings are only accessible via jdownloader2.yourdomain.com . Premium accounts such as mega.nz can be added via web interface. Use manual import from sonarr / radarr and navigate to /mnt/local/downloads/myjdownloader/output/ to import your files, note they must be already added as wanted media for import to recognise and identify your downloaded media. See https://my.jdownloader.org/ for browser extensions and phone apps as desired. Documentation","title":"Jdownloader2"},{"location":"sandbox/apps/jdownloader2/#jdownloader","text":"","title":"JDownloader"},{"location":"sandbox/apps/jdownloader2/#what-is-it","text":"JDownloader is a free download-manager that makes downloading as easy, fast and automated as it should be. It's like your personal internet robot that does all the work for you. He will download whole photo albums, playlists or just about anything else with just one click. Go ahead and try it! Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/jdownloader2/#1-installation","text":"sb install sandbox-jdownloader2","title":"1. Installation"},{"location":"sandbox/apps/jdownloader2/#2-url","text":"To access JDownloader, visit https://jdownloader2._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/jdownloader2/#3-setup","text":"The configured password is taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Configure your myjdownloader account (Create at https://my.jdownloader.org/ if needed) and name your instance so you can connect via web or browser extensions. Use clipboard for two step copy and paste if needed. Note that some settings are only accessible via jdownloader2.yourdomain.com . Premium accounts such as mega.nz can be added via web interface. Use manual import from sonarr / radarr and navigate to /mnt/local/downloads/myjdownloader/output/ to import your files, note they must be already added as wanted media for import to recognise and identify your downloaded media. See https://my.jdownloader.org/ for browser extensions and phone apps as desired. Documentation","title":"3. Setup"},{"location":"sandbox/apps/jirafeau/","text":"Jirafeau \u00b6 What is it? \u00b6 Jirafeau is a web site permitting to upload a file in a simple way and give an unique link to it. Jirafeau is a \"one-click-filesharing\": Select your file, upload, share a link. That's it. See jirafeau.net for a demo. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-jirafeau 2. URL \u00b6 To access Jirafeau, visit https://jirafeau._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Jirafeau"},{"location":"sandbox/apps/jirafeau/#jirafeau","text":"","title":"Jirafeau"},{"location":"sandbox/apps/jirafeau/#what-is-it","text":"Jirafeau is a web site permitting to upload a file in a simple way and give an unique link to it. Jirafeau is a \"one-click-filesharing\": Select your file, upload, share a link. That's it. See jirafeau.net for a demo. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/jirafeau/#1-installation","text":"sb install sandbox-jirafeau","title":"1. Installation"},{"location":"sandbox/apps/jirafeau/#2-url","text":"To access Jirafeau, visit https://jirafeau._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/jirafeau/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/joplin/","text":"Joplin \u00b6 What is it? \u00b6 Joplin is an open source note-taking app. Capture your thoughts and securely access them from any device. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-joplin 2. URL \u00b6 To access Joplin, visit https://joplin._yourdomain.com_ 3. Setup \u00b6 Info Default login for joplin is email: admin@localhost password: admin Change this asap. Visit here to learn how to use end to end encryption. (Very simple) Documentation","title":"Joplin"},{"location":"sandbox/apps/joplin/#joplin","text":"","title":"Joplin"},{"location":"sandbox/apps/joplin/#what-is-it","text":"Joplin is an open source note-taking app. Capture your thoughts and securely access them from any device. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/joplin/#1-installation","text":"sb install sandbox-joplin","title":"1. Installation"},{"location":"sandbox/apps/joplin/#2-url","text":"To access Joplin, visit https://joplin._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/joplin/#3-setup","text":"Info Default login for joplin is email: admin@localhost password: admin Change this asap. Visit here to learn how to use end to end encryption. (Very simple) Documentation","title":"3. Setup"},{"location":"sandbox/apps/kavita/","text":"Kavita \u00b6 What is it? \u00b6 Kavita is a fast, feature rich, cross platform reading server. Built with a focus for manga, and the goal of being a full solution for all your reading needs. Setup your own server and share your reading collection with your friends and family! Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-kavita 2. URL \u00b6 To access Kavita, visit https://kavita._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"kavita"},{"location":"sandbox/apps/kavita/#kavita","text":"","title":"Kavita"},{"location":"sandbox/apps/kavita/#what-is-it","text":"Kavita is a fast, feature rich, cross platform reading server. Built with a focus for manga, and the goal of being a full solution for all your reading needs. Setup your own server and share your reading collection with your friends and family! Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/kavita/#1-installation","text":"sb install sandbox-kavita","title":"1. Installation"},{"location":"sandbox/apps/kavita/#2-url","text":"To access Kavita, visit https://kavita._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/kavita/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/kcptun_client/","text":"kcptun client \u00b6 What is it? \u00b6 kcptun client is a Stable & Secure Tunnel based on KCP with N:M multiplexing and FEC. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-kcptun-client 2. Setup \u00b6 Documentation","title":"kcptun_client"},{"location":"sandbox/apps/kcptun_client/#kcptun-client","text":"","title":"kcptun client"},{"location":"sandbox/apps/kcptun_client/#what-is-it","text":"kcptun client is a Stable & Secure Tunnel based on KCP with N:M multiplexing and FEC. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/kcptun_client/#1-installation","text":"sb install sandbox-kcptun-client","title":"1. Installation"},{"location":"sandbox/apps/kcptun_client/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"sandbox/apps/kcptun_server/","text":"kcptun server \u00b6 What is it? \u00b6 kcptun Server is a Stable & Secure Tunnel based on KCP with N:M multiplexing and FEC. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-kcptun-server 2. Setup \u00b6 Documentation","title":"kcptun_server"},{"location":"sandbox/apps/kcptun_server/#kcptun-server","text":"","title":"kcptun server"},{"location":"sandbox/apps/kcptun_server/#what-is-it","text":"kcptun Server is a Stable & Secure Tunnel based on KCP with N:M multiplexing and FEC. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/kcptun_server/#1-installation","text":"sb install sandbox-kcptun-server","title":"1. Installation"},{"location":"sandbox/apps/kcptun_server/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"sandbox/apps/kitana/","text":"Kitana \u00b6 What is it? \u00b6 Kitana is a responsive Plex plugin web frontend. Running one instance of Kitana can serve infinite amounts of servers and plugins - you can even expose your Kitana instance to your friends, so they can manage their plugins as well, so they don't have to run their own Kitana instance. Kitana was built for Sub-Zero originally, but handles other plugins just as well. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-kitana 2. URL \u00b6 To access Kitana, visit https://kitana._yourdomain.com_ 3. Setup \u00b6 pen your browser and visit your Kitana instance https://kitana._yourdomain.com_ authenticate against Plex.TV select your server (non-owned may not work; local connections are preferred) profit Documentation","title":"kitana"},{"location":"sandbox/apps/kitana/#kitana","text":"","title":"Kitana"},{"location":"sandbox/apps/kitana/#what-is-it","text":"Kitana is a responsive Plex plugin web frontend. Running one instance of Kitana can serve infinite amounts of servers and plugins - you can even expose your Kitana instance to your friends, so they can manage their plugins as well, so they don't have to run their own Kitana instance. Kitana was built for Sub-Zero originally, but handles other plugins just as well. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/kitana/#1-installation","text":"sb install sandbox-kitana","title":"1. Installation"},{"location":"sandbox/apps/kitana/#2-url","text":"To access Kitana, visit https://kitana._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/kitana/#3-setup","text":"pen your browser and visit your Kitana instance https://kitana._yourdomain.com_ authenticate against Plex.TV select your server (non-owned may not work; local connections are preferred) profit Documentation","title":"3. Setup"},{"location":"sandbox/apps/komga/","text":"Komga \u00b6 What is it? \u00b6 Komga is a free and open source comics/mangas server. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-komga 2. URL \u00b6 To access Komga, visit https://komga._yourdomain.com_ 3. Setup \u00b6 On first opening you will be asked to create a user account. Choose an email and password, then click on Create User Account. Komga expects comics to be stored in /mnt/unionfs/Media/Comics . /mnt is accessible to the container as well. Documentation","title":"komga"},{"location":"sandbox/apps/komga/#komga","text":"","title":"Komga"},{"location":"sandbox/apps/komga/#what-is-it","text":"Komga is a free and open source comics/mangas server. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/komga/#1-installation","text":"sb install sandbox-komga","title":"1. Installation"},{"location":"sandbox/apps/komga/#2-url","text":"To access Komga, visit https://komga._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/komga/#3-setup","text":"On first opening you will be asked to create a user account. Choose an email and password, then click on Create User Account. Komga expects comics to be stored in /mnt/unionfs/Media/Comics . /mnt is accessible to the container as well. Documentation","title":"3. Setup"},{"location":"sandbox/apps/lazylibrarian/","text":"LazyLibrarian \u00b6 What is it? \u00b6 LazyLibrarian is a program to follow authors and grab metadata for all your digital reading needs. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-lazylibrarian 2. URL \u00b6 To access LazyLibrarian, visit https://lazylibrarian._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"lazylibrarian"},{"location":"sandbox/apps/lazylibrarian/#lazylibrarian","text":"","title":"LazyLibrarian"},{"location":"sandbox/apps/lazylibrarian/#what-is-it","text":"LazyLibrarian is a program to follow authors and grab metadata for all your digital reading needs. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/lazylibrarian/#1-installation","text":"sb install sandbox-lazylibrarian","title":"1. Installation"},{"location":"sandbox/apps/lazylibrarian/#2-url","text":"To access LazyLibrarian, visit https://lazylibrarian._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/lazylibrarian/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/linkding/","text":"Linkding \u00b6 What is it? \u00b6 Linkding is a simple bookmark service that you can host yourself. It's designed be to be minimal and fast. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-linkding 2. URL \u00b6 To access linkding, visit https://linkding._yourdomain.com_ 3. Setup \u00b6 Default login: Username : user from accounts.yml Password : password from accounts.yml Documentation","title":"Linkding"},{"location":"sandbox/apps/linkding/#linkding","text":"","title":"Linkding"},{"location":"sandbox/apps/linkding/#what-is-it","text":"Linkding is a simple bookmark service that you can host yourself. It's designed be to be minimal and fast. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/linkding/#1-installation","text":"sb install sandbox-linkding","title":"1. Installation"},{"location":"sandbox/apps/linkding/#2-url","text":"To access linkding, visit https://linkding._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/linkding/#3-setup","text":"Default login: Username : user from accounts.yml Password : password from accounts.yml Documentation","title":"3. Setup"},{"location":"sandbox/apps/logarr/","text":"Logarr ALPHA \u00b6 What is it? \u00b6 Logarr ALPHA is a Self-hosted, single-page, log consolidation tool written in PHP. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-logarr 2. URL \u00b6 To access Logarr ALPHA, visit https://logarr._yourdomain.com_ 3. Setup \u00b6 See documentation for configuration and instructions for adding more logs to your instance. Documentation","title":"logarr"},{"location":"sandbox/apps/logarr/#logarr-alpha","text":"","title":"Logarr ALPHA"},{"location":"sandbox/apps/logarr/#what-is-it","text":"Logarr ALPHA is a Self-hosted, single-page, log consolidation tool written in PHP. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/logarr/#1-installation","text":"sb install sandbox-logarr","title":"1. Installation"},{"location":"sandbox/apps/logarr/#2-url","text":"To access Logarr ALPHA, visit https://logarr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/logarr/#3-setup","text":"See documentation for configuration and instructions for adding more logs to your instance. Documentation","title":"3. Setup"},{"location":"sandbox/apps/makemkv/","text":"MakeMKV \u00b6 What is it? \u00b6 MakeMKV is your one-click solution to convert video that you own into free and patents-unencumbered format that can be played everywhere. MakeMKV is a format converter, otherwise called \"transcoder\". It converts the video clips from proprietary (and usually encrypted) disc into a set of MKV files, preserving most information but not changing it in any way. The MKV format can store multiple video/audio tracks with all meta-information and preserve chapters. Info By default, the role is protected behind your Authelia/SSO middleware. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-makemkv 2. URL \u00b6 To access makemkv, visit https://makemkv._yourdomain.com_ Documentation: MakeMKV Docs","title":"MakeMKV"},{"location":"sandbox/apps/makemkv/#makemkv","text":"","title":"MakeMKV"},{"location":"sandbox/apps/makemkv/#what-is-it","text":"MakeMKV is your one-click solution to convert video that you own into free and patents-unencumbered format that can be played everywhere. MakeMKV is a format converter, otherwise called \"transcoder\". It converts the video clips from proprietary (and usually encrypted) disc into a set of MKV files, preserving most information but not changing it in any way. The MKV format can store multiple video/audio tracks with all meta-information and preserve chapters. Info By default, the role is protected behind your Authelia/SSO middleware. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/makemkv/#1-installation","text":"sb install sandbox-makemkv","title":"1. Installation"},{"location":"sandbox/apps/makemkv/#2-url","text":"To access makemkv, visit https://makemkv._yourdomain.com_ Documentation: MakeMKV Docs","title":"2. URL"},{"location":"sandbox/apps/mcrouter/","text":"mcrouter \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 mcrouter is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-mcrouter 2. URL \u00b6 To access mcrouter, visit https://mcrouter._yourdomain.com_ 3. Usage \u00b6 Instructions for mcrouter","title":"mcrouter"},{"location":"sandbox/apps/mcrouter/#mcrouter","text":"","title":"mcrouter"},{"location":"sandbox/apps/mcrouter/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/mcrouter/#what-is-it","text":"mcrouter is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/mcrouter/#1-installation","text":"sb install sandbox-mcrouter","title":"1. Installation"},{"location":"sandbox/apps/mcrouter/#2-url","text":"To access mcrouter, visit https://mcrouter._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/mcrouter/#3-usage","text":"Instructions for mcrouter","title":"3. Usage"},{"location":"sandbox/apps/medusa/","text":"Medusa \u00b6 What is it? \u00b6 Medusa is an automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-medusa 2. URL \u00b6 To access Medusa, visit https://medusa._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Medusa"},{"location":"sandbox/apps/medusa/#medusa","text":"","title":"Medusa"},{"location":"sandbox/apps/medusa/#what-is-it","text":"Medusa is an automatic Video Library Manager for TV Shows. It watches for new episodes of your favorite shows, and when they are posted it does its magic. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/medusa/#1-installation","text":"sb install sandbox-medusa","title":"1. Installation"},{"location":"sandbox/apps/medusa/#2-url","text":"To access Medusa, visit https://medusa._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/medusa/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/minecraft-bedrock/","text":"Minecraft Bedrock \u00b6 What is it? \u00b6 This is a Minecraft Bedrock server for the multi-platform Minecraft version. Note \ud83d\udce2 This server will expose the port UDP 19132 Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-minecraft-bedrock 2. Join Server \u00b6 The server will be accesible at minecraft-bedrock._yourdomain.com_ or _yourserverip_:19132 Change server version \u00b6 By default, the server will be using the latest version available. To choose a specific version add minecraft_bedrock_version: \"1.19.31\" to the inventory system .","title":"Minecraft Bedrock"},{"location":"sandbox/apps/minecraft-bedrock/#minecraft-bedrock","text":"","title":"Minecraft Bedrock"},{"location":"sandbox/apps/minecraft-bedrock/#what-is-it","text":"This is a Minecraft Bedrock server for the multi-platform Minecraft version. Note \ud83d\udce2 This server will expose the port UDP 19132 Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/minecraft-bedrock/#1-installation","text":"sb install sandbox-minecraft-bedrock","title":"1. Installation"},{"location":"sandbox/apps/minecraft-bedrock/#2-join-server","text":"The server will be accesible at minecraft-bedrock._yourdomain.com_ or _yourserverip_:19132","title":"2. Join Server"},{"location":"sandbox/apps/minecraft-bedrock/#change-server-version","text":"By default, the server will be using the latest version available. To choose a specific version add minecraft_bedrock_version: \"1.19.31\" to the inventory system .","title":"Change server version"},{"location":"sandbox/apps/minecraft/","text":"Minecraft \u00b6 What is it? \u00b6 Run one or multiple minecraft servers with custom domains. Utilises minecraft server and mc-router to allow each server to have its own subdomain with the default port. Details Project home Docs Github Docker Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-minecraft This will install mc-router and the minecraft server. If you have listed multiple minecraft instances, it will install these too. (See below for multi server instructions) 2. Join Server \u00b6 By default, a single server will be accesible at minecraft._yourdomain.com_ If you have set up multiple instances, these will be accesible by default at instanceName._yourdomain.com_ (See multi server instructions below) 3. Multi Server Set Up \u00b6 To add multiple instances, add: minecraft_instances : [ \"server1\" , \"server2\" ] To the inventory files. See instuctions on inventory here These servers will be accesible at instanceName.__yourdomain.com__ So for the example above, server1.youdomain.com and server2.yourdomain.com 4. Setup \u00b6 For individual servers, you can change things such as memory using custom docker envs. See instuctions on inventory here For a single install, the inventory paths will look like this minecraft_docker_image_tag When you have set up multiple servers, they will all use the minecraft_docker_image_tag settings as a default. To override this use the instance name instead. E.g instanceName_docker_image_tag - Documentation","title":"Minecraft"},{"location":"sandbox/apps/minecraft/#minecraft","text":"","title":"Minecraft"},{"location":"sandbox/apps/minecraft/#what-is-it","text":"Run one or multiple minecraft servers with custom domains. Utilises minecraft server and mc-router to allow each server to have its own subdomain with the default port. Details Project home Docs Github Docker Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/minecraft/#1-installation","text":"sb install sandbox-minecraft This will install mc-router and the minecraft server. If you have listed multiple minecraft instances, it will install these too. (See below for multi server instructions)","title":"1. Installation"},{"location":"sandbox/apps/minecraft/#2-join-server","text":"By default, a single server will be accesible at minecraft._yourdomain.com_ If you have set up multiple instances, these will be accesible by default at instanceName._yourdomain.com_ (See multi server instructions below)","title":"2. Join Server"},{"location":"sandbox/apps/minecraft/#3-multi-server-set-up","text":"To add multiple instances, add: minecraft_instances : [ \"server1\" , \"server2\" ] To the inventory files. See instuctions on inventory here These servers will be accesible at instanceName.__yourdomain.com__ So for the example above, server1.youdomain.com and server2.yourdomain.com","title":"3. Multi Server Set Up"},{"location":"sandbox/apps/minecraft/#4-setup","text":"For individual servers, you can change things such as memory using custom docker envs. See instuctions on inventory here For a single install, the inventory paths will look like this minecraft_docker_image_tag When you have set up multiple servers, they will all use the minecraft_docker_image_tag settings as a default. To override this use the instance name instead. E.g instanceName_docker_image_tag - Documentation","title":"4. Setup"},{"location":"sandbox/apps/mkvtoolnix/","text":"MKVToolNix \u00b6 What is it? \u00b6 MKVToolNix is a set of tools to create, alter and inspect Matroska files. You can use MKVToolNix to create, split, edit, mux, demux, merge, extract or inspect Matroska files. The program will also work with other video formats (AVI, MPEG, MP4, MPEG, Ogg/OGM, RealVideo, MPEG1/2, h264/AVC, Dirac, VC1) including some video codecs (such as VP9 video codec support - reading from IVF/Matroska/WebM files, extract to IVF files). Audio formats (AAC, FLAC, MP2, MP3, (E)AC3, DTS/DTS-HD, Vorbis, RealAudio) and also most subtitle formats (SRT, PGS/SUP, VobSub, ASS, SSA, etc.). Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-mkvtoolnix 2. URL \u00b6 To access MKVToolNix, visit https://mkvtoolnix._yourdomain.com_ 3. Setup \u00b6 Documentation: MKVToolNix Client Docs","title":"MKVToolNix"},{"location":"sandbox/apps/mkvtoolnix/#mkvtoolnix","text":"","title":"MKVToolNix"},{"location":"sandbox/apps/mkvtoolnix/#what-is-it","text":"MKVToolNix is a set of tools to create, alter and inspect Matroska files. You can use MKVToolNix to create, split, edit, mux, demux, merge, extract or inspect Matroska files. The program will also work with other video formats (AVI, MPEG, MP4, MPEG, Ogg/OGM, RealVideo, MPEG1/2, h264/AVC, Dirac, VC1) including some video codecs (such as VP9 video codec support - reading from IVF/Matroska/WebM files, extract to IVF files). Audio formats (AAC, FLAC, MP2, MP3, (E)AC3, DTS/DTS-HD, Vorbis, RealAudio) and also most subtitle formats (SRT, PGS/SUP, VobSub, ASS, SSA, etc.). Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/mkvtoolnix/#1-installation","text":"sb install sandbox-mkvtoolnix","title":"1. Installation"},{"location":"sandbox/apps/mkvtoolnix/#2-url","text":"To access MKVToolNix, visit https://mkvtoolnix._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/mkvtoolnix/#3-setup","text":"Documentation: MKVToolNix Client Docs","title":"3. Setup"},{"location":"sandbox/apps/monitorr/","text":"Monitorr \u00b6 What is it? \u00b6 Monitorr is a self-hosted PHP web app that monitors the status of local and remote network services, websites, and applications. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-monitorr 2. URL \u00b6 To access Monitorr, visit https://monitorr._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"monitorr"},{"location":"sandbox/apps/monitorr/#monitorr","text":"","title":"Monitorr"},{"location":"sandbox/apps/monitorr/#what-is-it","text":"Monitorr is a self-hosted PHP web app that monitors the status of local and remote network services, websites, and applications. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/monitorr/#1-installation","text":"sb install sandbox-monitorr","title":"1. Installation"},{"location":"sandbox/apps/monitorr/#2-url","text":"To access Monitorr, visit https://monitorr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/monitorr/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/moviematch/","text":"MovieMatch \u00b6 What is it? \u00b6 MovieMatch is an app that helps you and your friends pick a movie to watch from a Plex server. MovieMatch connects to your Plex server and gets a list of movies (from any libraries marked as a movie library). As many people as you want connect to your MovieMatch server and get a list of shuffled movies. Swipe right to +1, swipe left to -1. If two (or more) people swipe right on the same movie, it'll show up in everyone's matches. The movies that the most people swiped right on will show up first. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-moviematch 2. URL \u00b6 To access MovieMatch, visit https://moviematch._yourdomain.com_ 3. Setup \u00b6 Via UI \u00b6 If you prefer to set up MovieMatch using a web interface, just start MovieMatch and you will be presented with a configuration screen. The configuration will be saved in the working directory. Via YAML \u00b6 MovieMatch can be configured with a simple YAML document, which allows connecting to multiple Plex servers. Here's a simple example: host : 0.0.0.0 port : 8000 servers : - url : https://plex.example.com token : abcdef12346 MovieMatch will read the config from /opt/moviematch/config.yaml by default. Documentation","title":"moviematch"},{"location":"sandbox/apps/moviematch/#moviematch","text":"","title":"MovieMatch"},{"location":"sandbox/apps/moviematch/#what-is-it","text":"MovieMatch is an app that helps you and your friends pick a movie to watch from a Plex server. MovieMatch connects to your Plex server and gets a list of movies (from any libraries marked as a movie library). As many people as you want connect to your MovieMatch server and get a list of shuffled movies. Swipe right to +1, swipe left to -1. If two (or more) people swipe right on the same movie, it'll show up in everyone's matches. The movies that the most people swiped right on will show up first. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/moviematch/#1-installation","text":"sb install sandbox-moviematch","title":"1. Installation"},{"location":"sandbox/apps/moviematch/#2-url","text":"To access MovieMatch, visit https://moviematch._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/moviematch/#3-setup","text":"","title":"3. Setup"},{"location":"sandbox/apps/moviematch/#via-ui","text":"If you prefer to set up MovieMatch using a web interface, just start MovieMatch and you will be presented with a configuration screen. The configuration will be saved in the working directory.","title":"Via UI"},{"location":"sandbox/apps/moviematch/#via-yaml","text":"MovieMatch can be configured with a simple YAML document, which allows connecting to multiple Plex servers. Here's a simple example: host : 0.0.0.0 port : 8000 servers : - url : https://plex.example.com token : abcdef12346 MovieMatch will read the config from /opt/moviematch/config.yaml by default. Documentation","title":"Via YAML"},{"location":"sandbox/apps/mylar3/","text":"Mylar3 \u00b6 What is it? \u00b6 Mylar3 is an automated Comic Book downloader (cbr/cbz) for use with SABnzbd, NZBGet and torrents. Also provides an OPDS server distribution. Mylar allows you to create a watchlist of series that it monitors for various things (new issues, updated information, etc). It will grab, sort, and rename downloaded issues. It will also allow you to monitor weekly pull-lists for items belonging to said watchlisted series to download, as well as being able to monitor and maintain story-arcs. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-ROLENAME 2. URL \u00b6 To access Mylar3, visit https://ROLENAME._yourdomain.com_ 3. Setup \u00b6 It's highly unlikely your mylar install is up to date. Press the Update link on the dialog in the bottom right hand corner. Mylar3 will update and then restart. Enable some authentication. Add a username and password and set your preferred login method . Make sure Launch Browser on startup is disabled. You'll need a ComicVine API Key for Mylar to be useful. Create an account , and your key will be at the top of this page . Set the Comic Location path to /comics . It will already be mounted. Uncheck enforce permissions Optional : Enable Series-Annual Integration Save and then restart the app Note If you enable to OPDS server, DO NOT ENABLE OPDS Fetch MetaInfo . It queries the file system. Download settings \u00b6 (These instructions are for NZBGet. Adapt for other Download Apps) Configure NZBGet \u00b6 Log into https://nzbget._youdomain_.com Go to Settings > Categories Scroll to bottom, click Add Another Category Name it mylar Configure Mylar \u00b6 Set Usenet client to NZBGet Fill in the server stuff like it would be in sonarr / radarr / etc Set values: Host: nzbget Port: 6789 Username: Your NZBGet Username Password: Your NZBGet Password Category: mylar Use SSL: No NZBGet Download Directory: Leave Blank Enable Completed Download Handling: X Search Providers \u00b6 Click Add Indexer ( + ). Select \"Newznab\". Add the following: Use Newznab: X NewzNab Name: NZBHydra2 NewzNab Host: http://nzbhydra2:5076 Verify SSL: Disabled API Key: Your NZBHydra2 API Key Enabled: X Quality and Post Processing \u00b6 Enable Failed Download Handling: X Enable Automatic-Retry for Failed Downloads: X Enable Post-Processing: X When Post-Processing move the files Advanced Settings \u00b6 These settings are up to the user Rename Files: X Folder Format: $Series ($Year) (My recommendation) File Format: $Series $Annual $Issue ($Year) (My recommendation) See the Mylar Wiki for more information \u00b6 Documentation","title":"mylar3"},{"location":"sandbox/apps/mylar3/#mylar3","text":"","title":"Mylar3"},{"location":"sandbox/apps/mylar3/#what-is-it","text":"Mylar3 is an automated Comic Book downloader (cbr/cbz) for use with SABnzbd, NZBGet and torrents. Also provides an OPDS server distribution. Mylar allows you to create a watchlist of series that it monitors for various things (new issues, updated information, etc). It will grab, sort, and rename downloaded issues. It will also allow you to monitor weekly pull-lists for items belonging to said watchlisted series to download, as well as being able to monitor and maintain story-arcs. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/mylar3/#1-installation","text":"sb install sandbox-ROLENAME","title":"1. Installation"},{"location":"sandbox/apps/mylar3/#2-url","text":"To access Mylar3, visit https://ROLENAME._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/mylar3/#3-setup","text":"It's highly unlikely your mylar install is up to date. Press the Update link on the dialog in the bottom right hand corner. Mylar3 will update and then restart. Enable some authentication. Add a username and password and set your preferred login method . Make sure Launch Browser on startup is disabled. You'll need a ComicVine API Key for Mylar to be useful. Create an account , and your key will be at the top of this page . Set the Comic Location path to /comics . It will already be mounted. Uncheck enforce permissions Optional : Enable Series-Annual Integration Save and then restart the app Note If you enable to OPDS server, DO NOT ENABLE OPDS Fetch MetaInfo . It queries the file system.","title":"3. Setup"},{"location":"sandbox/apps/mylar3/#download-settings","text":"(These instructions are for NZBGet. Adapt for other Download Apps)","title":"Download settings"},{"location":"sandbox/apps/mylar3/#configure-nzbget","text":"Log into https://nzbget._youdomain_.com Go to Settings > Categories Scroll to bottom, click Add Another Category Name it mylar","title":"Configure NZBGet"},{"location":"sandbox/apps/mylar3/#configure-mylar","text":"Set Usenet client to NZBGet Fill in the server stuff like it would be in sonarr / radarr / etc Set values: Host: nzbget Port: 6789 Username: Your NZBGet Username Password: Your NZBGet Password Category: mylar Use SSL: No NZBGet Download Directory: Leave Blank Enable Completed Download Handling: X","title":"Configure Mylar"},{"location":"sandbox/apps/mylar3/#search-providers","text":"Click Add Indexer ( + ). Select \"Newznab\". Add the following: Use Newznab: X NewzNab Name: NZBHydra2 NewzNab Host: http://nzbhydra2:5076 Verify SSL: Disabled API Key: Your NZBHydra2 API Key Enabled: X","title":"Search Providers"},{"location":"sandbox/apps/mylar3/#quality-and-post-processing","text":"Enable Failed Download Handling: X Enable Automatic-Retry for Failed Downloads: X Enable Post-Processing: X When Post-Processing move the files","title":"Quality and Post Processing"},{"location":"sandbox/apps/mylar3/#advanced-settings","text":"These settings are up to the user Rename Files: X Folder Format: $Series ($Year) (My recommendation) File Format: $Series $Annual $Issue ($Year) (My recommendation)","title":"Advanced Settings"},{"location":"sandbox/apps/mylar3/#see-the-mylar-wiki-for-more-information","text":"Documentation","title":"See the Mylar Wiki for more information"},{"location":"sandbox/apps/nabarr/","text":"Nabarr \u00b6 What is it? \u00b6 Nabarr monitors Newznab/Torznab RSS feeds to find new media to add to Sonarr and or Radarr. Details Nabarr Docs Github Docker: 1. Installation \u00b6 sb install sandbox-nabarr 2. Setup \u00b6 Documentation: Nabarr Docs","title":"Nabarr"},{"location":"sandbox/apps/nabarr/#nabarr","text":"","title":"Nabarr"},{"location":"sandbox/apps/nabarr/#what-is-it","text":"Nabarr monitors Newznab/Torznab RSS feeds to find new media to add to Sonarr and or Radarr. Details Nabarr Docs Github Docker:","title":"What is it?"},{"location":"sandbox/apps/nabarr/#1-installation","text":"sb install sandbox-nabarr","title":"1. Installation"},{"location":"sandbox/apps/nabarr/#2-setup","text":"Documentation: Nabarr Docs","title":"2. Setup"},{"location":"sandbox/apps/navidrome/","text":"Navidrome \u00b6 What is it? \u00b6 Navidrome allows you to enjoy your music collection from anywhere, by making it available through a modern Web UI and through a wide range of third-party compatible mobile apps, for both iOS and Android devices. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-navidrome 2. URL \u00b6 To access Navidrome, visit https://navidrome._yourdomain.com_ 3. Setup \u00b6 After installing Navidrome in your platform, you need to create your first user. This will be your admin user, a super user that can manage all aspects of Navidrome, including the ability to manage other users. Just browse to Navidrome\u2019s homepage at https://navidrome._yourdomain.com_ and you will be greeted with a screen like this: Just fill out the username and password you want to use, confirm the password and click on the \u201cCreate Admin\u201d button. That\u2019s it! You should now be able to browse and listen to all your music. Note It usually take a couple of minutes for your music to start appearing in Navidrome\u2019s UI. You can check the logs to see what is the scan progress. If you have a large library this may take some time. Documentation","title":"navidrome"},{"location":"sandbox/apps/navidrome/#navidrome","text":"","title":"Navidrome"},{"location":"sandbox/apps/navidrome/#what-is-it","text":"Navidrome allows you to enjoy your music collection from anywhere, by making it available through a modern Web UI and through a wide range of third-party compatible mobile apps, for both iOS and Android devices. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/navidrome/#1-installation","text":"sb install sandbox-navidrome","title":"1. Installation"},{"location":"sandbox/apps/navidrome/#2-url","text":"To access Navidrome, visit https://navidrome._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/navidrome/#3-setup","text":"After installing Navidrome in your platform, you need to create your first user. This will be your admin user, a super user that can manage all aspects of Navidrome, including the ability to manage other users. Just browse to Navidrome\u2019s homepage at https://navidrome._yourdomain.com_ and you will be greeted with a screen like this: Just fill out the username and password you want to use, confirm the password and click on the \u201cCreate Admin\u201d button. That\u2019s it! You should now be able to browse and listen to all your music. Note It usually take a couple of minutes for your music to start appearing in Navidrome\u2019s UI. You can check the logs to see what is the scan progress. If you have a large library this may take some time. Documentation","title":"3. Setup"},{"location":"sandbox/apps/nextcloud/","text":"Nextcloud \u00b6 What is it? \u00b6 Nextcloud is safe home for all your data. Access & share your files, calendars, contacts, mail & more from any device, on your terms. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-nextcloud 2. URL \u00b6 To access Nextcloud, visit https://nextcloud._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Nextcloud"},{"location":"sandbox/apps/nextcloud/#nextcloud","text":"","title":"Nextcloud"},{"location":"sandbox/apps/nextcloud/#what-is-it","text":"Nextcloud is safe home for all your data. Access & share your files, calendars, contacts, mail & more from any device, on your terms. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/nextcloud/#1-installation","text":"sb install sandbox-nextcloud","title":"1. Installation"},{"location":"sandbox/apps/nextcloud/#2-url","text":"To access Nextcloud, visit https://nextcloud._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/nextcloud/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/notifiarr/","text":"Notifiarr Client \u00b6 What is it? \u00b6 Notifiarr Client is the unified client for Notifiarr.com. The client enables content requests from Media Bot in your Discord Server. It also provides reports for Plex usage and system health. Other features can be configured on the Notifiarr website. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-notifiarr 2. URL \u00b6 The Notifiarr url will only display the app status https://notifiarr._yourdomain.com_ 3. Setup \u00b6 You will need a notifiar account api key to use notifiarr. You can get one by signing up for a free account. After logging in, you should be redirected to your profile screen. Click on Generate API Key (This needs to be done) Select your Country Select your Timezone Change your Time Format to your liking Select your Site Theme Select your Notification Language Don't forget to Save your changes Add your API key to the Sandbox settings file Now run the installer sb install sandbox-notifiarr Now go to the Notifiarr website and configure your integrations and discord server. Refer to the Notifiarr documentation for more information. The role will attempt to configure sonarr, radarr, plex, and tautulli. Other apps can be edited in the config file which can be found at \"/opt/notifiarr/notifiarr.conf\" in a standard install. From time to time new options will be added and an example config file can be found here. A quickstart guide can be found on the Trash Guides website. Documentation: Notifiarr Client Docs","title":"Notifiarr"},{"location":"sandbox/apps/notifiarr/#notifiarr-client","text":"","title":"Notifiarr Client"},{"location":"sandbox/apps/notifiarr/#what-is-it","text":"Notifiarr Client is the unified client for Notifiarr.com. The client enables content requests from Media Bot in your Discord Server. It also provides reports for Plex usage and system health. Other features can be configured on the Notifiarr website. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/notifiarr/#1-installation","text":"sb install sandbox-notifiarr","title":"1. Installation"},{"location":"sandbox/apps/notifiarr/#2-url","text":"The Notifiarr url will only display the app status https://notifiarr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/notifiarr/#3-setup","text":"You will need a notifiar account api key to use notifiarr. You can get one by signing up for a free account. After logging in, you should be redirected to your profile screen. Click on Generate API Key (This needs to be done) Select your Country Select your Timezone Change your Time Format to your liking Select your Site Theme Select your Notification Language Don't forget to Save your changes Add your API key to the Sandbox settings file Now run the installer sb install sandbox-notifiarr Now go to the Notifiarr website and configure your integrations and discord server. Refer to the Notifiarr documentation for more information. The role will attempt to configure sonarr, radarr, plex, and tautulli. Other apps can be edited in the config file which can be found at \"/opt/notifiarr/notifiarr.conf\" in a standard install. From time to time new options will be added and an example config file can be found here. A quickstart guide can be found on the Trash Guides website. Documentation: Notifiarr Client Docs","title":"3. Setup"},{"location":"sandbox/apps/olivetin/","text":"OliveTin \u00b6 What is it? \u00b6 OliveTin gives safe and simple access to predefined shell commands from a web interface. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-olivetin 2. URL \u00b6 To access OliveTin, visit https://olivetin._yourdomain.com_ 3. Configuration \u00b6 A barebones configuration is imported by the role to /opt/olivetin/config.yaml provisioning a default \"Hello world!\" item Check out the configuration section of the documentation to start building your actions. Documentation","title":"OliveTin"},{"location":"sandbox/apps/olivetin/#olivetin","text":"","title":"OliveTin"},{"location":"sandbox/apps/olivetin/#what-is-it","text":"OliveTin gives safe and simple access to predefined shell commands from a web interface. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/olivetin/#1-installation","text":"sb install sandbox-olivetin","title":"1. Installation"},{"location":"sandbox/apps/olivetin/#2-url","text":"To access OliveTin, visit https://olivetin._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/olivetin/#3-configuration","text":"A barebones configuration is imported by the role to /opt/olivetin/config.yaml provisioning a default \"Hello world!\" item Check out the configuration section of the documentation to start building your actions. Documentation","title":"3. Configuration"},{"location":"sandbox/apps/ombi/","text":"Ombi \u00b6 What is it? \u00b6 Ombi is a self-hosted web application that automatically gives your shared Plex or Emby users the ability to request content by themselves! Ombi can be linked to multiple TV Show and Movie DVR tools to create a seamless end-to-end experience for your users. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-ombi 2. URL \u00b6 To access Ombi, visit https://ombi._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Ombi"},{"location":"sandbox/apps/ombi/#ombi","text":"","title":"Ombi"},{"location":"sandbox/apps/ombi/#what-is-it","text":"Ombi is a self-hosted web application that automatically gives your shared Plex or Emby users the ability to request content by themselves! Ombi can be linked to multiple TV Show and Movie DVR tools to create a seamless end-to-end experience for your users. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/ombi/#1-installation","text":"sb install sandbox-ombi","title":"1. Installation"},{"location":"sandbox/apps/ombi/#2-url","text":"To access Ombi, visit https://ombi._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/ombi/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/ombix/","text":"Ombi X \u00b6 What is it? \u00b6 Ombi X is an arr X role for Ombi . Ombi is a self-hosted web application that automatically gives your shared Plex or Emby users the ability to request content by themselves! Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-ombix 2. URL \u00b6 To access Ombi X , visit https://OmbiX._yourdomain.com_ 3. Setup \u00b6 Read through the general arr X role instructions . Add your X instance names to the Ombi X section in saltbox settings.yml : using a list format as below. ombix : roles : - 4k - anime For app specific instructions refer to the parent role, Ombi and the upstream documentation Documentation","title":"Ombix"},{"location":"sandbox/apps/ombix/#ombix","text":"","title":"OmbiX"},{"location":"sandbox/apps/ombix/#what-is-it","text":"Ombi X is an arr X role for Ombi . Ombi is a self-hosted web application that automatically gives your shared Plex or Emby users the ability to request content by themselves! Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/ombix/#1-installation","text":"sb install sandbox-ombix","title":"1. Installation"},{"location":"sandbox/apps/ombix/#2-url","text":"To access Ombi X , visit https://OmbiX._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/ombix/#3-setup","text":"Read through the general arr X role instructions . Add your X instance names to the Ombi X section in saltbox settings.yml : using a list format as below. ombix : roles : - 4k - anime For app specific instructions refer to the parent role, Ombi and the upstream documentation Documentation","title":"3. Setup"},{"location":"sandbox/apps/omegabrr/","text":"Omegabrr \u00b6 What is it? \u00b6 Omegabrr is a companion app to autobrr . It syncs monitored titles from Radarr and Sonarr to assigned filters in autobrr. Details Github Recommended install types: Feederbox, Saltbox, Core 1. Installation \u00b6 sb install sandbox-omegabrr 2. URL (API) \u00b6 Local applications may reach the Omegabrr server via http://omegabrr:7441 . For external use, https://omegabrr._yourdomain.com_ is available. 3. Setup \u00b6 The configuration file /opt/omegabrr/config.yaml will be pre-filled with your new API token and your Radarr and Sonarr details, but missing an autobrr API key which you must provide. Add your filter IDs (inside the brackets\u2013comma separated) to their corresponding *arr instance: filters : [ 9 , 10 , 99 , 100 ] Restart the Docker container for the changes to take effect. 4. Usage \u00b6 Use the URL with the provided API token to trigger filter refreshes via webhook: Service","title":"Omegabrr"},{"location":"sandbox/apps/omegabrr/#omegabrr","text":"","title":"Omegabrr"},{"location":"sandbox/apps/omegabrr/#what-is-it","text":"Omegabrr is a companion app to autobrr . It syncs monitored titles from Radarr and Sonarr to assigned filters in autobrr. Details Github Recommended install types: Feederbox, Saltbox, Core","title":"What is it?"},{"location":"sandbox/apps/omegabrr/#1-installation","text":"sb install sandbox-omegabrr","title":"1. Installation"},{"location":"sandbox/apps/omegabrr/#2-url-api","text":"Local applications may reach the Omegabrr server via http://omegabrr:7441 . For external use, https://omegabrr._yourdomain.com_ is available.","title":"2. URL (API)"},{"location":"sandbox/apps/omegabrr/#3-setup","text":"The configuration file /opt/omegabrr/config.yaml will be pre-filled with your new API token and your Radarr and Sonarr details, but missing an autobrr API key which you must provide. Add your filter IDs (inside the brackets\u2013comma separated) to their corresponding *arr instance: filters : [ 9 , 10 , 99 , 100 ] Restart the Docker container for the changes to take effect.","title":"3. Setup"},{"location":"sandbox/apps/omegabrr/#4-usage","text":"Use the URL with the provided API token to trigger filter refreshes via webhook: Service","title":"4. Usage"},{"location":"sandbox/apps/ouroboros/","text":"Ouroboros \u00b6 What is it? \u00b6 Ouroboros will automatically update your running Docker containers to the latest available image. A python-based alternative to watchtower Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-ouroboros 2. Setup \u00b6 Documentation","title":"ouroboros"},{"location":"sandbox/apps/ouroboros/#ouroboros","text":"","title":"Ouroboros"},{"location":"sandbox/apps/ouroboros/#what-is-it","text":"Ouroboros will automatically update your running Docker containers to the latest available image. A python-based alternative to watchtower Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/ouroboros/#1-installation","text":"sb install sandbox-ouroboros","title":"1. Installation"},{"location":"sandbox/apps/ouroboros/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"sandbox/apps/paperless-ngx/","text":"Paperless NGX \u00b6 What is it? \u00b6 Paperless NGX is a simple Django application running in two parts: a Consumer (the thing that does the indexing) and the Web server (the part that lets you search & download already-indexed documents). Paperless-NGX is forked from paperless-ng to continue the great work and distribute responsibility of supporting and advancing the project among a team of people. Info By default, the role is protected behind your Authelia/SSO middleware. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-paperless-ngx 2. URL \u00b6 To access pgadmin, visit https://paperless._yourdomain.com_ 3. Setup \u00b6 Info Please refer to this comment on the initial PR for questions about google storage! Documentation: Paperless NGX Docs","title":"Paperless-NGX"},{"location":"sandbox/apps/paperless-ngx/#paperless-ngx","text":"","title":"Paperless NGX"},{"location":"sandbox/apps/paperless-ngx/#what-is-it","text":"Paperless NGX is a simple Django application running in two parts: a Consumer (the thing that does the indexing) and the Web server (the part that lets you search & download already-indexed documents). Paperless-NGX is forked from paperless-ng to continue the great work and distribute responsibility of supporting and advancing the project among a team of people. Info By default, the role is protected behind your Authelia/SSO middleware. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/paperless-ngx/#1-installation","text":"sb install sandbox-paperless-ngx","title":"1. Installation"},{"location":"sandbox/apps/paperless-ngx/#2-url","text":"To access pgadmin, visit https://paperless._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/paperless-ngx/#3-setup","text":"Info Please refer to this comment on the initial PR for questions about google storage! Documentation: Paperless NGX Docs","title":"3. Setup"},{"location":"sandbox/apps/pgadmin/","text":"pgadmin \u00b6 What is it? \u00b6 pgadmin is a popular and feature rich Open Source administration and development platform for PostgreSQL. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-pgadmin 2. URL \u00b6 To access pgadmin, visit https://pgadmin._yourdomain.com_ 3. Setup \u00b6 Default login: Username : \"your email from accounts.yml\" Password : your_normal_password Documentation: pgadmin Docs","title":"PGAdmin"},{"location":"sandbox/apps/pgadmin/#pgadmin","text":"","title":"pgadmin"},{"location":"sandbox/apps/pgadmin/#what-is-it","text":"pgadmin is a popular and feature rich Open Source administration and development platform for PostgreSQL. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/pgadmin/#1-installation","text":"sb install sandbox-pgadmin","title":"1. Installation"},{"location":"sandbox/apps/pgadmin/#2-url","text":"To access pgadmin, visit https://pgadmin._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/pgadmin/#3-setup","text":"Default login: Username : \"your email from accounts.yml\" Password : your_normal_password Documentation: pgadmin Docs","title":"3. Setup"},{"location":"sandbox/apps/photoprism/","text":"Photoprism \u00b6 What is it? \u00b6 Photoprism\u00ae is an AI-Powered Photos App for the Decentralized Web. It makes use of the latest technologies to tag and find pictures automatically without getting in your way. You can run it at home, on a private server, or in the cloud. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Note: This is not a multi-user app. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-photoprism 2. URL \u00b6 To access Photoprism, visit https://photoprism._yourdomain.com_ 3. Setup \u00b6 Default login: Username : admin Password : your_normal_password Documentation: Photoprism Docs","title":"Photoprism"},{"location":"sandbox/apps/photoprism/#photoprism","text":"","title":"Photoprism"},{"location":"sandbox/apps/photoprism/#what-is-it","text":"Photoprism\u00ae is an AI-Powered Photos App for the Decentralized Web. It makes use of the latest technologies to tag and find pictures automatically without getting in your way. You can run it at home, on a private server, or in the cloud. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Note: This is not a multi-user app. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/photoprism/#1-installation","text":"sb install sandbox-photoprism","title":"1. Installation"},{"location":"sandbox/apps/photoprism/#2-url","text":"To access Photoprism, visit https://photoprism._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/photoprism/#3-setup","text":"Default login: Username : admin Password : your_normal_password Documentation: Photoprism Docs","title":"3. Setup"},{"location":"sandbox/apps/plex-credits-detect/","text":"Plex-Credits-Detect \u00b6 What is it? \u00b6 Plex-Credits-Detect uses audio spectrographic fingerprinting (thanks to AddictedCS/soundfingerprinting) to analyze all episodes in a season and insert the credit timings into the plex intro database. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-plex_credits_detect 2. Setup \u00b6 Documentation A default configuration file is imported upon first running the role. This can be edited according to the project's documentation.","title":"Plex-Credits-Detect"},{"location":"sandbox/apps/plex-credits-detect/#plex-credits-detect","text":"","title":"Plex-Credits-Detect"},{"location":"sandbox/apps/plex-credits-detect/#what-is-it","text":"Plex-Credits-Detect uses audio spectrographic fingerprinting (thanks to AddictedCS/soundfingerprinting) to analyze all episodes in a season and insert the credit timings into the plex intro database. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/plex-credits-detect/#1-installation","text":"sb install sandbox-plex_credits_detect","title":"1. Installation"},{"location":"sandbox/apps/plex-credits-detect/#2-setup","text":"Documentation A default configuration file is imported upon first running the role. This can be edited according to the project's documentation.","title":"2. Setup"},{"location":"sandbox/apps/plex-meta-manager/","text":"Plex Meta Manager \u00b6 What is it? \u00b6 Plex Meta Manager can update many metadata fields for movies, shows, collections, seasons, and episodes and can act as a backup if your plex DB goes down. It can even update metadata the plex UI can't like Season Names. If the time is put into the metadata configuration file you can have a way to recreate your library and all its metadata changes with the click of a button. Details Project home Docs Github Docker 1. Installation \u00b6 You will need to create a config file prior to running the tag: /opt/plex-meta-manager/config.yml There is a Docker-based walkthrough on the PMM wiki here that you can use to learn how to create this file. Once you've created it, move the file into /opt/plex-meta-manager/ and then run the tag. sb install sandbox-plex-meta-manager 2. Setup \u00b6 Documentation","title":"Plex Meta Manager"},{"location":"sandbox/apps/plex-meta-manager/#plex-meta-manager","text":"","title":"Plex Meta Manager"},{"location":"sandbox/apps/plex-meta-manager/#what-is-it","text":"Plex Meta Manager can update many metadata fields for movies, shows, collections, seasons, and episodes and can act as a backup if your plex DB goes down. It can even update metadata the plex UI can't like Season Names. If the time is put into the metadata configuration file you can have a way to recreate your library and all its metadata changes with the click of a button. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/plex-meta-manager/#1-installation","text":"You will need to create a config file prior to running the tag: /opt/plex-meta-manager/config.yml There is a Docker-based walkthrough on the PMM wiki here that you can use to learn how to create this file. Once you've created it, move the file into /opt/plex-meta-manager/ and then run the tag. sb install sandbox-plex-meta-manager","title":"1. Installation"},{"location":"sandbox/apps/plex-meta-manager/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"sandbox/apps/plex-utills/","text":"Plex Utills \u00b6 What is it? \u00b6 Plex Utills is a set of scripts that enhance your plex library: 4K/HDR Posters \u00b6 This script will go through your library and add a 4k banner to your posters. Configurable options include: Selecting full width banners or mini corner banners enabling HDR banners Backup your original posters alongside your media This can be run on both your films library and your TV shows Library. If enabled on your TV shows, a mini 4K banner will be added to each of your 4K episodes, not the season posters. This is due to the possibility of having Shows/Seasons with mixed resolutions. TV shows will be done at the same time as film posters. 3D Posters \u00b6 Much like the 4K poster script, this will go through your films and add a 3D banner to your films. Currently as Plex has no support for labelling content as 3D this will only work for 3D films kept in a separate library. You can configure the script to have full width banners or the mini corner banners as well as backing up your posters. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-plex_utills 2. Setup \u00b6 Visit https://plex-utills._yourdomain.com_ and set up plex-utills according to the Documentation","title":"plex-utills"},{"location":"sandbox/apps/plex-utills/#plex-utills","text":"","title":"Plex Utills"},{"location":"sandbox/apps/plex-utills/#what-is-it","text":"Plex Utills is a set of scripts that enhance your plex library:","title":"What is it?"},{"location":"sandbox/apps/plex-utills/#4khdr-posters","text":"This script will go through your library and add a 4k banner to your posters. Configurable options include: Selecting full width banners or mini corner banners enabling HDR banners Backup your original posters alongside your media This can be run on both your films library and your TV shows Library. If enabled on your TV shows, a mini 4K banner will be added to each of your 4K episodes, not the season posters. This is due to the possibility of having Shows/Seasons with mixed resolutions. TV shows will be done at the same time as film posters.","title":"4K/HDR Posters"},{"location":"sandbox/apps/plex-utills/#3d-posters","text":"Much like the 4K poster script, this will go through your films and add a 3D banner to your films. Currently as Plex has no support for labelling content as 3D this will only work for 3D films kept in a separate library. You can configure the script to have full width banners or the mini corner banners as well as backing up your posters. Details Project home Docs Github Docker","title":"3D Posters"},{"location":"sandbox/apps/plex-utills/#1-installation","text":"sb install sandbox-plex_utills","title":"1. Installation"},{"location":"sandbox/apps/plex-utills/#2-setup","text":"Visit https://plex-utills._yourdomain.com_ and set up plex-utills according to the Documentation","title":"2. Setup"},{"location":"sandbox/apps/plex_auto_languages/","text":"plex_auto_languages \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 plex_auto_languages is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-plex_auto_languages 2. URL \u00b6 To access plex_auto_languages, visit https://plex_auto_languages._yourdomain.com_ 3. Usage \u00b6 Instructions for plex_auto_languages","title":"plex_auto_languages"},{"location":"sandbox/apps/plex_auto_languages/#plex_auto_languages","text":"","title":"plex_auto_languages"},{"location":"sandbox/apps/plex_auto_languages/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/plex_auto_languages/#what-is-it","text":"plex_auto_languages is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/plex_auto_languages/#1-installation","text":"sb install sandbox-plex_auto_languages","title":"1. Installation"},{"location":"sandbox/apps/plex_auto_languages/#2-url","text":"To access plex_auto_languages, visit https://plex_auto_languages._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/plex_auto_languages/#3-usage","text":"Instructions for plex_auto_languages","title":"3. Usage"},{"location":"sandbox/apps/plex_autoscan/","text":"plex_autoscan \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 plex_autoscan is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-plex_autoscan 2. URL \u00b6 To access plex_autoscan, visit https://plex_autoscan._yourdomain.com_ 3. Usage \u00b6 Instructions for plex_autoscan","title":"plex_autoscan"},{"location":"sandbox/apps/plex_autoscan/#plex_autoscan","text":"","title":"plex_autoscan"},{"location":"sandbox/apps/plex_autoscan/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/plex_autoscan/#what-is-it","text":"plex_autoscan is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/plex_autoscan/#1-installation","text":"sb install sandbox-plex_autoscan","title":"1. Installation"},{"location":"sandbox/apps/plex_autoscan/#2-url","text":"To access plex_autoscan, visit https://plex_autoscan._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/plex_autoscan/#3-usage","text":"Instructions for plex_autoscan","title":"3. Usage"},{"location":"sandbox/apps/plex_dupefinder/","text":"Plex_Dupefinder \u00b6 What is it? \u00b6 Plex_Dupefinder Plex DupeFinder is a python script that finds duplicate versions of media (TV episodes and movies) in your Plex Library and tells Plex to remove the lowest rated files/versions (based on user-specified scoring) to leave behind a single file/version. Duplicates can be either in bulk (automatic) or one-by-one (interactively). Note \ud83d\udce2 You will need to have allow media deletion: enabled ticked. here Details Project home Docs Github 1. Installation \u00b6 sb install sandbox-plex_dupefinder 2. Setup \u00b6 Documentation","title":"plex_dupefinder"},{"location":"sandbox/apps/plex_dupefinder/#plex_dupefinder","text":"","title":"Plex_Dupefinder"},{"location":"sandbox/apps/plex_dupefinder/#what-is-it","text":"Plex_Dupefinder Plex DupeFinder is a python script that finds duplicate versions of media (TV episodes and movies) in your Plex Library and tells Plex to remove the lowest rated files/versions (based on user-specified scoring) to leave behind a single file/version. Duplicates can be either in bulk (automatic) or one-by-one (interactively). Note \ud83d\udce2 You will need to have allow media deletion: enabled ticked. here Details Project home Docs Github","title":"What is it?"},{"location":"sandbox/apps/plex_dupefinder/#1-installation","text":"sb install sandbox-plex_dupefinder","title":"1. Installation"},{"location":"sandbox/apps/plex_dupefinder/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"sandbox/apps/plex_patrol/","text":"plex_patrol \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 plex_patrol is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-plex_patrol 2. URL \u00b6 To access plex_patrol, visit https://plex_patrol._yourdomain.com_ 3. Usage \u00b6 Instructions for plex_patrol","title":"plex_patrol"},{"location":"sandbox/apps/plex_patrol/#plex_patrol","text":"","title":"plex_patrol"},{"location":"sandbox/apps/plex_patrol/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/plex_patrol/#what-is-it","text":"plex_patrol is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/plex_patrol/#1-installation","text":"sb install sandbox-plex_patrol","title":"1. Installation"},{"location":"sandbox/apps/plex_patrol/#2-url","text":"To access plex_patrol, visit https://plex_patrol._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/plex_patrol/#3-usage","text":"Instructions for plex_patrol","title":"3. Usage"},{"location":"sandbox/apps/plex_utills/","text":"plex_utills \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 plex_utills is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-plex_utills 2. URL \u00b6 To access plex_utills, visit https://plex_utills._yourdomain.com_ 3. Usage \u00b6 Instructions for plex_utills","title":"plex_utills"},{"location":"sandbox/apps/plex_utills/#plex_utills","text":"","title":"plex_utills"},{"location":"sandbox/apps/plex_utills/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/plex_utills/#what-is-it","text":"plex_utills is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/plex_utills/#1-installation","text":"sb install sandbox-plex_utills","title":"1. Installation"},{"location":"sandbox/apps/plex_utills/#2-url","text":"To access plex_utills, visit https://plex_utills._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/plex_utills/#3-usage","text":"Instructions for plex_utills","title":"3. Usage"},{"location":"sandbox/apps/plextraktsync/","text":"PlexTraktSync \u00b6 What is it? \u00b6 PlexTraktSync adds a two-way-sync between trakt.tv and Plex Media Server. It requires a trakt.tv account but no Plex premium and no Trakt VIP subscriptions, unlike the Plex app provided by Trakt. Details Github Recommended install types: Mediabox, Saltbox 1. Installation \u00b6 sb install sandbox-plextraktsync 2. Setup \u00b6 Set your general preferences in /opt/plextraktsync/config.yml . The following command will launch an interactive script prompting you for missing credentials (use this to set up Trakt.tv): docker exec -it plextraktsync python3 -m plextraktsync login By default, the target Plex server is set to your main Plex Saltbox instance, and the sync user is set to that server's owner account. If you wish to reset this, run: docker exec -it plextraktsync python3 -m plextraktsync plex-login Most of these fields can be manually edited in /opt/plextraktsync/.env . 3. Usage \u00b6 By default, the PlexTraktSync instance's only assignment is to listen to your configured user's Plex activity and scrobble it. You may also wish to sync your backlog on a schedule, for example, by adding a crontab line containing docker exec plextraktsync python3 -m plextraktsync . To get a list of commands, run: docker exec -it plextraktsync python3 -m plextraktsync --help","title":"PlexTraktSync"},{"location":"sandbox/apps/plextraktsync/#plextraktsync","text":"","title":"PlexTraktSync"},{"location":"sandbox/apps/plextraktsync/#what-is-it","text":"PlexTraktSync adds a two-way-sync between trakt.tv and Plex Media Server. It requires a trakt.tv account but no Plex premium and no Trakt VIP subscriptions, unlike the Plex app provided by Trakt. Details Github Recommended install types: Mediabox, Saltbox","title":"What is it?"},{"location":"sandbox/apps/plextraktsync/#1-installation","text":"sb install sandbox-plextraktsync","title":"1. Installation"},{"location":"sandbox/apps/plextraktsync/#2-setup","text":"Set your general preferences in /opt/plextraktsync/config.yml . The following command will launch an interactive script prompting you for missing credentials (use this to set up Trakt.tv): docker exec -it plextraktsync python3 -m plextraktsync login By default, the target Plex server is set to your main Plex Saltbox instance, and the sync user is set to that server's owner account. If you wish to reset this, run: docker exec -it plextraktsync python3 -m plextraktsync plex-login Most of these fields can be manually edited in /opt/plextraktsync/.env .","title":"2. Setup"},{"location":"sandbox/apps/plextraktsync/#3-usage","text":"By default, the PlexTraktSync instance's only assignment is to listen to your configured user's Plex activity and scrobble it. You may also wish to sync your backlog on a schedule, for example, by adding a crontab line containing docker exec plextraktsync python3 -m plextraktsync . To get a list of commands, run: docker exec -it plextraktsync python3 -m plextraktsync --help","title":"3. Usage"},{"location":"sandbox/apps/privatebin/","text":"PrivateBin \u00b6 What is it? \u00b6 PrivateBin PrivateBin is a minimalist, open source online pastebin where the server has zero knowledge of pasted data. It's privacy-preserving and encrypted-by-default. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-privatebin 2. URL \u00b6 To access PrivateBin, visit https://privatebin._yourdomain.com_ 3. Setup \u00b6 Documentation Edit /opt/privatebin/conf.php to customize your instance.","title":"PrivateBin"},{"location":"sandbox/apps/privatebin/#privatebin","text":"","title":"PrivateBin"},{"location":"sandbox/apps/privatebin/#what-is-it","text":"PrivateBin PrivateBin is a minimalist, open source online pastebin where the server has zero knowledge of pasted data. It's privacy-preserving and encrypted-by-default. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/privatebin/#1-installation","text":"sb install sandbox-privatebin","title":"1. Installation"},{"location":"sandbox/apps/privatebin/#2-url","text":"To access PrivateBin, visit https://privatebin._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/privatebin/#3-setup","text":"Documentation Edit /opt/privatebin/conf.php to customize your instance.","title":"3. Setup"},{"location":"sandbox/apps/puddletag/","text":"Puddletag \u00b6 What is it? \u00b6 Puddletag is an audio tag editor (primarily created) for GNU/Linux similar to the Windows program, Mp3tag. Unlike most taggers for GNU/Linux, it uses a spreadsheet-like layout so that all the tags you want to edit by hand are visible and easily editable. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. (Basic Auth) Details Project home Docs Github 1. Installation \u00b6 sb install sandbox-puddletag 2. URL \u00b6 To access Puddletag, visit https://puddletag._yourdomain.com_ 3. Setup \u00b6 Default login: Username : \"your user from accounts.yml\" Password : your_normal_password Documentation: Puddletag Docs","title":"Puddletag"},{"location":"sandbox/apps/puddletag/#puddletag","text":"","title":"Puddletag"},{"location":"sandbox/apps/puddletag/#what-is-it","text":"Puddletag is an audio tag editor (primarily created) for GNU/Linux similar to the Windows program, Mp3tag. Unlike most taggers for GNU/Linux, it uses a spreadsheet-like layout so that all the tags you want to edit by hand are visible and easily editable. Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. (Basic Auth) Details Project home Docs Github","title":"What is it?"},{"location":"sandbox/apps/puddletag/#1-installation","text":"sb install sandbox-puddletag","title":"1. Installation"},{"location":"sandbox/apps/puddletag/#2-url","text":"To access Puddletag, visit https://puddletag._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/puddletag/#3-setup","text":"Default login: Username : \"your user from accounts.yml\" Password : your_normal_password Documentation: Puddletag Docs","title":"3. Setup"},{"location":"sandbox/apps/pyload/","text":"pyload \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 pyload is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-pyload 2. URL \u00b6 To access pyload, visit https://pyload._yourdomain.com_ 3. Usage \u00b6 Instructions for pyload","title":"pyload"},{"location":"sandbox/apps/pyload/#pyload","text":"","title":"pyload"},{"location":"sandbox/apps/pyload/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/pyload/#what-is-it","text":"pyload is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/pyload/#1-installation","text":"sb install sandbox-pyload","title":"1. Installation"},{"location":"sandbox/apps/pyload/#2-url","text":"To access pyload, visit https://pyload._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/pyload/#3-usage","text":"Instructions for pyload","title":"3. Usage"},{"location":"sandbox/apps/python-plexlibrary/","text":"python-plexlibrary \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 python-plexlibrary is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-python-plexlibrary 2. URL \u00b6 To access python-plexlibrary, visit https://python-plexlibrary._yourdomain.com_ 3. Usage \u00b6 Instructions for python-plexlibrary","title":"python-plexlibrary"},{"location":"sandbox/apps/python-plexlibrary/#python-plexlibrary","text":"","title":"python-plexlibrary"},{"location":"sandbox/apps/python-plexlibrary/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/python-plexlibrary/#what-is-it","text":"python-plexlibrary is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/python-plexlibrary/#1-installation","text":"sb install sandbox-python-plexlibrary","title":"1. Installation"},{"location":"sandbox/apps/python-plexlibrary/#2-url","text":"To access python-plexlibrary, visit https://python-plexlibrary._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/python-plexlibrary/#3-usage","text":"Instructions for python-plexlibrary","title":"3. Usage"},{"location":"sandbox/apps/qbit_manage/","text":"qBit Management \u00b6 What is it? \u00b6 qBit Management is a program used to manage your qBittorrent instance. Details qBit Management Docs Github Docker: Functions include:- Tag torrents based on tracker and then set seed goals/limit upload speed by tag. Update categories based on save directory. Remove unregistered torrents (delete data & torrent if it is not being cross-seeded, otherwise it will just remove the torrent). Automatically add cross-seed torrents in paused state. Note: cross-seed now allows for torrent injections directly to qBit, making this feature obsolete. Recheck paused torrents sorted by lowest size and resume if completed. Remove orphaned files from your root directory that are not referenced by qBittorrent. Tag any torrents that have no hard links and allows optional cleanup to delete these torrents and contents based on maximum ratio and/or time seeded. RecycleBin function to move files into a RecycleBin folder instead of deleting the data directly when deleting a torrent. Built-in scheduler to run the script every x minutes. (Can use --run command to run without the scheduler). Webhook notifications with Notifiarr and Apprise API integration. 1. Installation \u00b6 Before installing qBit Management, you should have a qBittorrent instance running on your local machine. sb install sandbox-qbit_manage After installation has finished, stop the qbit_manage docker container and edit the config file that will have been created at /opt/qbit_manage/config.yml docker stop qbit_manage Minimally you will need to change the following items in order to connect with your qBittorrent instance:- qbt : host : \"qbittorrent:8080\" user : \"qbittorrent_username\" pass : \"qbittorrent_password\" directory : cross_seed : \"/your/path/here/\" root_dir : \"/mnt/unionfs/downloads/torrents/qbittorrent/completed/\" remote_dir : \"/mnt/unionfs/torrents/your/path/here/\" An indepth explanation of the config file settings can be found here. The config file is full of examples that more than likely will not work for you, sections you aren't using can be safely commented out or left blank. An up to date example configuration file can be found here when you wish to add newer features or restore a self mangled section. YAML spacing matters. After making adjustments to the config file, you can start the docker container again. docker start qbit_manage Either tail the log ( tail -f \"/opt/qbit_manage/activity.log\" ) or open the log file after a few minutes to check for any errors or behaviour that may have been unexpected. The container has been deliberately set to DRY RUN MODE initially so you can see what the script will do without actually moving deleting, tagging, or categorising anything.. Once you are happy your life's work will not be destroyed and any errors have been resolved you can edit the qbit_manage variables in the sandbox settings.yml file and then run the role again. Set qbt_dry_run: false to run in live mode. This will delete and move files according to your settings. Apply the changes to the sandbox settings file with: sb install sandbox-qbit_manage 3. Setup \u00b6 The following variables are available to set in the sandbox settings.yml file. An explanation of these settings can be found here . qbit_manage : qbt_run : \"false\" # Default is \"false\" qbt_schedule : \"30\" # Default is \"30\" qbt_config : \"config.yml\" # Default is \"config.yml\" qbt_logfile : \"activity.log\" # Default is \"activity.log\" qbt_cross_seed : \"false\" # Default is \"false\" qbt_recheck : \"false\" # Default is \"false\" qbt_cat_update : \"false\" # Default is \"false\" qbt_tag_update : \"false\" # Default is \"false\" qbt_rem_unregistered : \"false\" # Default is \"false\" qbt_rem_orphaned : \"false\" # Default is \"false\" qbt_tag_nohardlinks : \"false\" # Default is \"false\" qbt_skip_recycle : \"false\" # Default is \"false\" qbt_dry_run : \"true\" # Default is \"false\" qbt_log_level : \"INFO\" # Default is \"INFO\" qbt_divider : \"=\" # Default is \"=\" qbt_width : \"100\" # Default is \"100\" Documentation: qBit Management Docs","title":"qBit Management"},{"location":"sandbox/apps/qbit_manage/#qbit-management","text":"","title":"qBit Management"},{"location":"sandbox/apps/qbit_manage/#what-is-it","text":"qBit Management is a program used to manage your qBittorrent instance. Details qBit Management Docs Github Docker: Functions include:- Tag torrents based on tracker and then set seed goals/limit upload speed by tag. Update categories based on save directory. Remove unregistered torrents (delete data & torrent if it is not being cross-seeded, otherwise it will just remove the torrent). Automatically add cross-seed torrents in paused state. Note: cross-seed now allows for torrent injections directly to qBit, making this feature obsolete. Recheck paused torrents sorted by lowest size and resume if completed. Remove orphaned files from your root directory that are not referenced by qBittorrent. Tag any torrents that have no hard links and allows optional cleanup to delete these torrents and contents based on maximum ratio and/or time seeded. RecycleBin function to move files into a RecycleBin folder instead of deleting the data directly when deleting a torrent. Built-in scheduler to run the script every x minutes. (Can use --run command to run without the scheduler). Webhook notifications with Notifiarr and Apprise API integration.","title":"What is it?"},{"location":"sandbox/apps/qbit_manage/#1-installation","text":"Before installing qBit Management, you should have a qBittorrent instance running on your local machine. sb install sandbox-qbit_manage After installation has finished, stop the qbit_manage docker container and edit the config file that will have been created at /opt/qbit_manage/config.yml docker stop qbit_manage Minimally you will need to change the following items in order to connect with your qBittorrent instance:- qbt : host : \"qbittorrent:8080\" user : \"qbittorrent_username\" pass : \"qbittorrent_password\" directory : cross_seed : \"/your/path/here/\" root_dir : \"/mnt/unionfs/downloads/torrents/qbittorrent/completed/\" remote_dir : \"/mnt/unionfs/torrents/your/path/here/\" An indepth explanation of the config file settings can be found here. The config file is full of examples that more than likely will not work for you, sections you aren't using can be safely commented out or left blank. An up to date example configuration file can be found here when you wish to add newer features or restore a self mangled section. YAML spacing matters. After making adjustments to the config file, you can start the docker container again. docker start qbit_manage Either tail the log ( tail -f \"/opt/qbit_manage/activity.log\" ) or open the log file after a few minutes to check for any errors or behaviour that may have been unexpected. The container has been deliberately set to DRY RUN MODE initially so you can see what the script will do without actually moving deleting, tagging, or categorising anything.. Once you are happy your life's work will not be destroyed and any errors have been resolved you can edit the qbit_manage variables in the sandbox settings.yml file and then run the role again. Set qbt_dry_run: false to run in live mode. This will delete and move files according to your settings. Apply the changes to the sandbox settings file with: sb install sandbox-qbit_manage","title":"1. Installation"},{"location":"sandbox/apps/qbit_manage/#3-setup","text":"The following variables are available to set in the sandbox settings.yml file. An explanation of these settings can be found here . qbit_manage : qbt_run : \"false\" # Default is \"false\" qbt_schedule : \"30\" # Default is \"30\" qbt_config : \"config.yml\" # Default is \"config.yml\" qbt_logfile : \"activity.log\" # Default is \"activity.log\" qbt_cross_seed : \"false\" # Default is \"false\" qbt_recheck : \"false\" # Default is \"false\" qbt_cat_update : \"false\" # Default is \"false\" qbt_tag_update : \"false\" # Default is \"false\" qbt_rem_unregistered : \"false\" # Default is \"false\" qbt_rem_orphaned : \"false\" # Default is \"false\" qbt_tag_nohardlinks : \"false\" # Default is \"false\" qbt_skip_recycle : \"false\" # Default is \"false\" qbt_dry_run : \"true\" # Default is \"false\" qbt_log_level : \"INFO\" # Default is \"INFO\" qbt_divider : \"=\" # Default is \"=\" qbt_width : \"100\" # Default is \"100\" Documentation: qBit Management Docs","title":"3. Setup"},{"location":"sandbox/apps/qbittorrentvpn/","text":"qbittorrentvpn \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 qbittorrentvpn is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-qbittorrentvpn 2. URL \u00b6 To access qbittorrentvpn, visit https://qbittorrentvpn._yourdomain.com_ 3. Usage \u00b6 Instructions for qbittorrentvpn","title":"qbittorrentvpn"},{"location":"sandbox/apps/qbittorrentvpn/#qbittorrentvpn","text":"","title":"qbittorrentvpn"},{"location":"sandbox/apps/qbittorrentvpn/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/qbittorrentvpn/#what-is-it","text":"qbittorrentvpn is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/qbittorrentvpn/#1-installation","text":"sb install sandbox-qbittorrentvpn","title":"1. Installation"},{"location":"sandbox/apps/qbittorrentvpn/#2-url","text":"To access qbittorrentvpn, visit https://qbittorrentvpn._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/qbittorrentvpn/#3-usage","text":"Instructions for qbittorrentvpn","title":"3. Usage"},{"location":"sandbox/apps/rdtclient/","text":"rdtclient \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 rdtclient is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-rdtclient 2. URL \u00b6 To access rdtclient, visit https://rdtclient._yourdomain.com_ 3. Usage \u00b6 Instructions for rdtclient","title":"rdtclient"},{"location":"sandbox/apps/rdtclient/#rdtclient","text":"","title":"rdtclient"},{"location":"sandbox/apps/rdtclient/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/rdtclient/#what-is-it","text":"rdtclient is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/rdtclient/#1-installation","text":"sb install sandbox-rdtclient","title":"1. Installation"},{"location":"sandbox/apps/rdtclient/#2-url","text":"To access rdtclient, visit https://rdtclient._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/rdtclient/#3-usage","text":"Instructions for rdtclient","title":"3. Usage"},{"location":"sandbox/apps/recyclarr/","text":"Recyclarr \u00b6 What is it? \u00b6 Recyclarr automatically synchronizes recommended settings from TRaSH guides to your Sonarr/Radarr instances. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-recyclarr 2. Setup \u00b6 Edit the Recyclarr section in sandbox settings.yml : and enter your desired update schedule using standard cron syntax. recyclarr : cron_schedule : \"@daily\" Edit the file /opt/recyclarr/recyclarr.yml . Configure Sonarr section sonarr : - base_url : http://sonarr:8989 - api_key : your_sonarr_api_key Configure Radarr section radarr : - base_url : http://radarr:7878 - api_key : your_radarr_api_key Danger When running Recyclarr manually via docker exec , ensure you pass your user/group. Example: docker exec --user=$(id -u):$(id -g) recyclarr recyclarr radarr --list-custom-formats Follow documentation to complete configuration Documentation","title":"Recyclarr"},{"location":"sandbox/apps/recyclarr/#recyclarr","text":"","title":"Recyclarr"},{"location":"sandbox/apps/recyclarr/#what-is-it","text":"Recyclarr automatically synchronizes recommended settings from TRaSH guides to your Sonarr/Radarr instances. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/recyclarr/#1-installation","text":"sb install sandbox-recyclarr","title":"1. Installation"},{"location":"sandbox/apps/recyclarr/#2-setup","text":"Edit the Recyclarr section in sandbox settings.yml : and enter your desired update schedule using standard cron syntax. recyclarr : cron_schedule : \"@daily\" Edit the file /opt/recyclarr/recyclarr.yml . Configure Sonarr section sonarr : - base_url : http://sonarr:8989 - api_key : your_sonarr_api_key Configure Radarr section radarr : - base_url : http://radarr:7878 - api_key : your_radarr_api_key Danger When running Recyclarr manually via docker exec , ensure you pass your user/group. Example: docker exec --user=$(id -u):$(id -g) recyclarr recyclarr radarr --list-custom-formats Follow documentation to complete configuration Documentation","title":"2. Setup"},{"location":"sandbox/apps/reposilite/","text":"reposilite \u00b6 What is it? \u00b6 reposilite is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-reposilite 2. URL \u00b6 To access reposilite, visit https://reposilite._yourdomain.com_ 3. Usage \u00b6 Consult the doc","title":"Reposilite"},{"location":"sandbox/apps/reposilite/#reposilite","text":"","title":"reposilite"},{"location":"sandbox/apps/reposilite/#what-is-it","text":"reposilite is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/reposilite/#1-installation","text":"sb install sandbox-reposilite","title":"1. Installation"},{"location":"sandbox/apps/reposilite/#2-url","text":"To access reposilite, visit https://reposilite._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/reposilite/#3-usage","text":"Consult the doc","title":"3. Usage"},{"location":"sandbox/apps/requestrr/","text":"Requestrr \u00b6 What is it? \u00b6 Requestrr is a chatbot used to simplify using services like Sonarr/Radarr/Ombi via the use of chat. Current platform is Discord only, but the bot was built around the ideology of quick adaptation for new features as well as new platforms. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-requestrr 2. URL \u00b6 To access Requestrr, visit https://requestrr._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Requestrr"},{"location":"sandbox/apps/requestrr/#requestrr","text":"","title":"Requestrr"},{"location":"sandbox/apps/requestrr/#what-is-it","text":"Requestrr is a chatbot used to simplify using services like Sonarr/Radarr/Ombi via the use of chat. Current platform is Discord only, but the bot was built around the ideology of quick adaptation for new features as well as new platforms. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/requestrr/#1-installation","text":"sb install sandbox-requestrr","title":"1. Installation"},{"location":"sandbox/apps/requestrr/#2-url","text":"To access Requestrr, visit https://requestrr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/requestrr/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/requestrrx/","text":"Requestrr X \u00b6 What is it? \u00b6 RequestrrX is an arr X role for Requestrr . Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-requestrrx 2. URL \u00b6 To access Requestrr X , visit https://requestrrx._yourdomain.com_ 3. Setup \u00b6 Read through the general arr X role instructions . Add your X instance names to the Requestrr X section in saltbox settings.yml : using a list format as below. requestrrx : roles : - 1080 - 4k Run the Saltbox installer to generate your X instances of requestrr. sb install sandbox-requestrrx For app specific instructions refer to the parent role, requestrr and the requestrr upstream documentation Documentation","title":"Requestrrx"},{"location":"sandbox/apps/requestrrx/#requestrrx","text":"","title":"RequestrrX"},{"location":"sandbox/apps/requestrrx/#what-is-it","text":"RequestrrX is an arr X role for Requestrr . Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/requestrrx/#1-installation","text":"sb install sandbox-requestrrx","title":"1. Installation"},{"location":"sandbox/apps/requestrrx/#2-url","text":"To access Requestrr X , visit https://requestrrx._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/requestrrx/#3-setup","text":"Read through the general arr X role instructions . Add your X instance names to the Requestrr X section in saltbox settings.yml : using a list format as below. requestrrx : roles : - 1080 - 4k Run the Saltbox installer to generate your X instances of requestrr. sb install sandbox-requestrrx For app specific instructions refer to the parent role, requestrr and the requestrr upstream documentation Documentation","title":"3. Setup"},{"location":"sandbox/apps/resilio_sync/","text":"Resilio Sync \u00b6 ! NOT INTEGRATED - MAKE SANDBOX REQUEST IF NEEDED What is it? \u00b6 Resilio Sync uses peer-to-peer technology to provide fast, private file sharing for teams and individuals. By skipping the cloud, transfers can be significantly faster because files take the shortest path between devices. Sync does not store your information on servers in the cloud, avoiding cloud privacy concerns. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-resilio-sync 2. URL \u00b6 To access Resilio Sync, visit https://resilio-sync._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Resilio Sync"},{"location":"sandbox/apps/resilio_sync/#resilio-sync","text":"! NOT INTEGRATED - MAKE SANDBOX REQUEST IF NEEDED","title":"Resilio Sync"},{"location":"sandbox/apps/resilio_sync/#what-is-it","text":"Resilio Sync uses peer-to-peer technology to provide fast, private file sharing for teams and individuals. By skipping the cloud, transfers can be significantly faster because files take the shortest path between devices. Sync does not store your information on servers in the cloud, avoiding cloud privacy concerns. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/resilio_sync/#1-installation","text":"sb install sandbox-resilio-sync","title":"1. Installation"},{"location":"sandbox/apps/resilio_sync/#2-url","text":"To access Resilio Sync, visit https://resilio-sync._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/resilio_sync/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/resiliosync/","text":"Resilio Sync \u00b6 What is it? \u00b6 Resilio Sync uses peer-to-peer technology to provide fast, private file sharing for teams and individuals. By skipping the cloud, transfers can be significantly faster because files take the shortest path between devices. Sync does not store your information on servers in the cloud, avoiding cloud privacy concerns. Details Project home Docs Docker 1. Installation \u00b6 sb install sandbox-resiliosync 2. URL \u00b6 To access Resilio Sync, visit https://resiliosync._yourdomain.com_ 3. Setup \u00b6 Documentation: Resilio Sync Docs Note: The default data port for this container is 55555. Sync will try to use this port for data transfer, if the port is not open Sync will automatically use a relay server to make your connection. For best performance, please ensure this port is opened in your firewall. Sync's data port can be customized by changing the Sync settings as well as adding the following to /srv/git/saltbox/inventories/host_vars/localhost.yml and rerunning the installation tag: yaml resiliosync_data_port: \"#####\"","title":"Resilio Sync"},{"location":"sandbox/apps/resiliosync/#resilio-sync","text":"","title":"Resilio Sync"},{"location":"sandbox/apps/resiliosync/#what-is-it","text":"Resilio Sync uses peer-to-peer technology to provide fast, private file sharing for teams and individuals. By skipping the cloud, transfers can be significantly faster because files take the shortest path between devices. Sync does not store your information on servers in the cloud, avoiding cloud privacy concerns. Details Project home Docs Docker","title":"What is it?"},{"location":"sandbox/apps/resiliosync/#1-installation","text":"sb install sandbox-resiliosync","title":"1. Installation"},{"location":"sandbox/apps/resiliosync/#2-url","text":"To access Resilio Sync, visit https://resiliosync._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/resiliosync/#3-setup","text":"Documentation: Resilio Sync Docs Note: The default data port for this container is 55555. Sync will try to use this port for data transfer, if the port is not open Sync will automatically use a relay server to make your connection. For best performance, please ensure this port is opened in your firewall. Sync's data port can be customized by changing the Sync settings as well as adding the following to /srv/git/saltbox/inventories/host_vars/localhost.yml and rerunning the installation tag: yaml resiliosync_data_port: \"#####\"","title":"3. Setup"},{"location":"sandbox/apps/rflood/","text":"rFlood \u00b6 What is it? \u00b6 rFlood docker image with rTorrent and the Flood UI, also optional WireGuard VPN support. Project Information \u00b6 rFlood Docs Github rTorrent: Github Flood: Docker: 1. Installation \u00b6 sb install sandbox-rflood 2. URL \u00b6 To access rFlood, visit https://rflood._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Rflood"},{"location":"sandbox/apps/rflood/#rflood","text":"","title":"rFlood"},{"location":"sandbox/apps/rflood/#what-is-it","text":"rFlood docker image with rTorrent and the Flood UI, also optional WireGuard VPN support.","title":"What is it?"},{"location":"sandbox/apps/rflood/#project-information","text":"rFlood Docs Github rTorrent: Github Flood: Docker:","title":"Project Information"},{"location":"sandbox/apps/rflood/#1-installation","text":"sb install sandbox-rflood","title":"1. Installation"},{"location":"sandbox/apps/rflood/#2-url","text":"To access rFlood, visit https://rflood._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/rflood/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/rfloodx/","text":"rFlood X \u00b6 What is it? \u00b6 rFloodX is an arr X role for rFlood . Project Information \u00b6 rFlood Docs Github rTorrent: Github Flood: Docker: 1. Installation \u00b6 sb install sandbox-rfloodx 2. URL \u00b6 To access rFlood X , visit https://rfloodx._yourdomain.com_ 3. Setup \u00b6 Read through the general arr X role instructions . Add your X instance names to the rFlood X section in saltbox settings.yml : using a list format as below. rfloodx : roles : - linuxisos - anime Run the Saltbox installer to generate your X instances of rflood. sb install sandbox-rfloodx For app specific instructions refer to the parent role, rflood and the rflood upstream documentation Documentation","title":"Rfloodx"},{"location":"sandbox/apps/rfloodx/#rfloodx","text":"","title":"rFloodX"},{"location":"sandbox/apps/rfloodx/#what-is-it","text":"rFloodX is an arr X role for rFlood .","title":"What is it?"},{"location":"sandbox/apps/rfloodx/#project-information","text":"rFlood Docs Github rTorrent: Github Flood: Docker:","title":"Project Information"},{"location":"sandbox/apps/rfloodx/#1-installation","text":"sb install sandbox-rfloodx","title":"1. Installation"},{"location":"sandbox/apps/rfloodx/#2-url","text":"To access rFlood X , visit https://rfloodx._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/rfloodx/#3-setup","text":"Read through the general arr X role instructions . Add your X instance names to the rFlood X section in saltbox settings.yml : using a list format as below. rfloodx : roles : - linuxisos - anime Run the Saltbox installer to generate your X instances of rflood. sb install sandbox-rfloodx For app specific instructions refer to the parent role, rflood and the rflood upstream documentation Documentation","title":"3. Setup"},{"location":"sandbox/apps/rocketchat/","text":"rocketchat \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 rocketchat is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-rocketchat 2. URL \u00b6 To access rocketchat, visit https://rocketchat._yourdomain.com_ 3. Usage \u00b6 Instructions for rocketchat","title":"rocketchat"},{"location":"sandbox/apps/rocketchat/#rocketchat","text":"","title":"rocketchat"},{"location":"sandbox/apps/rocketchat/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/rocketchat/#what-is-it","text":"rocketchat is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/rocketchat/#1-installation","text":"sb install sandbox-rocketchat","title":"1. Installation"},{"location":"sandbox/apps/rocketchat/#2-url","text":"To access rocketchat, visit https://rocketchat._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/rocketchat/#3-usage","text":"Instructions for rocketchat","title":"3. Usage"},{"location":"sandbox/apps/sabthrottle/","text":"SABThrottle \u00b6 What is it? \u00b6 SABThrottle Sabthrottle was designed in order to dynamically control the bandwidth allocation when users are actively streaming from Plex to avoid unnecessary buffering while still allowing the user to download at the fastest rate possible. Remember nzbthrottle from daghaian, yes its exactly like that but for SABnzbd with some additional tweaks. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-sabthrottle 2. Setup \u00b6 See documentation for configuration and instructions see the sample configuration and description below it. Running the role will autopopulate plex token and plex url. If you require more then 5 stream count just follow the example and add more using proper yml formatting. You can always check logs via docker logs -f sabthrottle Documentation","title":"sabthrottle"},{"location":"sandbox/apps/sabthrottle/#sabthrottle","text":"","title":"SABThrottle"},{"location":"sandbox/apps/sabthrottle/#what-is-it","text":"SABThrottle Sabthrottle was designed in order to dynamically control the bandwidth allocation when users are actively streaming from Plex to avoid unnecessary buffering while still allowing the user to download at the fastest rate possible. Remember nzbthrottle from daghaian, yes its exactly like that but for SABnzbd with some additional tweaks. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/sabthrottle/#1-installation","text":"sb install sandbox-sabthrottle","title":"1. Installation"},{"location":"sandbox/apps/sabthrottle/#2-setup","text":"See documentation for configuration and instructions see the sample configuration and description below it. Running the role will autopopulate plex token and plex url. If you require more then 5 stream count just follow the example and add more using proper yml formatting. You can always check logs via docker logs -f sabthrottle Documentation","title":"2. Setup"},{"location":"sandbox/apps/sarotate/","text":"sarotate \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 sarotate is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-sarotate 2. URL \u00b6 To access sarotate, visit https://sarotate._yourdomain.com_ 3. Usage \u00b6 Instructions for sarotate","title":"sarotate"},{"location":"sandbox/apps/sarotate/#sarotate","text":"","title":"sarotate"},{"location":"sandbox/apps/sarotate/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/sarotate/#what-is-it","text":"sarotate is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/sarotate/#1-installation","text":"sb install sandbox-sarotate","title":"1. Installation"},{"location":"sandbox/apps/sarotate/#2-url","text":"To access sarotate, visit https://sarotate._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/sarotate/#3-usage","text":"Instructions for sarotate","title":"3. Usage"},{"location":"sandbox/apps/speedtest/","text":"Speedtest \u00b6 What is it? \u00b6 Speedtest is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-speedtest 2. URL \u00b6 To access Speedtest, visit https://speedtest._yourdomain.com_ 3. Setup \u00b6 Documentation To use a custom domain, add a custom value for speedtest_web_subdomain in the /srv/git/saltbox/inventories/host_vars/localhost.yml file. More info can be found here .","title":"speedtest"},{"location":"sandbox/apps/speedtest/#speedtest","text":"","title":"Speedtest"},{"location":"sandbox/apps/speedtest/#what-is-it","text":"Speedtest is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/speedtest/#1-installation","text":"sb install sandbox-speedtest","title":"1. Installation"},{"location":"sandbox/apps/speedtest/#2-url","text":"To access Speedtest, visit https://speedtest._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/speedtest/#3-setup","text":"Documentation To use a custom domain, add a custom value for speedtest_web_subdomain in the /srv/git/saltbox/inventories/host_vars/localhost.yml file. More info can be found here .","title":"3. Setup"},{"location":"sandbox/apps/sqlitebrowser/","text":"SQLite Browser \u00b6 What is it? \u00b6 SQLite Browser is a high quality, visual, open source tool to create, design, and edit database files compatible with SQLite. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-sqlitebrowser 2. URL \u00b6 To access SQLite Browser, visit https://sqlitebrowser._yourdomain.com_ By default, the role is protected behind your Authelia/SSO middleware. 3. Setup \u00b6 Documentation: SQLite Browser Docs","title":"sqlitebrowser"},{"location":"sandbox/apps/sqlitebrowser/#sqlite-browser","text":"","title":"SQLite Browser"},{"location":"sandbox/apps/sqlitebrowser/#what-is-it","text":"SQLite Browser is a high quality, visual, open source tool to create, design, and edit database files compatible with SQLite. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/sqlitebrowser/#1-installation","text":"sb install sandbox-sqlitebrowser","title":"1. Installation"},{"location":"sandbox/apps/sqlitebrowser/#2-url","text":"To access SQLite Browser, visit https://sqlitebrowser._yourdomain.com_ By default, the role is protected behind your Authelia/SSO middleware.","title":"2. URL"},{"location":"sandbox/apps/sqlitebrowser/#3-setup","text":"Documentation: SQLite Browser Docs","title":"3. Setup"},{"location":"sandbox/apps/sshwifty/","text":"Sshwifty \u00b6 What is it? \u00b6 Sshwifty is an SSH and Telnet connector made for the Web. It can be deployed on your computer or server to provide SSH and Telnet access interface for any compatible (standard) web browser. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-sshwifty 2. URL \u00b6 To access Sshwifty, visit https://sshwifty._yourdomain.com_ 3. Setup \u00b6 The pre-configured password is taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"sshwifty"},{"location":"sandbox/apps/sshwifty/#sshwifty","text":"","title":"Sshwifty"},{"location":"sandbox/apps/sshwifty/#what-is-it","text":"Sshwifty is an SSH and Telnet connector made for the Web. It can be deployed on your computer or server to provide SSH and Telnet access interface for any compatible (standard) web browser. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/sshwifty/#1-installation","text":"sb install sandbox-sshwifty","title":"1. Installation"},{"location":"sandbox/apps/sshwifty/#2-url","text":"To access Sshwifty, visit https://sshwifty._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/sshwifty/#3-setup","text":"The pre-configured password is taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Documentation","title":"3. Setup"},{"location":"sandbox/apps/stash/","text":"Stash \u00b6 What is it? \u00b6 Stash is a locally hosted web-based app written in Go which organizes and serves your porn. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-stash 2. URL \u00b6 To access Stash, visit https://stash._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"stash"},{"location":"sandbox/apps/stash/#stash","text":"","title":"Stash"},{"location":"sandbox/apps/stash/#what-is-it","text":"Stash is a locally hosted web-based app written in Go which organizes and serves your porn. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/stash/#1-installation","text":"sb install sandbox-stash","title":"1. Installation"},{"location":"sandbox/apps/stash/#2-url","text":"To access Stash, visit https://stash._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/stash/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/syncthing/","text":"Syncthing \u00b6 What is it? \u00b6 Syncthing is a continuous file synchronization program. It synchronizes files between two or more computers in real time, safely protected from prying eyes. Your data is your data alone and you deserve to choose where it is stored, whether it is shared with some third party, and how it's transmitted over the internet. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-syncthing 2. URL \u00b6 To access the Syncthing dashboard, visit https://syncthing._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"SyncThing"},{"location":"sandbox/apps/syncthing/#syncthing","text":"","title":"Syncthing"},{"location":"sandbox/apps/syncthing/#what-is-it","text":"Syncthing is a continuous file synchronization program. It synchronizes files between two or more computers in real time, safely protected from prying eyes. Your data is your data alone and you deserve to choose where it is stored, whether it is shared with some third party, and how it's transmitted over the internet. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/syncthing/#1-installation","text":"sb install sandbox-syncthing","title":"1. Installation"},{"location":"sandbox/apps/syncthing/#2-url","text":"To access the Syncthing dashboard, visit https://syncthing._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/syncthing/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/tandoor/","text":"Tandoor Recipes \u00b6 What is it? \u00b6 Tandoor Recipes is an application for managing recipes, planning meals, building shopping lists and much much more!. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-tandoor 2. URL \u00b6 To access Tandoor, visit https://tandoor._yourdomain.com_ 3. Setup \u00b6 Documentation To use a custom domain, add a custom value for tandoor_web_subdomain in the /srv/git/saltbox/inventories/host_vars/localhost.yml file. More info can be found here .","title":"Tandoor Recipes"},{"location":"sandbox/apps/tandoor/#tandoor-recipes","text":"","title":"Tandoor Recipes"},{"location":"sandbox/apps/tandoor/#what-is-it","text":"Tandoor Recipes is an application for managing recipes, planning meals, building shopping lists and much much more!. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/tandoor/#1-installation","text":"sb install sandbox-tandoor","title":"1. Installation"},{"location":"sandbox/apps/tandoor/#2-url","text":"To access Tandoor, visit https://tandoor._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/tandoor/#3-setup","text":"Documentation To use a custom domain, add a custom value for tandoor_web_subdomain in the /srv/git/saltbox/inventories/host_vars/localhost.yml file. More info can be found here .","title":"3. Setup"},{"location":"sandbox/apps/tdarr/","text":"Tdarr \u00b6 What is it? \u00b6 Tdarr is a cross-platform conditional based transcoding application for automating media library transcode/remux management in order to process your media files as required. For example, you can set rules for the required codecs, containers, languages etc that your media should have which helps keeps things organized and can increase compatability with your devices. A common use for Tdarr is to simply convert video files from h264 to h265 (hevc), saving 40%-50% in size. Info By default, the role is protected behind your Authelia/SSO middleware. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-tdarr 2. URL \u00b6 To access Tdarr, visit https://tdarr._yourdomain.com_ 3. Setup \u00b6 Documentation: Tdarr Docs","title":"Tdarr"},{"location":"sandbox/apps/tdarr/#tdarr","text":"","title":"Tdarr"},{"location":"sandbox/apps/tdarr/#what-is-it","text":"Tdarr is a cross-platform conditional based transcoding application for automating media library transcode/remux management in order to process your media files as required. For example, you can set rules for the required codecs, containers, languages etc that your media should have which helps keeps things organized and can increase compatability with your devices. A common use for Tdarr is to simply convert video files from h264 to h265 (hevc), saving 40%-50% in size. Info By default, the role is protected behind your Authelia/SSO middleware. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/tdarr/#1-installation","text":"sb install sandbox-tdarr","title":"1. Installation"},{"location":"sandbox/apps/tdarr/#2-url","text":"To access Tdarr, visit https://tdarr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/tdarr/#3-setup","text":"Documentation: Tdarr Docs","title":"3. Setup"},{"location":"sandbox/apps/tdarr_node/","text":"Tdarr Node \u00b6 What is it? \u00b6 Tdarr Node is a cross-platform conditional based transcoding application for automating media library transcode/remux management in order to process your media files as required. Node is described as: Processes running same/other devices which collect tasks from the Server. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-tdarr_node 2. Usage \u00b6 The Tdarr Node is configured with the following defaults which can be modified via the inventory system. tdarr_node_server_ip : \"tdarr\" tdarr_node_server_port : \"8266\" tdarr_node_node_id : \"MainNode\" tdarr_node_node_ip : \"0.0.0.0\" tdarr_node_node_port : \"8267\" tdarr_node_external : false By switching tdarr_node_external to true the node will be accessible externally via the specified tdarr_node_node_port on any hostname or IP address pointing to the server. 3. Setup \u00b6 Documentation: Tdarr Node Docs","title":"Tdarr Node"},{"location":"sandbox/apps/tdarr_node/#tdarr-node","text":"","title":"Tdarr Node"},{"location":"sandbox/apps/tdarr_node/#what-is-it","text":"Tdarr Node is a cross-platform conditional based transcoding application for automating media library transcode/remux management in order to process your media files as required. Node is described as: Processes running same/other devices which collect tasks from the Server. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/tdarr_node/#1-installation","text":"sb install sandbox-tdarr_node","title":"1. Installation"},{"location":"sandbox/apps/tdarr_node/#2-usage","text":"The Tdarr Node is configured with the following defaults which can be modified via the inventory system. tdarr_node_server_ip : \"tdarr\" tdarr_node_server_port : \"8266\" tdarr_node_node_id : \"MainNode\" tdarr_node_node_ip : \"0.0.0.0\" tdarr_node_node_port : \"8267\" tdarr_node_external : false By switching tdarr_node_external to true the node will be accessible externally via the specified tdarr_node_node_port on any hostname or IP address pointing to the server.","title":"2. Usage"},{"location":"sandbox/apps/tdarr_node/#3-setup","text":"Documentation: Tdarr Node Docs","title":"3. Setup"},{"location":"sandbox/apps/teamspeak/","text":"teamspeak \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 teamspeak is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-teamspeak 2. URL \u00b6 To access teamspeak, visit https://teamspeak._yourdomain.com_ 3. Usage \u00b6 Instructions for teamspeak","title":"teamspeak"},{"location":"sandbox/apps/teamspeak/#teamspeak","text":"","title":"teamspeak"},{"location":"sandbox/apps/teamspeak/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/teamspeak/#what-is-it","text":"teamspeak is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/teamspeak/#1-installation","text":"sb install sandbox-teamspeak","title":"1. Installation"},{"location":"sandbox/apps/teamspeak/#2-url","text":"To access teamspeak, visit https://teamspeak._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/teamspeak/#3-usage","text":"Instructions for teamspeak","title":"3. Usage"},{"location":"sandbox/apps/telegraf/","text":"Telegraf \u00b6 What is it? \u00b6 Telegraf is a plugin-driven server agent for collecting and sending metrics and events from databases, systems, and IoT sensors. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-telegraf 2. Setup \u00b6 Documentation","title":"Telegraf"},{"location":"sandbox/apps/telegraf/#telegraf","text":"","title":"Telegraf"},{"location":"sandbox/apps/telegraf/#what-is-it","text":"Telegraf is a plugin-driven server agent for collecting and sending metrics and events from databases, systems, and IoT sensors. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/telegraf/#1-installation","text":"sb install sandbox-telegraf","title":"1. Installation"},{"location":"sandbox/apps/telegraf/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"sandbox/apps/thelounge/","text":"The Lounge \u00b6 What is it? \u00b6 The Lounge is a self hosted web IRC client. In private mode, The Lounge acts like a bouncer and a client combined, in order to offer an experience similar to other modern chat applications outside the IRC world. Users can then access and resume their session without being disconnected from their channels. Details The Lounge Docs Github Docker: 1. Installation \u00b6 sb install sandbox-thelounge 2. URL \u00b6 To access The Lounge, visit https://thelounge._yourdomain.com_ 3. Setup \u00b6 When the application first runs, it will populate its /config Stop the container Now from the host, edit /config/config.js, wherever you've mapped it In most cases you want the value public: false to allow named users only Setting the two prefetch values to true improves usability, but uses more storage Once you have the configuration you want, save it and start the container again For each user, run the command docker exec -it thelounge s6-setuidgid abc thelounge add <user> You will be prompted to enter a password that will not be echoed. Saving logs to disk is the default, this consumes more space but allows scrollback. To log in to the application, browse to https://thelounge._yourdomain.com_ You should now be prompted for a username and password on the webinterface. Once logged in, you can add an IRC network. Some defaults are preset for Freenode. ZNC \u00b6 To connect to znc , you need to have a znc server running. A guide to using The Lounge with ZNC can be found here In this image we have a ZNC network defined. To add this network to The Lounge, give it a Name, it does not have to match the ZNC network settings. For the Server, use znc and set the port to 6502 For the Password, enter your ZNC user password Uncheck `Use secure connection (TLS) In the User Preferences section enter your Nick - I would recommend the same Nick as that set in ZNC. For the user name enter the <ZNC username>/<ZNC_Network_Name> . For Real Name, enter your desired <real_name> it does not need to match ZNC Save the network, and it should connect to ZNC. Documentation: The Lounge Docs","title":"The Lounge"},{"location":"sandbox/apps/thelounge/#the-lounge","text":"","title":"The Lounge"},{"location":"sandbox/apps/thelounge/#what-is-it","text":"The Lounge is a self hosted web IRC client. In private mode, The Lounge acts like a bouncer and a client combined, in order to offer an experience similar to other modern chat applications outside the IRC world. Users can then access and resume their session without being disconnected from their channels. Details The Lounge Docs Github Docker:","title":"What is it?"},{"location":"sandbox/apps/thelounge/#1-installation","text":"sb install sandbox-thelounge","title":"1. Installation"},{"location":"sandbox/apps/thelounge/#2-url","text":"To access The Lounge, visit https://thelounge._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/thelounge/#3-setup","text":"When the application first runs, it will populate its /config Stop the container Now from the host, edit /config/config.js, wherever you've mapped it In most cases you want the value public: false to allow named users only Setting the two prefetch values to true improves usability, but uses more storage Once you have the configuration you want, save it and start the container again For each user, run the command docker exec -it thelounge s6-setuidgid abc thelounge add <user> You will be prompted to enter a password that will not be echoed. Saving logs to disk is the default, this consumes more space but allows scrollback. To log in to the application, browse to https://thelounge._yourdomain.com_ You should now be prompted for a username and password on the webinterface. Once logged in, you can add an IRC network. Some defaults are preset for Freenode.","title":"3. Setup"},{"location":"sandbox/apps/thelounge/#znc","text":"To connect to znc , you need to have a znc server running. A guide to using The Lounge with ZNC can be found here In this image we have a ZNC network defined. To add this network to The Lounge, give it a Name, it does not have to match the ZNC network settings. For the Server, use znc and set the port to 6502 For the Password, enter your ZNC user password Uncheck `Use secure connection (TLS) In the User Preferences section enter your Nick - I would recommend the same Nick as that set in ZNC. For the user name enter the <ZNC username>/<ZNC_Network_Name> . For Real Name, enter your desired <real_name> it does not need to match ZNC Save the network, and it should connect to ZNC. Documentation: The Lounge Docs","title":"ZNC"},{"location":"sandbox/apps/tika/","text":"tika \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 tika is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-tika 2. URL \u00b6 To access tika, visit https://tika._yourdomain.com_ 3. Usage \u00b6 Instructions for tika","title":"tika"},{"location":"sandbox/apps/tika/#tika","text":"","title":"tika"},{"location":"sandbox/apps/tika/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/tika/#what-is-it","text":"tika is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/tika/#1-installation","text":"sb install sandbox-tika","title":"1. Installation"},{"location":"sandbox/apps/tika/#2-url","text":"To access tika, visit https://tika._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/tika/#3-usage","text":"Instructions for tika","title":"3. Usage"},{"location":"sandbox/apps/tqm/","text":"tqm \u00b6 What is it? \u00b6 tqm is a CLI tool to manage your torrent client queues. Primary focus is on removing torrents that meet specific criteria. The tqm binary is downloaded and a service and timer file created when the config is identified. Note \ud83d\udce2 You will need to have config.yaml in place ( /opt/tqm/ ) for the role to run successfully. Here is an example config you can grab and fill in with your own details. Details Github Recommended install types: Feederbox, Saltbox, Core 1. Setup \u00b6 Edit in your favorite code editor (with yaml highlighting) or even a unix editor like nano. nano /opt/tqm/config.yaml Modify \"Client\" section \u00b6 Note \ud83d\udce2 As setup for Saltbox, tqm uses this path to find your downloaded files: /mnt/unionfs/downloads/... (see Paths ) Client Example: ... deluge : enabled : false filter : default download_path : /mnt/unionfs/downloads/torrents/deluge free_space_path : /mnt/local/downloads/torrents/deluge download_path_mapping : /downloads/torrents/deluge : /mnt/unionfs/downloads/torrents/deluge host : deluge login : localclient password : password-from-/opt/deluge/auth port : 58846 type : deluge v2 : true qbt : download_path : /mnt/unionfs/downloads/torrents/qbittorrent/completed free_space_path : /mnt/local/downloads/torrents/qbittorrent/completed download_path_mapping : /mnt/unionfs/downloads/torrents/qbittorrent/completed : /mnt/unionfs/downloads/torrents/qbittorrent/completed enabled : true filter : default type : qbittorrent url : http://qbittorrent:8080 user : seed password : super_strong_password ... download_path: Where your downloaded files are stored. free_space_path: Typically the local mergerfs path to show available space. enabled: Set to boolean value (true, false) depending on the client you use. url: Set to the examples equivalent of your client. user: your default user from accounts.yml password: your default password from accounts.yml Modify \"Filter\" section \u00b6 Filter Example: ... filters : default : ignore : - TrackerName contains \"sportscult\" - TrackerStatus contains \"Tracker is down\" - Label contains \"upload\" - Downloaded == false && !IsUnregistered() remove : - IsUnregistered() - Label contains \"-imported\" && TrackerName contains \"avistaz.to\" && (Ratio > 2.0 || SeedingDays >= 21.0) - Label contains \"-imported\" && TrackerName contains \"nebulance.io\" && SeedingDays >= 6.0 - Label in [\"readarr-imported\", \"lidarr-imported\"] && (Ratio > 5.0 || SeedingDays >= 25.0) - Label in [\"autoremove-btn\"] && (Ratio > 3.0 || SeedingDays >= 15.0) ... ignore: Instructs tqm to ignore anything defined. remove: Instructs tqm what files to delete based on what is defined in the filter . Note: There are many ways to do the same thing. Check the language definitions for an explanation here Modify \"Label\" section \u00b6 Label Example: ... label : # Permaseed Animebytes torrents (all must evaluate to true) - name : permaseed-AB update : - SeedingSeconds > 1000.0 - Label contains \"-imported\" - TrackerName contains \"animebytes.tv\" # cleanup btn season packs to autoremove-btn (all must evaluate to true) - name : autoremove-btn update : - Label == \"sonarr-imported\" - TrackerName == \"landof.tv\" - not (Name contains \"1080p\") - len(Files) >= 3 ... Note \ud83d\udce2 tqm will not create a category for you, so be sure to create the category first. If you want the file moved as well, you will need to set Default Torrent Management Mode: Automatic . name: The category (label) you want the torrent changed to. update: Define what is to be moved by tqm. Modify the \"Settings\" file \u00b6 You can edit the settings.yml file in /opt/sandbox/ . The default is qbt , for qbittorrent. If you want to use deluge, change that entry. Once you set your download client, run the role again and it will update the service. Shortened example of settings.yml : ... tandoor : secret_key : tqm : download_client : \"qbt\" # Change this to deluge or whatever you specify in config.yaml transmissionvpn : vpn_user : vpn_pass : vpn_prov : ... 2. Installation \u00b6 sb install sandbox-tqm To check the status of the service, you can run: sudo systemctl status tqm.service You can also follow the logs with: tail -f /opt/tqm/activity.log Documentation","title":"tqm"},{"location":"sandbox/apps/tqm/#tqm","text":"","title":"tqm"},{"location":"sandbox/apps/tqm/#what-is-it","text":"tqm is a CLI tool to manage your torrent client queues. Primary focus is on removing torrents that meet specific criteria. The tqm binary is downloaded and a service and timer file created when the config is identified. Note \ud83d\udce2 You will need to have config.yaml in place ( /opt/tqm/ ) for the role to run successfully. Here is an example config you can grab and fill in with your own details. Details Github Recommended install types: Feederbox, Saltbox, Core","title":"What is it?"},{"location":"sandbox/apps/tqm/#1-setup","text":"Edit in your favorite code editor (with yaml highlighting) or even a unix editor like nano. nano /opt/tqm/config.yaml","title":"1. Setup"},{"location":"sandbox/apps/tqm/#modify-client-section","text":"Note \ud83d\udce2 As setup for Saltbox, tqm uses this path to find your downloaded files: /mnt/unionfs/downloads/... (see Paths ) Client Example: ... deluge : enabled : false filter : default download_path : /mnt/unionfs/downloads/torrents/deluge free_space_path : /mnt/local/downloads/torrents/deluge download_path_mapping : /downloads/torrents/deluge : /mnt/unionfs/downloads/torrents/deluge host : deluge login : localclient password : password-from-/opt/deluge/auth port : 58846 type : deluge v2 : true qbt : download_path : /mnt/unionfs/downloads/torrents/qbittorrent/completed free_space_path : /mnt/local/downloads/torrents/qbittorrent/completed download_path_mapping : /mnt/unionfs/downloads/torrents/qbittorrent/completed : /mnt/unionfs/downloads/torrents/qbittorrent/completed enabled : true filter : default type : qbittorrent url : http://qbittorrent:8080 user : seed password : super_strong_password ... download_path: Where your downloaded files are stored. free_space_path: Typically the local mergerfs path to show available space. enabled: Set to boolean value (true, false) depending on the client you use. url: Set to the examples equivalent of your client. user: your default user from accounts.yml password: your default password from accounts.yml","title":"Modify \"Client\" section"},{"location":"sandbox/apps/tqm/#modify-filter-section","text":"Filter Example: ... filters : default : ignore : - TrackerName contains \"sportscult\" - TrackerStatus contains \"Tracker is down\" - Label contains \"upload\" - Downloaded == false && !IsUnregistered() remove : - IsUnregistered() - Label contains \"-imported\" && TrackerName contains \"avistaz.to\" && (Ratio > 2.0 || SeedingDays >= 21.0) - Label contains \"-imported\" && TrackerName contains \"nebulance.io\" && SeedingDays >= 6.0 - Label in [\"readarr-imported\", \"lidarr-imported\"] && (Ratio > 5.0 || SeedingDays >= 25.0) - Label in [\"autoremove-btn\"] && (Ratio > 3.0 || SeedingDays >= 15.0) ... ignore: Instructs tqm to ignore anything defined. remove: Instructs tqm what files to delete based on what is defined in the filter . Note: There are many ways to do the same thing. Check the language definitions for an explanation here","title":"Modify \"Filter\" section"},{"location":"sandbox/apps/tqm/#modify-label-section","text":"Label Example: ... label : # Permaseed Animebytes torrents (all must evaluate to true) - name : permaseed-AB update : - SeedingSeconds > 1000.0 - Label contains \"-imported\" - TrackerName contains \"animebytes.tv\" # cleanup btn season packs to autoremove-btn (all must evaluate to true) - name : autoremove-btn update : - Label == \"sonarr-imported\" - TrackerName == \"landof.tv\" - not (Name contains \"1080p\") - len(Files) >= 3 ... Note \ud83d\udce2 tqm will not create a category for you, so be sure to create the category first. If you want the file moved as well, you will need to set Default Torrent Management Mode: Automatic . name: The category (label) you want the torrent changed to. update: Define what is to be moved by tqm.","title":"Modify \"Label\" section"},{"location":"sandbox/apps/tqm/#modify-the-settings-file","text":"You can edit the settings.yml file in /opt/sandbox/ . The default is qbt , for qbittorrent. If you want to use deluge, change that entry. Once you set your download client, run the role again and it will update the service. Shortened example of settings.yml : ... tandoor : secret_key : tqm : download_client : \"qbt\" # Change this to deluge or whatever you specify in config.yaml transmissionvpn : vpn_user : vpn_pass : vpn_prov : ...","title":"Modify the \"Settings\" file"},{"location":"sandbox/apps/tqm/#2-installation","text":"sb install sandbox-tqm To check the status of the service, you can run: sudo systemctl status tqm.service You can also follow the logs with: tail -f /opt/tqm/activity.log Documentation","title":"2. Installation"},{"location":"sandbox/apps/traefik_robotstxt/","text":"Robotstxt \u00b6 What is it? \u00b6 Robotstxt is a lightweight http-server, just serving a disallow-robots.txt file using the Zig programming language( https://ziglang.org/ ). Robots.txt basically works like a \u201cNo Trespassing\u201d sign. It actually, tells robots whether we want them to crawl the website or not. With this role, we are disallowing all robots to crawl and avoid indexing in search engines. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-traefik_robotstxt 2. Result \u00b6 HTTP/1.1 200 OK Content-Length: 26 User-agent: * Disallow: / When you want to reach *.yourdomain.tld/robots.txt","title":"Traefik-Robotstxt"},{"location":"sandbox/apps/traefik_robotstxt/#robotstxt","text":"","title":"Robotstxt"},{"location":"sandbox/apps/traefik_robotstxt/#what-is-it","text":"Robotstxt is a lightweight http-server, just serving a disallow-robots.txt file using the Zig programming language( https://ziglang.org/ ). Robots.txt basically works like a \u201cNo Trespassing\u201d sign. It actually, tells robots whether we want them to crawl the website or not. With this role, we are disallowing all robots to crawl and avoid indexing in search engines. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/traefik_robotstxt/#1-installation","text":"sb install sandbox-traefik_robotstxt","title":"1. Installation"},{"location":"sandbox/apps/traefik_robotstxt/#2-result","text":"HTTP/1.1 200 OK Content-Length: 26 User-agent: * Disallow: / When you want to reach *.yourdomain.tld/robots.txt","title":"2. Result"},{"location":"sandbox/apps/transmission/","text":"Transmission \u00b6 What is it? \u00b6 Transmission is a fast, easy, and free BitTorrent client. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-transmission 2. URL \u00b6 To access Transmission, visit https://transmission._yourdomain.com_ 3. Setup \u00b6 Suggested desktop client is Transmission Remote GUI . It is to be set up with ssl enabled on port 443 /watch is hard-coded in the software and not editable from the settings.json, see related issue. To get around this the folder is mounted to /mnt/local/downloads/torrents/transmission{{ rolename }}/watch Do not change the published ports if you want to be connectable. Documentation","title":"Transmission"},{"location":"sandbox/apps/transmission/#transmission","text":"","title":"Transmission"},{"location":"sandbox/apps/transmission/#what-is-it","text":"Transmission is a fast, easy, and free BitTorrent client. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/transmission/#1-installation","text":"sb install sandbox-transmission","title":"1. Installation"},{"location":"sandbox/apps/transmission/#2-url","text":"To access Transmission, visit https://transmission._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/transmission/#3-setup","text":"Suggested desktop client is Transmission Remote GUI . It is to be set up with ssl enabled on port 443 /watch is hard-coded in the software and not editable from the settings.json, see related issue. To get around this the folder is mounted to /mnt/local/downloads/torrents/transmission{{ rolename }}/watch Do not change the published ports if you want to be connectable. Documentation","title":"3. Setup"},{"location":"sandbox/apps/transmissionvpn/","text":"transmissionvpn \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 transmissionvpn is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-transmissionvpn 2. URL \u00b6 To access transmissionvpn, visit https://transmissionvpn._yourdomain.com_ 3. Usage \u00b6 Instructions for transmissionvpn","title":"transmissionvpn"},{"location":"sandbox/apps/transmissionvpn/#transmissionvpn","text":"","title":"transmissionvpn"},{"location":"sandbox/apps/transmissionvpn/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/transmissionvpn/#what-is-it","text":"transmissionvpn is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/transmissionvpn/#1-installation","text":"sb install sandbox-transmissionvpn","title":"1. Installation"},{"location":"sandbox/apps/transmissionvpn/#2-url","text":"To access transmissionvpn, visit https://transmissionvpn._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/transmissionvpn/#3-usage","text":"Instructions for transmissionvpn","title":"3. Usage"},{"location":"sandbox/apps/transmissionx/","text":"Transmission X \u00b6 What is it? \u00b6 Transmission X is an arr X role for Transmission . Transmission is a fast, easy, and free BitTorrent client. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-transmissionx 2. URL \u00b6 To access Transmission X , visit https://transmissionx._yourdomain.com_ 3. Setup \u00b6 Read through the general arr X role instructions . Add your X instance names to the Transmission X section in saltbox settings.yml : using a list format as below. transmissionx : roles : - reality - games Run the Saltbox installer to generate your X instances of transmission. sb install sandbox-transmissionx For app specific instructions refer to the parent role, transmission and the transmission upstream documentation Documentation","title":"Transmissionx"},{"location":"sandbox/apps/transmissionx/#transmissionx","text":"","title":"TransmissionX"},{"location":"sandbox/apps/transmissionx/#what-is-it","text":"Transmission X is an arr X role for Transmission . Transmission is a fast, easy, and free BitTorrent client. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/transmissionx/#1-installation","text":"sb install sandbox-transmissionx","title":"1. Installation"},{"location":"sandbox/apps/transmissionx/#2-url","text":"To access Transmission X , visit https://transmissionx._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/transmissionx/#3-setup","text":"Read through the general arr X role instructions . Add your X instance names to the Transmission X section in saltbox settings.yml : using a list format as below. transmissionx : roles : - reality - games Run the Saltbox installer to generate your X instances of transmission. sb install sandbox-transmissionx For app specific instructions refer to the parent role, transmission and the transmission upstream documentation Documentation","title":"3. Setup"},{"location":"sandbox/apps/trilium/","text":"Trilium Notes \u00b6 What is it? \u00b6 Trilium Notes is a hierarchical note taking application with focus on building large personal knowledge bases. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-trilium 2. URL \u00b6 To access Trilium Notes, visit https://trilium._yourdomain.com_ 3. Documentation \u00b6 Documentation","title":"Trilium Notes"},{"location":"sandbox/apps/trilium/#trilium-notes","text":"","title":"Trilium Notes"},{"location":"sandbox/apps/trilium/#what-is-it","text":"Trilium Notes is a hierarchical note taking application with focus on building large personal knowledge bases. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/trilium/#1-installation","text":"sb install sandbox-trilium","title":"1. Installation"},{"location":"sandbox/apps/trilium/#2-url","text":"To access Trilium Notes, visit https://trilium._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/trilium/#3-documentation","text":"Documentation","title":"3. Documentation"},{"location":"sandbox/apps/tubearchivist/","text":"Tubearchivist \u00b6 What is it? \u00b6 Tubearchivist is a self hosted Youtube media server. Subscribe to your favorite YouTube channels Download Videos using yt-dlp Index and make videos searchable Play videos Keep track of viewed and unviewed videos Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker Recommended install types: Feederbox, Saltbox, Core 1. Installation \u00b6 sb install sandbox-tubearchivist 2. URL \u00b6 To access tubearchivist, visit https://tubearchivist._yourdomain.com_ 3. Setup \u00b6 Default login: Username : \"your user from accounts.yml\" Password : your_normal_password Note Tubearchivist adds the downloaded media to /mnt/unionfs/downloads/tubearchivist/YT_CHANNEL_NAME Documentation: tubearchivist Docs","title":"Tubearchivist"},{"location":"sandbox/apps/tubearchivist/#tubearchivist","text":"","title":"Tubearchivist"},{"location":"sandbox/apps/tubearchivist/#what-is-it","text":"Tubearchivist is a self hosted Youtube media server. Subscribe to your favorite YouTube channels Download Videos using yt-dlp Index and make videos searchable Play videos Keep track of viewed and unviewed videos Info By default, the role is protected behind your Authelia/SSO middleware. You will also have to log into the app itself. Details Project home Docs Github Docker Recommended install types: Feederbox, Saltbox, Core","title":"What is it?"},{"location":"sandbox/apps/tubearchivist/#1-installation","text":"sb install sandbox-tubearchivist","title":"1. Installation"},{"location":"sandbox/apps/tubearchivist/#2-url","text":"To access tubearchivist, visit https://tubearchivist._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/tubearchivist/#3-setup","text":"Default login: Username : \"your user from accounts.yml\" Password : your_normal_password Note Tubearchivist adds the downloaded media to /mnt/unionfs/downloads/tubearchivist/YT_CHANNEL_NAME Documentation: tubearchivist Docs","title":"3. Setup"},{"location":"sandbox/apps/unifi/","text":"Unifi Controller \u00b6 What is it? \u00b6 Unifi Controller software is a powerful, enterprise wireless software engine ideal for high-density client deployments requiring low latency and high uptime performance. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-unifi 2. URL \u00b6 To access Unifi Controller, visit https://unifi._yourdomain.com_ 3. Setup \u00b6 Visit the Unifi Controller site at https://unifi._yourdomain.com_ For Unifi to adopt other devices, e.g. an Access Point, it is required to change the inform IP address. Because Unifi runs inside Docker by default it uses an IP address not accessible by other devices. To change this go to Settings > System Settings > Controller Configuration and set the Controller Hostname/IP to a hostname or IP address accessible by your devices. Additionally the checkbox \"Override inform host with controller hostname/IP\" has to be checked, so that devices can connect to the controller during adoption (devices use the inform-endpoint during adoption). In order to manually adopt a device take these steps: ssh ubnt@ $AP -IP set-inform http:// $address :8080/inform The default device password is ubnt . $address is the IP address of the host you are running this container on and $AP-IP is the Access Point IP address. When using a Security Gateway (router) it could be that network connected devices are unable to obtain an ip address. This can be fixed by setting \"DHCP Gateway IP\", under Settings > Networks > network_name, to a correct (and accessible) ip address. Documentation Note \ud83d\udce2 The default setup only publish the 8080 tcp port, which is the bare minimum to allow communication between your network equipment and Unifi Controller. Depending on your requirements, you may need additional ports according to the Documentation . The recommended way to customize these parameters is to use the inventory : You should edit /srv/git/saltbox/inventories/host_vars/localhost.yml and add the following section: ### Open Specified Ports for the specified container ### ##### Unifi Ports for aditional services ##### unifi_docker_ports_custom: - \"1900:1900/udp\" #Required for Make controller discoverable on L2 network option - \"8843:8843/tcp\" #Unifi guest portal HTTPS redirect port - \"8880:8880/tcp\" #Unifi guest portal HTTP redirect port - \"6789:6789/tcp\" #For mobile throughput test - \"5514:5514/udp\" #Remote syslog port","title":"unifi"},{"location":"sandbox/apps/unifi/#unifi-controller","text":"","title":"Unifi Controller"},{"location":"sandbox/apps/unifi/#what-is-it","text":"Unifi Controller software is a powerful, enterprise wireless software engine ideal for high-density client deployments requiring low latency and high uptime performance. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/unifi/#1-installation","text":"sb install sandbox-unifi","title":"1. Installation"},{"location":"sandbox/apps/unifi/#2-url","text":"To access Unifi Controller, visit https://unifi._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/unifi/#3-setup","text":"Visit the Unifi Controller site at https://unifi._yourdomain.com_ For Unifi to adopt other devices, e.g. an Access Point, it is required to change the inform IP address. Because Unifi runs inside Docker by default it uses an IP address not accessible by other devices. To change this go to Settings > System Settings > Controller Configuration and set the Controller Hostname/IP to a hostname or IP address accessible by your devices. Additionally the checkbox \"Override inform host with controller hostname/IP\" has to be checked, so that devices can connect to the controller during adoption (devices use the inform-endpoint during adoption). In order to manually adopt a device take these steps: ssh ubnt@ $AP -IP set-inform http:// $address :8080/inform The default device password is ubnt . $address is the IP address of the host you are running this container on and $AP-IP is the Access Point IP address. When using a Security Gateway (router) it could be that network connected devices are unable to obtain an ip address. This can be fixed by setting \"DHCP Gateway IP\", under Settings > Networks > network_name, to a correct (and accessible) ip address. Documentation Note \ud83d\udce2 The default setup only publish the 8080 tcp port, which is the bare minimum to allow communication between your network equipment and Unifi Controller. Depending on your requirements, you may need additional ports according to the Documentation . The recommended way to customize these parameters is to use the inventory : You should edit /srv/git/saltbox/inventories/host_vars/localhost.yml and add the following section: ### Open Specified Ports for the specified container ### ##### Unifi Ports for aditional services ##### unifi_docker_ports_custom: - \"1900:1900/udp\" #Required for Make controller discoverable on L2 network option - \"8843:8843/tcp\" #Unifi guest portal HTTPS redirect port - \"8880:8880/tcp\" #Unifi guest portal HTTP redirect port - \"6789:6789/tcp\" #For mobile throughput test - \"5514:5514/udp\" #Remote syslog port","title":"3. Setup"},{"location":"sandbox/apps/unmanic/","text":"Unmanic \u00b6 What is it? \u00b6 Unmanic is a simple tool for optimising your file library. You can use it to convert your files into a single, uniform format, manage file movements based on timestamps, or execute custom commands against a file based on its file size. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-unmanic 2. URL \u00b6 To access Unmanic, visit https://unmanic._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"unmanic"},{"location":"sandbox/apps/unmanic/#unmanic","text":"","title":"Unmanic"},{"location":"sandbox/apps/unmanic/#what-is-it","text":"Unmanic is a simple tool for optimising your file library. You can use it to convert your files into a single, uniform format, manage file movements based on timestamps, or execute custom commands against a file based on its file size. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/unmanic/#1-installation","text":"sb install sandbox-unmanic","title":"1. Installation"},{"location":"sandbox/apps/unmanic/#2-url","text":"To access Unmanic, visit https://unmanic._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/unmanic/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/unpackerr/","text":"Unpackerr \u00b6 What is it? \u00b6 Unpackerr checks for completed downloads and extracts them so Lidarr, Radarr, Readarr, Sonarr may import them. There are a handful of options out there for extracting and deleting files after your client downloads them. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-unpackerr 2. Setup \u00b6 Documentation The important part of the setup is the setup for the applications. You'll need to change these three settings for each: [[sonarr]] url = \"http://sonarr:8989\" api_key = \"YOUR_API_KEY\" # File system path where downloaded Sonarr items are located. paths = ['/mnt/unionfs/downloads/torrents/rutorrent/completed'] The path will depend on the torrent client you are using and its configuration. Same setup is required for radarr, lidarr, and readarr if you are using them.","title":"Unpackerr"},{"location":"sandbox/apps/unpackerr/#unpackerr","text":"","title":"Unpackerr"},{"location":"sandbox/apps/unpackerr/#what-is-it","text":"Unpackerr checks for completed downloads and extracts them so Lidarr, Radarr, Readarr, Sonarr may import them. There are a handful of options out there for extracting and deleting files after your client downloads them. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/unpackerr/#1-installation","text":"sb install sandbox-unpackerr","title":"1. Installation"},{"location":"sandbox/apps/unpackerr/#2-setup","text":"Documentation The important part of the setup is the setup for the applications. You'll need to change these three settings for each: [[sonarr]] url = \"http://sonarr:8989\" api_key = \"YOUR_API_KEY\" # File system path where downloaded Sonarr items are located. paths = ['/mnt/unionfs/downloads/torrents/rutorrent/completed'] The path will depend on the torrent client you are using and its configuration. Same setup is required for radarr, lidarr, and readarr if you are using them.","title":"2. Setup"},{"location":"sandbox/apps/uptime_kuma/","text":"Uptime Kuma \u00b6 What is it? \u00b6 Uptime Kuma is a self-hosted monitoring tool like \"Uptime Robot\". Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-uptime-kuma 2. URL \u00b6 To access Uptime Kuma, visit https://uptime._yourdomain.com_ 3. Setup \u00b6 Documentation","title":"Uptime Kuma"},{"location":"sandbox/apps/uptime_kuma/#uptime-kuma","text":"","title":"Uptime Kuma"},{"location":"sandbox/apps/uptime_kuma/#what-is-it","text":"Uptime Kuma is a self-hosted monitoring tool like \"Uptime Robot\". Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/uptime_kuma/#1-installation","text":"sb install sandbox-uptime-kuma","title":"1. Installation"},{"location":"sandbox/apps/uptime_kuma/#2-url","text":"To access Uptime Kuma, visit https://uptime._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/uptime_kuma/#3-setup","text":"Documentation","title":"3. Setup"},{"location":"sandbox/apps/varken/","text":"Varken \u00b6 What is it? \u00b6 Varken is Dutch for PIG . PIG is an Acronym for P lex/ I nfluxDB/ G rafana Varken is a standalone application to aggregate data from the Plex ecosystem into InfluxDB using Grafana for a frontend Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-varken 2. URL \u00b6 To access the Varken dashboard, visit https://grafana._yourdomain.com_ 3. Setup \u00b6 Run the Saltbox varken role to install varken/influxdb/telegraf/grafana: sb install sandbox-varken Add your Maxmind API key to varken.ini: nano /opt/varken/varken.ini Restart Varken: docker restart varken Visit grafana https://grafana._yourdomain.com_ The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Add data source InfluxDB named InfluxDB: HTTP : URL = http://influxdb:8086 InfluxDB Details : Database = varken Save & Test Add data source InfluxDB named Telegraf: HTTP : URL = http://influxdb:8086 InfluxDB Details : Database = telegraf Save & Test Grafana Example from Organizrr Discord (imported via Dashboards > Manage > Import ) : from: GilbN -- Plex dashboard for Grafana @Grafana-Group for anyone using Varken Thought I'd share the dashboard I made . (with the help of Rox and Tron) You will need to add the piechart and worldmap plugins for the dashboard to work. Use the variables to set the different data sources. To Install PieChart/WorldMap: cd /opt/grafana/plugins && git clone https://github.com/grafana/piechart-panel.git && git clone https://github.com/grafana/worldmap-panel.git && docker restart grafana Grafana Examples from Varken Discord: Varken Official Supported Dashboards: Online Users Table Example (Tautulli): World Map w/ geoIP Device Type Pie Chart: Basic Panel Structure For app specific instructions refer to the grafana role, grafana and the upstream documentation Documentation","title":"Varken"},{"location":"sandbox/apps/varken/#varken","text":"","title":"Varken"},{"location":"sandbox/apps/varken/#what-is-it","text":"Varken is Dutch for PIG . PIG is an Acronym for P lex/ I nfluxDB/ G rafana Varken is a standalone application to aggregate data from the Plex ecosystem into InfluxDB using Grafana for a frontend Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/varken/#1-installation","text":"sb install sandbox-varken","title":"1. Installation"},{"location":"sandbox/apps/varken/#2-url","text":"To access the Varken dashboard, visit https://grafana._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/varken/#3-setup","text":"Run the Saltbox varken role to install varken/influxdb/telegraf/grafana: sb install sandbox-varken Add your Maxmind API key to varken.ini: nano /opt/varken/varken.ini Restart Varken: docker restart varken Visit grafana https://grafana._yourdomain.com_ The configured username/password are taken from your Saltbox accounts.yml file located in /srv/git/saltbox/accounts.yml Add data source InfluxDB named InfluxDB: HTTP : URL = http://influxdb:8086 InfluxDB Details : Database = varken Save & Test Add data source InfluxDB named Telegraf: HTTP : URL = http://influxdb:8086 InfluxDB Details : Database = telegraf Save & Test Grafana Example from Organizrr Discord (imported via Dashboards > Manage > Import ) : from: GilbN -- Plex dashboard for Grafana @Grafana-Group for anyone using Varken Thought I'd share the dashboard I made . (with the help of Rox and Tron) You will need to add the piechart and worldmap plugins for the dashboard to work. Use the variables to set the different data sources. To Install PieChart/WorldMap: cd /opt/grafana/plugins && git clone https://github.com/grafana/piechart-panel.git && git clone https://github.com/grafana/worldmap-panel.git && docker restart grafana Grafana Examples from Varken Discord: Varken Official Supported Dashboards: Online Users Table Example (Tautulli): World Map w/ geoIP Device Type Pie Chart: Basic Panel Structure For app specific instructions refer to the grafana role, grafana and the upstream documentation Documentation","title":"3. Setup"},{"location":"sandbox/apps/vaultwarden/","text":"vaultwarden \u00b6 What is it? \u00b6 vaultwarden is an alternative implementation of the Bitwarden server API written in Rust and compatible with upstream Bitwarden clients*, perfect for self-hosted deployment where running the official resource-heavy service might not be ideal. Note \ud83d\udce2 This project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-vaultwarden 2. URL \u00b6 To access vaultwarden, visit https://vaultwarden._yourdomain.com_ 3. Setup \u00b6 Visit the vaultwarden site at https://vaultwarden._yourdomain.com_ Sign up with any email address and password. To access the Admin Panel go to https://vaultwarden._yourdomain.com_/admin You will need to enter an authentication key which you can find in /opt/vaultwarden/env . Look for ADMIN_TOKEN= . Documentation","title":"vaultwarden"},{"location":"sandbox/apps/vaultwarden/#vaultwarden","text":"","title":"vaultwarden"},{"location":"sandbox/apps/vaultwarden/#what-is-it","text":"vaultwarden is an alternative implementation of the Bitwarden server API written in Rust and compatible with upstream Bitwarden clients*, perfect for self-hosted deployment where running the official resource-heavy service might not be ideal. Note \ud83d\udce2 This project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/vaultwarden/#1-installation","text":"sb install sandbox-vaultwarden","title":"1. Installation"},{"location":"sandbox/apps/vaultwarden/#2-url","text":"To access vaultwarden, visit https://vaultwarden._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/vaultwarden/#3-setup","text":"Visit the vaultwarden site at https://vaultwarden._yourdomain.com_ Sign up with any email address and password. To access the Admin Panel go to https://vaultwarden._yourdomain.com_/admin You will need to enter an authentication key which you can find in /opt/vaultwarden/env . Look for ADMIN_TOKEN= . Documentation","title":"3. Setup"},{"location":"sandbox/apps/vnstat/","text":"vnStat \u00b6 What is it? \u00b6 vnStat dashboard is a user-friendly web dashboard for viewing the following: * Hourly Statistics Chart (using Google Charts) * Daily & Monthly Statistics Overview * Top 10 Day Statistics * Automatically populated interface selection Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-vnstat 2. URL \u00b6 To access vnStat, visit https://vnstat._yourdomain.com_","title":"VNStat"},{"location":"sandbox/apps/vnstat/#vnstat","text":"","title":"vnStat"},{"location":"sandbox/apps/vnstat/#what-is-it","text":"vnStat dashboard is a user-friendly web dashboard for viewing the following: * Hourly Statistics Chart (using Google Charts) * Daily & Monthly Statistics Overview * Top 10 Day Statistics * Automatically populated interface selection Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/vnstat/#1-installation","text":"sb install sandbox-vnstat","title":"1. Installation"},{"location":"sandbox/apps/vnstat/#2-url","text":"To access vnStat, visit https://vnstat._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/watchtower/","text":"Watchtower \u00b6 What is it? \u00b6 Watchtower is a process for automating Docker container base image updates. With watchtower you can update the running version of your containerized app simply by pushing a new image to the Docker Hub or your own image registry. Watchtower will pull down your new image, gracefully shut down your existing container and restart it with the same options that were used when it was deployed initially. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-watchtower 2. Setup \u00b6 Documentation","title":"watchtower"},{"location":"sandbox/apps/watchtower/#watchtower","text":"","title":"Watchtower"},{"location":"sandbox/apps/watchtower/#what-is-it","text":"Watchtower is a process for automating Docker container base image updates. With watchtower you can update the running version of your containerized app simply by pushing a new image to the Docker Hub or your own image registry. Watchtower will pull down your new image, gracefully shut down your existing container and restart it with the same options that were used when it was deployed initially. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/watchtower/#1-installation","text":"sb install sandbox-watchtower","title":"1. Installation"},{"location":"sandbox/apps/watchtower/#2-setup","text":"Documentation","title":"2. Setup"},{"location":"sandbox/apps/whisparr/","text":"whisparr \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 whisparr is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-whisparr 2. URL \u00b6 To access whisparr, visit https://whisparr._yourdomain.com_ 3. Usage \u00b6 Instructions for whisparr","title":"whisparr"},{"location":"sandbox/apps/whisparr/#whisparr","text":"","title":"whisparr"},{"location":"sandbox/apps/whisparr/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/whisparr/#what-is-it","text":"whisparr is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/whisparr/#1-installation","text":"sb install sandbox-whisparr","title":"1. Installation"},{"location":"sandbox/apps/whisparr/#2-url","text":"To access whisparr, visit https://whisparr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/whisparr/#3-usage","text":"Instructions for whisparr","title":"3. Usage"},{"location":"sandbox/apps/wireguard/","text":"Wireguard \u00b6 What is it? \u00b6 Wireguard is an extremely simple yet fast and modern VPN that utilizes state-of-the-art cryptography. The Wireguard server is deployed using the WG-Easy image with a simple Web UI for management. Details Wireguard Docs Github Docker: 1. Installation \u00b6 sb install sandbox-wireguard 2. URL \u00b6 To access Wireguard, visit https://wireguard._yourdomain.com_ The password provisioned is your Saltbox password. 3. Setup \u00b6 Use the Web UI to configure your clients.","title":"wireguard"},{"location":"sandbox/apps/wireguard/#wireguard","text":"","title":"Wireguard"},{"location":"sandbox/apps/wireguard/#what-is-it","text":"Wireguard is an extremely simple yet fast and modern VPN that utilizes state-of-the-art cryptography. The Wireguard server is deployed using the WG-Easy image with a simple Web UI for management. Details Wireguard Docs Github Docker:","title":"What is it?"},{"location":"sandbox/apps/wireguard/#1-installation","text":"sb install sandbox-wireguard","title":"1. Installation"},{"location":"sandbox/apps/wireguard/#2-url","text":"To access Wireguard, visit https://wireguard._yourdomain.com_ The password provisioned is your Saltbox password.","title":"2. URL"},{"location":"sandbox/apps/wireguard/#3-setup","text":"Use the Web UI to configure your clients.","title":"3. Setup"},{"location":"sandbox/apps/wizarr/","text":"Wizarr \u00b6 What is it? \u00b6 Wizarr ){: target=_blank rel=\"noopener noreferrer\" } is an invitation system for Plex. With Wizarr you can invite people to your plex server with a single invite URL. Create an invitation on the dashboard (Authelia protected), share it, and the invitee can use the link. Steps to connect or create a plex account are displayed when the invitee uses the URL. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-wizarr 2. Setup \u00b6 After installation, go to wizarr.yourdomain.tld, enter a name for your server, enter the plex server, plex token and choose the default librarys. As optional you can setup a request platform. Save, and you're ready to make your first invite URL! Documentation","title":"Wizarr"},{"location":"sandbox/apps/wizarr/#wizarr","text":"","title":"Wizarr"},{"location":"sandbox/apps/wizarr/#what-is-it","text":"Wizarr ){: target=_blank rel=\"noopener noreferrer\" } is an invitation system for Plex. With Wizarr you can invite people to your plex server with a single invite URL. Create an invitation on the dashboard (Authelia protected), share it, and the invitee can use the link. Steps to connect or create a plex account are displayed when the invitee uses the URL. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/wizarr/#1-installation","text":"sb install sandbox-wizarr","title":"1. Installation"},{"location":"sandbox/apps/wizarr/#2-setup","text":"After installation, go to wizarr.yourdomain.tld, enter a name for your server, enter the plex server, plex token and choose the default librarys. As optional you can setup a request platform. Save, and you're ready to make your first invite URL! Documentation","title":"2. Setup"},{"location":"sandbox/apps/wordpress/","text":"WordPress \u00b6 What is it? \u00b6 WordPress is open source software you can use to create a beautiful website, blog, or app. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-wordpress 2. URL \u00b6 To access WordPress , visit https://wordpress._yourdomain.com_ 3. Setup \u00b6 Visit the wordpress site at https://wordpress._yourdomain.com_ and the setup screen will appear. No default user is configured until you run through the setup screen, so you should ideally run through setup as soon as wordpress is deployed to secure the site. Documentation","title":"Wordpress"},{"location":"sandbox/apps/wordpress/#wordpress","text":"","title":"WordPress"},{"location":"sandbox/apps/wordpress/#what-is-it","text":"WordPress is open source software you can use to create a beautiful website, blog, or app. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/wordpress/#1-installation","text":"sb install sandbox-wordpress","title":"1. Installation"},{"location":"sandbox/apps/wordpress/#2-url","text":"To access WordPress , visit https://wordpress._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/wordpress/#3-setup","text":"Visit the wordpress site at https://wordpress._yourdomain.com_ and the setup screen will appear. No default user is configured until you run through the setup screen, so you should ideally run through setup as soon as wordpress is deployed to secure the site. Documentation","title":"3. Setup"},{"location":"sandbox/apps/wrapperr/","text":"Wrapperr \u00b6 What is it? \u00b6 Wrapperr is a website-based platform and API for collecting user stats within a set timeframe using Tautulli. The data is displayed as a statistics-summary, sort of like Spotify Wrapped. Yes, you need Tautulli to have been running beforehand and currently for this to work. Details - Wrapperr Docs Github Docker: 1. Installation \u00b6 sb install sandbox-wrapperr 2. URL \u00b6 To access Wrapperr, visit https://wrapperr._yourdomain.com_ 3. Setup \u00b6 The very first thing you should do after installing Wrapperr is visit https://wrapperr._yourdomain.com_ and configure an admin username/password. Do this NOW. Documentation: Wrapperr Docs","title":"Wrapperr"},{"location":"sandbox/apps/wrapperr/#wrapperr","text":"","title":"Wrapperr"},{"location":"sandbox/apps/wrapperr/#what-is-it","text":"Wrapperr is a website-based platform and API for collecting user stats within a set timeframe using Tautulli. The data is displayed as a statistics-summary, sort of like Spotify Wrapped. Yes, you need Tautulli to have been running beforehand and currently for this to work. Details - Wrapperr Docs Github Docker:","title":"What is it?"},{"location":"sandbox/apps/wrapperr/#1-installation","text":"sb install sandbox-wrapperr","title":"1. Installation"},{"location":"sandbox/apps/wrapperr/#2-url","text":"To access Wrapperr, visit https://wrapperr._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/wrapperr/#3-setup","text":"The very first thing you should do after installing Wrapperr is visit https://wrapperr._yourdomain.com_ and configure an admin username/password. Do this NOW. Documentation: Wrapperr Docs","title":"3. Setup"},{"location":"sandbox/apps/xbackbone/","text":"xbackbone \u00b6 THIS DOCUMENTATION IS NOT YET COMPLETED \u00b6 What is it? \u00b6 xbackbone is a... Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-xbackbone 2. URL \u00b6 To access xbackbone, visit https://xbackbone._yourdomain.com_ 3. Usage \u00b6 Instructions for xbackbone","title":"xbackbone"},{"location":"sandbox/apps/xbackbone/#xbackbone","text":"","title":"xbackbone"},{"location":"sandbox/apps/xbackbone/#this-documentation-is-not-yet-completed","text":"","title":"THIS DOCUMENTATION IS NOT YET COMPLETED"},{"location":"sandbox/apps/xbackbone/#what-is-it","text":"xbackbone is a... Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/xbackbone/#1-installation","text":"sb install sandbox-xbackbone","title":"1. Installation"},{"location":"sandbox/apps/xbackbone/#2-url","text":"To access xbackbone, visit https://xbackbone._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/xbackbone/#3-usage","text":"Instructions for xbackbone","title":"3. Usage"},{"location":"sandbox/apps/xteve/","text":"xTeVe \u00b6 What is it? \u00b6 xTeVe is a M3U proxy server for Plex, Emby and any client and provider which supports the .TS and .M3U8 (HLS) streaming formats. xTeVe emulates a SiliconDust HDHomeRun OTA tuner, which allows it to expose IPTV style channels to software, which would not normally support it. This Docker image includes the following packages and features: xTeVe v2.1 (Linux) x86 64 bit Latest Guide2go (Linux) x86 64 bit (Schedules Direct XMLTV grabber) Zap2XML Support (Perl based zap2it / TVguide.com XMLTV grabber) Bash, Perl & crond Support VLC & ffmpeg Support Automated XMLTV Guide Lineups & Cron\u2019s Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-xteve 2. URL \u00b6 To access xTeVe, visit https://ROLENAME._yourdomain.com_/web 3. Setup \u00b6 Access xTeVe web GUI, visit https://ROLENAME._yourdomain.com_/web Run through the Configuration Wizard. Documentation","title":"xteve"},{"location":"sandbox/apps/xteve/#xteve","text":"","title":"xTeVe"},{"location":"sandbox/apps/xteve/#what-is-it","text":"xTeVe is a M3U proxy server for Plex, Emby and any client and provider which supports the .TS and .M3U8 (HLS) streaming formats. xTeVe emulates a SiliconDust HDHomeRun OTA tuner, which allows it to expose IPTV style channels to software, which would not normally support it. This Docker image includes the following packages and features: xTeVe v2.1 (Linux) x86 64 bit Latest Guide2go (Linux) x86 64 bit (Schedules Direct XMLTV grabber) Zap2XML Support (Perl based zap2it / TVguide.com XMLTV grabber) Bash, Perl & crond Support VLC & ffmpeg Support Automated XMLTV Guide Lineups & Cron\u2019s Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/xteve/#1-installation","text":"sb install sandbox-xteve","title":"1. Installation"},{"location":"sandbox/apps/xteve/#2-url","text":"To access xTeVe, visit https://ROLENAME._yourdomain.com_/web","title":"2. URL"},{"location":"sandbox/apps/xteve/#3-setup","text":"Access xTeVe web GUI, visit https://ROLENAME._yourdomain.com_/web Run through the Configuration Wizard. Documentation","title":"3. Setup"},{"location":"sandbox/apps/yacht/","text":"Yacht \u00b6 What is it? \u00b6 Yacht is a web interface for managing docker containers with an emphasis on templating to provide one-click deployments of dockerized applications. Think of it like a decentralized app store for servers that anyone can make packages for. Details Project home Docs Github Docker 1. Installation \u00b6 sb install sandbox-yacht 2. URL \u00b6 To access Yacht, visit https://yacht._yourdomain.com_ 3. Setup \u00b6 The default login is the email accounts.yml and the password is pass Check out the getting started guide if this is the first time you've used Yacht. Documentation","title":"Yacht"},{"location":"sandbox/apps/yacht/#yacht","text":"","title":"Yacht"},{"location":"sandbox/apps/yacht/#what-is-it","text":"Yacht is a web interface for managing docker containers with an emphasis on templating to provide one-click deployments of dockerized applications. Think of it like a decentralized app store for servers that anyone can make packages for. Details Project home Docs Github Docker","title":"What is it?"},{"location":"sandbox/apps/yacht/#1-installation","text":"sb install sandbox-yacht","title":"1. Installation"},{"location":"sandbox/apps/yacht/#2-url","text":"To access Yacht, visit https://yacht._yourdomain.com_","title":"2. URL"},{"location":"sandbox/apps/yacht/#3-setup","text":"The default login is the email accounts.yml and the password is pass Check out the getting started guide if this is the first time you've used Yacht. Documentation","title":"3. Setup"},{"location":"sandbox/apps/znc/","text":"ZNC \u00b6 What is it? \u00b6 ZNC is an an advanced IRC bouncer that is left connected so an IRC client can disconnect/reconnect without losing the chat session. It can detach the client from the actual IRC server, and also from selected channels. Multiple clients from different locations can connect to a single ZNC account simultaneously and therefore appear under the same nickname on IRC. Details ZNC Docs Github Docker: 1. Installation \u00b6 sb install sandbox-znc 2. URL \u00b6 To access ZNC, visit https://znc._yourdomain.com_ Default user/password: admin/admin Change that password ASAP. 3. Setup \u00b6 Documentation: ZNC Docs","title":"ZNC"},{"location":"sandbox/apps/znc/#znc","text":"","title":"ZNC"},{"location":"sandbox/apps/znc/#what-is-it","text":"ZNC is an an advanced IRC bouncer that is left connected so an IRC client can disconnect/reconnect without losing the chat session. It can detach the client from the actual IRC server, and also from selected channels. Multiple clients from different locations can connect to a single ZNC account simultaneously and therefore appear under the same nickname on IRC. Details ZNC Docs Github Docker:","title":"What is it?"},{"location":"sandbox/apps/znc/#1-installation","text":"sb install sandbox-znc","title":"1. Installation"},{"location":"sandbox/apps/znc/#2-url","text":"To access ZNC, visit https://znc._yourdomain.com_ Default user/password: admin/admin Change that password ASAP.","title":"2. URL"},{"location":"sandbox/apps/znc/#3-setup","text":"Documentation: ZNC Docs","title":"3. Setup"}]}